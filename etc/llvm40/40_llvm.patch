diff --git a/CMakeLists.txt b/CMakeLists.txt
index 52a0927..ea04c47 100644
--- a/CMakeLists.txt
+++ b/CMakeLists.txt
@@ -280,7 +280,8 @@ set(LLVM_ALL_TARGETS
   )
 
 # List of targets with JIT support:
-set(LLVM_TARGETS_WITH_JIT X86 PowerPC AArch64 ARM Mips SystemZ)
+# disable unnecessary jit stuff
+#set(LLVM_TARGETS_WITH_JIT X86 PowerPC AArch64 ARM Mips SystemZ)
 
 set(LLVM_TARGETS_TO_BUILD "all"
     CACHE STRING "Semicolon-separated list of targets to build, or \"all\".")
diff --git a/configure b/configure
deleted file mode 100755
index bab3a0d..0000000
--- a/configure
+++ /dev/null
@@ -1,10 +0,0 @@
-#! /bin/sh
-echo "################################################################################"
-echo "################################################################################"
-echo "The LLVM project no longer supports building with configure & make."
-echo ""
-echo "Please migrate to the CMake-based build system."
-echo "For more information see: http://llvm.org/docs/CMake.html"
-echo "################################################################################"
-echo "################################################################################"
-exit 1
diff --git a/docs/SPIRVRepresentationInLLVM.rst b/docs/SPIRVRepresentationInLLVM.rst
new file mode 100644
index 0000000..c0b8761
--- /dev/null
+++ b/docs/SPIRVRepresentationInLLVM.rst
@@ -0,0 +1,241 @@
+================================
+SPIR-V representation in LLVM IR
+================================
+.. contents::
+   :local:
+
+Overview
+========
+
+As one of the goals of SPIR-V is to `"map easily to other IRs, including LLVM
+IR" <https://cvs.khronos.org/svn/repos/SPIRV/trunk/specs/SPIRV.html#_goals>`_,
+most of SPIR-V entities (global variables, constants, types, functions, basic
+blocks, instructions) have straightforward counterparts in LLVM. Therefore the
+focus of this document is those entities in SPIR-V which do not map to LLVM in
+an obvious way. These include:
+
+ * SPIR-V types mapped to LLVM types
+ * SPIR-V instructions mapped to LLVM function calls
+ * SPIR-V extended instructions mapped to LLVM function calls
+ * SPIR-V builtins variables mapped to LLVM global variables
+ * SPIR-V instructions mapped to LLVM metadata
+ * SPIR-V types mapped to LLVM opaque types
+ * SPIR-V decorations mapped to LLVM metadata or named attributes
+
+SPIR-V Types Mapped to LLVM Types
+=================================
+Limited to this section, we define the following common postfix.
+
+* {Access} - Postifix indicating the access qualifier.
+{Access} take integer literal values which are defined by the SPIR-V spec.
+
+OpTypeImage
+-----------
+OpTypeImage is mapped to LLVM opaque type
+spirv.Image._{SampledType}_{Dim}_{Depth}_{Arrayed}_{MS}_{Sampled}_{Format}_{Access}
+and mangled as __spirv_Image__{SampledType}_{Dim}_{Depth}_{Arrayed}_{MS}_{Sampled}_{Format}_{Access},
+
+where
+
+* {SampledType}={float|half|int|uint|void} - Postfix indicating the sampled data type
+  - void for unknown sampled data type
+* {Dim} - Postfix indicating the dimension of the image
+* {Depth} - Postfix indicating whether the image is a depth image
+* {Arrayed} - Postfix indicating whether the image is arrayed image
+* {MS} - Postfix indicating whether the image is multi-sampled
+* {Sampled} - Postfix indicating whether the image is associated with sampler
+* {Format} - Postfix indicating the image format
+
+Postfixes {Dim}, {Depth}, {Arrayed}, {MS}, {Sampled} and {Format} take integer
+literal values which are defined by the SPIR-V spec.
+
+OpTypeSampledImage
+------------------
+OpTypeSampledImage is mapped to LLVM opaque type
+spirv.SampledImage._{Postfixes} and mangled as __spirv_SampledImage__{Postfixes},
+where {Postfixes} are the same as the postfixes of the original image type, as
+defined above in this section.
+
+OpTypePipe
+----------
+OpTypePipe is mapped to LLVM opaque type
+spirv.Pipe._{Access} and mangled as __spirv_Pipe__{Access}.
+
+Other SPIR-V Types
+------------------
+* OpTypeEvent
+* OpTypeDeviceEvent
+* OpTypeReserveId
+* OpTypeQueue
+* OpTypeSampler
+* OpTypePipeStorage (SPIR-V 1.1)
+The above SPIR-V types are mapped to LLVM opaque type spirv.{TypeName} and
+mangled as __spirv_{TypeName}, where {TypeName} is the name of the SPIR-V
+type with "OpType" removed, e.g., OpTypeEvent is mapped to spirv.Event and
+mangled as __spirv_Event.
+
+SPIR-V Instructions Mapped to LLVM Function Calls
+=================================================
+
+Some SPIR-V instructions which can be included in basic blocks do not have
+corresponding LLVM instructions or intrinsics. These SPIR-V instructions are
+represented by function calls in LLVM. The function corresponding to a SPIR-V
+instruction is termed SPIR-V builtin function and its name is `IA64 mangled
+<https://mentorembedded.github.io/cxx-abi/abi.html#mangling>`_ with extensions
+for SPIR-V specific types. The unmangled name of a SPIR-V builtin function
+follows the convention
+
+.. code-block:: c
+
+  __spirv_{OpCodeName}{_OptionalPostfixes}
+
+where {OpCodeName} is the op code name of the SPIR-V instructions without the
+"Op" prefix, e.g. EnqueueKernel. {OptionalPostfixes} are optional postfixes to
+specify decorations for the SPIR-V instruction. The SPIR-V op code name and
+each postfix does not contain "_".
+
+SPIR-V builtin functions accepts all argument types accepted by the
+corresponding SPIR-V instructions. The literal operands of extended
+instruction are mapped to function call arguments with type i32.
+
+Optional Postfixes for SPIR-V Builtin Function Names
+----------------------------------------------------
+
+SPIR-V builtin functions corresponding to the following SPIR-V instructions are
+postfixed following the order specified as below:
+
+ * Instructions having identical argument types but different return types are postfixed with "_R{ReturnType}" where
+    - {ReturnType} = {ScalarType}|{VectorType}
+    - {ScalarType} = char|uchar|short|ushort|int|uint|long|ulong|half|float|double|bool
+    - {VectorType} = {ScalarType}{2|3|4|8|16}
+ * Instructions with saturation decoration are postfixed with "_sat"
+ * Instructions with floating point rounding mode decoration are postfixed with "_rtp|_rtn|_rtz|_rte"
+
+SPIR-V Builtin Conversion Function Names
+----------------------------------------
+
+The unmangled names of SPIR-V builtin conversion functions follow the convention:
+
+.. code-block:: c
+
+  __spirv_{ConversionOpCodeName}_R{ReturnType}{_sat}{_rtp|_rtn|_rtz|_rte}
+
+where
+
+ * {ConversionOpCodeName} = ConvertFToU|ConvertFToS|ConvertUToF|ConvertUToS|UConvert|SConvert|FConvert|SatConvertSToU|SatConvertUToS
+
+SPIR-V Builtin Reinterpret / Bitcast Function Names
+---------------------------------------------------
+
+The unmangled names of SPIR-V builtin reinterpret / bitcast functions follow the convention:
+
+.. code-block:: c
+
+  __spirv_{BitcastOpCodeName}_R{ReturnType}
+
+SPIR-V Builtin ImageSample Function Names
+----------------------------------------
+
+The unmangled names of SPIR-V builtin ImageSample functions follow the convention:
+
+.. code-block:: c
+
+  __spirv_{ImageSampleOpCodeName}_R{ReturnType}
+
+SPIR-V Builtin GenericCastToPtr Function Name
+----------------------------------------
+
+The unmangled names of SPIR-V builtin GenericCastToPtrExplicit function follow the convention:
+
+.. code-block:: c
+
+  __spirv_GenericCastToPtrExplicit_To{Global|Local|Private}
+  
+SPIR-V 1.1 Builtin CreatePipeFromPipeStorage Function Name 
+----------------------------------------
+
+The unmangled names of SPIR-V builtin CreatePipeFromPipeStorage function follow the convention:
+
+.. code-block:: c
+
+  __spirv_CreatePipeFromPipeStorage_{read|write}
+
+SPIR-V Extended Instructions Mapped to LLVM Function Calls
+==========================================================
+
+SPIR-V extended instructions are mapped to LLVM function calls. The function
+name is IA64 mangled and the unmangled name has the format
+
+.. code-block:: c
+
+  __spirv_{ExtendedInstructionSetName}_{ExtendedInstrutionName}{__OptionalPostfixes}
+
+where {ExtendedInstructionSetName} for OpenCL is "ocl".
+
+The translated functions accepts all argument types accepted by the
+corresponding SPIR-V instructions. The literal operands of extended
+instruction are mapped to function call arguments with type i32.
+
+The optional postfixes take the same format as SPIR-V builtin functions. The first postfix
+starts with two underscores to facilitate identification since extended instruction name
+may contain underscore. The remaining postfixes start with one underscore.
+
+OpenCL Extended Builtin Vector Load Function Names
+----------------------------------------
+
+The unmangled names of OpenCL extended vector load functions follow the convention:
+
+.. code-block:: c
+
+  __spirv_ocl_{VectorLoadOpCodeName}__R{ReturnType}
+
+where
+
+ * {VectorLoadOpCodeName} = vloadn|vload_half|vload_halfn|vloada_halfn
+
+
+SPIR-V Builtins Variables Mapped to LLVM Global Variables
+=========================================================
+
+SPIR-V builtin variables are mapped to LLVM global variables with unmangled
+name __spirv_BuiltIn{Name}.
+
+SPIR-V instructions mapped to LLVM metadata
+===========================================
+
+SPIR-V specification allows multiple module scope instructions, whereas LLVM
+named metadata must be unique, so encoding of such instructions has the
+following format:
+
+.. code-block:: llvm
+
+  !spirv.<OpCodeName> = !{!<InstructionMetadata1>, <InstructionMetadata2>, ..}
+  !<InstructionMetadata1> = !{<Operand1>, <Operand2>, ..}
+  !<InstructionMetadata2> = !{<Operand1>, <Operand2>, ..}
+
+For example:
+
+.. code-block:: llvm
+
+  !spirv.Source = !{!0}
+  !spirv.SourceExtension = !{!2, !3}
+  !spirv.Extension = !{!2}
+  !spirv.Capability = !{!4}
+  !spirv.MemoryModel = !{!5}
+  !spirv.EntryPoint = !{!6 ,!7}
+  !spirv.ExecutionMode = !{!8, !9}
+  !spirv.Generator = !{!10 }
+
+  ; 3 - OpenCL_C, 102000 - OpenCL version 1.2, !1 - optional file id.
+  !0 = !{i32 3, i32 102000, !1}
+  !1 = !{!"/tmp/opencl/program.cl"}
+  !2 = !{!"cl_khr_fp16"}
+  !3 = !{!"cl_khr_gl_sharing"}
+  !4 = !{i32 10}                ; Float64 - program uses doubles
+  !5 = !{i32 1, i32 2}     ; 1 - 32-bit addressing model, 2 - OpenCL memory model
+  !6 = !{i32 6, TBD, !"kernel1", TBD}
+  !7 = !{i32 6, TBD, !"kernel2", TBD}
+  !8 = !{!6, i32 18, i32 16, i32 1, i32 1}     ; local size hint <16, 1, 1> for 'kernel1'
+  !9 = !{!7, i32 32}     ; independent forward progress is required for 'kernel2'
+  !10 = !{i16 6, i16 123} ; 6 - Generator Id, 123 - Generator Version 
+
diff --git a/include/llvm-c/BitWriter32.h b/include/llvm-c/BitWriter32.h
new file mode 100644
index 0000000..9095668
--- /dev/null
+++ b/include/llvm-c/BitWriter32.h
@@ -0,0 +1,59 @@
+/*===-- llvm-c/BitWriter32.h - BitWriter Library C Interface ----*- C++ -*-===*\
+|*                                                                            *|
+|*                     The LLVM Compiler Infrastructure                       *|
+|*                                                                            *|
+|* This file is distributed under the University of Illinois Open Source      *|
+|* License. See LICENSE.TXT for details.                                      *|
+|*                                                                            *|
+|*===----------------------------------------------------------------------===*|
+|*                                                                            *|
+|* This header declares the C interface to libLLVMBitWriter32.a, which        *|
+|* implements output of the LLVM 3.2 bitcode format.                          *|
+|*                                                                            *|
+|* Many exotic languages can interoperate with C code but have a harder time  *|
+|* with C++ due to name mangling. So in addition to C, this interface enables *|
+|* tools written in such languages.                                           *|
+|*                                                                            *|
+\*===----------------------------------------------------------------------===*/
+
+#ifndef LLVM_C_BITWRITER_32_H
+#define LLVM_C_BITWRITER_32_H
+
+#include "llvm-c/Types.h"
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/**
+ * @defgroup LLVMCBitWriter Bit Writer
+ * @ingroup LLVMC
+ *
+ * @{
+ */
+
+/*===-- Operations on modules ---------------------------------------------===*/
+
+/** Writes a module to the specified path. Returns 0 on success. */
+int LLVMWriteBitcode32ToFile(LLVMModuleRef M, const char *Path);
+
+/** Writes a module to an open file descriptor. Returns 0 on success. */
+int LLVMWriteBitcode32ToFD(LLVMModuleRef M, int FD, int ShouldClose,
+                           int Unbuffered);
+
+/** Deprecated for LLVMWriteBitcodeToFD. Writes a module to an open file
+    descriptor. Returns 0 on success. Closes the Handle. */
+int LLVMWriteBitcode32ToFileHandle(LLVMModuleRef M, int Handle);
+
+/** Writes a module to a new memory buffer and returns it. */
+LLVMMemoryBufferRef LLVMWriteBitcode32ToMemoryBuffer(LLVMModuleRef M);
+
+/**
+ * @}
+ */
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif
diff --git a/include/llvm-c/BitWriter35.h b/include/llvm-c/BitWriter35.h
new file mode 100644
index 0000000..c92b357
--- /dev/null
+++ b/include/llvm-c/BitWriter35.h
@@ -0,0 +1,59 @@
+/*===-- llvm-c/BitWriter35.h - BitWriter Library C Interface ----*- C++ -*-===*\
+|*                                                                            *|
+|*                     The LLVM Compiler Infrastructure                       *|
+|*                                                                            *|
+|* This file is distributed under the University of Illinois Open Source      *|
+|* License. See LICENSE.TXT for details.                                      *|
+|*                                                                            *|
+|*===----------------------------------------------------------------------===*|
+|*                                                                            *|
+|* This header declares the C interface to libLLVMBitWriter35.a, which        *|
+|* implements output of the LLVM 3.5 bitcode format.                          *|
+|*                                                                            *|
+|* Many exotic languages can interoperate with C code but have a harder time  *|
+|* with C++ due to name mangling. So in addition to C, this interface enables *|
+|* tools written in such languages.                                           *|
+|*                                                                            *|
+\*===----------------------------------------------------------------------===*/
+
+#ifndef LLVM_C_BITWRITER_35_H
+#define LLVM_C_BITWRITER_35_H
+
+#include "llvm-c/Types.h"
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/**
+ * @defgroup LLVMCBitWriter Bit Writer
+ * @ingroup LLVMC
+ *
+ * @{
+ */
+
+/*===-- Operations on modules ---------------------------------------------===*/
+
+/** Writes a module to the specified path. Returns 0 on success. */
+int LLVMWriteBitcode35ToFile(LLVMModuleRef M, const char *Path);
+
+/** Writes a module to an open file descriptor. Returns 0 on success. */
+int LLVMWriteBitcode35ToFD(LLVMModuleRef M, int FD, int ShouldClose,
+                           int Unbuffered);
+
+/** Deprecated for LLVMWriteBitcodeToFD. Writes a module to an open file
+    descriptor. Returns 0 on success. Closes the Handle. */
+int LLVMWriteBitcode35ToFileHandle(LLVMModuleRef M, int Handle);
+
+/** Writes a module to a new memory buffer and returns it. */
+LLVMMemoryBufferRef LLVMWriteBitcode35ToMemoryBuffer(LLVMModuleRef M);
+
+/**
+ * @}
+ */
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif
diff --git a/include/llvm/ADT/Triple.h b/include/llvm/ADT/Triple.h
index b98f840..d7bc2ec 100644
--- a/include/llvm/ADT/Triple.h
+++ b/include/llvm/ADT/Triple.h
@@ -84,6 +84,7 @@ public:
     hsail64,        // AMD HSAIL with 64-bit pointers
     spir,           // SPIR: standard portable IR for OpenCL 32-bit version
     spir64,         // SPIR: standard portable IR for OpenCL 64-bit version
+    air64,          // AIR: Apple IR, used for Metal, always 64-bit
     kalimba,        // Kalimba: generic kalimba
     shave,          // SHAVE: Movidius vector VLIW processors
     lanai,          // Lanai: Lanai 32-bit
@@ -190,6 +191,7 @@ public:
     Itanium,
     Cygnus,
     AMDOpenCL,
+    Vulkan,
     CoreCLR,
     LastEnvironmentType = CoreCLR
   };
diff --git a/include/llvm/Analysis/CodeMetrics.h b/include/llvm/Analysis/CodeMetrics.h
index 9e861ac..636fb32 100644
--- a/include/llvm/Analysis/CodeMetrics.h
+++ b/include/llvm/Analysis/CodeMetrics.h
@@ -87,7 +87,8 @@ struct CodeMetrics {
 
   /// \brief Add information about a block to the current state.
   void analyzeBasicBlock(const BasicBlock *BB, const TargetTransformInfo &TTI,
-                         const SmallPtrSetImpl<const Value*> &EphValues);
+                         const SmallPtrSetImpl<const Value*> &EphValues,
+                         const bool allow_duplicate = false);
 
   /// \brief Collect a loop's ephemeral values (those used only by an assume
   /// or similar intrinsics in the loop).
diff --git a/include/llvm/Bitcode/BitcodeWriterPass.h b/include/llvm/Bitcode/BitcodeWriterPass.h
index 9ac6fba..a546c1c 100644
--- a/include/llvm/Bitcode/BitcodeWriterPass.h
+++ b/include/llvm/Bitcode/BitcodeWriterPass.h
@@ -40,6 +40,10 @@ ModulePass *createBitcodeWriterPass(raw_ostream &Str,
                                     bool EmitSummaryIndex = false,
                                     bool EmitModuleHash = false);
 
+ModulePass *createBitcode32WriterPass(raw_ostream &Str);
+
+ModulePass *createBitcode35WriterPass(raw_ostream &Str);
+
 /// \brief Pass for writing a module of IR out to a bitcode file.
 ///
 /// Note that this is intended for use with the new pass manager. To construct
@@ -70,6 +74,34 @@ public:
   PreservedAnalyses run(Module &M, ModuleAnalysisManager &);
 };
 
+class Bitcode32WriterPass {
+  raw_ostream &OS;
+
+public:
+  /// \brief Construct a bitcode writer pass around a particular output stream.
+  explicit Bitcode32WriterPass(raw_ostream &OS) : OS(OS) {}
+
+  /// \brief Run the bitcode writer pass, and output the module to the selected
+  /// output stream.
+  PreservedAnalyses run(Module &M);
+
+  static StringRef name() { return "Bitcode32WriterPass"; }
+};
+
+class Bitcode35WriterPass {
+  raw_ostream &OS;
+
+public:
+  /// \brief Construct a bitcode writer pass around a particular output stream.
+  explicit Bitcode35WriterPass(raw_ostream &OS) : OS(OS) {}
+
+  /// \brief Run the bitcode writer pass, and output the module to the selected
+  /// output stream.
+  PreservedAnalyses run(Module &M);
+
+  static StringRef name() { return "Bitcode35WriterPass"; }
+};
+
 }
 
 #endif
diff --git a/include/llvm/Bitcode/LLVMBitCodes.h b/include/llvm/Bitcode/LLVMBitCodes.h
index 52d4f01..37652a5 100644
--- a/include/llvm/Bitcode/LLVMBitCodes.h
+++ b/include/llvm/Bitcode/LLVMBitCodes.h
@@ -20,6 +20,23 @@
 
 #include "llvm/Bitcode/BitCodes.h"
 
+// error when using > 3.2 or > 3.5 enums with 3.2 or 3.5 resp.
+#if defined(__clang__) && (defined(LLVM_BITCODE_32) || defined(LLVM_BITCODE_35))
+#if defined(LLVM_BITCODE_32)
+#define BC35 __attribute__((unavailable))
+#else
+#define BC35
+#endif
+#define BC38 __attribute__((unavailable))
+#define BC40 __attribute__((unavailable))
+#define DONT_USE __attribute__((unavailable))
+#else
+#define BC35
+#define BC38
+#define BC40
+#define DONT_USE
+#endif
+
 namespace llvm {
 namespace bitc {
 // The only top-level block type defined is for a module.
@@ -29,7 +46,7 @@ enum BlockIDs {
 
   // Module sub-block id's.
   PARAMATTR_BLOCK_ID,
-  PARAMATTR_GROUP_BLOCK_ID,
+  PARAMATTR_GROUP_BLOCK_ID BC35,
 
   CONSTANTS_BLOCK_ID,
   FUNCTION_BLOCK_ID,
@@ -37,7 +54,7 @@ enum BlockIDs {
   // Block intended to contains information on the bitcode versioning.
   // Can be used to provide better error messages when we fail to parse a
   // bitcode file.
-  IDENTIFICATION_BLOCK_ID,
+  IDENTIFICATION_BLOCK_ID BC38,
 
   VALUE_SYMTAB_BLOCK_ID,
   METADATA_BLOCK_ID,
@@ -47,19 +64,19 @@ enum BlockIDs {
 
   USELIST_BLOCK_ID,
 
-  MODULE_STRTAB_BLOCK_ID,
-  GLOBALVAL_SUMMARY_BLOCK_ID,
+  MODULE_STRTAB_BLOCK_ID BC38,
+  GLOBALVAL_SUMMARY_BLOCK_ID BC38,
 
-  OPERAND_BUNDLE_TAGS_BLOCK_ID,
+  OPERAND_BUNDLE_TAGS_BLOCK_ID BC38,
 
-  METADATA_KIND_BLOCK_ID
+  METADATA_KIND_BLOCK_ID BC38
 };
 
 /// Identification block contains a string that describes the producer details,
 /// and an epoch that defines the auto-upgrade capability.
 enum IdentificationCodes {
-  IDENTIFICATION_CODE_STRING = 1, // IDENTIFICATION:      [strchr x N]
-  IDENTIFICATION_CODE_EPOCH = 2,  // EPOCH:               [epoch#]
+  IDENTIFICATION_CODE_STRING BC38 = 1, // IDENTIFICATION:      [strchr x N]
+  IDENTIFICATION_CODE_EPOCH BC38 = 2,  // EPOCH:               [epoch#]
 };
 
 /// The epoch that defines the auto-upgrade compatibility for the bitcode.
@@ -68,7 +85,7 @@ enum IdentificationCodes {
 /// generated by previous minor releases. We translate this by making the reader
 /// accepting only bitcode with the same epoch, except for the X.0 release which
 /// also accepts N-1.
-enum { BITCODE_CURRENT_EPOCH = 0 };
+enum { BITCODE_CURRENT_EPOCH BC38 = 0 };
 
 /// MODULE blocks have a number of optional fields and subblocks.
 enum ModuleCodes {
@@ -96,23 +113,23 @@ enum ModuleCodes {
   MODULE_CODE_PURGEVALS = 10,
 
   MODULE_CODE_GCNAME = 11, // GCNAME: [strchr x N]
-  MODULE_CODE_COMDAT = 12, // COMDAT: [selection_kind, name]
+  MODULE_CODE_COMDAT BC35 = 12, // COMDAT: [selection_kind, name]
 
-  MODULE_CODE_VSTOFFSET = 13, // VSTOFFSET: [offset]
+  MODULE_CODE_VSTOFFSET BC38 = 13, // VSTOFFSET: [offset]
 
   // ALIAS: [alias value type, addrspace, aliasee val#, linkage, visibility]
-  MODULE_CODE_ALIAS = 14,
+  MODULE_CODE_ALIAS BC38 = 14,
 
-  MODULE_CODE_METADATA_VALUES_UNUSED = 15,
+  MODULE_CODE_METADATA_VALUES_UNUSED BC38 = 15,
 
   // SOURCE_FILENAME: [namechar x N]
-  MODULE_CODE_SOURCE_FILENAME = 16,
+  MODULE_CODE_SOURCE_FILENAME BC40 = 16,
 
   // HASH: [5*i32]
-  MODULE_CODE_HASH = 17,
+  MODULE_CODE_HASH BC40 = 17,
 
   // IFUNC: [ifunc value type, addrspace, resolver val#, linkage, visibility]
-  MODULE_CODE_IFUNC = 18,
+  MODULE_CODE_IFUNC BC40 = 18,
 };
 
 /// PARAMATTR blocks have code for defining a parameter attribute set.
@@ -120,9 +137,9 @@ enum AttributeCodes {
   // FIXME: Remove `PARAMATTR_CODE_ENTRY_OLD' in 4.0
   PARAMATTR_CODE_ENTRY_OLD = 1, // ENTRY: [paramidx0, attr0,
                                 //         paramidx1, attr1...]
-  PARAMATTR_CODE_ENTRY = 2,     // ENTRY: [paramidx0, attrgrp0,
+  PARAMATTR_CODE_ENTRY BC35 = 2,     // ENTRY: [paramidx0, attrgrp0,
                                 //         paramidx1, attrgrp1, ...]
-  PARAMATTR_GRP_CODE_ENTRY = 3  // ENTRY: [id, attr0, att1, ...]
+  PARAMATTR_GRP_CODE_ENTRY BC35 = 3  // ENTRY: [id, attr0, att1, ...]
 };
 
 /// TYPE blocks have codes for each type primitive they use.
@@ -163,11 +180,11 @@ enum TypeCodes {
 
   TYPE_CODE_FUNCTION = 21, // FUNCTION: [vararg, retty, paramty x N]
 
-  TYPE_CODE_TOKEN = 22 // TOKEN
+  TYPE_CODE_TOKEN BC38 = 22 // TOKEN
 };
 
 enum OperandBundleTagCode {
-  OPERAND_BUNDLE_TAG = 1, // TAG: [strchr x N]
+  OPERAND_BUNDLE_TAG BC38 = 1, // TAG: [strchr x N]
 };
 
 // The type symbol table only has one code (TST_ENTRY_CODE).
@@ -179,15 +196,15 @@ enum TypeSymtabCodes {
 enum ValueSymtabCodes {
   VST_CODE_ENTRY = 1,   // VST_ENTRY: [valueid, namechar x N]
   VST_CODE_BBENTRY = 2, // VST_BBENTRY: [bbid, namechar x N]
-  VST_CODE_FNENTRY = 3, // VST_FNENTRY: [valueid, offset, namechar x N]
+  VST_CODE_FNENTRY BC38 = 3, // VST_FNENTRY: [valueid, offset, namechar x N]
   // VST_COMBINED_ENTRY: [valueid, refguid]
-  VST_CODE_COMBINED_ENTRY = 5
+  VST_CODE_COMBINED_ENTRY BC38 = 5
 };
 
 // The module path symbol table only has one code (MST_CODE_ENTRY).
 enum ModulePathSymtabCodes {
-  MST_CODE_ENTRY = 1, // MST_ENTRY: [modid, namechar x N]
-  MST_CODE_HASH = 2,  // MST_HASH:  [5*i32]
+  MST_CODE_ENTRY BC38 = 1, // MST_ENTRY: [modid, namechar x N]
+  MST_CODE_HASH BC40 = 2,  // MST_HASH:  [5*i32]
 };
 
 // The summary section uses different codes in the per-module
@@ -195,69 +212,69 @@ enum ModulePathSymtabCodes {
 enum GlobalValueSummarySymtabCodes {
   // PERMODULE: [valueid, flags, instcount, numrefs, numrefs x valueid,
   //             n x (valueid, callsitecount)]
-  FS_PERMODULE = 1,
+  FS_PERMODULE BC40 = 1,
   // PERMODULE_PROFILE: [valueid, flags, instcount, numrefs,
   //                     numrefs x valueid,
   //                     n x (valueid, callsitecount, profilecount)]
-  FS_PERMODULE_PROFILE = 2,
+  FS_PERMODULE_PROFILE BC40 = 2,
   // PERMODULE_GLOBALVAR_INIT_REFS: [valueid, flags, n x valueid]
-  FS_PERMODULE_GLOBALVAR_INIT_REFS = 3,
+  FS_PERMODULE_GLOBALVAR_INIT_REFS BC40 = 3,
   // COMBINED: [valueid, modid, flags, instcount, numrefs, numrefs x valueid,
   //            n x (valueid, callsitecount)]
-  FS_COMBINED = 4,
+  FS_COMBINED BC40 = 4,
   // COMBINED_PROFILE: [valueid, modid, flags, instcount, numrefs,
   //                    numrefs x valueid,
   //                    n x (valueid, callsitecount, profilecount)]
-  FS_COMBINED_PROFILE = 5,
+  FS_COMBINED_PROFILE BC40 = 5,
   // COMBINED_GLOBALVAR_INIT_REFS: [valueid, modid, flags, n x valueid]
-  FS_COMBINED_GLOBALVAR_INIT_REFS = 6,
+  FS_COMBINED_GLOBALVAR_INIT_REFS BC40 = 6,
   // ALIAS: [valueid, flags, valueid]
-  FS_ALIAS = 7,
+  FS_ALIAS BC40 = 7,
   // COMBINED_ALIAS: [valueid, modid, flags, valueid]
-  FS_COMBINED_ALIAS = 8,
+  FS_COMBINED_ALIAS BC40 = 8,
   // COMBINED_ORIGINAL_NAME: [original_name_hash]
-  FS_COMBINED_ORIGINAL_NAME = 9,
+  FS_COMBINED_ORIGINAL_NAME BC40 = 9,
   // VERSION of the summary, bumped when adding flags for instance.
-  FS_VERSION = 10,
+  FS_VERSION BC40 = 10,
 };
 
 enum MetadataCodes {
   METADATA_STRING_OLD = 1,       // MDSTRING:      [values]
-  METADATA_VALUE = 2,            // VALUE:         [type num, value num]
-  METADATA_NODE = 3,             // NODE:          [n x md num]
+  METADATA_VALUE BC38 = 2,            // VALUE:         [type num, value num]
+  METADATA_NODE BC38 = 3,             // NODE:          [n x md num]
   METADATA_NAME = 4,             // STRING:        [values]
-  METADATA_DISTINCT_NODE = 5,    // DISTINCT_NODE: [n x md num]
+  METADATA_DISTINCT_NODE BC38 = 5,    // DISTINCT_NODE: [n x md num]
   METADATA_KIND = 6,             // [n x [id, name]]
-  METADATA_LOCATION = 7,         // [distinct, line, col, scope, inlined-at?]
+  METADATA_LOCATION BC38 = 7,         // [distinct, line, col, scope, inlined-at?]
   METADATA_OLD_NODE = 8,         // OLD_NODE:      [n x (type num, value num)]
   METADATA_OLD_FN_NODE = 9,      // OLD_FN_NODE:   [n x (type num, value num)]
   METADATA_NAMED_NODE = 10,      // NAMED_NODE:    [n x mdnodes]
   METADATA_ATTACHMENT = 11,      // [m x [value, [n x [id, mdnode]]]
-  METADATA_GENERIC_DEBUG = 12,   // [distinct, tag, vers, header, n x md num]
-  METADATA_SUBRANGE = 13,        // [distinct, count, lo]
-  METADATA_ENUMERATOR = 14,      // [distinct, value, name]
-  METADATA_BASIC_TYPE = 15,      // [distinct, tag, name, size, align, enc]
-  METADATA_FILE = 16,            // [distinct, filename, directory]
-  METADATA_DERIVED_TYPE = 17,    // [distinct, ...]
-  METADATA_COMPOSITE_TYPE = 18,  // [distinct, ...]
-  METADATA_SUBROUTINE_TYPE = 19, // [distinct, flags, types, cc]
-  METADATA_COMPILE_UNIT = 20,    // [distinct, ...]
-  METADATA_SUBPROGRAM = 21,      // [distinct, ...]
-  METADATA_LEXICAL_BLOCK = 22,   // [distinct, scope, file, line, column]
-  METADATA_LEXICAL_BLOCK_FILE = 23, //[distinct, scope, file, discriminator]
-  METADATA_NAMESPACE = 24,          // [distinct, scope, file, name, line]
-  METADATA_TEMPLATE_TYPE = 25,      // [distinct, scope, name, type, ...]
-  METADATA_TEMPLATE_VALUE = 26,     // [distinct, scope, name, type, value, ...]
-  METADATA_GLOBAL_VAR = 27,         // [distinct, ...]
-  METADATA_LOCAL_VAR = 28,          // [distinct, ...]
-  METADATA_EXPRESSION = 29,         // [distinct, n x element]
-  METADATA_OBJC_PROPERTY = 30,      // [distinct, name, file, line, ...]
-  METADATA_IMPORTED_ENTITY = 31, // [distinct, tag, scope, entity, line, name]
-  METADATA_MODULE = 32,          // [distinct, scope, name, ...]
-  METADATA_MACRO = 33,           // [distinct, macinfo, line, name, value]
-  METADATA_MACRO_FILE = 34,      // [distinct, macinfo, line, file, ...]
-  METADATA_STRINGS = 35,         // [count, offset] blob([lengths][chars])
-  METADATA_GLOBAL_DECL_ATTACHMENT = 36, // [valueid, n x [id, mdnode]]
+  METADATA_GENERIC_DEBUG BC38 = 12,   // [distinct, tag, vers, header, n x md num]
+  METADATA_SUBRANGE BC38 = 13,        // [distinct, count, lo]
+  METADATA_ENUMERATOR BC38 = 14,      // [distinct, value, name]
+  METADATA_BASIC_TYPE BC38 = 15,      // [distinct, tag, name, size, align, enc]
+  METADATA_FILE BC38 = 16,            // [distinct, filename, directory]
+  METADATA_DERIVED_TYPE BC38 = 17,    // [distinct, ...]
+  METADATA_COMPOSITE_TYPE BC38 = 18,  // [distinct, ...]
+  METADATA_SUBROUTINE_TYPE BC38 = 19, // [distinct, flags, types, cc]
+  METADATA_COMPILE_UNIT BC38 = 20,    // [distinct, ...]
+  METADATA_SUBPROGRAM BC38 = 21,      // [distinct, ...]
+  METADATA_LEXICAL_BLOCK BC38 = 22,   // [distinct, scope, file, line, column]
+  METADATA_LEXICAL_BLOCK_FILE BC38 = 23, //[distinct, scope, file, discriminator]
+  METADATA_NAMESPACE BC38 = 24,          // [distinct, scope, file, name, line]
+  METADATA_TEMPLATE_TYPE BC38 = 25,      // [distinct, scope, name, type, ...]
+  METADATA_TEMPLATE_VALUE BC38 = 26,     // [distinct, scope, name, type, value, ...]
+  METADATA_GLOBAL_VAR BC38 = 27,         // [distinct, ...]
+  METADATA_LOCAL_VAR BC38 = 28,          // [distinct, ...]
+  METADATA_EXPRESSION BC38 = 29,         // [distinct, n x element]
+  METADATA_OBJC_PROPERTY BC38 = 30,      // [distinct, name, file, line, ...]
+  METADATA_IMPORTED_ENTITY BC38 = 31, // [distinct, tag, scope, entity, line, name]
+  METADATA_MODULE BC38 = 32,          // [distinct, scope, name, ...]
+  METADATA_MACRO BC38 = 33,           // [distinct, macinfo, line, name, value]
+  METADATA_MACRO_FILE BC38 = 34,      // [distinct, macinfo, line, file, ...]
+  METADATA_STRINGS BC40 = 35,         // [count, offset] blob([lengths][chars])
+  METADATA_GLOBAL_DECL_ATTACHMENT BC40 = 36, // [valueid, n x [id, mdnode]]
 };
 
 // The constants block (CONSTANTS_BLOCK_ID) describes emission for each
@@ -307,7 +324,7 @@ enum CastOpcodes {
   CAST_PTRTOINT = 9,
   CAST_INTTOPTR = 10,
   CAST_BITCAST = 11,
-  CAST_ADDRSPACECAST = 12
+  CAST_ADDRSPACECAST BC35 = 12
 };
 
 /// BinaryOpcodes - These are values used in the bitcode files to encode which
@@ -379,10 +396,10 @@ enum AtomicSynchScopeCodes {
 enum CallMarkersFlags {
   CALL_TAIL = 0,
   CALL_CCONV = 1,
-  CALL_MUSTTAIL = 14,
-  CALL_EXPLICIT_TYPE = 15,
-  CALL_NOTAIL = 16,
-  CALL_FMF = 17 // Call has optional fast-math-flags.
+  CALL_MUSTTAIL BC35 = 14,
+  CALL_EXPLICIT_TYPE BC38 = 15,
+  CALL_NOTAIL BC38 = 16,
+  CALL_FMF BC38 = 17 // Call has optional fast-math-flags.
 };
 
 // The function body block (FUNCTION_BLOCK_ID) describes function bodies.  It
@@ -447,30 +464,30 @@ enum FunctionCodes {
                                   //        ordering, synchscope]
   FUNC_CODE_INST_STOREATOMIC_OLD = 42, // STORE: [ptrty,ptr,val, align, vol
                                        //         ordering, synchscope]
-  FUNC_CODE_INST_GEP = 43,             // GEP:  [inbounds, n x operands]
-  FUNC_CODE_INST_STORE = 44,       // STORE: [ptrty,ptr,valty,val, align, vol]
-  FUNC_CODE_INST_STOREATOMIC = 45, // STORE: [ptrty,ptr,val, align, vol
-  FUNC_CODE_INST_CMPXCHG = 46,     // CMPXCHG: [ptrty,ptr,valty,cmp,new, align,
+  FUNC_CODE_INST_GEP BC38 = 43,             // GEP:  [inbounds, n x operands]
+  FUNC_CODE_INST_STORE BC38 = 44,       // STORE: [ptrty,ptr,valty,val, align, vol]
+  FUNC_CODE_INST_STOREATOMIC BC38 = 45, // STORE: [ptrty,ptr,val, align, vol
+  FUNC_CODE_INST_CMPXCHG BC38 = 46,     // CMPXCHG: [ptrty,ptr,valty,cmp,new, align,
                                    //           vol,ordering,synchscope]
-  FUNC_CODE_INST_LANDINGPAD = 47,  // LANDINGPAD: [ty,val,num,id0,val0...]
-  FUNC_CODE_INST_CLEANUPRET = 48,  // CLEANUPRET: [val] or [val,bb#]
-  FUNC_CODE_INST_CATCHRET = 49,    // CATCHRET: [val,bb#]
-  FUNC_CODE_INST_CATCHPAD = 50,    // CATCHPAD: [bb#,bb#,num,args...]
-  FUNC_CODE_INST_CLEANUPPAD = 51,  // CLEANUPPAD: [num,args...]
-  FUNC_CODE_INST_CATCHSWITCH =
+  FUNC_CODE_INST_LANDINGPAD BC38 = 47,  // LANDINGPAD: [ty,val,num,id0,val0...]
+  FUNC_CODE_INST_CLEANUPRET BC38 = 48,  // CLEANUPRET: [val] or [val,bb#]
+  FUNC_CODE_INST_CATCHRET BC38 = 49,    // CATCHRET: [val,bb#]
+  FUNC_CODE_INST_CATCHPAD BC38 = 50,    // CATCHPAD: [bb#,bb#,num,args...]
+  FUNC_CODE_INST_CLEANUPPAD BC38 = 51,  // CLEANUPPAD: [num,args...]
+  FUNC_CODE_INST_CATCHSWITCH BC38 =
       52, // CATCHSWITCH: [num,args...] or [num,args...,bb]
   // 53 is unused.
   // 54 is unused.
-  FUNC_CODE_OPERAND_BUNDLE = 55, // OPERAND_BUNDLE: [tag#, value...]
+  FUNC_CODE_OPERAND_BUNDLE BC40 = 55, // OPERAND_BUNDLE: [tag#, value...]
 };
 
 enum UseListCodes {
   USELIST_CODE_DEFAULT = 1, // DEFAULT: [index..., value-id]
-  USELIST_CODE_BB = 2       // BB: [index..., bb-id]
+  USELIST_CODE_BB BC38 = 2       // BB: [index..., bb-id]
 };
 
 enum AttributeKindCodes {
-  // = 0 is unused
+  ATTR_KIND_INVALID = 0,
   ATTR_KIND_ALIGNMENT = 1,
   ATTR_KIND_ALWAYS_INLINE = 2,
   ATTR_KIND_BY_VAL = 3,
@@ -508,29 +525,30 @@ enum AttributeKindCodes {
   ATTR_KIND_BUILTIN = 35,
   ATTR_KIND_COLD = 36,
   ATTR_KIND_OPTIMIZE_NONE = 37,
-  ATTR_KIND_IN_ALLOCA = 38,
-  ATTR_KIND_NON_NULL = 39,
-  ATTR_KIND_JUMP_TABLE = 40,
-  ATTR_KIND_DEREFERENCEABLE = 41,
-  ATTR_KIND_DEREFERENCEABLE_OR_NULL = 42,
-  ATTR_KIND_CONVERGENT = 43,
-  ATTR_KIND_SAFESTACK = 44,
-  ATTR_KIND_ARGMEMONLY = 45,
-  ATTR_KIND_SWIFT_SELF = 46,
-  ATTR_KIND_SWIFT_ERROR = 47,
-  ATTR_KIND_NO_RECURSE = 48,
-  ATTR_KIND_INACCESSIBLEMEM_ONLY = 49,
-  ATTR_KIND_INACCESSIBLEMEM_OR_ARGMEMONLY = 50,
-  ATTR_KIND_ALLOC_SIZE = 51,
-  ATTR_KIND_WRITEONLY = 52
+  //! NOTE: 38 - 41 are technically 3.5, but not supported by Metal
+  ATTR_KIND_IN_ALLOCA DONT_USE = 38,
+  ATTR_KIND_NON_NULL DONT_USE = 39,
+  ATTR_KIND_JUMP_TABLE DONT_USE = 40,
+  ATTR_KIND_DEREFERENCEABLE DONT_USE = 41,
+  ATTR_KIND_DEREFERENCEABLE_OR_NULL BC38 = 42,
+  ATTR_KIND_CONVERGENT BC38 = 43,
+  ATTR_KIND_SAFESTACK BC38 = 44,
+  ATTR_KIND_ARGMEMONLY BC38 = 45,
+  ATTR_KIND_SWIFT_SELF BC38 = 46,
+  ATTR_KIND_SWIFT_ERROR BC38 = 47,
+  ATTR_KIND_NO_RECURSE BC38 = 48,
+  ATTR_KIND_INACCESSIBLEMEM_ONLY BC38 = 49,
+  ATTR_KIND_INACCESSIBLEMEM_OR_ARGMEMONLY BC38 = 50,
+  ATTR_KIND_ALLOC_SIZE BC40 = 51,
+  ATTR_KIND_WRITEONLY BC40 = 52
 };
 
 enum ComdatSelectionKindCodes {
-  COMDAT_SELECTION_KIND_ANY = 1,
-  COMDAT_SELECTION_KIND_EXACT_MATCH = 2,
-  COMDAT_SELECTION_KIND_LARGEST = 3,
-  COMDAT_SELECTION_KIND_NO_DUPLICATES = 4,
-  COMDAT_SELECTION_KIND_SAME_SIZE = 5,
+  COMDAT_SELECTION_KIND_ANY BC35 = 1,
+  COMDAT_SELECTION_KIND_EXACT_MATCH BC35 = 2,
+  COMDAT_SELECTION_KIND_LARGEST BC35 = 3,
+  COMDAT_SELECTION_KIND_NO_DUPLICATES BC35 = 4,
+  COMDAT_SELECTION_KIND_SAME_SIZE BC35 = 5,
 };
 
 } // End bitc namespace
diff --git a/include/llvm/Bitcode/ReaderWriter.h b/include/llvm/Bitcode/ReaderWriter.h
index 0ff32d8..fa8ae77 100644
--- a/include/llvm/Bitcode/ReaderWriter.h
+++ b/include/llvm/Bitcode/ReaderWriter.h
@@ -104,6 +104,10 @@ namespace llvm {
                           const ModuleSummaryIndex *Index = nullptr,
                           bool GenerateHash = false);
 
+  void WriteBitcode32ToFile(const Module *M, raw_ostream &Out);
+
+  void WriteBitcode35ToFile(const Module *M, raw_ostream &Out);
+
   /// Write the specified module summary index to the given raw output stream,
   /// where it will be written in a new bitcode block. This is used when
   /// writing the combined index file for ThinLTO. When writing a subset of the
diff --git a/include/llvm/CodeGen/AsmPrinter.h b/include/llvm/CodeGen/AsmPrinter.h
index de618d1..d1e3957 100644
--- a/include/llvm/CodeGen/AsmPrinter.h
+++ b/include/llvm/CodeGen/AsmPrinter.h
@@ -254,7 +254,7 @@ public:
   /// requested, it will override the alignment request if required for
   /// correctness.
   ///
-  void EmitAlignment(unsigned NumBits, const GlobalObject *GO = nullptr) const;
+  virtual void EmitAlignment(unsigned NumBits, const GlobalObject *GO = nullptr) const;
 
   /// Lower the specified LLVM Constant to an MCExpr.
   virtual const MCExpr *lowerConstant(const Constant *CV);
@@ -539,7 +539,7 @@ private:
   void EmitVisibility(MCSymbol *Sym, unsigned Visibility,
                       bool IsDefinition = true) const;
 
-  void EmitLinkage(const GlobalValue *GV, MCSymbol *GVSym) const;
+  virtual void EmitLinkage(const GlobalValue *GV, MCSymbol *GVSym) const;
 
   void EmitJumpTableEntry(const MachineJumpTableInfo *MJTI,
                           const MachineBasicBlock *MBB, unsigned uid) const;
diff --git a/include/llvm/IR/BasicBlock.h b/include/llvm/IR/BasicBlock.h
index 50eedec..900a098 100644
--- a/include/llvm/IR/BasicBlock.h
+++ b/include/llvm/IR/BasicBlock.h
@@ -17,6 +17,7 @@
 #include "llvm/ADT/Twine.h"
 #include "llvm/ADT/ilist.h"
 #include "llvm/IR/Instruction.h"
+#include "llvm/IR/InstrTypes.h"
 #include "llvm/IR/SymbolTableListTraits.h"
 #include "llvm/Support/CBindingWrapping.h"
 #include "llvm/Support/DataTypes.h"
@@ -25,7 +26,6 @@ namespace llvm {
 
 class CallInst;
 class LandingPadInst;
-class TerminatorInst;
 class LLVMContext;
 class BlockAddress;
 class Function;
@@ -319,6 +319,130 @@ public:
   LandingPadInst *getLandingPadInst();
   const LandingPadInst *getLandingPadInst() const;
 
+  //
+  template <class Ptr, class USE_iterator> // Predecessor Iterator
+  class PredIterator : public std::iterator<std::forward_iterator_tag,
+                                            Ptr, ptrdiff_t, Ptr*, Ptr*> {
+    typedef std::iterator<std::forward_iterator_tag, Ptr, ptrdiff_t, Ptr*,
+                                                                      Ptr*> super;
+    typedef PredIterator<Ptr, USE_iterator> Self;
+    USE_iterator It;
+
+    inline void advancePastNonTerminators() {
+      // Loop to ignore non-terminator uses (for example BlockAddresses).
+      while (!It.atEnd() && !isa<TerminatorInst>(*It))
+        ++It;
+    }
+
+  public:
+    typedef typename super::pointer pointer;
+    typedef typename super::reference reference;
+
+    PredIterator() {}
+    explicit inline PredIterator(Ptr *bb) : It(bb->user_begin()) {
+      advancePastNonTerminators();
+    }
+    inline PredIterator(Ptr *bb, bool) : It(bb->user_end()) {}
+
+    inline bool operator==(const Self& x) const { return It == x.It; }
+    inline bool operator!=(const Self& x) const { return !operator==(x); }
+
+    inline reference operator*() const {
+      assert(!It.atEnd() && "pred_iterator out of range!");
+      return cast<TerminatorInst>(*It)->getParent();
+    }
+    inline pointer *operator->() const { return &operator*(); }
+
+    inline Self& operator++() {   // Preincrement
+      assert(!It.atEnd() && "pred_iterator out of range!");
+      ++It; advancePastNonTerminators();
+      return *this;
+    }
+
+    inline Self operator++(int) { // Postincrement
+      Self tmp = *this; ++*this; return tmp;
+    }
+
+    /// getOperandNo - Return the operand number in the predecessor's
+    /// terminator of the successor.
+    unsigned getOperandNo() const {
+      return It.getOperandNo();
+    }
+
+    /// getUse - Return the operand Use in the predecessor's terminator
+    /// of the successor.
+    Use &getUse() const {
+      return It.getUse();
+    }
+  };
+
+  typedef PredIterator<BasicBlock, Value::user_iterator> pred_iterator;
+  typedef PredIterator<const BasicBlock, Value::const_user_iterator> const_pred_iterator;
+  typedef llvm::iterator_range<pred_iterator> pred_range;
+  typedef llvm::iterator_range<const_pred_iterator> pred_const_range;
+
+  inline pred_iterator pred_begin() { return pred_iterator(this); }
+  inline const_pred_iterator pred_begin() const {
+    return const_pred_iterator(this);
+  }
+  inline pred_iterator pred_end() { return pred_iterator(this, true);}
+  inline const_pred_iterator pred_end() const {
+    return const_pred_iterator(this, true);
+  }
+  inline bool pred_empty() const {
+    return pred_begin() == pred_end();
+  }
+  inline pred_range predecessors() {
+    return pred_range(pred_begin(), pred_end());
+  }
+  inline pred_const_range predecessors() const {
+    return pred_const_range(pred_begin(), pred_end());
+  }
+  inline unsigned pred_size() {
+    return (unsigned)std::abs(std::distance(pred_begin(), pred_end()));
+  }
+
+  // returns true if BB is a predecessor of this BasicBlock
+  inline bool isPredecessor(const BasicBlock* BB) const {
+    return is_contained(predecessors(), BB);
+  }
+
+  //
+  typedef TerminatorInst::SuccIterator<TerminatorInst *, BasicBlock> succ_iterator;
+  typedef TerminatorInst::SuccIterator<const TerminatorInst *, const BasicBlock> succ_const_iterator;
+  typedef llvm::iterator_range<succ_iterator> succ_range;
+  typedef llvm::iterator_range<succ_const_iterator> succ_const_range;
+
+  inline succ_iterator succ_begin() {
+    return succ_iterator(getTerminator());
+  }
+  inline succ_const_iterator succ_begin() const {
+    return succ_const_iterator(getTerminator());
+  }
+  inline succ_iterator succ_end() {
+    return succ_iterator(getTerminator(), true);
+  }
+  inline succ_const_iterator succ_end() const {
+    return succ_const_iterator(getTerminator(), true);
+  }
+  inline bool succ_empty() const {
+    return succ_begin() == succ_end();
+  }
+  inline succ_range successors() {
+    return succ_range(succ_begin(), succ_end());
+  }
+  inline succ_const_range successors() const {
+    return succ_const_range(succ_begin(), succ_end());
+  }
+  inline unsigned succ_size() {
+    return (unsigned)std::abs(std::distance(succ_begin(), succ_end()));
+  }
+
+  // returns true if BB is a successor of this BasicBlock
+  inline bool isSuccessor(const BasicBlock* BB) const {
+    return is_contained(successors(), BB);
+  }
+
 private:
   /// \brief Increment the internal refcount of the number of BlockAddresses
   /// referencing this BasicBlock by \p Amt.
diff --git a/include/llvm/IR/CallingConv.h b/include/llvm/IR/CallingConv.h
index 4987b7e..97d8e69 100644
--- a/include/llvm/IR/CallingConv.h
+++ b/include/llvm/IR/CallingConv.h
@@ -117,23 +117,20 @@ namespace CallingConv {
     /// Passes all arguments in register or parameter space.
     PTX_Device = 72,
 
-    /// SPIR_FUNC - Calling convention for SPIR non-kernel device functions.
-    /// No lowering or expansion of arguments.
-    /// Structures are passed as a pointer to a struct with the byval attribute.
-    /// Functions can only call SPIR_FUNC and SPIR_KERNEL functions.
-    /// Functions can only have zero or one return values.
-    /// Variable arguments are not allowed, except for printf.
-    /// How arguments/return values are lowered are not specified.
-    /// Functions are only visible to the devices.
-    SPIR_FUNC = 75,
-
-    /// SPIR_KERNEL - Calling convention for SPIR kernel functions.
-    /// Inherits the restrictions of SPIR_FUNC, except
-    /// Cannot have non-void return values.
-    /// Cannot have variable arguments.
-    /// Can also be called by the host.
-    /// Is externally visible.
-    SPIR_KERNEL = 76,
+    /// AIR/Metal and SPIR-V/Vulkan vertex shader function calling convention
+    /// NOTE: for metal this is entirely virtual and will be stripped in the end
+    FLOOR_VERTEX = 73,
+    /// AIR/Metal and SPIR-V/Vulkan fragment shader function calling convention
+    /// NOTE: for metal this is entirely virtual and will be stripped in the end
+    FLOOR_FRAGMENT = 74,
+    /// OpenCL/SPIR/SPIR-V, AIR/Metal, CUDA and SPIR-V/Vulkan normal function calling convention (not an entry point)
+    /// NOTE: for metal this is entirely virtual and will be stripped in the end
+    /// NOTE: used to be SPIR_FUNC, must be 75 for binary compat
+    FLOOR_FUNC = 75,
+    /// OpenCL/SPIR/SPIR-V, AIR/Metal, CUDA and SPIR-V/Vulkan compute kernel function calling convention
+    /// NOTE: for metal this is entirely virtual and will be stripped in the end
+    /// NOTE: used to be SPIR_KERNEL, must be 76 for binary compat
+    FLOOR_KERNEL = 76,
 
     /// Intel_OCL_BI - Calling conventions for Intel OpenCL built-ins
     Intel_OCL_BI = 77,
diff --git a/include/llvm/IR/DebugInfoMetadata.h b/include/llvm/IR/DebugInfoMetadata.h
index a9caf79..b068353 100644
--- a/include/llvm/IR/DebugInfoMetadata.h
+++ b/include/llvm/IR/DebugInfoMetadata.h
@@ -216,6 +216,9 @@ public:
       return true;
     }
   }
+
+  // necessary for compat with llvm 3.5
+  MDTuple* contained_node { nullptr };
 };
 
 template <class T> struct simplify_type<const TypedDINodeRef<T>> {
@@ -448,6 +451,7 @@ public:
 /// TODO: Merge with directory/file node (including users).
 /// TODO: Canonicalize paths on creation.
 class DIFile : public DIScope {
+public: // NOTE: made this public for SPIRVReader
   friend class LLVMContextImpl;
   friend class MDNode;
 
@@ -1283,6 +1287,7 @@ public:
 /// TODO: Remove DisplayName.  It's always equal to Name.
 /// TODO: Split up flags.
 class DISubprogram : public DILocalScope {
+public: // NOTE: made this public for SPIRVReader
   friend class LLVMContextImpl;
   friend class MDNode;
 
@@ -1308,6 +1313,9 @@ class DISubprogram : public DILocalScope {
   unsigned IsLocalToUnit : 1;
   unsigned IsDefinition : 1;
   unsigned IsOptimized : 1;
+	
+  // necessary for llvm 3.5
+  Function* associated_function { nullptr };
 
   DISubprogram(LLVMContext &C, StorageType Storage, unsigned Line,
                unsigned ScopeLine, unsigned Virtuality, unsigned VirtualIndex,
diff --git a/include/llvm/IR/DerivedTypes.h b/include/llvm/IR/DerivedTypes.h
index efd0d07..3d949cd 100644
--- a/include/llvm/IR/DerivedTypes.h
+++ b/include/llvm/IR/DerivedTypes.h
@@ -203,7 +203,8 @@ class StructType : public CompositeType {
     SCDB_HasBody = 1,
     SCDB_Packed = 2,
     SCDB_IsLiteral = 4,
-    SCDB_IsSized = 8
+    SCDB_IsSized = 8,
+    SCDB_IsGraphicsReturnType = 16
   };
 
   /// For a named struct that actually has a name, this is a pointer to the
@@ -247,6 +248,15 @@ public:
   /// yet. These prints as 'opaque' in .ll files.
   bool isOpaque() const { return (getSubclassData() & SCDB_HasBody) == 0; }
 
+  /// isGraphicsReturnType - Return true if this type is used as a metal vertex/fragment
+  /// shader return type.
+  bool isGraphicsReturnType() const { return (getSubclassData() & SCDB_IsGraphicsReturnType) != 0; }
+
+  /// setGraphicsReturnType - Flags this type as a metal return type.
+  void setGraphicsReturnType() {
+    setSubclassData(getSubclassData() | SCDB_IsGraphicsReturnType);
+  }
+
   /// isSized - Return true if this is a sized type.
   bool isSized(SmallPtrSetImpl<Type *> *Visited = nullptr) const;
 
diff --git a/include/llvm/IR/Function.h b/include/llvm/IR/Function.h
index ff55fcb..6720241 100644
--- a/include/llvm/IR/Function.h
+++ b/include/llvm/IR/Function.h
@@ -112,6 +112,13 @@ public:
   /// \brief Provide fast operand accessors
   DECLARE_TRANSPARENT_OPERAND_ACCESSORS(Value);
 
+  // function type is separate from value type, so mutateType will no longer change it
+  // -> need a new function to specifically mutate the function type
+  void mutateFunctionType(FunctionType* NewTy) {
+    // NOTE: ValueType is now part of GlobalValue (and there is still a separate Ty in Value)
+    ValueType = NewTy;
+  }
+
   Type *getReturnType() const;           // Return the type of the ret val
   FunctionType *getFunctionType() const; // Return the FunctionType for me
 
diff --git a/include/llvm/IR/Metadata.h b/include/llvm/IR/Metadata.h
index 91f43d3..8ca6164 100644
--- a/include/llvm/IR/Metadata.h
+++ b/include/llvm/IR/Metadata.h
@@ -35,7 +35,10 @@ class Module;
 class ModuleSlotTracker;
 
 enum LLVMConstants : uint32_t {
-  DEBUG_METADATA_VERSION = 3 // Current debug info version number.
+  DEBUG_METADATA_VERSION = 3, // Current debug info version number.
+  DEBUG_METADATA_VERSION_32 = 1,
+  DEBUG_METADATA_VERSION_35 = 1,
+  IOS_METAL_DEBUG_METADATA_VERSION = 360203
 };
 
 /// \brief Root of the metadata hierarchy.
diff --git a/include/llvm/InitializePasses.h b/include/llvm/InitializePasses.h
index a411273..97312ac 100644
--- a/include/llvm/InitializePasses.h
+++ b/include/llvm/InitializePasses.h
@@ -345,6 +345,23 @@ void initializeWholeProgramDevirtPass(PassRegistry &);
 void initializeWinEHPreparePass(PassRegistry&);
 void initializeWriteBitcodePassPass(PassRegistry &);
 void initializeXRayInstrumentationPass(PassRegistry &);
+
+// libfloor passes
+void initializeAddressSpaceFixPass(PassRegistry&);
+void initializeEverythingInlinerPass(PassRegistry&);
+void initializeCUDAImagePass(PassRegistry&);
+void initializeCUDAFinalPass(PassRegistry&);
+void initializeMetalFirstPass(PassRegistry&);
+void initializeMetalFinalPass(PassRegistry&);
+void initializeMetalFinalModuleCleanupPass(PassRegistry&);
+void initializeMetalImagePass(PassRegistry&);
+void initializeSPIRFinalPass(PassRegistry&);
+void initializeSPIRImagePass(PassRegistry&);
+void initializeCFGStructurizationPass(PassRegistry&);
+void initializeVulkanFinalPass(PassRegistry&);
+void initializeVulkanFinalModuleCleanupPass(PassRegistry&);
+void initializePropagateRangeInfoPass(PassRegistry&);
+
 }
 
 #endif
diff --git a/include/llvm/LinkAllPasses.h b/include/llvm/LinkAllPasses.h
index 16c5f5c..2c2934f 100644
--- a/include/llvm/LinkAllPasses.h
+++ b/include/llvm/LinkAllPasses.h
@@ -99,6 +99,7 @@ namespace {
       (void) llvm::createFunctionImportPass();
       (void) llvm::createFunctionInliningPass();
       (void) llvm::createAlwaysInlinerLegacyPass();
+      (void) llvm::createEverythingInlinerPass();
       (void) llvm::createGlobalDCEPass();
       (void) llvm::createGlobalOptimizerPass();
       (void) llvm::createGlobalsAAWrapperPass();
@@ -211,6 +212,21 @@ namespace {
       X.add(nullptr, 0, llvm::AAMDNodes()); // for -print-alias-sets
       (void) llvm::AreStatisticsEnabled();
       (void) llvm::sys::RunningOnValgrind();
+
+      // libfloor passes
+      (void) llvm::createAddressSpaceFixPass();
+      (void) llvm::createCUDAImagePass(0);
+      (void) llvm::createCUDAFinalPass();
+      (void) llvm::createMetalFirstPass(false, false);
+      (void) llvm::createMetalFinalPass(false, false);
+      (void) llvm::createMetalFinalModuleCleanupPass();
+      (void) llvm::createMetalImagePass(0);
+      (void) llvm::createSPIRFinalPass();
+      (void) llvm::createSPIRImagePass(0, false);
+      (void) llvm::createCFGStructurizationPass();
+      (void) llvm::createVulkanFinalPass();
+      (void) llvm::createVulkanFinalModuleCleanupPass();
+      (void) llvm::createPropagateRangeInfoPass();
     }
   } ForcePassLinking; // Force link by creating a global definition.
 }
diff --git a/include/llvm/SPIRVerifier/SpirErrors.h b/include/llvm/SPIRVerifier/SpirErrors.h
new file mode 100644
index 0000000..88bd695
--- /dev/null
+++ b/include/llvm/SPIRVerifier/SpirErrors.h
@@ -0,0 +1,146 @@
+//===--------------------------- SpirErrors.h ----------------------------===//
+//
+//                              SPIR Tools
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===---------------------------------------------------------------------===//
+
+#ifndef __SPIR_ERRORS_H__
+#define __SPIR_ERRORS_H__
+
+#include <list>
+
+namespace llvm {
+  class Type;
+  class Value;
+  class Metadata;
+  class MDNode;
+  class NamedMDNode;
+  class StringRef;
+  class raw_ostream;
+}
+
+using namespace llvm;
+namespace SPIR {
+//
+// Validation Errors
+//
+
+typedef enum {
+  // Module (general) errors
+  // Type errors
+  ERR_INVALID_OCL_TYPE,
+  ERR_INVALID_LLVM_TYPE,
+  ERR_INVALID_KERNEL_RETURN_TYPE,
+  ERR_KERNEL_ARG_PTRPTR,
+  ERR_KERNEL_ARG_AS0,
+  ERR_MISMATCH_OCL_AND_LLVM_TYPES,
+  ERR_INVALID_GLOBAL_AS3_VAR,
+  ERR_INVALID_GLOBAL_VAR_ADDRESS_SPACE,
+  // Instruction errors
+  ERR_INVALID_INTRINSIC,
+  ERR_INVALID_ADDR_SPACE,
+  ERR_INVALID_ADDR_SPACE_CAST,
+  ERR_INVALID_INDIRECT_CALL,
+  ERR_INVALID_MEM_FENCE,
+  // Function errors
+  ERR_INVALID_CALLING_CONVENTION,
+  ERR_INVALID_LINKAGE_TYPE,
+  // Metadata errors
+  ERR_INVALID_CORE_FEATURE,
+  ERR_INVALID_KHR_EXT,
+  ERR_INVALID_COMPILER_OPTION,
+  ERR_MISSING_NAMED_METADATA,
+  ERR_INVALID_METADATA_KERNEL,
+  ERR_INVALID_METADATA_KERNEL_INFO,
+  ERR_MISSING_METADATA_KERNEL_INFO,
+  ERR_INVALID_METADATA_VERSION,
+  ERR_MISMATCH_METADATA_ADDR_SPACE,
+
+  SPIR_ERROR_NUM
+} SPIR_ERROR_TYPE;
+
+struct ErrorPrinter {
+  virtual ~ErrorPrinter() {};
+
+  /// @brief prints all errors to given output stream.
+  /// @param S output stream.
+  /// @param LITMode prints error names only in when set to true
+  virtual void print(llvm::raw_ostream &S, bool LITMode) const = 0;
+
+  /// @brief Checks if the module has errors.
+  /// @returns true if errors list is not emtpy.
+  virtual bool hasErrors() const = 0;
+};
+
+struct ErrorCreator {
+  virtual ~ErrorCreator() {};
+
+  /// @brief Creates and adds new error to the error list.
+  /// @param Err error type to be added.
+  /// @param S llvm string that leaded to the error.
+  virtual void addError(SPIR_ERROR_TYPE Err, const llvm::StringRef S) = 0;
+
+  /// @brief Creates and adds new error to the error list.
+  /// @param Err error type to be added.
+  /// @param V llvm value that leaded to the error.
+  virtual void addError(SPIR_ERROR_TYPE Err, const llvm::Value *V) = 0;
+
+  /// @brief Creates and adds new error to the error list.
+  /// @param Err error type to be added.
+  /// @param MD llvm metadata that leaded to the error.
+  virtual void addError(SPIR_ERROR_TYPE Err, const llvm::Metadata *MD) = 0;
+
+  /// @brief Creates and adds new error to the error list.
+  /// @param Err error type to be added.
+  /// @param NMD llvm named metadata node that leaded to the error.
+  virtual void addError(SPIR_ERROR_TYPE Err, const llvm::NamedMDNode *NMD) = 0;
+
+  /// @brief Creates and adds new error to the error list.
+  /// @param Err error type to be added.
+  /// @param T llvm type that leaded to the error.
+  /// @param S name of the function that T in its prototype.
+  virtual void addError(SPIR_ERROR_TYPE Err, const llvm::Type *T,
+                                             const llvm::StringRef S) = 0;
+
+  /// @brief Creates and adds new error to the error list.
+  /// @param Err error type to be added.
+  /// @param T llvm type that leaded to the error.
+  /// @param V value that T is its type.
+  virtual void addError(SPIR_ERROR_TYPE Err, const llvm::Type *T,
+                                             const llvm::Value *V) = 0;
+
+};
+
+struct ValidationError;
+typedef std::list<const ValidationError*> ErrorList;
+
+
+struct ErrorHolder : ErrorCreator, ErrorPrinter {
+  ErrorHolder();
+  virtual ~ErrorHolder();
+
+  /// Implementation of the pure virtual methods of ErrorCreator interface
+  virtual void addError(SPIR_ERROR_TYPE Err, const llvm::StringRef S);
+  virtual void addError(SPIR_ERROR_TYPE Err, const llvm::Value *V);
+  virtual void addError(SPIR_ERROR_TYPE Err, const llvm::Metadata *MD);
+  virtual void addError(SPIR_ERROR_TYPE Err, const llvm::NamedMDNode *NMD);
+  virtual void addError(SPIR_ERROR_TYPE Err, const llvm::Type *T,
+                                             const llvm::StringRef S);
+  virtual void addError(SPIR_ERROR_TYPE Err, const llvm::Type *T,
+                                             const llvm::Value *V);
+
+  /// Implementation of the pure virtual methods of ErrorPrinter interface
+  virtual void print(llvm::raw_ostream &S, bool LITMode) const;
+  virtual bool hasErrors() const;
+
+private:
+  /// @brief List of errors found in the module
+  ErrorList EL;
+};
+
+
+} // End SPIR namespace
+#endif // __SPIR_ERRORS_H__
diff --git a/include/llvm/SPIRVerifier/SpirIterators.h b/include/llvm/SPIRVerifier/SpirIterators.h
new file mode 100644
index 0000000..33a660a
--- /dev/null
+++ b/include/llvm/SPIRVerifier/SpirIterators.h
@@ -0,0 +1,461 @@
+//===------------------------- SpirIterators.h ---------------------------===//
+//
+//                              SPIR Tools
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===---------------------------------------------------------------------===//
+
+#ifndef __SPIR_ITERATORS_H__
+#define __SPIR_ITERATORS_H__
+
+#include <list>
+#include <map>
+
+namespace llvm {
+class Value;
+class Instruction;
+class BasicBlock;
+class Function;
+class Module;
+class MDNode;
+class GlobalVariable;
+}
+
+using namespace llvm;
+
+namespace SPIR {
+
+struct ErrorCreator;
+
+//
+// Executor interfaces.
+//
+
+/// @brief Interface for executor on llvm value.
+struct ValueExecutor {
+  virtual void execute(const Value*) = 0;
+};
+
+/// @brief Interface for executor on llvm instruction.
+struct InstructionExecutor {
+  virtual void execute(const Instruction*) = 0;
+};
+
+/// @brief Interface for executor on llvm function.
+struct FunctionExecutor {
+  virtual void execute(const Function*) = 0;
+};
+
+/// @brief Interface for executor on llvm global variables.
+struct GlobalVariableExecutor {
+  virtual void execute(const GlobalVariable*) = 0;
+};
+
+/// @brief Interface for executor on llvm module.
+struct ModuleExecutor {
+  virtual void execute(const Module*) = 0;
+};
+
+/// @brief Interface for executor on llvm metadata node.
+struct MDNodeExecutor {
+  virtual void execute(const MDNode*) = 0;
+};
+
+typedef std::list<ValueExecutor*> ValueExecutorList;
+typedef std::list<InstructionExecutor*> InstructionExecutorList;
+typedef std::list<FunctionExecutor*> FunctionExecutorList;
+typedef std::list<GlobalVariableExecutor*> GlobalVariableExecutorList;
+typedef std::list<ModuleExecutor*> ModuleExecutorList;
+typedef std::list<MDNodeExecutor*> MDNodeExecutorList;
+
+//
+// Iterator classes.
+//
+
+struct BasicBlockIterator {
+  /// @brief Constructor.
+  /// @param IEL list of instruction executors.
+  BasicBlockIterator(InstructionExecutorList& IEL) : m_iel(IEL) {
+  }
+
+  /// @brief Iterates over the instructions in a basic block
+  ///        and execute all executors from the list on each instruction.
+  /// @param Basic block to iterate over.
+  void execute(const BasicBlock& BB);
+
+private:
+  /// @brief List of instruction executors.
+  InstructionExecutorList& m_iel;
+};
+
+struct FunctionIterator {
+  /// @brief Constructor.
+  /// @param FEL list of function executors.
+  /// @param BBI basic block iterator (optional).
+  FunctionIterator(FunctionExecutorList& FEL, BasicBlockIterator *BBI = 0) :
+    m_fel(FEL), m_bbi(BBI) {
+  }
+
+  /// @brief Iterates over the basic blocks in a function.
+  /// @param F function to iterate over.
+  void execute(const Function& F);
+
+private:
+  /// @brief List of function executors.
+  FunctionExecutorList& m_fel;
+  /// @brief Basic block iterator.
+  BasicBlockIterator *m_bbi;
+};
+
+struct GlobalVariableIterator {
+  /// @hbrief Constructor.
+  /// @param GVEL list of global variable executors
+  GlobalVariableIterator(GlobalVariableExecutorList& GVEL) : m_gvel(GVEL) {
+  }
+
+  /// @brief Execute all the executors from the list on GlobalVariable.
+  /// @param GV Global variable to process.
+  void execute(const GlobalVariable& GV);
+
+private:
+  /// @brief List of GlobalVAriable executors.
+  GlobalVariableExecutorList& m_gvel;
+};
+
+struct ModuleIterator {
+  /// @brief Constructor.
+  /// @param MEL list of module executors.
+  /// @param FI function iterator (optional).
+  ModuleIterator(ModuleExecutorList& MEL, FunctionIterator *FI = 0,
+         GlobalVariableIterator *GI = 0) :
+    m_mel(MEL), m_fi(FI), m_gi(GI) {
+  }
+
+  /// @brief Iterates over the functions in a module.
+  /// @param M module to iterate over.
+  void execute(const Module& M);
+
+private:
+  /// @brief List of module executors.
+  ModuleExecutorList& m_mel;
+  /// @brief Function iterator.
+  FunctionIterator *m_fi;
+  /// @brief Global value iterator.
+  GlobalVariableIterator *m_gi;
+};
+
+/// @brief Iterates over the metadata nodes.
+struct MetaDataIterator {
+  /// @brief Constructor.
+  /// @param NEL list of metadata node executors.
+  MetaDataIterator(MDNodeExecutorList& NEL) : m_nel(NEL) {
+  }
+  /// @brief Iterates over the operands of a metadata node.
+  /// @param M module to iterate over.
+  void execute(const MDNode& Node);
+
+private:
+  /// @brief List of Metadata node executors.
+  MDNodeExecutorList& m_nel;
+};
+
+
+//
+// Module data holder class.
+//
+
+struct DataHolder {
+  DataHolder() :
+    Is32Bit(true),
+    HasDoubleFeature(false), HasImageFeature(false),
+    HASFp16Extension(false) {
+  }
+
+  /// @brief Sizeof pointer indectaor
+  bool Is32Bit;
+
+  // Core Features
+
+  /// @brief indicator for presence of cl_double core feature
+  bool HasDoubleFeature;
+
+  /// @brief indicator for presence of cl_images core feature
+  bool HasImageFeature;
+
+  // KHR Extensions
+
+  /// @brief indicator for presence of cl_khr_fp16 KHR extension
+  bool HASFp16Extension;
+};
+
+//
+// Verify Executor classes.
+//
+
+struct VerifyCall : public InstructionExecutor {
+  /// @brief Constructor.
+  /// @param EH error holder.
+  VerifyCall(ErrorCreator *EH) : ErrCreator(EH) {
+  }
+
+  /// @brief Verify that given instruction is not invalid call instruction.
+  /// @param I instruction to verify.
+  void execute(const Instruction *I) override;
+
+private:
+  ErrorCreator *ErrCreator;
+};
+
+struct VerifyBitcast : public InstructionExecutor {
+  /// @brief Constructor.
+  /// @param EH error holder.
+  VerifyBitcast(ErrorCreator *EH) : ErrCreator(EH) {
+  }
+
+  /// @brief Verify that given instruction is not invalid bitcast instruction
+  ///        and that it has no invalid bitcast constant expression operands.
+  /// @param I instruction to verify.
+  void execute(const Instruction *I) override;
+
+private:
+  ErrorCreator *ErrCreator;
+};
+
+struct VerifyInstructionType : public InstructionExecutor {
+  /// @brief Constructor.
+  /// @param EH error holder.
+  /// @param D data holder.
+  VerifyInstructionType(ErrorCreator *EH, DataHolder *D) :
+    ErrCreator(EH), Data(D) {
+  }
+
+  /// @brief Verify that given instruction has a valid type.
+  /// @param I instruction to verify.
+  void execute(const Instruction *I) override;
+
+private:
+  ErrorCreator *ErrCreator;
+  DataHolder *Data;
+};
+
+struct VerifyFunctionPrototype : public FunctionExecutor {
+  /// @brief Constructor.
+  /// @param EH error holder.
+  /// @param D data holder.
+  VerifyFunctionPrototype(ErrorCreator *EH, DataHolder *D) :
+    ErrCreator(EH), Data(D) {
+  }
+
+  /// @brief Verify that given function has valid prototype.
+  /// @param F function to verify.
+  void execute(const Function *F) override;
+
+private:
+  ErrorCreator *ErrCreator;
+  DataHolder *Data;
+};
+
+struct VerifyKernelPrototype : public FunctionExecutor {
+  /// @brief Constructor.
+  /// @param EH error holder.
+  /// @param D data holder.
+  VerifyKernelPrototype(ErrorCreator *EH, DataHolder *D) :
+    ErrCreator(EH), Data(D) {
+  }
+
+  /// @brief Verify that given OpenCL kernel has valid prototype.
+  /// @param F function to verify.
+  void execute(const Function *F) override;
+
+private:
+  ErrorCreator *ErrCreator;
+  __attribute__((unused)) DataHolder *Data;
+};
+
+struct VerifyGlobalVariable : public GlobalVariableExecutor {
+  /// @brief Constructor.
+  /// @param EH error holder.
+  /// @param D data holder.
+  VerifyGlobalVariable(ErrorCreator *EH, DataHolder *D) :
+    ErrCreator(EH), Data(D) {
+  }
+
+  /// @brief Verify varoius properties of given global variable
+  /// @param F function to verify.
+  void execute(const GlobalVariable *GV) override;
+
+private:
+  ErrorCreator *ErrCreator;
+  __attribute__((unused)) DataHolder *Data;
+};
+
+struct VerifyMetadataArgAddrSpace : public MDNodeExecutor {
+  /// @brief Constructor.
+  /// @param EH error holder.
+  /// @param F the function metadata arg base type is describing.
+  VerifyMetadataArgAddrSpace(ErrorCreator *EH, Function *F) :
+    ErrCreator(EH), Func(F), WasFound(false) {
+  }
+
+  /// @brief Verify that given metadata node is valid arg type metadata.
+  /// @param Node metadata node to verify.
+  void execute(const MDNode *Node) override;
+
+  bool found() {
+    return WasFound;
+  }
+
+private:
+  ErrorCreator *ErrCreator;
+  Function *Func;
+  bool WasFound;
+};
+
+struct VerifyMetadataArgType : public MDNodeExecutor {
+  /// @brief Constructor.
+  /// @param EH error holder.
+  VerifyMetadataArgType(ErrorCreator *EH) : ErrCreator(EH), WasFound(false) {
+  }
+
+  /// @brief Verify that given metadata node is valid arg type metadata.
+  /// @param Node metadata node to verify.
+  void execute(const MDNode *Node) override;
+
+  bool found() {
+    return WasFound;
+  }
+
+private:
+  __attribute__((unused)) ErrorCreator *ErrCreator;
+  bool WasFound;
+};
+
+struct VerifyMetadataArgBaseType : public MDNodeExecutor {
+  /// @brief Constructor.
+  /// @param EH error holder.
+  /// @param F the function metadata arg base type is describing.
+  VerifyMetadataArgBaseType(ErrorCreator *EH, Function *F, DataHolder *D) :
+    ErrCreator(EH), Func(F), Data(D), WasFound(false) {
+  }
+
+  /// @brief Verify that given metadata node is valid arg base type metadata.
+  /// @param Node metadata node to verify.
+  void execute(const MDNode *Node) override;
+
+  bool found() {
+    return WasFound;
+  }
+
+private:
+  ErrorCreator *ErrCreator;
+  Function *Func;
+  DataHolder *Data;
+  bool WasFound;
+};
+
+typedef std::map<const Function*, const MDNode*> FunctionToMDNodeMap;
+struct VerifyMetadataKernel : public MDNodeExecutor {
+  /// @brief Constructor.
+  /// @param EH error holder.
+  VerifyMetadataKernel(ErrorCreator *EH,
+    DataHolder *D, FunctionToMDNodeMap& Map) :
+    ErrCreator(EH), Data(D), FoundMap(Map) {
+  }
+
+  /// @brief Verify that given metadata node is valid arg type metadata.
+  /// @param Node metadata node to verify.
+  void execute(const MDNode *Node) override;
+
+private:
+  ErrorCreator *ErrCreator;
+  DataHolder *Data;
+  FunctionToMDNodeMap& FoundMap;
+};
+
+struct VerifyMetadataKernels : public ModuleExecutor {
+  /// @brief Constructor.
+  /// @param EH error holder.
+  /// @param D data holder.
+  VerifyMetadataKernels(ErrorCreator *EH, DataHolder *D) :
+    ErrCreator(EH), Data(D) {
+  }
+
+  void execute(const Module *M) override;
+
+private:
+  ErrorCreator *ErrCreator;
+  DataHolder *Data;
+};
+
+struct VerifyMetadataVersions : public ModuleExecutor {
+
+  typedef enum {
+    VERSION_OCL,
+    VERSION_SPIR,
+
+    OPENCL_VERISON_NUM
+  } OPENCL_VERSION_TYPE;
+
+  /// @brief Constructor.
+  /// @param EH error holder.
+  VerifyMetadataVersions(ErrorCreator *EH, OPENCL_VERSION_TYPE VTy) :
+    ErrCreator(EH), VType(VTy) {
+  }
+
+  void execute(const Module *M) override;
+
+private:
+  ErrorCreator *ErrCreator;
+  OPENCL_VERSION_TYPE VType;
+};
+
+struct VerifyMetadataCoreFeatures : public ModuleExecutor {
+  /// @brief Constructor.
+  /// @param EH error holder.
+  /// @param D data holder.s
+  VerifyMetadataCoreFeatures(ErrorCreator *EH, DataHolder *D) :
+    ErrCreator(EH), Data(D) {
+  }
+
+  void execute(const Module *M) override;
+
+private:
+  ErrorCreator *ErrCreator;
+  DataHolder *Data;
+};
+
+struct VerifyMetadataKHRExtensions : public ModuleExecutor {
+  /// @brief Constructor.
+  /// @param EH error holder.
+  /// @param D data holder.
+  VerifyMetadataKHRExtensions(ErrorCreator *EH, DataHolder *D) :
+    ErrCreator(EH), Data(D) {
+  }
+
+  void execute(const Module *M) override;
+
+private:
+  ErrorCreator *ErrCreator;
+  DataHolder *Data;
+};
+
+struct VerifyMetadataCompilerOptions : public ModuleExecutor {
+  /// @brief Constructor.
+  /// @param EH error holder.
+  /// @param D data holder.
+  VerifyMetadataCompilerOptions(ErrorCreator *EH, DataHolder *D) :
+    ErrCreator(EH), Data(D) {
+  }
+
+  void execute(const Module *M) override;
+
+private:
+  ErrorCreator *ErrCreator;
+  __attribute__((unused)) DataHolder *Data;
+};
+
+} // End SPIR namespace
+
+#endif // __SPIR_ITERATORS_H__
diff --git a/include/llvm/SPIRVerifier/SpirTables.h b/include/llvm/SPIRVerifier/SpirTables.h
new file mode 100644
index 0000000..e14e306
--- /dev/null
+++ b/include/llvm/SPIRVerifier/SpirTables.h
@@ -0,0 +1,171 @@
+//===--------------------------- SpirTable.h -----------------------------===//
+//
+//                              SPIR Tools
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===---------------------------------------------------------------------===//
+
+#ifndef __SPIR_TABLES_H__
+#define __SPIR_TABLES_H__
+
+#include <string>
+
+namespace SPIR {
+
+//
+// Constant definitions.
+//
+
+enum AddrSpace {
+  PRIVATE_ADDR_SPACE = 0,
+  GLOBAL_ADDR_SPACE = 1,
+  CONSTANT_ADDR_SPACE = 2,
+  LOCAL_ADDR_SPACE = 3
+};
+
+#define EXTREN_DCL_ARRAY_LENGTH(arr) extern const unsigned arr##_len
+
+extern const char *CORE_FEATURE_CL_DOUBLES;
+extern const char *CORE_FEATURE_CL_IMAGES;
+extern const char *g_valid_core_feature[];
+EXTREN_DCL_ARRAY_LENGTH(g_valid_core_feature);
+
+extern const char *EXTENSION_CL_KHR_FP16;
+extern const char *g_valid_khr_ext[];
+EXTREN_DCL_ARRAY_LENGTH(g_valid_khr_ext);
+
+extern const char *g_valid_compiler_options[];
+EXTREN_DCL_ARRAY_LENGTH(g_valid_compiler_options);
+
+///
+/// OpenCL C Type tables
+///
+extern const char *g_valid_ocl_primitives[];
+EXTREN_DCL_ARRAY_LENGTH(g_valid_ocl_primitives);
+
+extern const char *g_valid_ocl_vector_element_types[];
+EXTREN_DCL_ARRAY_LENGTH(g_valid_ocl_vector_element_types);
+
+extern const char *g_valid_ocl_opaque_types[];
+EXTREN_DCL_ARRAY_LENGTH(g_valid_ocl_opaque_types);
+
+extern const char *g_opencl_opaque_sufix;
+
+extern const char *g_ignored_ocl_types[];
+EXTREN_DCL_ARRAY_LENGTH(g_ignored_ocl_types);
+
+///
+/// OpenCL C Type tables
+///
+extern const char *g_valid_llvm_primitives[];
+EXTREN_DCL_ARRAY_LENGTH(g_valid_llvm_primitives);
+
+extern const char *g_valid_llvm_vector_element_types[];
+EXTREN_DCL_ARRAY_LENGTH(g_valid_llvm_vector_element_types);
+
+extern const char *g_valid_llvm_image_types[];
+EXTREN_DCL_ARRAY_LENGTH(g_valid_llvm_image_types);
+
+extern const char *g_valid_llvm_opaque_types[];
+EXTREN_DCL_ARRAY_LENGTH(g_valid_llvm_opaque_types);
+
+extern const char *g_llvm_opaque_prefix;
+
+///
+/// Other OpenCL Tables
+///
+extern const char *g_valid_vector_type_lengths[];
+EXTREN_DCL_ARRAY_LENGTH(g_valid_vector_type_lengths);
+
+extern const char *g_valid_instrinsic[];
+EXTREN_DCL_ARRAY_LENGTH(g_valid_instrinsic);
+
+extern const char *g_ignored_instrinsic[];
+EXTREN_DCL_ARRAY_LENGTH(g_ignored_instrinsic);
+
+extern const char *g_valid_sync_bi[];
+EXTREN_DCL_ARRAY_LENGTH(g_valid_sync_bi);
+
+extern const char *g_valid_address_space[];
+EXTREN_DCL_ARRAY_LENGTH(g_valid_address_space);
+
+extern const char *g_valid_calling_convention[];
+EXTREN_DCL_ARRAY_LENGTH(g_valid_calling_convention);
+
+extern const char *g_valid_linkage_type[];
+EXTREN_DCL_ARRAY_LENGTH(g_valid_linkage_type);
+
+extern const char *OPENCL_KERNELS;
+extern const char *OPENCL_SPIR_VERSION;
+extern const char *OPENCL_OCL_VERSION;
+extern const char *OPENCL_KHR_EXTENSIONS;
+extern const char *OPENCL_CORE_FEATURES;
+extern const char *OPENCL_COMPILER_OPTIONS;
+extern const char *g_valid_named_metadata[];
+EXTREN_DCL_ARRAY_LENGTH(g_valid_named_metadata);
+
+extern const char *KERNEL_ARG_ADDR_SPACE;
+extern const char *KERNEL_ARG_TY;
+extern const char *KERNEL_ARG_BASE_TY;
+extern const char *g_valid_kernel_arg_info[];
+EXTREN_DCL_ARRAY_LENGTH(g_valid_kernel_arg_info);
+
+extern const char *g_valid_version_names[];
+EXTREN_DCL_ARRAY_LENGTH(g_valid_version_names);
+
+extern const char *g_valid_spir_versions[][2];
+EXTREN_DCL_ARRAY_LENGTH(g_valid_spir_versions);
+
+extern const char *g_valid_ocl_versions[][2];
+EXTREN_DCL_ARRAY_LENGTH(g_valid_ocl_versions);
+
+
+
+
+///
+/// get error info message functions
+///
+
+extern std::string getValidOpenCLTypeMsg();
+
+extern std::string getValidLLVMTypeMsg();
+
+extern std::string getValidKernelReturnTypeMsg();
+
+extern std::string getValidIntrinsicMsg();
+
+extern std::string getValidAddressSpaceMsg();
+
+extern std::string getValidCallingConventionMsg();
+
+extern std::string getValidLinkageTypeMsg();
+
+extern std::string getValidGlobalAS3VariableMsg();
+
+extern std::string getValidGlobalVarAddressSpacesMsg();
+
+extern std::string getValidIndirectCallMsg();
+
+extern std::string getValidKernelArgInfoMsg();
+
+extern std::string getValidKernelArgAddressSpaceMsg();
+
+extern std::string getValidVersionMsg();
+
+extern std::string getValidMemFenceMsg();
+
+extern std::string getMapOpenCLToLLVMMsg();
+
+extern std::string getValidNamedMetadataMsg();
+
+extern std::string getValidCoreFeaturesMsg();
+
+extern std::string getValidKHRExtensionsMsg();
+
+extern std::string getValidCompilerOptionsMsg();
+
+} // End SPIR namespace
+
+#endif // __SPIR_TABLES_H__
diff --git a/include/llvm/SPIRVerifier/SpirValidation.h b/include/llvm/SPIRVerifier/SpirValidation.h
new file mode 100644
index 0000000..3a51e3a
--- /dev/null
+++ b/include/llvm/SPIRVerifier/SpirValidation.h
@@ -0,0 +1,59 @@
+//===------------------------ SpirValidation.h ---------------------------===//
+//
+//                              SPIR Tools
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===---------------------------------------------------------------------===//
+
+#ifndef __SPIR_VALIDATION_H__
+#define __SPIR_VALIDATION_H__
+
+#include "llvm/SPIRVerifier/SpirErrors.h"
+#include "llvm/Pass.h"
+
+namespace SPIR {
+
+/// @brief Indicates whether a given module is a valid SPIR module
+///        according to SPIR 1.2 spec.
+class SpirValidation : public llvm::ModulePass {
+public:
+
+  /// @brief Pass identification, replacement for typeid.
+  static char ID;
+
+  /// @brief Constructor.
+  SpirValidation();
+
+  /// @brief Distructor.
+  virtual ~SpirValidation();
+
+  /// @brief Provides name of pass.
+  virtual const char *getPassName() const;
+
+  /// @brief LLVM Module pass entry.
+  /// @param M Module to transform.
+  /// @returns true if changed.
+  bool runOnModule(llvm::Module&);
+
+  /// @brief returns instance of ErrorPrinter implementation.
+  /// @returns error printer instance.
+  const ErrorPrinter *getErrorPrinter() const {
+    return &ErrHolder;
+  }
+
+private:
+
+  /// @brief Holder for errors found in the module
+  ErrorHolder ErrHolder;
+};
+
+} // End SPIR namespace
+
+
+namespace llvm {
+  ModulePass *createSpirValidationPass();
+}
+
+#endif // __SPIR_VALIDATION_H__
diff --git a/include/llvm/Support/SPIRV.h b/include/llvm/Support/SPIRV.h
new file mode 100644
index 0000000..d340108
--- /dev/null
+++ b/include/llvm/Support/SPIRV.h
@@ -0,0 +1,162 @@
+//===- SPIRV.h  Read and write SPIR-V binary -------------------*- C++ -*-===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+/// \file SPIRV.h
+///
+/// This files declares functions and passes for translating between LLVM and
+/// SPIR-V.
+///
+///
+//===----------------------------------------------------------------------===//
+#ifndef LLVM_SUPPORT_SPIRV_H
+#define LLVM_SUPPORT_SPIRV_H
+
+#include <string>
+#include <iostream>
+
+namespace llvm {
+// Pass initialization functions need to be declared before inclusion of
+// PassSupport.h.
+class PassRegistry;
+void initializeLLVMToSPIRVPass(PassRegistry&);
+void initializeOCL20To12Pass(PassRegistry&);
+void initializeOCL20ToSPIRVPass(PassRegistry&);
+void initializeOCL21ToSPIRVPass(PassRegistry&);
+void initializeGLSLToSPIRVPass(PassRegistry&);
+void initializeOCLTypeToSPIRVPass(PassRegistry&);
+void initializeSPIRVLowerBoolPass(PassRegistry&);
+void initializeSPIRVLowerConstExprPass(PassRegistry&);
+void initializeSPIRVLowerOCLBlocksPass(PassRegistry&);
+void initializeSPIRVRegularizeLLVMPass(PassRegistry&);
+void initializeSPIRVToOCL20Pass(PassRegistry&);
+void initializeTransOCLMDPass(PassRegistry&);
+}
+
+#include "llvm/IR/Module.h"
+
+namespace SPIRV {
+class SPIRVModule;
+
+/// \brief Check if a string contains SPIR-V binary.
+bool IsSPIRVBinary(std::string &Img);
+
+#ifdef _SPIRV_SUPPORT_TEXT_FMT
+/// \brief Convert SPIR-V between binary and internal textual formats.
+/// This function is not thread safe and should not be used in multi-thread
+/// applications unless guarded by a critical section.
+/// \returns true if succeeds.
+bool ConvertSPIRV(std::istream &IS, llvm::raw_ostream &OS,
+    std::string &ErrMsg, bool FromText, bool ToText);
+
+/// \brief Convert SPIR-V between binary and internel text formats.
+/// This function is not thread safe and should not be used in multi-thread
+/// applications unless guarded by a critical section.
+bool ConvertSPIRV(std::string &Input, std::string &Out,
+    std::string &ErrMsg, bool ToText);
+
+/// \brief Check if a string contains SPIR-V in internal text format.
+bool IsSPIRVText(std::string &Img);
+#endif
+
+} // End namespace SPIRV
+
+namespace llvm {
+
+/// \brief Translate LLVM module to SPIRV and write to ostream.
+/// \returns true if succeeds.
+bool WriteSPIRV(llvm::Module *M, llvm::raw_ostream &OS, std::string &ErrMsg);
+
+/// \brief Load SPIRV from istream and translate to LLVM module.
+/// \returns true if succeeds.
+bool ReadSPIRV(llvm::LLVMContext &C, std::istream &IS, llvm::Module *&M,
+    std::string &ErrMsg);
+
+/// \brief Regularize LLVM module by removing entities not representable by
+/// SPIRV.
+bool RegularizeLLVMForSPIRV(llvm::Module *M, std::string &ErrMsg);
+
+/// \brief Mangle OpenCL builtin function function name.
+void MangleOpenCLBuiltin(const std::string &UnmangledName,
+    ArrayRef<Type*> ArgTypes, std::string &MangledName);
+
+/// Create a pass for translating LLVM to SPIR-V.
+ModulePass *createLLVMToSPIRV(SPIRV::SPIRVModule *);
+
+/// Create a pass for translating OCL 2.0 builtin functions to equivalent
+/// OCL 1.2 builtin functions.
+ModulePass *createOCL20To12();
+
+/// Create a pass for translating OCL 2.0 builtin functions to SPIR-V builtin
+/// functions.
+ModulePass *createOCL20ToSPIRV();
+
+/// Create a pass for translating OCL 2.1 builtin functions to SPIR-V builtin
+/// functions.
+ModulePass *createOCL21ToSPIRV();
+
+/// Create a pass for translating OCL/GLSL builtin functions to SPIR-V builtin
+/// functions.
+ModulePass *createGLSLToSPIRV();
+
+/// Create a pass for adapting OCL types for SPIRV.
+ModulePass *createOCLTypeToSPIRV();
+
+/// Create a pass for lowering cast instructions of i1 type.
+ModulePass *createSPIRVLowerBool();
+
+/// Create a pass for lowering constant expressions to instructions.
+ModulePass *createSPIRVLowerConstExpr();
+
+/// Create a pass for lowering OCL 2.0 blocks to functions calls.
+ModulePass *createSPIRVLowerOCLBlocks();
+
+/// Create a pass for regularize LLVM module to be translated to SPIR-V.
+ModulePass *createSPIRVRegularizeLLVM();
+
+/// Create a pass for translating SPIR-V builtin functions to OCL 2.0 builtin
+/// functions.
+ModulePass *createSPIRVToOCL20();
+
+/// Create a pass for translating SPIR 1.2/2.0 metadata to SPIR-V friendly
+/// metadata.
+ModulePass *createTransOCLMD();
+
+/// Create and return a pass that writes the module to the specified
+/// ostream.
+ModulePass *createSPIRVWriterPass(llvm::raw_ostream &Str);
+
+} // namespace llvm
+
+
+
+#endif
diff --git a/include/llvm/Transforms/IPO.h b/include/llvm/Transforms/IPO.h
index 9ef3881..2acf5b9 100644
--- a/include/llvm/Transforms/IPO.h
+++ b/include/llvm/Transforms/IPO.h
@@ -107,6 +107,12 @@ Pass *createFunctionInliningPass(unsigned OptLevel, unsigned SizeOptLevel);
 Pass *createFunctionInliningPass(InlineParams &Params);
 
 //===----------------------------------------------------------------------===//
+/// createEverythingInlinerPass - Return a new pass object that inlines
+/// everything, unless it was marked "noinline".
+Pass *createEverythingInlinerPass();
+Pass *createEverythingInlinerPass(bool InsertLifetime);
+
+//===----------------------------------------------------------------------===//
 /// createPruneEHPass - Return a new pass object which transforms invoke
 /// instructions into calls, if the callee can _not_ unwind the stack.
 ///
diff --git a/include/llvm/Transforms/IPO/PassManagerBuilder.h b/include/llvm/Transforms/IPO/PassManagerBuilder.h
index adc4179..ad2a706 100644
--- a/include/llvm/Transforms/IPO/PassManagerBuilder.h
+++ b/include/llvm/Transforms/IPO/PassManagerBuilder.h
@@ -150,6 +150,19 @@ public:
   /// Path of the profile data file.
   std::string PGOInstrUse;
 
+  bool EnableAddressSpaceFix;
+  bool EnableCUDAPasses;
+  bool EnableMetalPasses;
+  bool EnableMetalIntelWorkarounds;
+  bool EnableMetalNvidiaWorkarounds;
+  bool EnableSPIRPasses;
+  bool EnableSPIRIntelWorkarounds;
+  bool EnableVerifySPIR;
+  bool EnableVulkanPasses;
+
+  // can't rely on clang header here, so just use a uint32_t
+  unsigned int floor_image_capabilities { 0 };
+
 private:
   /// ExtensionList - This is list of all of the extensions that are registered.
   std::vector<std::pair<ExtensionPointTy, ExtensionFn>> Extensions;
diff --git a/include/llvm/Transforms/Scalar.h b/include/llvm/Transforms/Scalar.h
index 167cc94..1820b40 100644
--- a/include/llvm/Transforms/Scalar.h
+++ b/include/llvm/Transforms/Scalar.h
@@ -32,6 +32,89 @@ class TargetMachine;
 
 //===----------------------------------------------------------------------===//
 //
+// AddressSpaceFix - This pass fixes (intentionally) broken uses of addrspace
+// pointers that should be non-addrspace pointers.
+//
+ModulePass *createAddressSpaceFixPass();
+
+//===----------------------------------------------------------------------===//
+//
+// CUDAImage - This pass applies CUDA-specific floor image transformations.
+//
+FunctionPass *createCUDAImagePass(const uint32_t image_capabilities = 0);
+
+//===----------------------------------------------------------------------===//
+//
+// CUDAFinal - final pass, making CUDA related IR changes.
+//
+FunctionPass *createCUDAFinalPass();
+
+//===----------------------------------------------------------------------===//
+//
+// MetalFirst - This pass fixes Metal/AIR issues.
+//
+FunctionPass *createMetalFirstPass(const bool enable_intel_workarounds = false,
+                                   const bool enable_nvidia_workarounds = false);
+
+//===----------------------------------------------------------------------===//
+//
+// MetalFinal - This pass fixes Metal/AIR issues.
+//
+FunctionPass *createMetalFinalPass(const bool enable_intel_workarounds = false,
+                                   const bool enable_nvidia_workarounds = false);
+
+//===----------------------------------------------------------------------===//
+//
+// MetalFinalModuleCleanup - This pass removes any calling convention attributes
+// and removes unused functions/prototypes/externs.
+//
+ModulePass *createMetalFinalModuleCleanupPass();
+
+//===----------------------------------------------------------------------===//
+//
+// MetalImage - This pass applies Metal-specific floor image transformations.
+//
+FunctionPass *createMetalImagePass(const uint32_t image_capabilities = 0);
+
+//===----------------------------------------------------------------------===//
+//
+// SPIRFinal - This pass fixes LLVM IR to be SPIR-compliant.
+//
+FunctionPass *createSPIRFinalPass();
+
+//===----------------------------------------------------------------------===//
+//
+// SPIRImage - This pass applies SPIR-specific floor image transformations.
+//
+FunctionPass *createSPIRImagePass(const uint32_t image_capabilities = 0,
+                                  const bool enable_intel_workarounds = false);
+
+//===----------------------------------------------------------------------===//
+//
+// CFGStructurization - This pass transforms the CFG into a structurized CFG.
+//
+FunctionPass *createCFGStructurizationPass();
+
+//===----------------------------------------------------------------------===//
+//
+// VulkanFinal - This pass fixes Vulkan/SPIR-V issues.
+//
+FunctionPass *createVulkanFinalPass();
+
+//===----------------------------------------------------------------------===//
+//
+// VulkanFinalModuleCleanup - This pass removes unused functions/etc.
+//
+ModulePass *createVulkanFinalModuleCleanupPass();
+
+//===----------------------------------------------------------------------===//
+//
+// PropagateRangeInfo - This pass propagates range metadata info.
+//
+FunctionPass *createPropagateRangeInfoPass();
+
+//===----------------------------------------------------------------------===//
+//
 // ConstantPropagation - A worklist driven constant propagation pass
 //
 FunctionPass *createConstantPropagationPass();
diff --git a/include/llvm/Transforms/Scalar/FloorImage.h b/include/llvm/Transforms/Scalar/FloorImage.h
new file mode 100644
index 0000000..4d33ac6
--- /dev/null
+++ b/include/llvm/Transforms/Scalar/FloorImage.h
@@ -0,0 +1,386 @@
+//===-- FloorImage.h - base class for image transformations------*- C++ -*-===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+// This header file and class define and implement the base class for all
+// image transformations (CUDA and opaque, as used for Metal, OpenCL and Vulkan).
+//
+//===----------------------------------------------------------------------===//
+
+#ifndef LLVM_TRANSFORMS_SCALAR_FLOORIMAGE_H
+#define LLVM_TRANSFORMS_SCALAR_FLOORIMAGE_H
+
+#include <algorithm>
+#include <cstdarg>
+#include <cstdint>
+#include <memory>
+#include <string>
+#include <array>
+
+#include "llvm/Pass.h"
+#include "llvm/IR/InstIterator.h"
+#include "llvm/IR/InstVisitor.h"
+#include "llvm/IR/IntrinsicInst.h"
+#include "llvm/IR/IRBuilder.h"
+#include "llvm/IR/LLVMContext.h"
+
+// condensed version of the COMPUTE_IMAGE_TYPE defined by floor
+enum class COMPUTE_IMAGE_TYPE : uint32_t {
+	//! invalid/uninitialized
+	NONE					= (0u),
+	
+	//////////////////////////////////////////
+	// -> image flags and types
+	//! upper 12-bit (20-31): type flags
+	__FLAG_MASK				= (0xFFFC0000u),
+	__FLAG_SHIFT			= (20u),
+	//! base type: image is an array (aka has layers)
+	FLAG_ARRAY				= (1u << (__FLAG_SHIFT + 0u)),
+	//! base type: image is a buffer object
+	FLAG_BUFFER				= (1u << (__FLAG_SHIFT + 1u)),
+	//! base type: image uses mutli-sampling (consists of multiple samples)
+	FLAG_MSAA				= (1u << (__FLAG_SHIFT + 2u)),
+	//! base type: image is a cube map
+	FLAG_CUBE				= (1u << (__FLAG_SHIFT + 3u)),
+	//! base type: image is a depth image
+	FLAG_DEPTH				= (1u << (__FLAG_SHIFT + 4u)),
+	//! base type: image is a stencil image
+	FLAG_STENCIL			= (1u << (__FLAG_SHIFT + 5u)),
+	//! base type: image is a render target (Metal) / renderbuffer (OpenGL) / framebuffer attachment (Vulkan)
+	//! NOTE: only applicable when using OpenGL sharing, Metal or Vulkan
+	FLAG_RENDER_TARGET		= (1u << (__FLAG_SHIFT + 6u)),
+	//! optional type: image uses mip-mapping, i.e. has multiple LODs
+	FLAG_MIPMAPPED			= (1u << (__FLAG_SHIFT + 7u)),
+	//! optional type: image uses a fixed channel count
+	//! NOTE: only used internally, serves no purpose on the user-side
+	FLAG_FIXED_CHANNELS		= (1u << (__FLAG_SHIFT + 8u)),
+	//! optional type: image uses gather sampling (aka tld4/fetch4)
+	FLAG_GATHER				= (1u << (__FLAG_SHIFT + 9u)),
+	//! optional type: when using integer storage formats, the data is normalized in [0, 1]
+	FLAG_NORMALIZED			= (1u << (__FLAG_SHIFT + 10u)),
+	//! optional type: image data contains sRGB data
+	FLAG_SRGB				= (1u << (__FLAG_SHIFT + 11u)),
+	
+	//! bits 18-19: channel layout
+	__LAYOUT_MASK			= (0x000C0000u),
+	__LAYOUT_SHIFT			= (18u),
+	LAYOUT_RGBA				= (0u << __LAYOUT_SHIFT),
+	LAYOUT_BGRA				= (1u << __LAYOUT_SHIFT),
+	LAYOUT_ABGR				= (2u << __LAYOUT_SHIFT),
+	LAYOUT_ARGB				= (3u << __LAYOUT_SHIFT),
+	//! layout convenience aliases
+	LAYOUT_R				= LAYOUT_RGBA,
+	LAYOUT_RG				= LAYOUT_RGBA,
+	LAYOUT_RGB				= LAYOUT_RGBA,
+	LAYOUT_BGR				= LAYOUT_ABGR,
+	
+	//! bits 16-17: dimensionality
+	//! NOTE: cube maps and arrays use the dimensionality of their underlying image data
+	//!       -> 2D for cube maps, 2D for 2D arrays, 1D for 1D arrays
+	__DIM_MASK				= (0x00030000u),
+	__DIM_SHIFT				= (16u),
+	DIM_1D					= (1u << __DIM_SHIFT),
+	DIM_2D					= (2u << __DIM_SHIFT),
+	DIM_3D					= (3u << __DIM_SHIFT),
+	
+	//! bits 14-15: channel count
+	__CHANNELS_MASK			= (0x0000C000u),
+	__CHANNELS_SHIFT		= (14u),
+	CHANNELS_1				= (0u << __CHANNELS_SHIFT),
+	CHANNELS_2				= (1u << __CHANNELS_SHIFT),
+	CHANNELS_3				= (2u << __CHANNELS_SHIFT),
+	CHANNELS_4				= (3u << __CHANNELS_SHIFT),
+	//! channel convenience aliases
+	R 						= CHANNELS_1,
+	RG 						= CHANNELS_2,
+	RGB 					= CHANNELS_3,
+	RGBA					= CHANNELS_4,
+	
+	//! bits 12-13: storage data type
+	__DATA_TYPE_MASK		= (0x00003000u),
+	__DATA_TYPE_SHIFT		= (12u),
+	INT						= (1u << __DATA_TYPE_SHIFT),
+	UINT					= (2u << __DATA_TYPE_SHIFT),
+	FLOAT					= (3u << __DATA_TYPE_SHIFT),
+	
+	//! bits 10-11: access qualifier
+	__ACCESS_MASK			= (0x00000C00u),
+	__ACCESS_SHIFT			= (10u),
+	//! image is read-only (exluding host operations)
+	READ					= (1u << __ACCESS_SHIFT),
+	//! image is write-only (exluding host operations)
+	WRITE					= (2u << __ACCESS_SHIFT),
+	//! image is read-write
+	//! NOTE: also applies if neither is set
+	READ_WRITE				= (READ | WRITE),
+	
+	//! bits 6-9: compressed formats
+	__COMPRESSION_MASK		= (0x000003C0),
+	__COMPRESSION_SHIFT		= (6u),
+	//! image data is not compressed
+	UNCOMPRESSED			= (0u << __COMPRESSION_SHIFT),
+	//! S3TC/DXTn
+	BC1						= (1u << __COMPRESSION_SHIFT),
+	BC2						= (2u << __COMPRESSION_SHIFT),
+	BC3						= (3u << __COMPRESSION_SHIFT),
+	//! RGTC1/RGTC2
+	RGTC					= (4u << __COMPRESSION_SHIFT),
+	BC4						= RGTC,
+	BC5						= RGTC,
+	//! BPTC/BPTC_FLOAT
+	BPTC					= (5u << __COMPRESSION_SHIFT),
+	BC6H					= BPTC,
+	BC7						= BPTC,
+	//! PVRTC
+	PVRTC					= (6u << __COMPRESSION_SHIFT),
+	//! PVRTC2
+	PVRTC2					= (7u << __COMPRESSION_SHIFT),
+	//! EAC/ETC1
+	EAC						= (8u << __COMPRESSION_SHIFT),
+	ETC1					= EAC,
+	//! ETC2
+	ETC2					= (9u << __COMPRESSION_SHIFT),
+	//! ASTC
+	ASTC					= (10u << __COMPRESSION_SHIFT),
+	
+	//! bits 0-5: formats
+	//! NOTE: unless specified otherwise, a format is usable with any channel count
+	//! NOTE: not all backends support all formats (for portability, stick to 8-bit/16-bit/32-bit)
+	//! NOTE: channel layout / order is determined by LAYOUT_* -> bit/channel order in here can be different to the actual layout
+	__FORMAT_MASK			= (0x0000003Fu),
+	//! 1 bit per channel
+	FORMAT_1				= (1u),
+	//! 2 bits per channel
+	FORMAT_2				= (2u),
+	//! 3 channel format: 3-bit/3-bit/2-bit
+	FORMAT_3_3_2			= (3u),
+	//! 4 bits per channel or YUV444
+	FORMAT_4				= (4u),
+	//! YUV420
+	FORMAT_4_2_0			= (5u),
+	//! YUV411
+	FORMAT_4_1_1			= (6u),
+	//! YUV422
+	FORMAT_4_2_2			= (7u),
+	//! 3 channel format: 5-bit/5-bit/5-bit
+	FORMAT_5_5_5			= (8u),
+	//! 4 channel format: 5-bit/5-bit/5-bit/1-bit
+	FORMAT_5_5_5_ALPHA_1	= (9u),
+	//! 3 channel format: 5-bit/6-bit/5-bit
+	FORMAT_5_6_5			= (10u),
+	//! 8 bits per channel
+	FORMAT_8				= (11u),
+	//! 3 channel format: 9-bit/9-bit/9-bit (5-bit exp)
+	FORMAT_9_9_9_EXP_5		= (12u),
+	//! 3 channel format: 10-bit/10-bit/10-bit
+	FORMAT_10				= (13u),
+	//! 4 channel format: 10-bit/10-bit/10-bit/2-bit
+	FORMAT_10_10_10_ALPHA_2	= (14u),
+	//! 3 channel format: 11-bit/11-bit/10-bit
+	FORMAT_11_11_10			= (15u),
+	//! 3 channel format: 12-bit/12-bit/12-bit
+	FORMAT_12_12_12			= (16u),
+	//! 4 channel format: 12-bit/12-bit/12-bit/12-bit
+	FORMAT_12_12_12_12		= (17u),
+	//! 16 bits per channel
+	FORMAT_16				= (18u),
+	//! 2 channel format: 16-bit/8-bit
+	FORMAT_16_8				= (19u),
+	//! 1 channel format: 24-bit
+	FORMAT_24				= (20u),
+	//! 2 channel format: 24-bit/8-bit
+	FORMAT_24_8				= (21u),
+	//! 32 bits per channel
+	FORMAT_32				= (22u),
+	//! 2 channel format: 32-bit/8-bit
+	FORMAT_32_8				= (23u),
+	//! 64 bits per channel
+	FORMAT_64				= (24u),
+	__FORMAT_MAX			= FORMAT_64,
+	
+	//////////////////////////////////////////
+	// -> base image types
+	//! 1D image
+	IMAGE_1D				= DIM_1D,
+	//! array of 1D images
+	IMAGE_1D_ARRAY			= DIM_1D | FLAG_ARRAY,
+	//! 1D image buffer (special format on some platforms)
+	IMAGE_1D_BUFFER			= DIM_1D | FLAG_BUFFER,
+	
+	//! 2D image
+	IMAGE_2D				= DIM_2D,
+	//! array of 2D images
+	IMAGE_2D_ARRAY			= DIM_2D | FLAG_ARRAY,
+	//! multi-sampled 2D image
+	IMAGE_2D_MSAA			= DIM_2D | FLAG_MSAA,
+	//! array of multi-sampled 2D images
+	IMAGE_2D_MSAA_ARRAY		= DIM_2D | FLAG_MSAA | FLAG_ARRAY,
+	
+	//! cube map image
+	IMAGE_CUBE				= DIM_2D | FLAG_CUBE,
+	//! array of cube map images
+	IMAGE_CUBE_ARRAY		= DIM_2D | FLAG_CUBE | FLAG_ARRAY,
+	
+	//! 2D depth image
+	IMAGE_DEPTH				= FLAG_DEPTH | CHANNELS_1 | IMAGE_2D,
+	//! combined 2D depth + stencil image
+	IMAGE_DEPTH_STENCIL		= FLAG_DEPTH | CHANNELS_2 | IMAGE_2D | FLAG_STENCIL,
+	//! array of 2D depth images
+	IMAGE_DEPTH_ARRAY		= FLAG_DEPTH | CHANNELS_1 | IMAGE_2D_ARRAY,
+	//! depth cube map image
+	IMAGE_DEPTH_CUBE		= FLAG_DEPTH | CHANNELS_1 | IMAGE_CUBE,
+	//! array of depth cube map images
+	IMAGE_DEPTH_CUBE_ARRAY	= FLAG_DEPTH | CHANNELS_1 | IMAGE_CUBE | FLAG_ARRAY,
+	//! multi-sampled 2D depth image
+	IMAGE_DEPTH_MSAA		= FLAG_DEPTH | CHANNELS_1 | IMAGE_2D_MSAA,
+	//! array of multi-sampled 2D depth images
+	IMAGE_DEPTH_MSAA_ARRAY	= FLAG_DEPTH | CHANNELS_1 | IMAGE_2D_MSAA_ARRAY,
+	
+	//! 3D image
+	IMAGE_3D				= DIM_3D,
+	
+	//
+	BASE_TYPE_MASK			= (__DIM_MASK |
+							   FLAG_ARRAY | FLAG_BUFFER | FLAG_CUBE | FLAG_DEPTH | FLAG_MSAA | FLAG_STENCIL),
+	
+};
+__attribute__((always_inline, used)) static constexpr COMPUTE_IMAGE_TYPE operator|(const COMPUTE_IMAGE_TYPE& e0,
+																				   const COMPUTE_IMAGE_TYPE& e1) {
+	return (COMPUTE_IMAGE_TYPE)((typename std::underlying_type<COMPUTE_IMAGE_TYPE>::type)e0 |
+								(typename std::underlying_type<COMPUTE_IMAGE_TYPE>::type)e1);
+}
+__attribute__((always_inline, used)) static constexpr COMPUTE_IMAGE_TYPE operator&(const COMPUTE_IMAGE_TYPE& e0,
+																			 const COMPUTE_IMAGE_TYPE& e1) {
+	return (COMPUTE_IMAGE_TYPE)((typename std::underlying_type<COMPUTE_IMAGE_TYPE>::type)e0 &
+								(typename std::underlying_type<COMPUTE_IMAGE_TYPE>::type)e1);
+}
+template <COMPUTE_IMAGE_TYPE flag, typename int_type = typename std::underlying_type<COMPUTE_IMAGE_TYPE>::type>
+__attribute__((always_inline, used)) static constexpr bool has_flag(const COMPUTE_IMAGE_TYPE& enum_object) {
+	return ((int_type(flag) & int_type(enum_object)) == int_type(flag));
+}
+
+// compare function used by depth compare reads
+enum class COMPARE_FUNCTION : uint32_t {
+	NONE				= 0u,
+	LESS_OR_EQUAL		= 1u,
+	GREATER_OR_EQUAL	= 2u,
+	LESS				= 3u,
+	GREATER				= 4u,
+	EQUAL				= 5u,
+	NOT_EQUAL			= 6u,
+	ALWAYS				= 7u,
+	NEVER				= 8u,
+	__MAX_COMPARE_FUNCTION
+};
+
+// device image capabilities
+enum class IMAGE_CAPABILITY : uint32_t {
+	NONE					= (0u),
+	BASIC					= (1u << 0u),
+	
+	DEPTH_READ				= (1u << 1u),
+	DEPTH_WRITE				= (1u << 2u),
+	MSAA_READ				= (1u << 3u),
+	MSAA_WRITE				= (1u << 4u),
+	CUBE_READ				= (1u << 5u),
+	CUBE_WRITE				= (1u << 6u),
+	MIPMAP_READ				= (1u << 7u),
+	MIPMAP_WRITE			= (1u << 8u),
+	OFFSET_READ				= (1u << 9u),
+	OFFSET_WRITE			= (1u << 10u),
+	
+	DEPTH_COMPARE			= (1u << 16u),
+	GATHER					= (1u << 17u),
+	READ_WRITE				= (1u << 18u),
+};
+template <IMAGE_CAPABILITY flag, typename int_type = typename std::underlying_type<IMAGE_CAPABILITY>::type>
+__attribute__((always_inline, used)) static constexpr bool has_flag(const IMAGE_CAPABILITY& enum_object) {
+	return ((int_type(flag) & int_type(enum_object)) == int_type(flag));
+}
+
+namespace llvm {
+	struct FloorImageBasePass : public FunctionPass, InstVisitor<FloorImageBasePass> {
+		friend class InstVisitor<FloorImageBasePass>;
+		
+		enum class IMAGE_TYPE_ID {
+			CUDA,
+			OPAQUE
+		};
+		
+		explicit FloorImageBasePass(char &ID,
+									const IMAGE_TYPE_ID& image_type_id,
+									const uint32_t& image_capabilities);
+		
+		bool runOnFunction(Function &F) override;
+		
+		using InstVisitor<FloorImageBasePass>::visit;
+		void visit(Instruction& I);
+		void visitCallSite(CallSite CS);
+		
+		void handle_image(CallSite& CS, const StringRef& func_name);
+		
+		virtual void handle_read_image(Instruction& I,
+									   const StringRef& func_name,
+									   llvm::Value* img_handle_arg,
+									   const COMPUTE_IMAGE_TYPE& image_type,
+									   llvm::ConstantInt* const_sampler_arg,
+									   llvm::Value* dyn_sampler_arg,
+									   llvm::Value* coord_arg,
+									   llvm::Value* layer_arg,
+									   llvm::Value* sample_arg,
+									   llvm::Value* offset_arg,
+									   const SmallVector<llvm::Value*, 3>& offset_elems,
+									   const bool is_offset,
+									   llvm::Value* lod_or_bias_arg,
+									   const bool is_lod_or_bias, // true: lod, false: bias
+									   llvm::Value* dpdx_arg,
+									   llvm::Value* dpdy_arg,
+									   const bool is_gradient,
+									   const COMPARE_FUNCTION& compare_function,
+									   llvm::Value* compare_value_arg,
+									   const bool is_compare) = 0;
+		
+		virtual void handle_write_image(Instruction& I,
+										const StringRef& func_name,
+										llvm::Value* img_handle_arg,
+										const COMPUTE_IMAGE_TYPE& image_type,
+										const COMPUTE_IMAGE_TYPE& format_type,
+										const COMPUTE_IMAGE_TYPE& data_type,
+										const bool& is_normalized,
+										const uint32_t& image_channel_count,
+										llvm::Value* coord_arg,
+										llvm::Value* layer_arg,
+										llvm::Value* lod_arg,
+										const bool is_lod,
+										llvm::Value* data_arg) = 0;
+		
+	protected:
+		const IMAGE_TYPE_ID image_type_id;
+		const char* image_read_prefix;
+		const char* image_write_prefix;
+		Module* M { nullptr };
+		LLVMContext* ctx { nullptr };
+		Function* func { nullptr };
+		Instruction* alloca_insert { nullptr };
+		std::shared_ptr<IRBuilder<>> builder;
+		bool was_modified { false };
+		IMAGE_CAPABILITY image_capabilities { IMAGE_CAPABILITY::NONE };
+		
+		llvm::AttributeSet nounwind_readnone_attr;
+		llvm::AttributeSet nounwind_attr;
+		
+		// depth compare s/w emulation if not supported by backend h/w or s/w
+		void emulate_depth_compare(llvm::Value*& dst_vec,
+								   llvm::Value* tex_value,
+								   const COMPARE_FUNCTION& compare_function,
+								   llvm::Value* compare_value_arg);
+		
+	};
+}
+
+#endif
diff --git a/lib/Analysis/CodeMetrics.cpp b/lib/Analysis/CodeMetrics.cpp
index bdffdd8..30a3805 100644
--- a/lib/Analysis/CodeMetrics.cpp
+++ b/lib/Analysis/CodeMetrics.cpp
@@ -118,7 +118,8 @@ void CodeMetrics::collectEphemeralValues(
 /// block.
 void CodeMetrics::analyzeBasicBlock(const BasicBlock *BB,
                                     const TargetTransformInfo &TTI,
-                                    const SmallPtrSetImpl<const Value*> &EphValues) {
+                                    const SmallPtrSetImpl<const Value*> &EphValues,
+                                    const bool allow_duplicate) {
   ++NumBlocks;
   unsigned NumInstsBeforeThisBB = NumInsts;
   for (const Instruction &I : *BB) {
@@ -162,18 +163,18 @@ void CodeMetrics::analyzeBasicBlock(const BasicBlock *BB,
     if (isa<ExtractElementInst>(I) || I.getType()->isVectorTy())
       ++NumVectorInsts;
 
-    if (I.getType()->isTokenTy() && I.isUsedOutsideOfBlock(BB))
+    if (!allow_duplicate && I.getType()->isTokenTy() && I.isUsedOutsideOfBlock(BB))
       notDuplicatable = true;
 
     if (const CallInst *CI = dyn_cast<CallInst>(&I)) {
-      if (CI->cannotDuplicate())
+      if (!allow_duplicate && CI->cannotDuplicate())
         notDuplicatable = true;
       if (CI->isConvergent())
         convergent = true;
     }
 
     if (const InvokeInst *InvI = dyn_cast<InvokeInst>(&I))
-      if (InvI->cannotDuplicate())
+      if (!allow_duplicate && InvI->cannotDuplicate())
         notDuplicatable = true;
 
     NumInsts += TTI.getUserCost(&I);
diff --git a/lib/Analysis/LoopInfo.cpp b/lib/Analysis/LoopInfo.cpp
index 9d2e38e..019c03f 100644
--- a/lib/Analysis/LoopInfo.cpp
+++ b/lib/Analysis/LoopInfo.cpp
@@ -195,10 +195,11 @@ bool Loop::isSafeToClone() const {
     if (isa<IndirectBrInst>(BB->getTerminator()))
       return false;
 
-    for (Instruction &I : *BB)
-      if (auto CS = CallSite(&I))
-        if (CS.cannotDuplicate())
-          return false;
+    // TODO/NOTE: ignoring this for now, duplicates can very well exist in the same scope
+    //for (Instruction &I : *BB)
+    //  if (auto CS = CallSite(&I))
+    //    if (CS.cannotDuplicate())
+    //      return false;
   }
   return true;
 }
diff --git a/lib/AsmParser/LLLexer.cpp b/lib/AsmParser/LLLexer.cpp
index 58fe13e..416c3ce 100644
--- a/lib/AsmParser/LLLexer.cpp
+++ b/lib/AsmParser/LLLexer.cpp
@@ -580,8 +580,10 @@ lltok::Kind LLLexer::LexIdentifier() {
   KEYWORD(avr_signalcc);
   KEYWORD(ptx_kernel);
   KEYWORD(ptx_device);
-  KEYWORD(spir_kernel);
-  KEYWORD(spir_func);
+  KEYWORD(floor_kernel);
+  KEYWORD(floor_vertex);
+  KEYWORD(floor_fragment);
+  KEYWORD(floor_func);
   KEYWORD(intel_ocl_bicc);
   KEYWORD(x86_64_sysvcc);
   KEYWORD(x86_64_win64cc);
diff --git a/lib/AsmParser/LLParser.cpp b/lib/AsmParser/LLParser.cpp
index e97202d..f0403f7 100644
--- a/lib/AsmParser/LLParser.cpp
+++ b/lib/AsmParser/LLParser.cpp
@@ -1645,8 +1645,10 @@ void LLParser::ParseOptionalDLLStorageClass(unsigned &Res) {
 ///   ::= 'avr_signalcc'
 ///   ::= 'ptx_kernel'
 ///   ::= 'ptx_device'
-///   ::= 'spir_func'
-///   ::= 'spir_kernel'
+///   ::= 'floor_func'
+///   ::= 'floor_kernel'
+///   ::= 'floor_vertex'
+///   ::= 'floor_fragment'
 ///   ::= 'x86_64_sysvcc'
 ///   ::= 'x86_64_win64cc'
 ///   ::= 'webkit_jscc'
@@ -1686,8 +1688,10 @@ bool LLParser::ParseOptionalCallingConv(unsigned &CC) {
   case lltok::kw_avr_signalcc:   CC = CallingConv::AVR_SIGNAL; break;
   case lltok::kw_ptx_kernel:     CC = CallingConv::PTX_Kernel; break;
   case lltok::kw_ptx_device:     CC = CallingConv::PTX_Device; break;
-  case lltok::kw_spir_kernel:    CC = CallingConv::SPIR_KERNEL; break;
-  case lltok::kw_spir_func:      CC = CallingConv::SPIR_FUNC; break;
+  case lltok::kw_floor_kernel:   CC = CallingConv::FLOOR_KERNEL; break;
+  case lltok::kw_floor_vertex:   CC = CallingConv::FLOOR_VERTEX; break;
+  case lltok::kw_floor_fragment: CC = CallingConv::FLOOR_FRAGMENT; break;
+  case lltok::kw_floor_func:     CC = CallingConv::FLOOR_FUNC; break;
   case lltok::kw_intel_ocl_bicc: CC = CallingConv::Intel_OCL_BI; break;
   case lltok::kw_x86_64_sysvcc:  CC = CallingConv::X86_64_SysV; break;
   case lltok::kw_x86_64_win64cc: CC = CallingConv::X86_64_Win64; break;
@@ -2938,10 +2942,10 @@ bool LLParser::ParseValID(ValID &ID, PerFunctionState *PFS) {
         ParseType(DestTy) ||
         ParseToken(lltok::rparen, "expected ')' at end of constantexpr cast"))
       return true;
-    if (!CastInst::castIsValid((Instruction::CastOps)Opc, SrcVal, DestTy))
+    /*if (!CastInst::castIsValid((Instruction::CastOps)Opc, SrcVal, DestTy))
       return Error(ID.Loc, "invalid cast opcode for cast from '" +
                    getTypeString(SrcVal->getType()) + "' to '" +
-                   getTypeString(DestTy) + "'");
+                   getTypeString(DestTy) + "'");*/
     ID.ConstantVal = ConstantExpr::getCast((Instruction::CastOps)Opc,
                                                  SrcVal, DestTy);
     ID.Kind = ValID::t_Constant;
@@ -5633,12 +5637,12 @@ bool LLParser::ParseCast(Instruction *&Inst, PerFunctionState &PFS,
       ParseType(DestTy))
     return true;
 
-  if (!CastInst::castIsValid((Instruction::CastOps)Opc, Op, DestTy)) {
+  /*if (!CastInst::castIsValid((Instruction::CastOps)Opc, Op, DestTy)) {
     CastInst::castIsValid((Instruction::CastOps)Opc, Op, DestTy);
     return Error(Loc, "invalid cast opcode for cast from '" +
                  getTypeString(Op->getType()) + "' to '" +
                  getTypeString(DestTy) + "'");
-  }
+  }*/
   Inst = CastInst::Create((Instruction::CastOps)Opc, Op, DestTy);
   return false;
 }
diff --git a/lib/AsmParser/LLToken.h b/lib/AsmParser/LLToken.h
index 37998e8..72408bb 100644
--- a/lib/AsmParser/LLToken.h
+++ b/lib/AsmParser/LLToken.h
@@ -135,8 +135,10 @@ enum Kind {
   kw_avr_signalcc,
   kw_ptx_kernel,
   kw_ptx_device,
-  kw_spir_kernel,
-  kw_spir_func,
+  kw_floor_kernel,
+  kw_floor_vertex,
+  kw_floor_fragment,
+  kw_floor_func,
   kw_x86_64_sysvcc,
   kw_x86_64_win64cc,
   kw_webkit_jscc,
diff --git a/lib/Bitcode/CMakeLists.txt b/lib/Bitcode/CMakeLists.txt
index ff7e290..9e90072 100644
--- a/lib/Bitcode/CMakeLists.txt
+++ b/lib/Bitcode/CMakeLists.txt
@@ -1,2 +1,4 @@
 add_subdirectory(Reader)
 add_subdirectory(Writer)
+add_subdirectory(Writer32)
+add_subdirectory(Writer35)
diff --git a/lib/Bitcode/LLVMBuild.txt b/lib/Bitcode/LLVMBuild.txt
index af9936b..017dbe5 100644
--- a/lib/Bitcode/LLVMBuild.txt
+++ b/lib/Bitcode/LLVMBuild.txt
@@ -16,7 +16,7 @@
 ;===------------------------------------------------------------------------===;
 
 [common]
-subdirectories = Reader Writer
+subdirectories = Reader Writer Writer32 Writer35
 
 [component_0]
 type = Group
diff --git a/lib/Bitcode/Writer32/BitWriter32.cpp b/lib/Bitcode/Writer32/BitWriter32.cpp
new file mode 100644
index 0000000..31f7de4
--- /dev/null
+++ b/lib/Bitcode/Writer32/BitWriter32.cpp
@@ -0,0 +1,49 @@
+//===-- BitWriter32.cpp ---------------------------------------------------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+
+#include "llvm-c/BitWriter.h"
+#include "llvm/Bitcode/ReaderWriter.h"
+#include "llvm/IR/Module.h"
+#include "llvm/Support/FileSystem.h"
+#include "llvm/Support/raw_ostream.h"
+using namespace llvm;
+
+
+/*===-- Operations on modules ---------------------------------------------===*/
+
+int LLVMWriteBitcode32ToFile(LLVMModuleRef M, const char *Path) {
+  std::error_code EC;
+  raw_fd_ostream OS(Path, EC, sys::fs::F_None);
+
+  if (EC)
+    return -1;
+
+  WriteBitcode32ToFile(unwrap(M), OS);
+  return 0;
+}
+
+int LLVMWriteBitcode32ToFD(LLVMModuleRef M, int FD, int ShouldClose,
+                           int Unbuffered) {
+  raw_fd_ostream OS(FD, ShouldClose, Unbuffered);
+
+  WriteBitcode32ToFile(unwrap(M), OS);
+  return 0;
+}
+
+int LLVMWriteBitcode32ToFileHandle(LLVMModuleRef M, int FileHandle) {
+  return LLVMWriteBitcode32ToFD(M, FileHandle, true, false);
+}
+
+LLVMMemoryBufferRef LLVMWriteBitcode32ToMemoryBuffer(LLVMModuleRef M) {
+  std::string Data;
+  raw_string_ostream OS(Data);
+
+  WriteBitcode32ToFile(unwrap(M), OS);
+  return wrap(MemoryBuffer::getMemBufferCopy(OS.str()).release());
+}
diff --git a/lib/Bitcode/Writer32/BitcodeWriter32.cpp b/lib/Bitcode/Writer32/BitcodeWriter32.cpp
new file mode 100644
index 0000000..1cd27a9
--- /dev/null
+++ b/lib/Bitcode/Writer32/BitcodeWriter32.cpp
@@ -0,0 +1,2448 @@
+//===--- Bitcode/Writer32/BitcodeWriter32.cpp - Bitcode 3.2 Writer --------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+// Bitcode 3.2 writer implementation.
+//
+//===----------------------------------------------------------------------===//
+
+// enable errors when using > 3.2 bitcode enums from LLVMBitCodes.h
+#define LLVM_BITCODE_32 1
+
+#include "llvm/Bitcode/ReaderWriter.h"
+#include "ValueEnumerator32.h"
+#include "llvm/ADT/STLExtras.h"
+#include "llvm/ADT/Triple.h"
+#include "llvm/Bitcode/BitstreamWriter.h"
+#include "llvm/Bitcode/LLVMBitCodes.h"
+#include "llvm/IR/CallSite.h"
+#include "llvm/IR/Constants.h"
+#include "llvm/IR/DebugInfoMetadata.h"
+#include "llvm/IR/DerivedTypes.h"
+#include "llvm/IR/InlineAsm.h"
+#include "llvm/IR/Instructions.h"
+#include "llvm/IR/LLVMContext.h"
+#include "llvm/IR/IntrinsicInst.h"
+#include "llvm/IR/Module.h"
+#include "llvm/IR/Operator.h"
+#include "llvm/IR/UseListOrder.h"
+#include "llvm/IR/ValueSymbolTable.h"
+#include "llvm/Support/CommandLine.h"
+#include "llvm/Support/ErrorHandling.h"
+#include "llvm/Support/MathExtras.h"
+#include "llvm/Support/Program.h"
+#include "llvm/Support/raw_ostream.h"
+#include "llvm/Support/Dwarf.h"
+#include <cctype>
+#include <map>
+using namespace llvm;
+
+#define SPIR32_TRIPLE "spir-unknown-unknown"
+#define SPIR64_TRIPLE "spir64-unknown-unknown"
+#define SPIR32_DATALAYOUT                                         \
+  "e-p:32:32:32-i1:8:8-i8:8:8-i16:16:16-i32:32:32-i64:64:64-"     \
+  "f32:32:32-f64:64:64-v16:16:16-v24:32:32-v32:32:32-v48:64:64-"  \
+  "v64:64:64-v96:128:128-v128:128:128-v192:256:256-v256:256:256-" \
+  "v512:512:512-v1024:1024:1024"
+#define SPIR64_DATALAYOUT                                         \
+  "e-p:64:64:64-i1:8:8-i8:8:8-i16:16:16-i32:32:32-i64:64:64-"     \
+  "f32:32:32-f64:64:64-v16:16:16-v24:32:32-v32:32:32-v48:64:64-"  \
+  "v64:64:64-v96:128:128-v128:128:128-v192:256:256-v256:256:256-" \
+  "v512:512:512-v1024:1024:1024"
+
+/// These are manifest constants used by the bitcode writer. They do not need to
+/// be kept in sync with the reader, but need to be consistent within this file.
+enum {
+  // VALUE_SYMTAB_BLOCK abbrev id's.
+  VST_ENTRY_8_ABBREV = bitc::FIRST_APPLICATION_ABBREV,
+  VST_ENTRY_7_ABBREV,
+  VST_ENTRY_6_ABBREV,
+  VST_BBENTRY_6_ABBREV,
+
+  // CONSTANTS_BLOCK abbrev id's.
+  CONSTANTS_SETTYPE_ABBREV = bitc::FIRST_APPLICATION_ABBREV,
+  CONSTANTS_INTEGER_ABBREV,
+  CONSTANTS_CE_CAST_Abbrev,
+  CONSTANTS_NULL_Abbrev,
+
+  // FUNCTION_BLOCK abbrev id's.
+  FUNCTION_INST_LOAD_ABBREV = bitc::FIRST_APPLICATION_ABBREV,
+  FUNCTION_INST_BINOP_ABBREV,
+  FUNCTION_INST_BINOP_FLAGS_ABBREV,
+  FUNCTION_INST_CAST_ABBREV,
+  FUNCTION_INST_RET_VOID_ABBREV,
+  FUNCTION_INST_RET_VAL_ABBREV,
+  FUNCTION_INST_UNREACHABLE_ABBREV,
+  FUNCTION_INST_GEP_ABBREV BC38,
+
+  // SwitchInst Magic
+  SWITCH_INST_MAGIC = 0x4B5 // May 2012 => 1205 => Hex
+};
+
+static unsigned GetEncodedCastOpcode(unsigned Opcode) {
+  switch (Opcode) {
+  default: llvm_unreachable("Unknown cast instruction!");
+  case Instruction::Trunc   : return bitc::CAST_TRUNC;
+  case Instruction::ZExt    : return bitc::CAST_ZEXT;
+  case Instruction::SExt    : return bitc::CAST_SEXT;
+  case Instruction::FPToUI  : return bitc::CAST_FPTOUI;
+  case Instruction::FPToSI  : return bitc::CAST_FPTOSI;
+  case Instruction::UIToFP  : return bitc::CAST_UITOFP;
+  case Instruction::SIToFP  : return bitc::CAST_SITOFP;
+  case Instruction::FPTrunc : return bitc::CAST_FPTRUNC;
+  case Instruction::FPExt   : return bitc::CAST_FPEXT;
+  case Instruction::PtrToInt: return bitc::CAST_PTRTOINT;
+  case Instruction::IntToPtr: return bitc::CAST_INTTOPTR;
+  case Instruction::BitCast : return bitc::CAST_BITCAST;
+  case Instruction::AddrSpaceCast:
+    assert(false && "addrspacecast instructions must be filtered out before writing 3.2 bitcode");
+    llvm_unreachable("addrspacecast instructions must be filtered out before writing 3.2 bitcode");
+  }
+}
+
+static unsigned GetEncodedBinaryOpcode(unsigned Opcode) {
+  switch (Opcode) {
+  default: llvm_unreachable("Unknown binary instruction!");
+  case Instruction::Add:
+  case Instruction::FAdd: return bitc::BINOP_ADD;
+  case Instruction::Sub:
+  case Instruction::FSub: return bitc::BINOP_SUB;
+  case Instruction::Mul:
+  case Instruction::FMul: return bitc::BINOP_MUL;
+  case Instruction::UDiv: return bitc::BINOP_UDIV;
+  case Instruction::FDiv:
+  case Instruction::SDiv: return bitc::BINOP_SDIV;
+  case Instruction::URem: return bitc::BINOP_UREM;
+  case Instruction::FRem:
+  case Instruction::SRem: return bitc::BINOP_SREM;
+  case Instruction::Shl:  return bitc::BINOP_SHL;
+  case Instruction::LShr: return bitc::BINOP_LSHR;
+  case Instruction::AShr: return bitc::BINOP_ASHR;
+  case Instruction::And:  return bitc::BINOP_AND;
+  case Instruction::Or:   return bitc::BINOP_OR;
+  case Instruction::Xor:  return bitc::BINOP_XOR;
+  }
+}
+
+static unsigned GetEncodedRMWOperation(AtomicRMWInst::BinOp Op) {
+  switch (Op) {
+  default: llvm_unreachable("Unknown RMW operation!");
+  case AtomicRMWInst::Xchg: return bitc::RMW_XCHG;
+  case AtomicRMWInst::Add: return bitc::RMW_ADD;
+  case AtomicRMWInst::Sub: return bitc::RMW_SUB;
+  case AtomicRMWInst::And: return bitc::RMW_AND;
+  case AtomicRMWInst::Nand: return bitc::RMW_NAND;
+  case AtomicRMWInst::Or: return bitc::RMW_OR;
+  case AtomicRMWInst::Xor: return bitc::RMW_XOR;
+  case AtomicRMWInst::Max: return bitc::RMW_MAX;
+  case AtomicRMWInst::Min: return bitc::RMW_MIN;
+  case AtomicRMWInst::UMax: return bitc::RMW_UMAX;
+  case AtomicRMWInst::UMin: return bitc::RMW_UMIN;
+  }
+}
+
+static unsigned GetEncodedOrdering(AtomicOrdering Ordering) {
+  switch (Ordering) {
+  case AtomicOrdering::NotAtomic: return bitc::ORDERING_NOTATOMIC;
+  case AtomicOrdering::Unordered: return bitc::ORDERING_UNORDERED;
+  case AtomicOrdering::Monotonic: return bitc::ORDERING_MONOTONIC;
+  case AtomicOrdering::Acquire: return bitc::ORDERING_ACQUIRE;
+  case AtomicOrdering::Release: return bitc::ORDERING_RELEASE;
+  case AtomicOrdering::AcquireRelease: return bitc::ORDERING_ACQREL;
+  case AtomicOrdering::SequentiallyConsistent: return bitc::ORDERING_SEQCST;
+  }
+  llvm_unreachable("Invalid ordering");
+}
+
+static unsigned GetEncodedSynchScope(SynchronizationScope SynchScope) {
+  switch (SynchScope) {
+  case SingleThread: return bitc::SYNCHSCOPE_SINGLETHREAD;
+  case CrossThread: return bitc::SYNCHSCOPE_CROSSTHREAD;
+  }
+  llvm_unreachable("Invalid synch scope");
+}
+
+static void WriteStringRecord(unsigned Code, StringRef Str,
+                              unsigned AbbrevToUse, BitstreamWriter &Stream) {
+  SmallVector<unsigned, 64> Vals;
+
+  // Code: [strchar x N]
+  for (unsigned i = 0, e = Str.size(); i != e; ++i) {
+    if (AbbrevToUse && !BitCodeAbbrevOp::isChar6(Str[i]))
+      AbbrevToUse = 0;
+    Vals.push_back(Str[i]);
+  }
+
+  // Emit the finished record.
+  Stream.EmitRecord(Code, Vals, AbbrevToUse);
+}
+
+static uint64_t getAttrKindEncoding(Attribute::AttrKind Kind) {
+  // NOTE: these are the only parameter attributes supported by SPIR 1.2 (see "3.9 Parameter Attributes")
+  // NOTE: nocapture is technically supported as well, but leads to problems on certain implementations
+  switch (Kind) {
+  case Attribute::None:            return 0;
+  case Attribute::ZExt:            return 1 << 0;
+  case Attribute::SExt:            return 1 << 1;
+  case Attribute::StructRet:       return 1 << 4;
+  case Attribute::ByVal:           return 1 << 7;
+  default: return 0; // just drop the attr
+  }
+}
+
+static void WriteAttributeTable(const ValueEnumerator32 &VE,
+                                BitstreamWriter &Stream) {
+  const std::vector<AttributeSet> &Attrs = VE.getAttributes();
+  if (Attrs.empty()) return;
+
+  Stream.EnterSubblock(bitc::PARAMATTR_BLOCK_ID, 3);
+
+  SmallVector<uint64_t, 64> Record;
+  for (unsigned i = 0, e = Attrs.size(); i != e; ++i) {
+    const AttributeSet &A = Attrs[i];
+    for (unsigned i = 0, e = A.getNumSlots(); i != e; ++i) {
+      unsigned Slot = A.getSlotIndex(i);
+
+      // manual A.raw(Slot) so that we don't hit any asserts or unreachables (for attrs that have no raw representation)
+      // also: ignore 3.5+ style alignment, 3.2 style alignment is handled after this
+      uint64_t raw_attrs = 0;
+      AttributeSet attrs = A.getSlotAttributes(i);
+      for (auto attr_iter = attrs.begin(0), E = attrs.end(0); attr_iter != E; ++attr_iter) {
+        Attribute Attr = *attr_iter;
+        // can't handle non enum/int attrs
+        if (!Attr.isEnumAttribute() && !Attr.isIntAttribute()) continue;
+
+        Attribute::AttrKind Kind = Attr.getKindAsEnum();
+        if (Kind == Attribute::Alignment) { /* drop it */ }
+        else if (Kind == Attribute::StackAlignment) { /* drop it */ }
+        else if (Kind == Attribute::Dereferenceable) { /* drop it */ }
+        else raw_attrs |= getAttrKindEncoding(Kind);
+      }
+
+      // Taken from LLVM 3.2 Attributes::encodeLLVMAttributesForBitcode
+      uint64_t EncodedAttrs = raw_attrs & 0xffff;
+      if (A.hasAttribute(Slot, Attribute::Alignment))
+        EncodedAttrs |= A.getAttribute(Slot, Attribute::Alignment).getAlignment() << 16;
+      EncodedAttrs |= (raw_attrs & (0xffffULL << 21)) << 11;
+
+      Record.push_back(Slot);
+      Record.push_back(EncodedAttrs);
+    }
+
+    Stream.EmitRecord(bitc::PARAMATTR_CODE_ENTRY_OLD, Record);
+    Record.clear();
+  }
+
+  Stream.ExitBlock();
+}
+
+/// WriteTypeTable - Write out the type table for a module.
+static void WriteTypeTable(const ValueEnumerator32 &VE, BitstreamWriter &Stream) {
+  const ValueEnumerator32::TypeList &TypeList = VE.getTypes();
+
+  Stream.EnterSubblock(bitc::TYPE_BLOCK_ID_NEW, 4 /*count from # abbrevs */);
+  SmallVector<uint64_t, 64> TypeVals;
+
+  uint64_t NumBits = VE.computeBitsRequiredForTypeIndicies();
+
+  // Abbrev for TYPE_CODE_POINTER.
+  BitCodeAbbrev *Abbv = new BitCodeAbbrev();
+  Abbv->Add(BitCodeAbbrevOp(bitc::TYPE_CODE_POINTER));
+  Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, NumBits));
+  Abbv->Add(BitCodeAbbrevOp(0));  // Addrspace = 0
+  unsigned PtrAbbrev = Stream.EmitAbbrev(Abbv);
+
+  // Abbrev for TYPE_CODE_FUNCTION.
+  Abbv = new BitCodeAbbrev();
+  Abbv->Add(BitCodeAbbrevOp(bitc::TYPE_CODE_FUNCTION));
+  Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, 1));  // isvararg
+  Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Array));
+  Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, NumBits));
+
+  unsigned FunctionAbbrev = Stream.EmitAbbrev(Abbv);
+
+  // Abbrev for TYPE_CODE_STRUCT_ANON.
+  Abbv = new BitCodeAbbrev();
+  Abbv->Add(BitCodeAbbrevOp(bitc::TYPE_CODE_STRUCT_ANON));
+  Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, 1));  // ispacked
+  Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Array));
+  Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, NumBits));
+
+  unsigned StructAnonAbbrev = Stream.EmitAbbrev(Abbv);
+
+  // Abbrev for TYPE_CODE_STRUCT_NAME.
+  Abbv = new BitCodeAbbrev();
+  Abbv->Add(BitCodeAbbrevOp(bitc::TYPE_CODE_STRUCT_NAME));
+  Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Array));
+  Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Char6));
+  unsigned StructNameAbbrev = Stream.EmitAbbrev(Abbv);
+
+  // Abbrev for TYPE_CODE_STRUCT_NAMED.
+  Abbv = new BitCodeAbbrev();
+  Abbv->Add(BitCodeAbbrevOp(bitc::TYPE_CODE_STRUCT_NAMED));
+  Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, 1));  // ispacked
+  Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Array));
+  Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, NumBits));
+
+  unsigned StructNamedAbbrev = Stream.EmitAbbrev(Abbv);
+
+  // Abbrev for TYPE_CODE_ARRAY.
+  Abbv = new BitCodeAbbrev();
+  Abbv->Add(BitCodeAbbrevOp(bitc::TYPE_CODE_ARRAY));
+  Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::VBR, 8));   // size
+  Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, NumBits));
+
+  unsigned ArrayAbbrev = Stream.EmitAbbrev(Abbv);
+
+  // don't emit token types for 3.2
+  unsigned int ignored_types = 0;
+  for (const auto& type : TypeList) {
+    if (type->getTypeID() == Type::TokenTyID) {
+      ++ignored_types;
+    }
+  }
+
+  // Emit an entry count so the reader can reserve space.
+  TypeVals.push_back(TypeList.size() - ignored_types);
+  Stream.EmitRecord(bitc::TYPE_CODE_NUMENTRY, TypeVals);
+  TypeVals.clear();
+
+  // Loop over all of the types, emitting each in turn.
+  for (unsigned i = 0, e = TypeList.size(); i != e; ++i) {
+    Type *T = TypeList[i];
+    int AbbrevToUse = 0;
+    unsigned Code = 0;
+
+    // not in 3.2
+    if (T->getTypeID() == Type::TokenTyID) continue;
+
+    switch (T->getTypeID()) {
+    case Type::VoidTyID:      Code = bitc::TYPE_CODE_VOID;      break;
+    case Type::HalfTyID:      Code = bitc::TYPE_CODE_HALF;      break;
+    case Type::FloatTyID:     Code = bitc::TYPE_CODE_FLOAT;     break;
+    case Type::DoubleTyID:    Code = bitc::TYPE_CODE_DOUBLE;    break;
+    case Type::X86_FP80TyID:  Code = bitc::TYPE_CODE_X86_FP80;  break;
+    case Type::FP128TyID:     Code = bitc::TYPE_CODE_FP128;     break;
+    case Type::PPC_FP128TyID: Code = bitc::TYPE_CODE_PPC_FP128; break;
+    case Type::LabelTyID:     Code = bitc::TYPE_CODE_LABEL;     break;
+    case Type::MetadataTyID:  Code = bitc::TYPE_CODE_METADATA;  break;
+    case Type::X86_MMXTyID:   Code = bitc::TYPE_CODE_X86_MMX;   break;
+    case Type::TokenTyID: break; // already handled
+    case Type::IntegerTyID:
+      // INTEGER: [width]
+      Code = bitc::TYPE_CODE_INTEGER;
+      TypeVals.push_back(cast<IntegerType>(T)->getBitWidth());
+      break;
+    case Type::PointerTyID: {
+      PointerType *PTy = cast<PointerType>(T);
+      // POINTER: [pointee type, address space]
+      Code = bitc::TYPE_CODE_POINTER;
+      TypeVals.push_back(VE.getTypeID(PTy->getElementType()));
+      unsigned AddressSpace = PTy->getAddressSpace();
+      TypeVals.push_back(AddressSpace);
+      if (AddressSpace == 0) AbbrevToUse = PtrAbbrev;
+      break;
+    }
+    case Type::FunctionTyID: {
+      FunctionType *FT = cast<FunctionType>(T);
+      // FUNCTION: [isvararg, retty, paramty x N]
+      Code = bitc::TYPE_CODE_FUNCTION;
+      TypeVals.push_back(FT->isVarArg());
+      TypeVals.push_back(VE.getTypeID(FT->getReturnType()));
+      for (unsigned i = 0, e = FT->getNumParams(); i != e; ++i)
+        TypeVals.push_back(VE.getTypeID(FT->getParamType(i)));
+      AbbrevToUse = FunctionAbbrev;
+      break;
+    }
+    case Type::StructTyID: {
+      StructType *ST = cast<StructType>(T);
+      // STRUCT: [ispacked, eltty x N]
+      TypeVals.push_back(ST->isPacked());
+      // Output all of the element types.
+      for (StructType::element_iterator I = ST->element_begin(),
+           E = ST->element_end(); I != E; ++I)
+        TypeVals.push_back(VE.getTypeID(*I));
+
+      if (ST->isLiteral()) {
+        Code = bitc::TYPE_CODE_STRUCT_ANON;
+        AbbrevToUse = StructAnonAbbrev;
+      } else {
+        if (ST->isOpaque()) {
+          Code = bitc::TYPE_CODE_OPAQUE;
+        } else {
+          Code = bitc::TYPE_CODE_STRUCT_NAMED;
+          AbbrevToUse = StructNamedAbbrev;
+        }
+
+        // Emit the name if it is present.
+        if (!ST->getName().empty())
+          WriteStringRecord(bitc::TYPE_CODE_STRUCT_NAME, ST->getName(),
+                            StructNameAbbrev, Stream);
+      }
+      break;
+    }
+    case Type::ArrayTyID: {
+      ArrayType *AT = cast<ArrayType>(T);
+      // ARRAY: [numelts, eltty]
+      Code = bitc::TYPE_CODE_ARRAY;
+      TypeVals.push_back(AT->getNumElements());
+      TypeVals.push_back(VE.getTypeID(AT->getElementType()));
+      AbbrevToUse = ArrayAbbrev;
+      break;
+    }
+    case Type::VectorTyID: {
+      VectorType *VT = cast<VectorType>(T);
+      // VECTOR [numelts, eltty]
+      Code = bitc::TYPE_CODE_VECTOR;
+      TypeVals.push_back(VT->getNumElements());
+      TypeVals.push_back(VE.getTypeID(VT->getElementType()));
+      break;
+    }
+    }
+
+    // Emit the finished record.
+    Stream.EmitRecord(Code, TypeVals, AbbrevToUse);
+    TypeVals.clear();
+  }
+
+  Stream.ExitBlock();
+}
+
+static unsigned getEncodedLinkage(const GlobalValue &GV) {
+  switch (GV.getLinkage()) {
+  case GlobalValue::ExternalLinkage:                 return 0;
+  case GlobalValue::WeakAnyLinkage:                  return 1;
+  case GlobalValue::AppendingLinkage:                return 2;
+  case GlobalValue::InternalLinkage:                 return 3;
+  case GlobalValue::LinkOnceAnyLinkage:              return 4;
+  case GlobalValue::ExternalWeakLinkage:             return 7;
+  case GlobalValue::CommonLinkage:                   return 8;
+  case GlobalValue::PrivateLinkage:                  return 9;
+  case GlobalValue::WeakODRLinkage:                  return 10;
+  case GlobalValue::LinkOnceODRLinkage:              return 11;
+  case GlobalValue::AvailableExternallyLinkage:      return 12;
+  }
+  llvm_unreachable("Invalid linkage");
+}
+
+static unsigned getEncodedVisibility(const GlobalValue &GV) {
+  switch (GV.getVisibility()) {
+  case GlobalValue::DefaultVisibility:   return 0;
+  case GlobalValue::HiddenVisibility:    return 1;
+  case GlobalValue::ProtectedVisibility: return 2;
+  }
+  llvm_unreachable("Invalid visibility");
+}
+
+static unsigned getEncodedThreadLocalMode(const GlobalValue &GV) {
+  switch (GV.getThreadLocalMode()) {
+    case GlobalVariable::NotThreadLocal:         return 0;
+    case GlobalVariable::GeneralDynamicTLSModel: return 1;
+    case GlobalVariable::LocalDynamicTLSModel:   return 2;
+    case GlobalVariable::InitialExecTLSModel:    return 3;
+    case GlobalVariable::LocalExecTLSModel:      return 4;
+  }
+  llvm_unreachable("Invalid TLS model");
+}
+
+/// Emit top-level description of module, including target triple, inline asm,
+/// descriptors for global variables, and function prototype info.
+/// Returns the bit offset to backpatch with the location of the real VST.
+static uint64_t WriteModuleInfo(const Module *M, const ValueEnumerator32 &VE,
+                                BitstreamWriter &Stream) {
+  // always override target triple and data layout
+  const bool is_64_bit = (M->getTargetTriple().compare(0, 6, "spir64") == 0);
+  WriteStringRecord(bitc::MODULE_CODE_TRIPLE,
+                    is_64_bit ? SPIR64_TRIPLE : SPIR32_TRIPLE,
+                    0, Stream);
+  WriteStringRecord(bitc::MODULE_CODE_DATALAYOUT,
+                    is_64_bit ? SPIR64_DATALAYOUT : SPIR32_DATALAYOUT,
+                    0, Stream);
+
+  if (!M->getModuleInlineAsm().empty())
+    WriteStringRecord(bitc::MODULE_CODE_ASM, M->getModuleInlineAsm(),
+                      0/*TODO*/, Stream);
+
+  // Emit information about sections and GC, computing how many there are. Also
+  // compute the maximum alignment value.
+  std::map<std::string, unsigned> SectionMap;
+  std::map<std::string, unsigned> GCMap;
+  unsigned MaxAlignment = 0;
+  unsigned MaxGlobalType = 0;
+  for (const GlobalValue &GV : M->globals()) {
+    MaxAlignment = std::max(MaxAlignment, GV.getAlignment());
+    MaxGlobalType = std::max(MaxGlobalType, VE.getTypeID(GV.getType()));
+    if (GV.hasSection()) {
+      // Give section names unique ID's.
+      unsigned &Entry = SectionMap[GV.getSection()];
+      if (!Entry) {
+        WriteStringRecord(bitc::MODULE_CODE_SECTIONNAME, GV.getSection(),
+                          0/*TODO*/, Stream);
+        Entry = SectionMap.size();
+      }
+    }
+  }
+  for (const Function &F : *M) {
+    MaxAlignment = std::max(MaxAlignment, F.getAlignment());
+    if (F.hasSection()) {
+      // Give section names unique ID's.
+      unsigned &Entry = SectionMap[F.getSection()];
+      if (!Entry) {
+        WriteStringRecord(bitc::MODULE_CODE_SECTIONNAME, F.getSection(),
+                          0/*TODO*/, Stream);
+        Entry = SectionMap.size();
+      }
+    }
+    if (F.hasGC()) {
+      // Same for GC names.
+      unsigned &Entry = GCMap[F.getGC()];
+      if (!Entry) {
+        WriteStringRecord(bitc::MODULE_CODE_GCNAME, F.getGC(),
+                          0/*TODO*/, Stream);
+        Entry = GCMap.size();
+      }
+    }
+  }
+
+  // Emit abbrev for globals, now that we know # sections and max alignment.
+  unsigned SimpleGVarAbbrev = 0;
+  if (!M->global_empty()) {
+    // Add an abbrev for common globals with no visibility or thread localness.
+    BitCodeAbbrev *Abbv = new BitCodeAbbrev();
+    Abbv->Add(BitCodeAbbrevOp(bitc::MODULE_CODE_GLOBALVAR));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed,
+                              Log2_32_Ceil(MaxGlobalType+1)));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, 1));      // Constant.
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::VBR, 6));        // Initializer.
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, 4));      // Linkage.
+    if (MaxAlignment == 0)                                      // Alignment.
+      Abbv->Add(BitCodeAbbrevOp(0));
+    else {
+      unsigned MaxEncAlignment = Log2_32(MaxAlignment)+1;
+      Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed,
+                               Log2_32_Ceil(MaxEncAlignment+1)));
+    }
+    if (SectionMap.empty())                                    // Section.
+      Abbv->Add(BitCodeAbbrevOp(0));
+    else
+      Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed,
+                               Log2_32_Ceil(SectionMap.size()+1)));
+    // Don't bother emitting vis + thread local.
+    SimpleGVarAbbrev = Stream.EmitAbbrev(Abbv);
+  }
+
+  // Emit the global variable information.
+  SmallVector<unsigned, 64> Vals;
+  for (const GlobalVariable &GV : M->globals()) {
+    unsigned AbbrevToUse = 0;
+
+    // GLOBALVAR: [type, isconst, initid,
+    //             linkage, alignment, section, visibility, threadlocal,
+    //             unnamed_addr]
+    Vals.push_back(VE.getTypeID(GV.getType()));
+    Vals.push_back(GV.isConstant());
+    Vals.push_back(GV.isDeclaration() ? 0 :
+                   (VE.getValueID(GV.getInitializer()) + 1));
+    Vals.push_back(getEncodedLinkage(GV));
+    Vals.push_back(Log2_32(GV.getAlignment())+1);
+    Vals.push_back(GV.hasSection() ? SectionMap[GV.getSection()] : 0);
+    if (GV.isThreadLocal() ||
+        GV.getVisibility() != GlobalValue::DefaultVisibility ||
+        GV.hasGlobalUnnamedAddr()) {
+      Vals.push_back(getEncodedVisibility(GV));
+      Vals.push_back(getEncodedThreadLocalMode(GV));
+      Vals.push_back(GV.hasGlobalUnnamedAddr());
+    } else {
+      AbbrevToUse = SimpleGVarAbbrev;
+    }
+
+    Stream.EmitRecord(bitc::MODULE_CODE_GLOBALVAR, Vals, AbbrevToUse);
+    Vals.clear();
+  }
+
+  // Emit the function proto information.
+  for (const Function &F : *M) {
+    // FUNCTION:  [type, callingconv, isproto, linkage, paramattrs, alignment,
+    //             section, visibility, gc, unnamed_addr]
+    Vals.push_back(VE.getTypeID(F.getType()));
+    Vals.push_back(F.getCallingConv());
+    Vals.push_back(F.isDeclaration());
+    Vals.push_back(getEncodedLinkage(F));
+    Vals.push_back(VE.getAttributeID(F.getAttributes()));
+    Vals.push_back(Log2_32(F.getAlignment())+1);
+    Vals.push_back(F.hasSection() ? SectionMap[F.getSection()] : 0);
+    Vals.push_back(getEncodedVisibility(F));
+    Vals.push_back(F.hasGC() ? GCMap[F.getGC()] : 0);
+    Vals.push_back(F.hasGlobalUnnamedAddr());
+
+    unsigned AbbrevToUse = 0;
+    Stream.EmitRecord(bitc::MODULE_CODE_FUNCTION, Vals, AbbrevToUse);
+    Vals.clear();
+  }
+
+  // Emit the alias information.
+  for (const GlobalAlias &A : M->aliases()) {
+    // ALIAS: [alias type, aliasee val#, linkage, visibility]
+    Vals.push_back(VE.getTypeID(A.getType()));
+    Vals.push_back(VE.getValueID(A.getAliasee()));
+    Vals.push_back(getEncodedLinkage(A));
+    Vals.push_back(getEncodedVisibility(A));
+    unsigned AbbrevToUse = 0;
+    Stream.EmitRecord(bitc::MODULE_CODE_ALIAS_OLD, Vals, AbbrevToUse);
+    Vals.clear();
+  }
+
+  return 0;
+}
+
+static uint64_t GetOptimizationFlags(const Value *V) {
+  uint64_t Flags = 0;
+
+  if (const auto *OBO = dyn_cast<OverflowingBinaryOperator>(V)) {
+    if (OBO->hasNoSignedWrap())
+      Flags |= 1 << bitc::OBO_NO_SIGNED_WRAP;
+    if (OBO->hasNoUnsignedWrap())
+      Flags |= 1 << bitc::OBO_NO_UNSIGNED_WRAP;
+  } else if (const auto *PEO = dyn_cast<PossiblyExactOperator>(V)) {
+    if (PEO->isExact())
+      Flags |= 1 << bitc::PEO_EXACT;
+  }
+  // no fast math flags in 3.2
+
+  return Flags;
+}
+
+static void WriteValueAsMetadata(const ValueAsMetadata *MD,
+                                 const ValueEnumerator32 &VE,
+                                 BitstreamWriter &Stream,
+                                 SmallVectorImpl<uint64_t> &Record,
+                                 const bool func_local = false) {
+  // Mimic an MDNode with a value as one operand.
+  Value *V = MD->getValue();
+  Record.push_back(VE.getTypeID(V->getType()));
+  Record.push_back(VE.getValueID(V));
+  Stream.EmitRecord(!func_local ? bitc::METADATA_OLD_NODE : bitc::METADATA_OLD_FN_NODE, Record, 0);
+  Record.clear();
+}
+
+// NOTE: similar to WriteMDNode from 3.2 (however, no function-local in here!)
+static void WriteMDTuple(const MDTuple *N, const ValueEnumerator32 &VE,
+                         BitstreamWriter &Stream,
+                         SmallVectorImpl<uint64_t> &Record, unsigned Abbrev) {
+  for (unsigned i = 0, e = N->getNumOperands(); i != e; ++i) {
+    const Metadata* op = N->getOperand(i);
+    if (op == nullptr) {
+      Record.push_back(VE.getTypeID(Type::getVoidTy(N->getContext())));
+      Record.push_back(0);
+      continue;
+    }
+    
+    switch (op->getMetadataID()) {
+      case Metadata::LocalAsMetadataKind:
+        assert(false && "Unexpected function-local metadata");
+        break;
+      case Metadata::ConstantAsMetadataKind: {
+        auto V = dyn_cast<ConstantAsMetadata>(op)->getValue();
+        Record.push_back(VE.getTypeID(V->getType()));
+        Record.push_back(VE.getValueID(V));
+        break;
+      }
+      default:
+        Record.push_back(VE.getTypeID(Type::getMetadataTy(N->getContext())));
+        Record.push_back(VE.getMetadataID(op));
+        break;
+    }
+  }
+  Stream.EmitRecord(bitc::METADATA_OLD_NODE, Record, Abbrev);
+  Record.clear();
+}
+
+// DI* helper functions/macros
+static void WriteDI_UNIMPLEMENTED(BitstreamWriter &Stream) {
+  SmallVector<uint64_t, 1> empty_record;
+  Stream.EmitRecord(bitc::METADATA_OLD_NODE, empty_record, 0);
+}
+
+#define DI_TYPE_I1() Record.push_back(VE.getTypeID(Type::getInt1Ty(N->getContext())))
+#define DI_I1(val) { DI_TYPE_I1(); Record.push_back(VE.getValueID(ConstantInt::get(llvm::Type::getInt1Ty(N->getContext()), val))); }
+
+#define DI_TYPE_I32() Record.push_back(VE.getTypeID(Type::getInt32Ty(N->getContext())))
+#define DI_I32(val) { DI_TYPE_I32(); Record.push_back(VE.getValueID(ConstantInt::get(llvm::Type::getInt32Ty(N->getContext()), val))); }
+
+#define DI_TYPE_I64() Record.push_back(VE.getTypeID(Type::getInt64Ty(N->getContext())))
+#define DI_I64(val) { DI_TYPE_I64(); Record.push_back(VE.getValueID(ConstantInt::get(llvm::Type::getInt64Ty(N->getContext()), val))); }
+
+#define DI_TYPE_META() Record.push_back(VE.getTypeID(Type::getMetadataTy(N->getContext())))
+#define DI_META(val) { DI_TYPE_META(); Record.push_back(VE.getMetadataID(val)); }
+
+#define DI_TYPE_VOID() Record.push_back(VE.getTypeID(Type::getVoidTy(N->getContext())))
+#define DI_NULL() { DI_TYPE_VOID(); Record.push_back(0); }
+
+#define DI_FUNC(func) { Record.push_back(VE.getTypeID(func->getType())); Record.push_back(VE.getValueID(func)); }
+
+#define DI_TAG(tag) { DI_TYPE_I32(); Record.push_back(VE.getValueID(GetTagConstant(N->getContext(), tag))); }
+
+#define DI_META_OR_NULL(val) if(val) DI_META(val) else DI_NULL()
+
+// from 3.2 DIBuilder.cpp
+static Constant *GetTagConstant(LLVMContext &VMContext, unsigned Tag) {
+  assert((Tag & 0xffff0000 /* LLVMDebugVersionMask */) == 0 &&
+         "Tag too large for debug encoding!");
+  return ConstantInt::get(Type::getInt32Ty(VMContext), Tag | (12 << 16) /* LLVMDebugVersion */);
+}
+
+static void WriteDILocation(const DILocation *N, const ValueEnumerator32 &VE,
+                            BitstreamWriter &Stream,
+                            SmallVectorImpl<uint64_t> &Record,
+                            unsigned Abbrev) {
+  DI_I32(N->getLine());
+  DI_I32(N->getColumn());
+  DI_META(N->getScope());
+  DI_META_OR_NULL(N->getInlinedAt());
+
+  Stream.EmitRecord(bitc::METADATA_OLD_NODE, Record, Abbrev);
+  Record.clear();
+}
+
+// NOTE: not in 3.2
+static void WriteGenericDINode(const GenericDINode *,
+                               const ValueEnumerator32 &,
+                               BitstreamWriter &Stream,
+                               SmallVectorImpl<uint64_t> &,
+                               unsigned) {
+  WriteDI_UNIMPLEMENTED(Stream);
+}
+
+#if 0
+static uint64_t rotateSign(int64_t I) {
+  uint64_t U = I;
+  return I < 0 ? ~(U << 1) : U << 1;
+}
+#endif
+
+static void WriteDISubrange(const DISubrange *N, const ValueEnumerator32 &,
+                            BitstreamWriter &Stream,
+                            SmallVectorImpl<uint64_t> &Record,
+                            unsigned Abbrev) {
+#if 1
+  WriteDI_UNIMPLEMENTED(Stream);
+#else
+  Record.push_back(N->getCount());
+  Record.push_back(rotateSign(N->getLowerBound()));
+
+  Stream.EmitRecord(bitc::METADATA_OLD_NODE, Record, Abbrev);
+  Record.clear();
+#endif
+}
+
+static void WriteDIEnumerator(const DIEnumerator *N, const ValueEnumerator32 &VE,
+                              BitstreamWriter &Stream,
+                              SmallVectorImpl<uint64_t> &Record,
+                              unsigned Abbrev) {
+#if 1
+  WriteDI_UNIMPLEMENTED(Stream);
+#else
+  Record.push_back(rotateSign(N->getValue()));
+  Record.push_back(VE.getMetadataOrNullID(N->getRawName()));
+
+  Stream.EmitRecord(bitc::METADATA_OLD_NODE, Record, Abbrev);
+  Record.clear();
+#endif
+}
+
+static void WriteDIBasicType(const DIBasicType *N, const ValueEnumerator32 &VE,
+                             BitstreamWriter &Stream,
+                             SmallVectorImpl<uint64_t> &Record,
+                             unsigned Abbrev) {
+#if 1
+  WriteDI_UNIMPLEMENTED(Stream);
+#else
+  Record.push_back(N->getTag());
+  Record.push_back(VE.getMetadataOrNullID(N->getRawName()));
+  Record.push_back(N->getSizeInBits());
+  Record.push_back(N->getAlignInBits());
+  Record.push_back(N->getEncoding());
+
+  Stream.EmitRecord(bitc::METADATA_OLD_NODE, Record, Abbrev);
+  Record.clear();
+#endif
+}
+
+static void WriteDIDerivedType(const DIDerivedType *N,
+                               const ValueEnumerator32 &VE,
+                               BitstreamWriter &Stream,
+                               SmallVectorImpl<uint64_t> &Record,
+                               unsigned Abbrev) {
+#if 1
+  WriteDI_UNIMPLEMENTED(Stream);
+#else
+  Record.push_back(N->getTag());
+  Record.push_back(VE.getMetadataOrNullID(N->getRawName()));
+  Record.push_back(VE.getMetadataOrNullID(N->getFile()));
+  Record.push_back(N->getLine());
+  Record.push_back(VE.getMetadataOrNullID(N->getScope()));
+  Record.push_back(VE.getMetadataOrNullID(N->getBaseType()));
+  Record.push_back(N->getSizeInBits());
+  Record.push_back(N->getAlignInBits());
+  Record.push_back(N->getOffsetInBits());
+  Record.push_back(N->getFlags());
+  Record.push_back(VE.getMetadataOrNullID(N->getExtraData()));
+
+  Stream.EmitRecord(bitc::METADATA_OLD_NODE, Record, Abbrev);
+  Record.clear();
+#endif
+}
+
+static void WriteDICompositeType(const DICompositeType *N,
+                                 const ValueEnumerator32 &VE,
+                                 BitstreamWriter &Stream,
+                                 SmallVectorImpl<uint64_t> &Record,
+                                 unsigned Abbrev) {
+#if 1
+  WriteDI_UNIMPLEMENTED(Stream);
+#else
+  Record.push_back(N->getTag());
+  Record.push_back(VE.getMetadataOrNullID(N->getRawName()));
+  Record.push_back(VE.getMetadataOrNullID(N->getFile()));
+  Record.push_back(N->getLine());
+  Record.push_back(VE.getMetadataOrNullID(N->getScope()));
+  Record.push_back(VE.getMetadataOrNullID(N->getBaseType()));
+  Record.push_back(N->getSizeInBits());
+  Record.push_back(N->getAlignInBits());
+  Record.push_back(N->getOffsetInBits());
+  Record.push_back(N->getFlags());
+  Record.push_back(VE.getMetadataOrNullID(N->getElements().get()));
+  Record.push_back(N->getRuntimeLang());
+  Record.push_back(VE.getMetadataOrNullID(N->getVTableHolder()));
+  Record.push_back(VE.getMetadataOrNullID(N->getTemplateParams().get()));
+  Record.push_back(VE.getMetadataOrNullID(N->getRawIdentifier()));
+
+  Stream.EmitRecord(bitc::METADATA_OLD_NODE, Record, Abbrev);
+  Record.clear();
+#endif
+}
+
+static void WriteDISubroutineType(const DISubroutineType *N,
+                                  const ValueEnumerator32 &VE,
+                                  BitstreamWriter &Stream,
+                                  SmallVectorImpl<uint64_t> &Record,
+                                  unsigned Abbrev) {
+  DI_TAG(dwarf::DW_TAG_subroutine_type);
+
+  DI_I32(0);
+  DI_NULL();
+  auto empty_str_node = MDString::get(N->getContext(), "");
+  DI_META(empty_str_node);
+  DI_I32(0);
+  DI_I64(0);
+  DI_I64(0);
+  DI_I64(0);
+  DI_I32(N->getFlags());
+  DI_NULL();
+  DI_META_OR_NULL(N->getTypeArray().get());
+  DI_I32(0);
+  DI_NULL();
+  DI_NULL();
+  DI_NULL();
+
+  Stream.EmitRecord(bitc::METADATA_OLD_NODE, Record, Abbrev);
+  Record.clear();
+}
+
+static void WriteDIFile(const DIFile *N, const ValueEnumerator32 &VE,
+                        BitstreamWriter &Stream,
+                        SmallVectorImpl<uint64_t> &Record, unsigned Abbrev) {
+  // NOTE: { file, dir } node will already have been written
+  DI_TAG(dwarf::DW_TAG_file_type);
+
+  DI_META(N->contained_node);
+
+  Stream.EmitRecord(bitc::METADATA_OLD_NODE, Record, Abbrev);
+  Record.clear();
+}
+
+static void WriteDICompileUnit(const DICompileUnit *N,
+                               const ValueEnumerator32 &VE,
+                               BitstreamWriter &Stream,
+                               SmallVectorImpl<uint64_t> &Record,
+                               unsigned Abbrev) {
+  assert(N->isDistinct() && "Expected distinct compile units");
+
+  DI_TAG(dwarf::DW_TAG_compile_unit);
+
+  if (N->getFile()) {
+    // not an actual DIFile node, but directly points to a { file, dir } node
+    DI_META(N->getFile()->contained_node);
+  } else DI_NULL()
+
+  DI_I32(N->getSourceLanguage());
+  DI_META_OR_NULL(N->getRawProducer());
+  DI_I1(N->isOptimized());
+  DI_META_OR_NULL(N->getRawFlags());
+  DI_I32(N->getRuntimeVersion());
+  DI_META_OR_NULL(N->getEnumTypes().get());
+  DI_META_OR_NULL(N->getRetainedTypes().get());
+  DI_META_OR_NULL(/*N->getSubprograms().get()*/ nullptr); // TODO: fix this, subprogram <-> cu ownership switched in 3.9
+  DI_META_OR_NULL(N->getGlobalVariables().get());
+  DI_META_OR_NULL(N->getImportedEntities().get());
+  DI_META_OR_NULL(N->getRawSplitDebugFilename());
+  DI_I32(N->getEmissionKind());
+  // NOTE: no macros or dwarf id
+
+  Stream.EmitRecord(bitc::METADATA_OLD_NODE, Record, Abbrev);
+  Record.clear();
+}
+
+static void WriteDISubprogram(const DISubprogram *N, const ValueEnumerator32 &VE,
+                              BitstreamWriter &Stream,
+                              SmallVectorImpl<uint64_t> &Record,
+                              unsigned Abbrev) {
+  DI_TAG(dwarf::DW_TAG_subprogram);
+
+  DI_META_OR_NULL(N->getFile());
+  DI_META_OR_NULL(N->getScope());
+  DI_META_OR_NULL(N->getRawName());
+  DI_META_OR_NULL(N->getRawName());
+  DI_META_OR_NULL(N->getRawLinkageName());
+  DI_I32(N->getLine());
+  DI_META_OR_NULL(N->getType());
+  DI_I1(N->isLocalToUnit());
+  DI_I1(N->isDefinition());
+  DI_I32(N->getVirtuality());
+  DI_I32(N->getVirtualIndex());
+  DI_META_OR_NULL(N->getContainingType());
+  DI_I32(N->getFlags());
+  DI_I1(N->isOptimized());
+  if (N->associated_function) {
+    DI_FUNC(N->associated_function);
+  }
+  else DI_NULL();
+  DI_META_OR_NULL(N->getTemplateParams().get());
+  DI_META_OR_NULL(N->getDeclaration());
+  // TODO: always pointing to an empty node if non-existent?
+  if (N->getVariables()) {
+    DI_META(N->getVariables().get());
+  }
+  else {
+    auto empty_node = MDTuple::getTemporary(N->getContext(), {});
+    DI_META(empty_node.get());
+  }
+  DI_I32(N->getScopeLine());
+
+  Stream.EmitRecord(bitc::METADATA_OLD_NODE, Record, Abbrev);
+  Record.clear();
+}
+
+static void WriteDILexicalBlock(const DILexicalBlock *N,
+                                const ValueEnumerator32 &VE,
+                                BitstreamWriter &Stream,
+                                SmallVectorImpl<uint64_t> &Record,
+                                unsigned Abbrev) {
+  DI_TAG(dwarf::DW_TAG_lexical_block);
+
+  static unsigned int unique_id = 0;
+  DI_META_OR_NULL(N->getFile());
+  DI_META_OR_NULL(N->getScope());
+  DI_I32(N->getLine());
+  DI_I32(N->getColumn());
+  DI_I32(0); // NOTE: no discriminator (also 0 in 3.2)
+  DI_I32(unique_id++);
+
+  Stream.EmitRecord(bitc::METADATA_OLD_NODE, Record, Abbrev);
+  Record.clear();
+}
+
+static void WriteDILexicalBlockFile(const DILexicalBlockFile *N,
+                                    const ValueEnumerator32 &VE,
+                                    BitstreamWriter &Stream,
+                                    SmallVectorImpl<uint64_t> &Record,
+                                    unsigned Abbrev) {
+#if 1
+  WriteDI_UNIMPLEMENTED(Stream);
+#else
+  Record.push_back(VE.getMetadataOrNullID(N->getScope()));
+  Record.push_back(VE.getMetadataOrNullID(N->getFile()));
+  Record.push_back(N->getDiscriminator());
+
+  Stream.EmitRecord(bitc::METADATA_OLD_NODE, Record, Abbrev);
+  Record.clear();
+#endif
+}
+
+static void WriteDINamespace(const DINamespace *N, const ValueEnumerator32 &VE,
+                             BitstreamWriter &Stream,
+                             SmallVectorImpl<uint64_t> &Record,
+                             unsigned Abbrev) {
+#if 1
+  WriteDI_UNIMPLEMENTED(Stream);
+#else
+  Record.push_back(VE.getMetadataOrNullID(N->getScope()));
+  Record.push_back(VE.getMetadataOrNullID(N->getFile()));
+  Record.push_back(VE.getMetadataOrNullID(N->getRawName()));
+  Record.push_back(N->getLine());
+
+  Stream.EmitRecord(bitc::METADATA_OLD_NODE, Record, Abbrev);
+  Record.clear();
+#endif
+}
+
+// NOTE: not in 3.2
+static void WriteDIMacro(const DIMacro *, const ValueEnumerator32 &,
+                         BitstreamWriter &Stream,
+                         SmallVectorImpl<uint64_t> &, unsigned) {
+  WriteDI_UNIMPLEMENTED(Stream);
+}
+
+// NOTE: not in 3.2
+static void WriteDIMacroFile(const DIMacroFile *, const ValueEnumerator32 &,
+                             BitstreamWriter &Stream,
+                             SmallVectorImpl<uint64_t> &,
+                             unsigned) {
+  WriteDI_UNIMPLEMENTED(Stream);
+}
+
+// NOTE: not in 3.2
+static void WriteDIModule(const DIModule *, const ValueEnumerator32 &,
+                          BitstreamWriter &Stream,
+                          SmallVectorImpl<uint64_t> &, unsigned ) {
+  WriteDI_UNIMPLEMENTED(Stream);
+}
+
+static void WriteDITemplateTypeParameter(const DITemplateTypeParameter *N,
+                                         const ValueEnumerator32 &VE,
+                                         BitstreamWriter &Stream,
+                                         SmallVectorImpl<uint64_t> &Record,
+                                         unsigned Abbrev) {
+#if 1
+  WriteDI_UNIMPLEMENTED(Stream);
+#else
+  Record.push_back(VE.getMetadataOrNullID(N->getRawName()));
+  Record.push_back(VE.getMetadataOrNullID(N->getType()));
+
+  Stream.EmitRecord(bitc::METADATA_OLD_NODE, Record, Abbrev);
+  Record.clear();
+#endif
+}
+
+static void WriteDITemplateValueParameter(const DITemplateValueParameter *N,
+                                          const ValueEnumerator32 &VE,
+                                          BitstreamWriter &Stream,
+                                          SmallVectorImpl<uint64_t> &Record,
+                                          unsigned Abbrev) {
+#if 1
+  WriteDI_UNIMPLEMENTED(Stream);
+#else
+  Record.push_back(N->getTag());
+  Record.push_back(VE.getMetadataOrNullID(N->getRawName()));
+  Record.push_back(VE.getMetadataOrNullID(N->getType()));
+  Record.push_back(VE.getMetadataOrNullID(N->getValue()));
+
+  Stream.EmitRecord(bitc::METADATA_OLD_NODE, Record, Abbrev);
+  Record.clear();
+#endif
+}
+
+static void WriteDIGlobalVariable(const DIGlobalVariable *N,
+                                  const ValueEnumerator32 &VE,
+                                  BitstreamWriter &Stream,
+                                  SmallVectorImpl<uint64_t> &Record,
+                                  unsigned Abbrev) {
+#if 1
+  WriteDI_UNIMPLEMENTED(Stream);
+#else
+  Record.push_back(VE.getMetadataOrNullID(N->getScope()));
+  Record.push_back(VE.getMetadataOrNullID(N->getRawName()));
+  Record.push_back(VE.getMetadataOrNullID(N->getRawLinkageName()));
+  Record.push_back(VE.getMetadataOrNullID(N->getFile()));
+  Record.push_back(N->getLine());
+  Record.push_back(VE.getMetadataOrNullID(N->getType()));
+  Record.push_back(N->isLocalToUnit());
+  Record.push_back(N->isDefinition());
+  Record.push_back(VE.getMetadataOrNullID(N->getRawVariable()));
+  Record.push_back(VE.getMetadataOrNullID(N->getStaticDataMemberDeclaration()));
+
+  Stream.EmitRecord(bitc::METADATA_OLD_NODE, Record, Abbrev);
+  Record.clear();
+#endif
+}
+
+// NOTE: not in 3.2
+static void WriteDILocalVariable(const DILocalVariable *,
+                                 const ValueEnumerator32 &,
+                                 BitstreamWriter &Stream,
+                                 SmallVectorImpl<uint64_t> &,
+                                 unsigned) {
+  WriteDI_UNIMPLEMENTED(Stream);
+}
+
+// NOTE: not in 3.2
+static void WriteDIExpression(const DIExpression *, const ValueEnumerator32 &,
+                              BitstreamWriter &Stream,
+                              SmallVectorImpl<uint64_t> &,
+                              unsigned) {
+  WriteDI_UNIMPLEMENTED(Stream);
+}
+
+// NOTE: not supported, since there is no objective-c
+static void WriteDIObjCProperty(const DIObjCProperty *,
+                                const ValueEnumerator32 &,
+                                BitstreamWriter &Stream,
+                                SmallVectorImpl<uint64_t> &,
+                                unsigned) {
+  WriteDI_UNIMPLEMENTED(Stream);
+}
+
+static void WriteDIImportedEntity(const DIImportedEntity *N,
+                                  const ValueEnumerator32 &VE,
+                                  BitstreamWriter &Stream,
+                                  SmallVectorImpl<uint64_t> &Record,
+                                  unsigned Abbrev) {
+#if 1
+  WriteDI_UNIMPLEMENTED(Stream);
+#else
+  Record.push_back(N->getTag());
+  Record.push_back(VE.getMetadataOrNullID(N->getScope()));
+  Record.push_back(VE.getMetadataOrNullID(N->getEntity()));
+  Record.push_back(N->getLine());
+  Record.push_back(VE.getMetadataOrNullID(N->getRawName()));
+
+  Stream.EmitRecord(bitc::METADATA_OLD_NODE, Record, Abbrev);
+  Record.clear();
+#endif
+}
+
+static void WriteModuleMetadata(const Module *M,
+                                const ValueEnumerator32 &VE,
+                                BitstreamWriter &Stream) {
+  const auto &MDs = VE.getMDs();
+  if (MDs.empty() && M->named_metadata_empty())
+    return;
+
+  // NOTE: always present with AIR/SPIR (no need for StartedMetadataBlock)
+  Stream.EnterSubblock(bitc::METADATA_BLOCK_ID, 3);
+
+  unsigned MDSAbbrev = 0;
+  if (VE.hasMDString()) {
+    // Abbrev for METADATA_STRING_OLD.
+    BitCodeAbbrev *Abbv = new BitCodeAbbrev();
+    Abbv->Add(BitCodeAbbrevOp(bitc::METADATA_STRING_OLD));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Array));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, 8));
+    MDSAbbrev = Stream.EmitAbbrev(Abbv);
+  }
+
+  SmallVector<uint64_t, 64> Record;
+  for (const Metadata *MD : MDs) {
+    if (const MDNode *N = dyn_cast<MDNode>(MD)) {
+      assert(N->isResolved() && "Expected forward references to be resolved");
+
+      // NOTE: no function-local in here
+      // NOTE: no abbreviations in here
+      switch (N->getMetadataID()) {
+      default:
+        llvm_unreachable("Invalid MDNode subclass");
+#define HANDLE_MDNODE_LEAF(CLASS)                                              \
+  case Metadata::CLASS##Kind:                                                  \
+    Write##CLASS(cast<CLASS>(N), VE, Stream, Record, 0);                       \
+    continue;
+#include "llvm/IR/Metadata.def"
+      }
+    } else if (const auto *MDC = dyn_cast<ConstantAsMetadata>(MD)) {
+      WriteValueAsMetadata(MDC, VE, Stream, Record);
+    } else if (const MDString *MDS = dyn_cast<MDString>(MD)) {
+      // Code: [strchar x N]
+      Record.append(MDS->bytes_begin(), MDS->bytes_end());
+
+      // Emit the finished record.
+      Stream.EmitRecord(bitc::METADATA_STRING_OLD, Record, MDSAbbrev);
+      Record.clear();
+    } else {
+      assert(false && "unhandled MD type");
+    }
+  }
+
+  // Write named metadata.
+  for (const NamedMDNode &NMD : M->named_metadata()) {
+    // Write name.
+    StringRef Str = NMD.getName();
+    Record.append(Str.bytes_begin(), Str.bytes_end());
+    Stream.EmitRecord(bitc::METADATA_NAME, Record, 0);
+    Record.clear();
+
+    // Write named metadata operands.
+    for (const MDNode *N : NMD.operands())
+      Record.push_back(VE.getMetadataID(N));
+    Stream.EmitRecord(bitc::METADATA_NAMED_NODE, Record, 0);
+    Record.clear();
+  }
+
+  Stream.ExitBlock();
+}
+
+static void WriteFunctionLocalMetadata(const Function &F,
+                                       const ValueEnumerator32 &VE,
+                                       BitstreamWriter &Stream) {
+  bool StartedMetadataBlock = false;
+  SmallVector<uint64_t, 64> Record;
+  const SmallVectorImpl<const LocalAsMetadata *> &MDs =
+      VE.getFunctionLocalMDs();
+  for (unsigned i = 0, e = MDs.size(); i != e; ++i) {
+    assert(MDs[i] && "Expected valid function-local metadata");
+    if (!StartedMetadataBlock) {
+      Stream.EnterSubblock(bitc::METADATA_BLOCK_ID, 3);
+      StartedMetadataBlock = true;
+    }
+    WriteValueAsMetadata(MDs[i], VE, Stream, Record, true);
+  }
+
+  if (StartedMetadataBlock)
+    Stream.ExitBlock();
+}
+
+static void WriteMetadataAttachment(const Function &F,
+                                    const ValueEnumerator32 &VE,
+                                    BitstreamWriter &Stream) {
+  Stream.EnterSubblock(bitc::METADATA_ATTACHMENT_ID, 3);
+
+  SmallVector<uint64_t, 64> Record;
+
+  // Write metadata attachments
+  // METADATA_ATTACHMENT - [m x [value, [n x [id, mdnode]]]
+  SmallVector<std::pair<unsigned, MDNode *>, 4> MDs;
+
+  for (const BasicBlock &BB : F)
+    for (const Instruction &I : BB) {
+      MDs.clear();
+      I.getAllMetadataOtherThanDebugLoc(MDs);
+
+      // If no metadata, ignore instruction.
+      if (MDs.empty()) continue;
+
+      Record.push_back(VE.getInstructionID(&I));
+
+      for (unsigned i = 0, e = MDs.size(); i != e; ++i) {
+        Record.push_back(MDs[i].first);
+        Record.push_back(VE.getMetadataID(MDs[i].second));
+      }
+      Stream.EmitRecord(bitc::METADATA_ATTACHMENT, Record, 0);
+      Record.clear();
+    }
+
+  Stream.ExitBlock();
+}
+
+static void WriteModuleMetadataStore(const Module *M, BitstreamWriter &Stream) {
+  SmallVector<uint64_t, 64> Record;
+
+  // Write metadata kinds
+  // METADATA_KIND - [n x [id, name]]
+  SmallVector<StringRef, 8> Names;
+  M->getMDKindNames(Names);
+
+  if (Names.empty()) return;
+
+  Stream.EnterSubblock(bitc::METADATA_BLOCK_ID, 3);
+
+  for (unsigned MDKindID = 0, e = Names.size(); MDKindID != e; ++MDKindID) {
+    Record.push_back(MDKindID);
+    StringRef KName = Names[MDKindID];
+    Record.append(KName.begin(), KName.end());
+
+    Stream.EmitRecord(bitc::METADATA_KIND, Record, 0);
+    Record.clear();
+  }
+
+  Stream.ExitBlock();
+}
+
+static void emitSignedInt64(SmallVectorImpl<uint64_t> &Vals, uint64_t V) {
+  if ((int64_t)V >= 0)
+    Vals.push_back(V << 1);
+  else
+    Vals.push_back((-V << 1) | 1);
+}
+
+static void EmitAPInt(SmallVectorImpl<uint64_t> &Vals,
+                      unsigned &Code, unsigned &AbbrevToUse, const APInt &Val,
+                      bool EmitSizeForWideNumbers = false) {
+  if (Val.getBitWidth() <= 64) {
+    uint64_t V = Val.getSExtValue();
+    emitSignedInt64(Vals, V);
+    Code = bitc::CST_CODE_INTEGER;
+    AbbrevToUse = CONSTANTS_INTEGER_ABBREV;
+  } else {
+    // Wide integers, > 64 bits in size.
+    // We have an arbitrary precision integer value to write whose
+    // bit width is > 64. However, in canonical unsigned integer
+    // format it is likely that the high bits are going to be zero.
+    // So, we only write the number of active words.
+    unsigned NWords = Val.getActiveWords();
+
+    if (EmitSizeForWideNumbers)
+      Vals.push_back(NWords);
+
+    const uint64_t *RawWords = Val.getRawData();
+    for (unsigned i = 0; i != NWords; ++i) {
+      emitSignedInt64(Vals, RawWords[i]);
+    }
+    Code = bitc::CST_CODE_WIDE_INTEGER;
+  }
+}
+
+static void WriteConstants(unsigned FirstVal, unsigned LastVal,
+                           const ValueEnumerator32 &VE,
+                           BitstreamWriter &Stream, bool isGlobal) {
+  if (FirstVal == LastVal) return;
+
+  Stream.EnterSubblock(bitc::CONSTANTS_BLOCK_ID, 4);
+
+  unsigned AggregateAbbrev = 0;
+  unsigned String8Abbrev = 0;
+  unsigned CString7Abbrev = 0;
+  unsigned CString6Abbrev = 0;
+  // If this is a constant pool for the module, emit module-specific abbrevs.
+  if (isGlobal) {
+    // Abbrev for CST_CODE_AGGREGATE.
+    BitCodeAbbrev *Abbv = new BitCodeAbbrev();
+    Abbv->Add(BitCodeAbbrevOp(bitc::CST_CODE_AGGREGATE));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Array));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, Log2_32_Ceil(LastVal+1)));
+    AggregateAbbrev = Stream.EmitAbbrev(Abbv);
+
+    // Abbrev for CST_CODE_STRING.
+    Abbv = new BitCodeAbbrev();
+    Abbv->Add(BitCodeAbbrevOp(bitc::CST_CODE_STRING));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Array));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, 8));
+    String8Abbrev = Stream.EmitAbbrev(Abbv);
+    // Abbrev for CST_CODE_CSTRING.
+    Abbv = new BitCodeAbbrev();
+    Abbv->Add(BitCodeAbbrevOp(bitc::CST_CODE_CSTRING));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Array));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, 7));
+    CString7Abbrev = Stream.EmitAbbrev(Abbv);
+    // Abbrev for CST_CODE_CSTRING.
+    Abbv = new BitCodeAbbrev();
+    Abbv->Add(BitCodeAbbrevOp(bitc::CST_CODE_CSTRING));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Array));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Char6));
+    CString6Abbrev = Stream.EmitAbbrev(Abbv);
+  }
+
+  SmallVector<uint64_t, 64> Record;
+
+  const ValueEnumerator32::ValueList &Vals = VE.getValues();
+  Type *LastTy = nullptr;
+  for (unsigned i = FirstVal; i != LastVal; ++i) {
+    const Value *V = Vals[i].first;
+    // If we need to switch types, do so now.
+    if (V->getType() != LastTy) {
+      LastTy = V->getType();
+      Record.push_back(VE.getTypeID(LastTy));
+      Stream.EmitRecord(bitc::CST_CODE_SETTYPE, Record,
+                        CONSTANTS_SETTYPE_ABBREV);
+      Record.clear();
+    }
+
+    if (const InlineAsm *IA = dyn_cast<InlineAsm>(V)) {
+      Record.push_back(unsigned(IA->hasSideEffects()) |
+                       unsigned(IA->isAlignStack()) << 1 |
+                       unsigned(IA->getDialect()&1) << 2);
+
+      // Add the asm string.
+      const std::string &AsmStr = IA->getAsmString();
+      Record.push_back(AsmStr.size());
+      Record.append(AsmStr.begin(), AsmStr.end());
+
+      // Add the constraint string.
+      const std::string &ConstraintStr = IA->getConstraintString();
+      Record.push_back(ConstraintStr.size());
+      Record.append(ConstraintStr.begin(), ConstraintStr.end());
+      Stream.EmitRecord(bitc::CST_CODE_INLINEASM, Record);
+      Record.clear();
+      continue;
+    }
+    const Constant *C = cast<Constant>(V);
+    unsigned Code = -1U;
+    unsigned AbbrevToUse = 0;
+    if (C->isNullValue()) {
+      Code = bitc::CST_CODE_NULL;
+    } else if (isa<UndefValue>(C)) {
+      Code = bitc::CST_CODE_UNDEF;
+    } else if (const ConstantInt *IV = dyn_cast<ConstantInt>(C)) {
+      EmitAPInt(Record, Code, AbbrevToUse, IV->getValue());
+    } else if (const ConstantFP *CFP = dyn_cast<ConstantFP>(C)) {
+      Code = bitc::CST_CODE_FLOAT;
+      Type *Ty = CFP->getType();
+      if (Ty->isHalfTy() || Ty->isFloatTy() || Ty->isDoubleTy()) {
+        Record.push_back(CFP->getValueAPF().bitcastToAPInt().getZExtValue());
+      } else if (Ty->isX86_FP80Ty()) {
+        // api needed to prevent premature destruction
+        // bits are not in the same order as a normal i80 APInt, compensate.
+        APInt api = CFP->getValueAPF().bitcastToAPInt();
+        const uint64_t *p = api.getRawData();
+        Record.push_back((p[1] << 48) | (p[0] >> 16));
+        Record.push_back(p[0] & 0xffffLL);
+      } else if (Ty->isFP128Ty() || Ty->isPPC_FP128Ty()) {
+        APInt api = CFP->getValueAPF().bitcastToAPInt();
+        const uint64_t *p = api.getRawData();
+        Record.push_back(p[0]);
+        Record.push_back(p[1]);
+      } else {
+        assert (0 && "Unknown FP type!");
+      }
+    } else if (isa<ConstantDataSequential>(C) &&
+               cast<ConstantDataSequential>(C)->isString()) {
+      const ConstantDataSequential *Str = cast<ConstantDataSequential>(C);
+      // Emit constant strings specially.
+      unsigned NumElts = Str->getNumElements();
+      // If this is a null-terminated string, use the denser CSTRING encoding.
+      if (Str->isCString()) {
+        Code = bitc::CST_CODE_CSTRING;
+        --NumElts;  // Don't encode the null, which isn't allowed by char6.
+      } else {
+        Code = bitc::CST_CODE_STRING;
+        AbbrevToUse = String8Abbrev;
+      }
+      bool isCStr7 = Code == bitc::CST_CODE_CSTRING;
+      bool isCStrChar6 = Code == bitc::CST_CODE_CSTRING;
+      for (unsigned i = 0; i != NumElts; ++i) {
+        unsigned char V = Str->getElementAsInteger(i);
+        Record.push_back(V);
+        isCStr7 &= (V & 128) == 0;
+        if (isCStrChar6)
+          isCStrChar6 = BitCodeAbbrevOp::isChar6(V);
+      }
+
+      if (isCStrChar6)
+        AbbrevToUse = CString6Abbrev;
+      else if (isCStr7)
+        AbbrevToUse = CString7Abbrev;
+    } else if (const ConstantDataSequential *CDS =
+                  dyn_cast<ConstantDataSequential>(C)) {
+      Code = bitc::CST_CODE_DATA;
+      Type *EltTy = CDS->getType()->getElementType();
+      if (isa<IntegerType>(EltTy)) {
+        for (unsigned i = 0, e = CDS->getNumElements(); i != e; ++i)
+          Record.push_back(CDS->getElementAsInteger(i));
+      } else if (EltTy->isFloatTy()) {
+        for (unsigned i = 0, e = CDS->getNumElements(); i != e; ++i) {
+          union { float F; uint32_t I; };
+          F = CDS->getElementAsFloat(i);
+          Record.push_back(I);
+        }
+      } else {
+        assert(EltTy->isDoubleTy() && "Unknown ConstantData element type");
+        for (unsigned i = 0, e = CDS->getNumElements(); i != e; ++i) {
+          union { double F; uint64_t I; };
+          F = CDS->getElementAsDouble(i);
+          Record.push_back(I);
+        }
+      }
+    } else if (isa<ConstantArray>(C) || isa<ConstantStruct>(C) ||
+               isa<ConstantVector>(C)) {
+      Code = bitc::CST_CODE_AGGREGATE;
+      for (const Value *Op : C->operands())
+        Record.push_back(VE.getValueID(Op));
+      AbbrevToUse = AggregateAbbrev;
+    } else if (const ConstantExpr *CE = dyn_cast<ConstantExpr>(C)) {
+      switch (CE->getOpcode()) {
+      default:
+        if (Instruction::isCast(CE->getOpcode())) {
+          Code = bitc::CST_CODE_CE_CAST;
+          Record.push_back(GetEncodedCastOpcode(CE->getOpcode()));
+          Record.push_back(VE.getTypeID(C->getOperand(0)->getType()));
+          Record.push_back(VE.getValueID(C->getOperand(0)));
+          AbbrevToUse = CONSTANTS_CE_CAST_Abbrev;
+        } else {
+          assert(CE->getNumOperands() == 2 && "Unknown constant expr!");
+          Code = bitc::CST_CODE_CE_BINOP;
+          Record.push_back(GetEncodedBinaryOpcode(CE->getOpcode()));
+          Record.push_back(VE.getValueID(C->getOperand(0)));
+          Record.push_back(VE.getValueID(C->getOperand(1)));
+          uint64_t Flags = GetOptimizationFlags(CE);
+          if (Flags != 0)
+            Record.push_back(Flags);
+        }
+        break;
+      case Instruction::GetElementPtr: {
+        Code = bitc::CST_CODE_CE_GEP;
+        const auto *GO = cast<GEPOperator>(C);
+        if (GO->isInBounds())
+          Code = bitc::CST_CODE_CE_INBOUNDS_GEP;
+        for (unsigned i = 0, e = CE->getNumOperands(); i != e; ++i) {
+          Record.push_back(VE.getTypeID(C->getOperand(i)->getType()));
+          Record.push_back(VE.getValueID(C->getOperand(i)));
+        }
+        break;
+      }
+      case Instruction::Select:
+        Code = bitc::CST_CODE_CE_SELECT;
+        Record.push_back(VE.getValueID(C->getOperand(0)));
+        Record.push_back(VE.getValueID(C->getOperand(1)));
+        Record.push_back(VE.getValueID(C->getOperand(2)));
+        break;
+      case Instruction::ExtractElement:
+        Code = bitc::CST_CODE_CE_EXTRACTELT;
+        Record.push_back(VE.getTypeID(C->getOperand(0)->getType()));
+        Record.push_back(VE.getValueID(C->getOperand(0)));
+        Record.push_back(VE.getValueID(C->getOperand(1)));
+        break;
+      case Instruction::InsertElement:
+        Code = bitc::CST_CODE_CE_INSERTELT;
+        Record.push_back(VE.getValueID(C->getOperand(0)));
+        Record.push_back(VE.getValueID(C->getOperand(1)));
+        Record.push_back(VE.getValueID(C->getOperand(2)));
+        break;
+      case Instruction::ShuffleVector:
+        // If the return type and argument types are the same, this is a
+        // standard shufflevector instruction.  If the types are different,
+        // then the shuffle is widening or truncating the input vectors, and
+        // the argument type must also be encoded.
+        if (C->getType() == C->getOperand(0)->getType()) {
+          Code = bitc::CST_CODE_CE_SHUFFLEVEC;
+        } else {
+          Code = bitc::CST_CODE_CE_SHUFVEC_EX;
+          Record.push_back(VE.getTypeID(C->getOperand(0)->getType()));
+        }
+        Record.push_back(VE.getValueID(C->getOperand(0)));
+        Record.push_back(VE.getValueID(C->getOperand(1)));
+        Record.push_back(VE.getValueID(C->getOperand(2)));
+        break;
+      case Instruction::ICmp:
+      case Instruction::FCmp:
+        Code = bitc::CST_CODE_CE_CMP;
+        Record.push_back(VE.getTypeID(C->getOperand(0)->getType()));
+        Record.push_back(VE.getValueID(C->getOperand(0)));
+        Record.push_back(VE.getValueID(C->getOperand(1)));
+        Record.push_back(CE->getPredicate());
+        break;
+      }
+    } else if (const BlockAddress *BA = dyn_cast<BlockAddress>(C)) {
+      Code = bitc::CST_CODE_BLOCKADDRESS;
+      Record.push_back(VE.getTypeID(BA->getFunction()->getType()));
+      Record.push_back(VE.getValueID(BA->getFunction()));
+      Record.push_back(VE.getGlobalBasicBlockID(BA->getBasicBlock()));
+    } else {
+#ifndef NDEBUG
+      C->dump();
+#endif
+      llvm_unreachable("Unknown constant!");
+    }
+    Stream.EmitRecord(Code, Record, AbbrevToUse);
+    Record.clear();
+  }
+
+  Stream.ExitBlock();
+}
+
+static void WriteModuleConstants(const ValueEnumerator32 &VE,
+                                 BitstreamWriter &Stream) {
+  const ValueEnumerator32::ValueList &Vals = VE.getValues();
+
+  // Find the first constant to emit, which is the first non-globalvalue value.
+  // We know globalvalues have been emitted by WriteModuleInfo.
+  for (unsigned i = 0, e = Vals.size(); i != e; ++i) {
+    if (!isa<GlobalValue>(Vals[i].first)) {
+      WriteConstants(i, Vals.size(), VE, Stream, true);
+      return;
+    }
+  }
+}
+
+/// PushValueAndType - The file has to encode both the value and type id for
+/// many values, because we need to know what type to create for forward
+/// references.  However, most operands are not forward references, so this type
+/// field is not needed.
+///
+/// This function adds V's value ID to Vals.  If the value ID is higher than the
+/// instruction ID, then it is a forward reference, and it also includes the
+/// type ID.  The value ID that is written is encoded relative to the InstID.
+static bool PushValueAndType(const Value *V, unsigned InstID,
+                             SmallVectorImpl<unsigned> &Vals,
+                             ValueEnumerator32 &VE) {
+  unsigned ValID = VE.getValueID(V);
+  // Make encoding relative to the InstID.
+  Vals.push_back(InstID - ValID);
+  if (ValID >= InstID) {
+    Vals.push_back(VE.getTypeID(V->getType()));
+    return true;
+  }
+  return false;
+}
+
+/// pushValue - Like PushValueAndType, but where the type of the value is
+/// omitted (perhaps it was already encoded in an earlier operand).
+static void pushValue(const Value *V, unsigned InstID,
+                      SmallVectorImpl<unsigned> &Vals,
+                      ValueEnumerator32 &VE) {
+  unsigned ValID = VE.getValueID(V);
+  Vals.push_back(InstID - ValID);
+}
+
+static void pushValue64(const Value *V, unsigned InstID,
+                        SmallVector<uint64_t, 128> &Vals,
+                        ValueEnumerator32 &VE) {
+  uint64_t ValID = VE.getValueID(V);
+  Vals.push_back(InstID - ValID);
+}
+
+static void pushValueSigned(const Value *V, unsigned InstID,
+                            SmallVectorImpl<uint64_t> &Vals,
+                            ValueEnumerator32 &VE) {
+  unsigned ValID = VE.getValueID(V);
+  int64_t diff = ((int32_t)InstID - (int32_t)ValID);
+  emitSignedInt64(Vals, diff);
+}
+
+/// WriteInstruction - Emit an instruction to the specified stream.
+static void WriteInstruction(const Instruction &I, unsigned InstID,
+                             ValueEnumerator32 &VE, BitstreamWriter &Stream,
+                             SmallVectorImpl<unsigned> &Vals) {
+  unsigned Code = 0;
+  unsigned AbbrevToUse = 0;
+  VE.setInstructionID(&I);
+  switch (I.getOpcode()) {
+  default:
+    if (Instruction::isCast(I.getOpcode())) {
+      Code = bitc::FUNC_CODE_INST_CAST;
+      if (!PushValueAndType(I.getOperand(0), InstID, Vals, VE))
+        AbbrevToUse = FUNCTION_INST_CAST_ABBREV;
+      Vals.push_back(VE.getTypeID(I.getType()));
+      Vals.push_back(GetEncodedCastOpcode(I.getOpcode()));
+    } else {
+      assert(isa<BinaryOperator>(I) && "Unknown instruction!");
+      Code = bitc::FUNC_CODE_INST_BINOP;
+      if (!PushValueAndType(I.getOperand(0), InstID, Vals, VE))
+        AbbrevToUse = FUNCTION_INST_BINOP_ABBREV;
+      pushValue(I.getOperand(1), InstID, Vals, VE);
+      Vals.push_back(GetEncodedBinaryOpcode(I.getOpcode()));
+      uint64_t Flags = GetOptimizationFlags(&I);
+      if (Flags != 0) {
+        if (AbbrevToUse == FUNCTION_INST_BINOP_ABBREV)
+          AbbrevToUse = FUNCTION_INST_BINOP_FLAGS_ABBREV;
+        Vals.push_back(Flags);
+      }
+    }
+    break;
+
+  case Instruction::GetElementPtr: {
+    Code = bitc::FUNC_CODE_INST_GEP_OLD;
+    //AbbrevToUse = FUNCTION_INST_GEP_ABBREV;
+    auto &GEPInst = cast<GetElementPtrInst>(I);
+    if (GEPInst.isInBounds())
+      Code = bitc::FUNC_CODE_INST_INBOUNDS_GEP_OLD;
+    for (unsigned i = 0, e = I.getNumOperands(); i != e; ++i)
+      PushValueAndType(I.getOperand(i), InstID, Vals, VE);
+    break;
+  }
+  case Instruction::ExtractValue: {
+    Code = bitc::FUNC_CODE_INST_EXTRACTVAL;
+    PushValueAndType(I.getOperand(0), InstID, Vals, VE);
+    const ExtractValueInst *EVI = cast<ExtractValueInst>(&I);
+    Vals.append(EVI->idx_begin(), EVI->idx_end());
+    break;
+  }
+  case Instruction::InsertValue: {
+    Code = bitc::FUNC_CODE_INST_INSERTVAL;
+    PushValueAndType(I.getOperand(0), InstID, Vals, VE);
+    PushValueAndType(I.getOperand(1), InstID, Vals, VE);
+    const InsertValueInst *IVI = cast<InsertValueInst>(&I);
+    Vals.append(IVI->idx_begin(), IVI->idx_end());
+    break;
+  }
+  case Instruction::Select:
+    Code = bitc::FUNC_CODE_INST_VSELECT;
+    PushValueAndType(I.getOperand(1), InstID, Vals, VE);
+    pushValue(I.getOperand(2), InstID, Vals, VE);
+    PushValueAndType(I.getOperand(0), InstID, Vals, VE);
+    break;
+  case Instruction::ExtractElement:
+    Code = bitc::FUNC_CODE_INST_EXTRACTELT;
+    PushValueAndType(I.getOperand(0), InstID, Vals, VE);
+    pushValue(I.getOperand(1), InstID, Vals, VE);
+    break;
+  case Instruction::InsertElement:
+    Code = bitc::FUNC_CODE_INST_INSERTELT;
+    PushValueAndType(I.getOperand(0), InstID, Vals, VE);
+    pushValue(I.getOperand(1), InstID, Vals, VE);
+    pushValue(I.getOperand(2), InstID, Vals, VE);
+    break;
+  case Instruction::ShuffleVector:
+    Code = bitc::FUNC_CODE_INST_SHUFFLEVEC;
+    PushValueAndType(I.getOperand(0), InstID, Vals, VE);
+    pushValue(I.getOperand(1), InstID, Vals, VE);
+    pushValue(I.getOperand(2), InstID, Vals, VE);
+    break;
+  case Instruction::ICmp:
+  case Instruction::FCmp: {
+    // compare returning Int1Ty or vector of Int1Ty
+    Code = bitc::FUNC_CODE_INST_CMP2;
+    PushValueAndType(I.getOperand(0), InstID, Vals, VE);
+    pushValue(I.getOperand(1), InstID, Vals, VE);
+    Vals.push_back(cast<CmpInst>(I).getPredicate());
+    break;
+  }
+
+  case Instruction::Ret:
+    {
+      Code = bitc::FUNC_CODE_INST_RET;
+      unsigned NumOperands = I.getNumOperands();
+      if (NumOperands == 0)
+        AbbrevToUse = FUNCTION_INST_RET_VOID_ABBREV;
+      else if (NumOperands == 1) {
+        if (!PushValueAndType(I.getOperand(0), InstID, Vals, VE))
+          AbbrevToUse = FUNCTION_INST_RET_VAL_ABBREV;
+      } else {
+        for (unsigned i = 0, e = NumOperands; i != e; ++i)
+          PushValueAndType(I.getOperand(i), InstID, Vals, VE);
+      }
+    }
+    break;
+  case Instruction::Br:
+    {
+      Code = bitc::FUNC_CODE_INST_BR;
+      const BranchInst &II = cast<BranchInst>(I);
+      Vals.push_back(VE.getValueID(II.getSuccessor(0)));
+      if (II.isConditional()) {
+        Vals.push_back(VE.getValueID(II.getSuccessor(1)));
+        pushValue(II.getCondition(), InstID, Vals, VE);
+      }
+    }
+    break;
+  case Instruction::Switch:
+    {
+      // Redefine Vals, since here we need to use 64 bit values
+      // explicitly to store large APInt numbers.
+      SmallVector<uint64_t, 128> Vals64;
+
+      Code = bitc::FUNC_CODE_INST_SWITCH;
+      const SwitchInst &SI = cast<SwitchInst>(I);
+
+      // Compute hash (LLVM 3.2 SwitchInst::Hash)
+      uint32_t NumberOfCases = (uint32_t)SI.getNumCases();
+      uint16_t Hash = (0xFFFF & NumberOfCases) ^ (NumberOfCases >> 16);
+      for (SwitchInst::ConstCaseIt i = SI.case_begin(), e = SI.case_end();
+           i != e; ++i) {
+        uint32_t NumItems = 1;
+        Hash = (Hash << 1) ^ (0xFFFF & NumItems) ^ (NumItems >> 16);
+      }
+
+      uint32_t SwitchRecordHeader = Hash | (SWITCH_INST_MAGIC << 16);
+      Vals64.push_back(SwitchRecordHeader);
+
+      Vals64.push_back(VE.getTypeID(SI.getCondition()->getType()));
+      pushValue64(SI.getCondition(), InstID, Vals64, VE);
+      Vals64.push_back(VE.getValueID(SI.getDefaultDest()));
+      Vals64.push_back(SI.getNumCases());
+      for (SwitchInst::ConstCaseIt i = SI.case_begin(), e = SI.case_end();
+           i != e; ++i) {
+        unsigned Code, Abbrev; // will unused.
+        Vals64.push_back(1/*NumItems = 1*/);
+        Vals64.push_back(true/*IsSingleNumber = true*/);
+        EmitAPInt(Vals64, Code, Abbrev, i.getCaseValue()->getValue(), true);
+        Vals64.push_back(VE.getValueID(i.getCaseSuccessor()));
+      }
+
+      Stream.EmitRecord(Code, Vals64, AbbrevToUse);
+
+      // Also do expected action - clear external Vals collection:
+      Vals.clear();
+      return;
+    }
+    break;
+  case Instruction::IndirectBr:
+    Code = bitc::FUNC_CODE_INST_INDIRECTBR;
+    Vals.push_back(VE.getTypeID(I.getOperand(0)->getType()));
+    // Encode the address operand as relative, but not the basic blocks.
+    pushValue(I.getOperand(0), InstID, Vals, VE);
+    for (unsigned i = 1, e = I.getNumOperands(); i != e; ++i)
+      Vals.push_back(VE.getValueID(I.getOperand(i)));
+    break;
+
+  case Instruction::Invoke: {
+    const InvokeInst *II = cast<InvokeInst>(&I);
+    const Value *Callee = II->getCalledValue();
+    FunctionType *FTy = II->getFunctionType();
+
+    Code = bitc::FUNC_CODE_INST_INVOKE;
+
+    Vals.push_back(VE.getAttributeID(II->getAttributes()));
+    Vals.push_back(II->getCallingConv());
+    Vals.push_back(VE.getValueID(II->getNormalDest()));
+    Vals.push_back(VE.getValueID(II->getUnwindDest()));
+    PushValueAndType(Callee, InstID, Vals, VE);
+
+    // Emit value #'s for the fixed parameters.
+    for (unsigned i = 0, e = FTy->getNumParams(); i != e; ++i)
+      pushValue(I.getOperand(i), InstID, Vals, VE);  // fixed param.
+
+    // Emit type/value pairs for varargs params.
+    if (FTy->isVarArg()) {
+      for (unsigned i = FTy->getNumParams(), e = I.getNumOperands()-3;
+           i != e; ++i)
+        PushValueAndType(I.getOperand(i), InstID, Vals, VE); // vararg
+    }
+    break;
+  }
+  case Instruction::Resume:
+    Code = bitc::FUNC_CODE_INST_RESUME;
+    PushValueAndType(I.getOperand(0), InstID, Vals, VE);
+    break;
+  case Instruction::CleanupRet:
+  case Instruction::CatchRet:
+  case Instruction::CleanupPad:
+  case Instruction::CatchPad:
+  case Instruction::CatchSwitch:
+    // all unsupported in 3.2
+    assert(false && "encountered unsupported instruction (these need to be filtered out before writing 3.2 bitcode)");
+    return;
+  case Instruction::Unreachable:
+    Code = bitc::FUNC_CODE_INST_UNREACHABLE;
+    AbbrevToUse = FUNCTION_INST_UNREACHABLE_ABBREV;
+    break;
+
+  case Instruction::PHI: {
+    const PHINode &PN = cast<PHINode>(I);
+    Code = bitc::FUNC_CODE_INST_PHI;
+    // With the newer instruction encoding, forward references could give
+    // negative valued IDs.  This is most common for PHIs, so we use
+    // signed VBRs.
+    SmallVector<uint64_t, 128> Vals64;
+    Vals64.push_back(VE.getTypeID(PN.getType()));
+    for (unsigned i = 0, e = PN.getNumIncomingValues(); i != e; ++i) {
+      pushValueSigned(PN.getIncomingValue(i), InstID, Vals64, VE);
+      Vals64.push_back(VE.getValueID(PN.getIncomingBlock(i)));
+    }
+    // Emit a Vals64 vector and exit.
+    Stream.EmitRecord(Code, Vals64, AbbrevToUse);
+    Vals64.clear();
+    return;
+  }
+
+  case Instruction::LandingPad: {
+    const LandingPadInst &LP = cast<LandingPadInst>(I);
+    Code = bitc::FUNC_CODE_INST_LANDINGPAD_OLD;
+    Vals.push_back(VE.getTypeID(LP.getType()));
+    PushValueAndType(LP.getFunction()->getPersonalityFn(), InstID, Vals, VE);
+    Vals.push_back(LP.isCleanup());
+    Vals.push_back(LP.getNumClauses());
+    for (unsigned I = 0, E = LP.getNumClauses(); I != E; ++I) {
+      if (LP.isCatch(I))
+        Vals.push_back(LandingPadInst::Catch);
+      else
+        Vals.push_back(LandingPadInst::Filter);
+      PushValueAndType(LP.getClause(I), InstID, Vals, VE);
+    }
+    break;
+  }
+
+  case Instruction::Alloca: {
+    Code = bitc::FUNC_CODE_INST_ALLOCA;
+    const AllocaInst &AI = cast<AllocaInst>(I);
+    Vals.push_back(VE.getTypeID(I.getType()));
+    Vals.push_back(VE.getTypeID(I.getOperand(0)->getType()));
+    Vals.push_back(VE.getValueID(I.getOperand(0))); // size.
+    unsigned AlignRecord = Log2_32(AI.getAlignment()) + 1;
+    assert(Log2_32(Value::MaximumAlignment) + 1 < 1 << 5 &&
+           "not enough bits for maximum alignment");
+    assert(AlignRecord < 1 << 5 && "alignment greater than 1 << 64");
+    Vals.push_back(AlignRecord);
+    break;
+  }
+
+  case Instruction::Load:
+    if (cast<LoadInst>(I).isAtomic()) {
+      Code = bitc::FUNC_CODE_INST_LOADATOMIC;
+      PushValueAndType(I.getOperand(0), InstID, Vals, VE);
+    } else {
+      Code = bitc::FUNC_CODE_INST_LOAD;
+      if (!PushValueAndType(I.getOperand(0), InstID, Vals, VE))  // ptr
+        AbbrevToUse = FUNCTION_INST_LOAD_ABBREV;
+    }
+    Vals.push_back(Log2_32(cast<LoadInst>(I).getAlignment())+1);
+    Vals.push_back(cast<LoadInst>(I).isVolatile());
+    if (cast<LoadInst>(I).isAtomic()) {
+      Vals.push_back(GetEncodedOrdering(cast<LoadInst>(I).getOrdering()));
+      Vals.push_back(GetEncodedSynchScope(cast<LoadInst>(I).getSynchScope()));
+    }
+    break;
+  case Instruction::Store:
+    if (cast<StoreInst>(I).isAtomic())
+      Code = bitc::FUNC_CODE_INST_STOREATOMIC_OLD;
+    else
+      Code = bitc::FUNC_CODE_INST_STORE_OLD;
+    PushValueAndType(I.getOperand(1), InstID, Vals, VE);  // ptrty + ptr
+    pushValue(I.getOperand(0), InstID, Vals, VE);         // val.
+    Vals.push_back(Log2_32(cast<StoreInst>(I).getAlignment())+1);
+    Vals.push_back(cast<StoreInst>(I).isVolatile());
+    if (cast<StoreInst>(I).isAtomic()) {
+      Vals.push_back(GetEncodedOrdering(cast<StoreInst>(I).getOrdering()));
+      Vals.push_back(GetEncodedSynchScope(cast<StoreInst>(I).getSynchScope()));
+    }
+    break;
+  case Instruction::AtomicCmpXchg:
+    Code = bitc::FUNC_CODE_INST_CMPXCHG_OLD;
+    PushValueAndType(I.getOperand(0), InstID, Vals, VE);  // ptrty + ptr
+    pushValue(I.getOperand(1), InstID, Vals, VE);         // cmp.
+    pushValue(I.getOperand(2), InstID, Vals, VE);         // newval.
+    Vals.push_back(cast<AtomicCmpXchgInst>(I).isVolatile());
+    Vals.push_back(GetEncodedOrdering(
+                     cast<AtomicCmpXchgInst>(I).getSuccessOrdering()));
+    Vals.push_back(GetEncodedSynchScope(
+                     cast<AtomicCmpXchgInst>(I).getSynchScope()));
+    break;
+  case Instruction::AtomicRMW:
+    Code = bitc::FUNC_CODE_INST_ATOMICRMW;
+    PushValueAndType(I.getOperand(0), InstID, Vals, VE);  // ptrty + ptr
+    pushValue(I.getOperand(1), InstID, Vals, VE);         // val.
+    Vals.push_back(GetEncodedRMWOperation(
+                     cast<AtomicRMWInst>(I).getOperation()));
+    Vals.push_back(cast<AtomicRMWInst>(I).isVolatile());
+    Vals.push_back(GetEncodedOrdering(cast<AtomicRMWInst>(I).getOrdering()));
+    Vals.push_back(GetEncodedSynchScope(
+                     cast<AtomicRMWInst>(I).getSynchScope()));
+    break;
+  case Instruction::Fence:
+    Code = bitc::FUNC_CODE_INST_FENCE;
+    Vals.push_back(GetEncodedOrdering(cast<FenceInst>(I).getOrdering()));
+    Vals.push_back(GetEncodedSynchScope(cast<FenceInst>(I).getSynchScope()));
+    break;
+  case Instruction::Call: {
+    const CallInst &CI = cast<CallInst>(I);
+    FunctionType *FTy = CI.getFunctionType();
+
+    Code = bitc::FUNC_CODE_INST_CALL;
+
+    Vals.push_back(VE.getAttributeID(CI.getAttributes()));
+    Vals.push_back(CI.getCallingConv() << bitc::CALL_CCONV |
+                   unsigned(CI.isTailCall()) << bitc::CALL_TAIL);
+
+    PushValueAndType(CI.getCalledValue(), InstID, Vals, VE);  // Callee
+
+    // Emit value #'s for the fixed parameters.
+    for (unsigned i = 0, e = FTy->getNumParams(); i != e; ++i) {
+      // Check for labels (can happen with asm labels).
+      if (FTy->getParamType(i)->isLabelTy())
+        Vals.push_back(VE.getValueID(CI.getArgOperand(i)));
+      else
+        pushValue(CI.getArgOperand(i), InstID, Vals, VE);  // fixed param.
+    }
+
+    // Emit type/value pairs for varargs params.
+    if (FTy->isVarArg()) {
+      for (unsigned i = FTy->getNumParams(), e = CI.getNumArgOperands();
+           i != e; ++i)
+        PushValueAndType(CI.getArgOperand(i), InstID, Vals, VE);  // varargs
+    }
+    break;
+  }
+  case Instruction::VAArg:
+    Code = bitc::FUNC_CODE_INST_VAARG;
+    Vals.push_back(VE.getTypeID(I.getOperand(0)->getType()));   // valistty
+    pushValue(I.getOperand(0), InstID, Vals, VE); // valist.
+    Vals.push_back(VE.getTypeID(I.getType())); // restype.
+    break;
+  }
+
+  Stream.EmitRecord(Code, Vals, AbbrevToUse);
+  Vals.clear();
+}
+
+enum StringEncoding { SE_Char6, SE_Fixed7, SE_Fixed8 };
+
+/// Determine the encoding to use for the given string name and length.
+static StringEncoding getStringEncoding(const char *Str, unsigned StrLen) {
+  bool isChar6 = true;
+  for (const char *C = Str, *E = C + StrLen; C != E; ++C) {
+    if (isChar6)
+      isChar6 = BitCodeAbbrevOp::isChar6(*C);
+    if ((unsigned char)*C & 128)
+      // don't bother scanning the rest.
+      return SE_Fixed8;
+  }
+  if (isChar6)
+    return SE_Char6;
+  else
+    return SE_Fixed7;
+}
+
+/// Emit names for globals/functions etc. The VSTOffsetPlaceholder,
+/// BitcodeStartBit and FunctionIndex are only passed for the module-level
+/// VST, where we are including a function bitcode index and need to
+/// backpatch the VST forward declaration record.
+static void WriteValueSymbolTable(
+    const ValueSymbolTable &VST, const ValueEnumerator32 &VE,
+    BitstreamWriter &Stream, uint64_t VSTOffsetPlaceholder = 0,
+    uint64_t BitcodeStartBit = 0
+// TODO: is this necessary? handle it?
+// -> new one: DenseMap<const Function *, uint64_t> *FunctionToBitcodeIndex
+    /*DenseMap<const Function *, std::unique_ptr<FunctionInfo>> *FunctionIndex =
+        nullptr*/) {
+  if (VST.empty()) {
+    // WriteValueSymbolTableForwardDecl should have returned early as
+    // well. Ensure this handling remains in sync by asserting that
+    // the placeholder offset is not set.
+    assert(VSTOffsetPlaceholder == 0);
+    return;
+  }
+
+  Stream.EnterSubblock(bitc::VALUE_SYMTAB_BLOCK_ID, 4);
+
+  // FIXME: Set up the abbrev, we know how many values there are!
+  // FIXME: We know if the type names can use 7-bit ascii.
+  SmallVector<unsigned, 64> NameVals;
+
+  for (const ValueName &Name : VST) {
+    // Figure out the encoding to use for the name.
+    StringEncoding Bits =
+        getStringEncoding(Name.getKeyData(), Name.getKeyLength());
+
+    unsigned AbbrevToUse = VST_ENTRY_8_ABBREV;
+    NameVals.push_back(VE.getValueID(Name.getValue()));
+
+    // VST_ENTRY:   [valueid, namechar x N]
+    // VST_BBENTRY: [bbid, namechar x N]
+    unsigned Code;
+    if (isa<BasicBlock>(Name.getValue())) {
+      Code = bitc::VST_CODE_BBENTRY;
+      if (Bits == SE_Char6)
+        AbbrevToUse = VST_BBENTRY_6_ABBREV;
+    } else {
+      Code = bitc::VST_CODE_ENTRY;
+      if (Bits == SE_Char6)
+        AbbrevToUse = VST_ENTRY_6_ABBREV;
+      else if (Bits == SE_Fixed7)
+        AbbrevToUse = VST_ENTRY_7_ABBREV;
+    }
+
+    for (const auto P : Name.getKey())
+      NameVals.push_back((unsigned char)P);
+
+    // Emit the finished record.
+    Stream.EmitRecord(Code, NameVals, AbbrevToUse);
+    NameVals.clear();
+  }
+  Stream.ExitBlock();
+}
+
+/// Emit a function body to the module stream.
+static void WriteFunction(
+    const Function &F, ValueEnumerator32 &VE, BitstreamWriter &Stream) {
+  Stream.EnterSubblock(bitc::FUNCTION_BLOCK_ID, 4);
+  VE.incorporateFunction(F);
+
+  SmallVector<unsigned, 64> Vals;
+
+  // Emit the number of basic blocks, so the reader can create them ahead of
+  // time.
+  Vals.push_back(VE.getBasicBlocks().size());
+  Stream.EmitRecord(bitc::FUNC_CODE_DECLAREBLOCKS, Vals);
+  Vals.clear();
+
+  // If there are function-local constants, emit them now.
+  unsigned CstStart, CstEnd;
+  VE.getFunctionConstantRange(CstStart, CstEnd);
+  WriteConstants(CstStart, CstEnd, VE, Stream, false);
+
+  // If there is function-local metadata, emit it now.
+  WriteFunctionLocalMetadata(F, VE, Stream);
+
+  // Keep a running idea of what the instruction ID is.
+  unsigned InstID = CstEnd;
+
+  bool NeedsMetadataAttachment = false;
+
+  DILocation *LastDL = nullptr;
+
+  // Finally, emit all the instructions, in order.
+  for (Function::const_iterator BB = F.begin(), E = F.end(); BB != E; ++BB)
+    for (BasicBlock::const_iterator I = BB->begin(), E = BB->end();
+         I != E; ++I) {
+      WriteInstruction(*I, InstID, VE, Stream, Vals);
+
+      if (!I->getType()->isVoidTy())
+        ++InstID;
+
+      // If the instruction has metadata, write a metadata attachment later.
+      NeedsMetadataAttachment |= I->hasMetadataOtherThanDebugLoc();
+
+      // If the instruction has a debug location, emit it.
+      DILocation *DL = I->getDebugLoc();
+      if (!DL)
+        continue;
+
+      if (DL == LastDL) {
+        // Just repeat the same debug loc as last time.
+        Stream.EmitRecord(bitc::FUNC_CODE_DEBUG_LOC_AGAIN, Vals);
+        continue;
+      }
+
+      Vals.push_back(DL->getLine());
+      Vals.push_back(DL->getColumn());
+      Vals.push_back(VE.getMetadataOrNullID(DL->getScope()));
+      Vals.push_back(VE.getMetadataOrNullID(DL->getInlinedAt()));
+      Stream.EmitRecord(bitc::FUNC_CODE_DEBUG_LOC, Vals);
+      Vals.clear();
+
+      LastDL = DL;
+    }
+
+  // Emit names for all the instructions etc.
+  WriteValueSymbolTable(F.getValueSymbolTable(), VE, Stream);
+
+  if (NeedsMetadataAttachment)
+    WriteMetadataAttachment(F, VE, Stream);
+  VE.purgeFunction();
+  Stream.ExitBlock();
+}
+
+// Emit blockinfo, which defines the standard abbreviations etc.
+static void WriteBlockInfo(const ValueEnumerator32 &VE, BitstreamWriter &Stream) {
+  // We only want to emit block info records for blocks that have multiple
+  // instances: CONSTANTS_BLOCK, FUNCTION_BLOCK and VALUE_SYMTAB_BLOCK.
+  // Other blocks can define their abbrevs inline.
+  Stream.EnterBlockInfoBlock(2);
+
+  { // 8-bit fixed-width VST_ENTRY/VST_BBENTRY strings.
+    BitCodeAbbrev *Abbv = new BitCodeAbbrev();
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, 3));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::VBR, 8));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Array));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, 8));
+    if (Stream.EmitBlockInfoAbbrev(bitc::VALUE_SYMTAB_BLOCK_ID,
+                                   Abbv) != VST_ENTRY_8_ABBREV)
+      llvm_unreachable("Unexpected abbrev ordering!");
+  }
+
+  { // 7-bit fixed width VST_ENTRY strings.
+    BitCodeAbbrev *Abbv = new BitCodeAbbrev();
+    Abbv->Add(BitCodeAbbrevOp(bitc::VST_CODE_ENTRY));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::VBR, 8));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Array));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, 7));
+    if (Stream.EmitBlockInfoAbbrev(bitc::VALUE_SYMTAB_BLOCK_ID,
+                                   Abbv) != VST_ENTRY_7_ABBREV)
+      llvm_unreachable("Unexpected abbrev ordering!");
+  }
+  { // 6-bit char6 VST_ENTRY strings.
+    BitCodeAbbrev *Abbv = new BitCodeAbbrev();
+    Abbv->Add(BitCodeAbbrevOp(bitc::VST_CODE_ENTRY));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::VBR, 8));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Array));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Char6));
+    if (Stream.EmitBlockInfoAbbrev(bitc::VALUE_SYMTAB_BLOCK_ID,
+                                   Abbv) != VST_ENTRY_6_ABBREV)
+      llvm_unreachable("Unexpected abbrev ordering!");
+  }
+  { // 6-bit char6 VST_BBENTRY strings.
+    BitCodeAbbrev *Abbv = new BitCodeAbbrev();
+    Abbv->Add(BitCodeAbbrevOp(bitc::VST_CODE_BBENTRY));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::VBR, 8));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Array));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Char6));
+    if (Stream.EmitBlockInfoAbbrev(bitc::VALUE_SYMTAB_BLOCK_ID,
+                                   Abbv) != VST_BBENTRY_6_ABBREV)
+      llvm_unreachable("Unexpected abbrev ordering!");
+  }
+
+
+
+  { // SETTYPE abbrev for CONSTANTS_BLOCK.
+    BitCodeAbbrev *Abbv = new BitCodeAbbrev();
+    Abbv->Add(BitCodeAbbrevOp(bitc::CST_CODE_SETTYPE));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed,
+                              VE.computeBitsRequiredForTypeIndicies()));
+    if (Stream.EmitBlockInfoAbbrev(bitc::CONSTANTS_BLOCK_ID,
+                                   Abbv) != CONSTANTS_SETTYPE_ABBREV)
+      llvm_unreachable("Unexpected abbrev ordering!");
+  }
+
+  { // INTEGER abbrev for CONSTANTS_BLOCK.
+    BitCodeAbbrev *Abbv = new BitCodeAbbrev();
+    Abbv->Add(BitCodeAbbrevOp(bitc::CST_CODE_INTEGER));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::VBR, 8));
+    if (Stream.EmitBlockInfoAbbrev(bitc::CONSTANTS_BLOCK_ID,
+                                   Abbv) != CONSTANTS_INTEGER_ABBREV)
+      llvm_unreachable("Unexpected abbrev ordering!");
+  }
+
+  { // CE_CAST abbrev for CONSTANTS_BLOCK.
+    BitCodeAbbrev *Abbv = new BitCodeAbbrev();
+    Abbv->Add(BitCodeAbbrevOp(bitc::CST_CODE_CE_CAST));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, 4));  // cast opc
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed,       // typeid
+                              VE.computeBitsRequiredForTypeIndicies()));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::VBR, 8));    // value id
+
+    if (Stream.EmitBlockInfoAbbrev(bitc::CONSTANTS_BLOCK_ID,
+                                   Abbv) != CONSTANTS_CE_CAST_Abbrev)
+      llvm_unreachable("Unexpected abbrev ordering!");
+  }
+  { // NULL abbrev for CONSTANTS_BLOCK.
+    BitCodeAbbrev *Abbv = new BitCodeAbbrev();
+    Abbv->Add(BitCodeAbbrevOp(bitc::CST_CODE_NULL));
+    if (Stream.EmitBlockInfoAbbrev(bitc::CONSTANTS_BLOCK_ID,
+                                   Abbv) != CONSTANTS_NULL_Abbrev)
+      llvm_unreachable("Unexpected abbrev ordering!");
+  }
+
+  // FIXME: This should only use space for first class types!
+
+  { // INST_LOAD abbrev for FUNCTION_BLOCK.
+    BitCodeAbbrev *Abbv = new BitCodeAbbrev();
+    Abbv->Add(BitCodeAbbrevOp(bitc::FUNC_CODE_INST_LOAD));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::VBR, 6)); // Ptr
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::VBR, 4)); // Align
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, 1)); // volatile
+    if (Stream.EmitBlockInfoAbbrev(bitc::FUNCTION_BLOCK_ID,
+                                   Abbv) != FUNCTION_INST_LOAD_ABBREV)
+      llvm_unreachable("Unexpected abbrev ordering!");
+  }
+  { // INST_BINOP abbrev for FUNCTION_BLOCK.
+    BitCodeAbbrev *Abbv = new BitCodeAbbrev();
+    Abbv->Add(BitCodeAbbrevOp(bitc::FUNC_CODE_INST_BINOP));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::VBR, 6)); // LHS
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::VBR, 6)); // RHS
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, 4)); // opc
+    if (Stream.EmitBlockInfoAbbrev(bitc::FUNCTION_BLOCK_ID,
+                                   Abbv) != FUNCTION_INST_BINOP_ABBREV)
+      llvm_unreachable("Unexpected abbrev ordering!");
+  }
+  { // INST_BINOP_FLAGS abbrev for FUNCTION_BLOCK.
+    BitCodeAbbrev *Abbv = new BitCodeAbbrev();
+    Abbv->Add(BitCodeAbbrevOp(bitc::FUNC_CODE_INST_BINOP));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::VBR, 6)); // LHS
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::VBR, 6)); // RHS
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, 4)); // opc
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, 7)); // flags
+    if (Stream.EmitBlockInfoAbbrev(bitc::FUNCTION_BLOCK_ID,
+                                   Abbv) != FUNCTION_INST_BINOP_FLAGS_ABBREV)
+      llvm_unreachable("Unexpected abbrev ordering!");
+  }
+  { // INST_CAST abbrev for FUNCTION_BLOCK.
+    BitCodeAbbrev *Abbv = new BitCodeAbbrev();
+    Abbv->Add(BitCodeAbbrevOp(bitc::FUNC_CODE_INST_CAST));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::VBR, 6));    // OpVal
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed,       // dest ty
+                              VE.computeBitsRequiredForTypeIndicies()));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, 4));  // opc
+    if (Stream.EmitBlockInfoAbbrev(bitc::FUNCTION_BLOCK_ID,
+                                   Abbv) != FUNCTION_INST_CAST_ABBREV)
+      llvm_unreachable("Unexpected abbrev ordering!");
+  }
+
+  { // INST_RET abbrev for FUNCTION_BLOCK.
+    BitCodeAbbrev *Abbv = new BitCodeAbbrev();
+    Abbv->Add(BitCodeAbbrevOp(bitc::FUNC_CODE_INST_RET));
+    if (Stream.EmitBlockInfoAbbrev(bitc::FUNCTION_BLOCK_ID,
+                                   Abbv) != FUNCTION_INST_RET_VOID_ABBREV)
+      llvm_unreachable("Unexpected abbrev ordering!");
+  }
+  { // INST_RET abbrev for FUNCTION_BLOCK.
+    BitCodeAbbrev *Abbv = new BitCodeAbbrev();
+    Abbv->Add(BitCodeAbbrevOp(bitc::FUNC_CODE_INST_RET));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::VBR, 6)); // ValID
+    if (Stream.EmitBlockInfoAbbrev(bitc::FUNCTION_BLOCK_ID,
+                                   Abbv) != FUNCTION_INST_RET_VAL_ABBREV)
+      llvm_unreachable("Unexpected abbrev ordering!");
+  }
+  { // INST_UNREACHABLE abbrev for FUNCTION_BLOCK.
+    BitCodeAbbrev *Abbv = new BitCodeAbbrev();
+    Abbv->Add(BitCodeAbbrevOp(bitc::FUNC_CODE_INST_UNREACHABLE));
+    if (Stream.EmitBlockInfoAbbrev(bitc::FUNCTION_BLOCK_ID,
+                                   Abbv) != FUNCTION_INST_UNREACHABLE_ABBREV)
+      llvm_unreachable("Unexpected abbrev ordering!");
+  }
+
+  Stream.ExitBlock();
+}
+
+/// WriteModule - Emit the specified module to the bitstream.
+static void WriteModule(const Module *M, BitstreamWriter &Stream) {
+  Stream.EnterSubblock(bitc::MODULE_BLOCK_ID, 3);
+
+  SmallVector<unsigned, 1> Vals;
+  unsigned CurVersion = 1;
+  Vals.push_back(CurVersion);
+  Stream.EmitRecord(bitc::MODULE_CODE_VERSION, Vals);
+
+  // Analyze the module, enumerating globals, functions, etc.
+  ValueEnumerator32 VE(*M);
+
+  // Emit blockinfo, which defines the standard abbreviations etc.
+  WriteBlockInfo(VE, Stream);
+
+  // Emit information about parameter attributes.
+  WriteAttributeTable(VE, Stream);
+
+  // Emit information describing all of the types in the module.
+  WriteTypeTable(VE, Stream);
+
+  // Emit top-level description of module, including target triple, inline asm,
+  // descriptors for global variables, and function prototype info.
+  WriteModuleInfo(M, VE, Stream);
+
+  // Emit constants.
+  WriteModuleConstants(VE, Stream);
+
+  // Emit metadata.
+  WriteModuleMetadata(M, VE, Stream);
+
+  // Emit metadata.
+  WriteModuleMetadataStore(M, Stream);
+
+  // Emit names for globals/functions etc.
+  WriteValueSymbolTable(M->getValueSymbolTable(), VE, Stream);
+
+  // Emit function bodies.
+  for (Module::const_iterator F = M->begin(), E = M->end(); F != E; ++F)
+    if (!F->isDeclaration())
+      WriteFunction(*F, VE, Stream);
+
+  Stream.ExitBlock();
+}
+
+/// EmitDarwinBCHeader - If generating a bc file on darwin, we have to emit a
+/// header and trailer to make it compatible with the system archiver.  To do
+/// this we emit the following header, and then emit a trailer that pads the
+/// file out to be a multiple of 16 bytes.
+///
+/// struct bc_header {
+///   uint32_t Magic;         // 0x0B17C0DE
+///   uint32_t Version;       // Version, currently always 0.
+///   uint32_t BitcodeOffset; // Offset to traditional bitcode file.
+///   uint32_t BitcodeSize;   // Size of traditional bitcode file.
+///   uint32_t CPUType;       // CPU specifier.
+///   ... potentially more later ...
+/// };
+enum {
+  DarwinBCSizeFieldOffset = 3*4, // Offset to bitcode_size.
+  DarwinBCHeaderSize = 5*4
+};
+
+static void WriteInt32ToBuffer(uint32_t Value, SmallVectorImpl<char> &Buffer,
+                               uint32_t &Position) {
+  support::endian::write32le(&Buffer[Position], Value);
+  Position += 4;
+}
+
+static void EmitDarwinBCHeaderAndTrailer(SmallVectorImpl<char> &Buffer,
+                                         const Triple &TT) {
+  unsigned CPUType = ~0U;
+
+  // Match x86_64-*, i[3-9]86-*, powerpc-*, powerpc64-*, arm-*, thumb-*,
+  // armv[0-9]-*, thumbv[0-9]-*, armv5te-*, or armv6t2-*. The CPUType is a magic
+  // number from /usr/include/mach/machine.h.  It is ok to reproduce the
+  // specific constants here because they are implicitly part of the Darwin ABI.
+  enum {
+    DARWIN_CPU_ARCH_ABI64      = 0x01000000,
+    DARWIN_CPU_TYPE_X86        = 7,
+    DARWIN_CPU_TYPE_ARM        = 12,
+    DARWIN_CPU_TYPE_POWERPC    = 18
+  };
+
+  Triple::ArchType Arch = TT.getArch();
+  if (Arch == Triple::x86_64)
+    CPUType = DARWIN_CPU_TYPE_X86 | DARWIN_CPU_ARCH_ABI64;
+  else if (Arch == Triple::x86)
+    CPUType = DARWIN_CPU_TYPE_X86;
+  else if (Arch == Triple::ppc)
+    CPUType = DARWIN_CPU_TYPE_POWERPC;
+  else if (Arch == Triple::ppc64)
+    CPUType = DARWIN_CPU_TYPE_POWERPC | DARWIN_CPU_ARCH_ABI64;
+  else if (Arch == Triple::arm || Arch == Triple::thumb)
+    CPUType = DARWIN_CPU_TYPE_ARM;
+
+  // Traditional Bitcode starts after header.
+  assert(Buffer.size() >= DarwinBCHeaderSize &&
+         "Expected header size to be reserved");
+  unsigned BCOffset = DarwinBCHeaderSize;
+  unsigned BCSize = Buffer.size()-DarwinBCHeaderSize;
+
+  // Write the magic and version.
+  unsigned Position = 0;
+  WriteInt32ToBuffer(0x0B17C0DE , Buffer, Position);
+  WriteInt32ToBuffer(0          , Buffer, Position); // Version.
+  WriteInt32ToBuffer(BCOffset   , Buffer, Position);
+  WriteInt32ToBuffer(BCSize     , Buffer, Position);
+  WriteInt32ToBuffer(CPUType    , Buffer, Position);
+
+  // If the file is not a multiple of 16 bytes, insert dummy padding.
+  while (Buffer.size() & 15)
+    Buffer.push_back(0);
+}
+
+/// Helper to write the header common to all bitcode files.
+static void WriteBitcodeHeader(BitstreamWriter &Stream) {
+  // Emit the file header.
+  Stream.Emit((unsigned)'B', 8);
+  Stream.Emit((unsigned)'C', 8);
+  Stream.Emit(0x0, 4);
+  Stream.Emit(0xC, 4);
+  Stream.Emit(0xE, 4);
+  Stream.Emit(0xD, 4);
+}
+
+/// WriteBitcodeToFile - Write the specified module to the specified output
+/// stream.
+void llvm::WriteBitcode32ToFile(const Module *M, raw_ostream &Out) {
+  SmallVector<char, 0> Buffer;
+  Buffer.reserve(256*1024);
+
+  // swap out DEBUG_METADATA_VERSION if it is present (yes, this is evil)
+  // NOTE: doesn't affect IOS_METAL_DEBUG_METADATA_VERSION, this is already correct
+  StringRef debug_info_version_str = "Debug Info Version";
+  if (auto debug_info_node = M->getModuleFlag(debug_info_version_str)) {
+    if (auto debug_info_version = dyn_cast<ConstantAsMetadata>(debug_info_node)) {
+      if(auto version_int = dyn_cast<ConstantInt>(debug_info_version->getValue())) {
+        if(version_int->getZExtValue() == DEBUG_METADATA_VERSION) {
+          // slightly awkward, the agony is real
+          NamedMDNode* module_flags = ((Module*)M)->getOrInsertModuleFlagsMetadata();
+          for(unsigned int i = 0, count = module_flags->getNumOperands(); i < count; ++i) {
+            auto Flag = module_flags->getOperand(i);
+            if (Flag->getNumOperands() >= 3 &&
+                dyn_cast_or_null<MDString>(Flag->getOperand(1)) &&
+                cast<MDString>(Flag->getOperand(1))->getString() == debug_info_version_str) {
+              Metadata *Ops[3] = {
+                ConstantAsMetadata::get(ConstantInt::get(Type::getInt32Ty(M->getContext()), llvm::Module::Warning)),
+                MDString::get(M->getContext(), debug_info_version_str),
+                ConstantAsMetadata::get(ConstantInt::get(Type::getInt32Ty(M->getContext()), DEBUG_METADATA_VERSION_32))
+              };
+              module_flags->setOperand(i, MDNode::get(M->getContext(), Ops));
+              break;
+            }
+          }
+        }
+      }
+    }
+  }
+
+  // If this is darwin or another generic macho target, reserve space for the
+  // header.
+  Triple TT(M->getTargetTriple());
+  if (TT.isOSDarwin())
+    Buffer.insert(Buffer.begin(), DarwinBCHeaderSize, 0);
+
+  // Emit the module into the buffer.
+  {
+    BitstreamWriter Stream(Buffer);
+
+    // Emit the file header.
+    WriteBitcodeHeader(Stream);
+
+    // Emit the module.
+    WriteModule(M, Stream);
+  }
+
+  if (TT.isOSDarwin())
+    EmitDarwinBCHeaderAndTrailer(Buffer, TT);
+
+  // Write the generated bitstream to "Out".
+  Out.write((char*)&Buffer.front(), Buffer.size());
+}
diff --git a/lib/Bitcode/Writer32/BitcodeWriterPass32.cpp b/lib/Bitcode/Writer32/BitcodeWriterPass32.cpp
new file mode 100644
index 0000000..6d7ee26
--- /dev/null
+++ b/lib/Bitcode/Writer32/BitcodeWriterPass32.cpp
@@ -0,0 +1,48 @@
+//===- BitcodeWriterPass32.cpp - Bitcode 3.2 writing pass -----------------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+// BitcodeWriter32Pass implementation.
+//
+//===----------------------------------------------------------------------===//
+
+#include "llvm/Bitcode/BitcodeWriterPass.h"
+#include "llvm/Bitcode/ReaderWriter.h"
+#include "llvm/IR/Module.h"
+#include "llvm/IR/PassManager.h"
+#include "llvm/Pass.h"
+using namespace llvm;
+
+PreservedAnalyses Bitcode32WriterPass::run(Module &M) {
+  WriteBitcode32ToFile(&M, OS);
+  return PreservedAnalyses::all();
+}
+
+namespace {
+  class WriteBitcode32Pass : public ModulePass {
+    raw_ostream &OS; // raw_ostream to print on
+
+  public:
+    static char ID; // Pass identification, replacement for typeid
+    explicit WriteBitcode32Pass(raw_ostream &o)
+        : ModulePass(ID), OS(o) {}
+
+    const char *getPassName() const override { return "Bitcode 3.2 Writer"; }
+
+    bool runOnModule(Module &M) override {
+      WriteBitcode32ToFile(&M, OS);
+      return false;
+    }
+  };
+}
+
+char WriteBitcode32Pass::ID = 0;
+
+ModulePass *llvm::createBitcode32WriterPass(raw_ostream &Str) {
+  return new WriteBitcode32Pass(Str);
+}
diff --git a/lib/Bitcode/Writer32/CMakeLists.txt b/lib/Bitcode/Writer32/CMakeLists.txt
new file mode 100644
index 0000000..c427bb3
--- /dev/null
+++ b/lib/Bitcode/Writer32/CMakeLists.txt
@@ -0,0 +1,9 @@
+add_llvm_library(LLVMBitWriter32
+  BitWriter32.cpp
+  BitcodeWriter32.cpp
+  BitcodeWriterPass32.cpp
+  ValueEnumerator32.cpp
+
+  DEPENDS
+  intrinsics_gen
+  )
diff --git a/lib/Bitcode/Writer32/LLVMBuild.txt b/lib/Bitcode/Writer32/LLVMBuild.txt
new file mode 100644
index 0000000..c1d3f27
--- /dev/null
+++ b/lib/Bitcode/Writer32/LLVMBuild.txt
@@ -0,0 +1,22 @@
+;===- ./lib/Bitcode/Writer32/LLVMBuild.txt ---------------------*- Conf -*--===;
+;
+;                     The LLVM Compiler Infrastructure
+;
+; This file is distributed under the University of Illinois Open Source
+; License. See LICENSE.TXT for details.
+;
+;===------------------------------------------------------------------------===;
+;
+; This is an LLVMBuild description file for the components in this subdirectory.
+;
+; For more information on the LLVMBuild system, please see:
+;
+;   http://llvm.org/docs/LLVMBuild.html
+;
+;===------------------------------------------------------------------------===;
+
+[component_0]
+type = Library
+name = BitWriter32
+parent = Bitcode
+required_libraries = Core Support
diff --git a/lib/Bitcode/Writer32/Makefile b/lib/Bitcode/Writer32/Makefile
new file mode 100644
index 0000000..d8135de
--- /dev/null
+++ b/lib/Bitcode/Writer32/Makefile
@@ -0,0 +1,15 @@
+##===- lib/Bitcode/Writer32/Makefile -----------------------*- Makefile -*-===##
+#
+#                     The LLVM Compiler Infrastructure
+#
+# This file is distributed under the University of Illinois Open Source
+# License. See LICENSE.TXT for details.
+#
+##===----------------------------------------------------------------------===##
+
+LEVEL = ../../..
+LIBRARYNAME = LLVMBitWriter32
+BUILD_ARCHIVE = 1
+
+include $(LEVEL)/Makefile.common
+
diff --git a/lib/Bitcode/Writer32/ValueEnumerator32.cpp b/lib/Bitcode/Writer32/ValueEnumerator32.cpp
new file mode 100644
index 0000000..2524d2d
--- /dev/null
+++ b/lib/Bitcode/Writer32/ValueEnumerator32.cpp
@@ -0,0 +1,645 @@
+//===- ValueEnumerator32.cpp - Number values and types for bitcode writer -===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+// This file implements the ValueEnumerator32 class.
+//
+//===----------------------------------------------------------------------===//
+
+#include "ValueEnumerator32.h"
+#include "llvm/ADT/STLExtras.h"
+#include "llvm/ADT/SmallPtrSet.h"
+#include "llvm/IR/Constants.h"
+#include "llvm/IR/DebugInfoMetadata.h"
+#include "llvm/IR/DerivedTypes.h"
+#include "llvm/IR/Instructions.h"
+#include "llvm/IR/Module.h"
+#include "llvm/IR/UseListOrder.h"
+#include "llvm/IR/ValueSymbolTable.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/raw_ostream.h"
+#include <algorithm>
+using namespace llvm;
+
+static bool isIntOrIntVectorValue(const std::pair<const Value*, unsigned> &V) {
+  return V.first->getType()->isIntOrIntVectorTy();
+}
+
+ValueEnumerator32::ValueEnumerator32(const Module &M)
+    : HasMDString(false), HasDILocation(false), HasGenericDINode(false) {
+  // Enumerate the global variables.
+  for (const GlobalVariable &GV : M.globals())
+    EnumerateValue(&GV);
+
+  // Enumerate the functions.
+  for (const Function & F : M) {
+    EnumerateValue(&F);
+    EnumerateAttributes(F.getAttributes());
+  }
+
+  // Enumerate the aliases.
+  for (const GlobalAlias &GA : M.aliases())
+    EnumerateValue(&GA);
+
+  // Remember what is the cutoff between globalvalue's and other constants.
+  unsigned FirstConstant = Values.size();
+
+  // Enumerate the global variable initializers.
+  for (const GlobalVariable &GV : M.globals())
+    if (GV.hasInitializer())
+      EnumerateValue(GV.getInitializer());
+
+  // Enumerate the aliasees.
+  for (const GlobalAlias &GA : M.aliases())
+    EnumerateValue(GA.getAliasee());
+
+  // Enumerate any optional Function data.
+  for (const Function &F : M)
+    for (const Use &U : F.operands())
+      EnumerateValue(U.get());
+
+  // Enumerate the metadata type.
+  //
+  // TODO: Move this to ValueEnumerator32::EnumerateOperandType() once bitcode
+  // only encodes the metadata type when it's used as a value.
+  EnumerateType(Type::getMetadataTy(M.getContext()));
+
+  // Insert constants and metadata that are named at module level into the slot
+  // pool so that the module symbol table can refer to them...
+  EnumerateValueSymbolTable(M.getValueSymbolTable());
+  EnumerateNamedMetadata(M);
+
+  SmallVector<std::pair<unsigned, MDNode *>, 8> MDs;
+
+  // Enumerate types used by function bodies and argument lists.
+  for (const Function &F : M) {
+    for (const Argument &A : F.args())
+      EnumerateType(A.getType());
+
+    for (const BasicBlock &BB : F)
+      for (const Instruction &I : BB) {
+        for (const Use &Op : I.operands()) {
+          auto *MD = dyn_cast<MetadataAsValue>(&Op);
+          if (!MD) {
+            EnumerateOperandType(Op);
+            continue;
+          }
+
+          // Local metadata is enumerated during function-incorporation.
+          if (isa<LocalAsMetadata>(MD->getMetadata()))
+            continue;
+
+          EnumerateMetadata(MD->getMetadata());
+        }
+        EnumerateType(I.getType());
+        if (const CallInst *CI = dyn_cast<CallInst>(&I))
+          EnumerateAttributes(CI->getAttributes());
+        else if (const InvokeInst *II = dyn_cast<InvokeInst>(&I))
+          EnumerateAttributes(II->getAttributes());
+
+        // Enumerate metadata attached with this instruction.
+        MDs.clear();
+        I.getAllMetadataOtherThanDebugLoc(MDs);
+        for (unsigned i = 0, e = MDs.size(); i != e; ++i)
+          EnumerateMetadata(MDs[i].second);
+
+        // Don't enumerate the location directly -- it has a special record
+        // type -- but enumerate its operands.
+        if (DILocation *L = I.getDebugLoc())
+          EnumerateMDNodeOperands(L);
+      }
+  }
+
+  // Optimize constant ordering.
+  OptimizeConstants(FirstConstant, Values.size());
+}
+
+unsigned ValueEnumerator32::getInstructionID(const Instruction *Inst) const {
+  InstructionMapType::const_iterator I = InstructionMap.find(Inst);
+  assert(I != InstructionMap.end() && "Instruction is not mapped!");
+  return I->second;
+}
+
+unsigned ValueEnumerator32::getComdatID(const Comdat *C) const {
+  unsigned ComdatID = Comdats.idFor(C);
+  assert(ComdatID && "Comdat not found!");
+  return ComdatID;
+}
+
+void ValueEnumerator32::setInstructionID(const Instruction *I) {
+  InstructionMap[I] = InstructionCount++;
+}
+
+unsigned ValueEnumerator32::getMetadataID(const Metadata *MD) const {
+  auto ID = getMetadataOrNullID(MD);
+#if 0
+  if(ID == 0) {
+    errs() << "invalid MD: ";
+    if(MD) errs() << MD;
+    else errs() << "nullptr";
+    errs() << "\n";
+  }
+#endif
+  assert(ID != 0 && "Metadata not in slotcalculator!");
+  return ID - 1;
+}
+
+unsigned ValueEnumerator32::getValueID(const Value *V) const {
+  if (auto *MD = dyn_cast<MetadataAsValue>(V))
+    return getMetadataID(MD->getMetadata());
+
+  ValueMapType::const_iterator I = ValueMap.find(V);
+#if 0
+  if(I == ValueMap.end()) {
+    errs() << "invalid value: " << *V << "\n";
+  }
+#endif
+  assert(I != ValueMap.end() && "Value not in slotcalculator!");
+  return I->second-1;
+}
+
+void ValueEnumerator32::dump() const {
+  print(dbgs(), ValueMap, "Default");
+  dbgs() << '\n';
+  print(dbgs(), MetadataMap, "MetaData");
+  dbgs() << '\n';
+}
+
+void ValueEnumerator32::print(raw_ostream &OS, const ValueMapType &Map,
+                              const char *Name) const {
+
+  OS << "Map Name: " << Name << "\n";
+  OS << "Size: " << Map.size() << "\n";
+  for (ValueMapType::const_iterator I = Map.begin(),
+         E = Map.end(); I != E; ++I) {
+
+    const Value *V = I->first;
+    if (V->hasName())
+      OS << "Value: " << V->getName();
+    else
+      OS << "Value: [null]\n";
+    V->dump();
+
+    OS << " Uses(" << std::distance(V->use_begin(),V->use_end()) << "):";
+    for (const Use &U : V->uses()) {
+      if (&U != &*V->use_begin())
+        OS << ",";
+      if(U->hasName())
+        OS << " " << U->getName();
+      else
+        OS << " [null]";
+
+    }
+    OS <<  "\n\n";
+  }
+}
+
+void ValueEnumerator32::print(raw_ostream &OS, const MetadataMapType &Map,
+                              const char *Name) const {
+
+  OS << "Map Name: " << Name << "\n";
+  OS << "Size: " << Map.size() << "\n";
+  for (auto I = Map.begin(), E = Map.end(); I != E; ++I) {
+    const Metadata *MD = I->first;
+    OS << "Metadata: slot = " << I->second << "\n";
+    MD->print(OS);
+  }
+}
+
+/// OptimizeConstants - Reorder constant pool for denser encoding.
+void ValueEnumerator32::OptimizeConstants(unsigned CstStart, unsigned CstEnd) {
+  if (CstStart == CstEnd || CstStart+1 == CstEnd) return;
+
+  std::stable_sort(Values.begin() + CstStart, Values.begin() + CstEnd,
+                   [this](const std::pair<const Value *, unsigned> &LHS,
+                          const std::pair<const Value *, unsigned> &RHS) {
+    // Sort by plane.
+    if (LHS.first->getType() != RHS.first->getType())
+      return getTypeID(LHS.first->getType()) < getTypeID(RHS.first->getType());
+    // Then by frequency.
+    return LHS.second > RHS.second;
+  });
+
+  // Ensure that integer and vector of integer constants are at the start of the
+  // constant pool.  This is important so that GEP structure indices come before
+  // gep constant exprs.
+  std::partition(Values.begin()+CstStart, Values.begin()+CstEnd,
+                 isIntOrIntVectorValue);
+
+  // Rebuild the modified portion of ValueMap.
+  for (; CstStart != CstEnd; ++CstStart)
+    ValueMap[Values[CstStart].first] = CstStart+1;
+}
+
+
+/// EnumerateValueSymbolTable - Insert all of the values in the specified symbol
+/// table into the values table.
+void ValueEnumerator32::EnumerateValueSymbolTable(const ValueSymbolTable &VST) {
+  for (ValueSymbolTable::const_iterator VI = VST.begin(), VE = VST.end();
+       VI != VE; ++VI)
+    EnumerateValue(VI->getValue());
+}
+
+/// Insert all of the values referenced by named metadata in the specified
+/// module.
+void ValueEnumerator32::EnumerateNamedMetadata(const Module &M) {
+  for (const auto &I : M.named_metadata())
+    EnumerateNamedMDNode(&I);
+}
+
+void ValueEnumerator32::EnumerateNamedMDNode(const NamedMDNode *MD) {
+  for (unsigned i = 0, e = MD->getNumOperands(); i != e; ++i)
+    EnumerateMetadata(MD->getOperand(i));
+}
+
+/// EnumerateMDNodeOperands - Enumerate all non-function-local values
+/// and types referenced by the given MDNode.
+void ValueEnumerator32::EnumerateMDNodeOperands(const MDNode *N) {
+  for (unsigned i = 0, e = N->getNumOperands(); i != e; ++i) {
+    const Metadata* MD = N->getOperand(i);
+    if (!MD) {
+      EnumerateType(Type::getVoidTy(N->getContext()));
+      continue;
+    }
+    assert(!isa<LocalAsMetadata>(MD) && "MDNodes cannot be function-local");
+    if(isa<MDNode>(MD) || isa<MDString>(MD)) {
+      EnumerateMetadata(MD);
+    } else if(auto* V = dyn_cast<ValueAsMetadata>(MD)) {
+      EnumerateValue(V->getValue());
+    }
+  }
+}
+
+#define EnumerateI1(DI_obj, val) EnumerateValue(ConstantInt::get(Type::getInt1Ty(DI_obj->getContext()), val))
+#define EnumerateI32(DI_obj, val) EnumerateValue(ConstantInt::get(Type::getInt32Ty(DI_obj->getContext()), val))
+#define EnumerateI64(DI_obj, val) EnumerateValue(ConstantInt::get(Type::getInt64Ty(DI_obj->getContext()), val))
+#define DW_TAG(tag) (tag | (12 << 16))
+
+void ValueEnumerator32::EnumerateMetadata(const Metadata *MD) {
+  assert(
+      (isa<MDNode>(MD) || isa<MDString>(MD) || isa<ConstantAsMetadata>(MD)) &&
+      "Invalid metadata kind");
+
+  // Insert a dummy ID to block the co-recursive call to
+  // EnumerateMDNodeOperands() from re-visiting MD in a cyclic graph.
+  //
+  // Return early if there's already an ID.
+  if (!MetadataMap.insert(std::make_pair(MD, 0)).second)
+    return;
+
+  // Visit operands first to minimize RAUW.
+  // NOTE: debug info must be handled manually (this is different to 3.8 handling)
+  if (auto *DILoc = dyn_cast<DILocation>(MD)) {
+    EnumerateI32(DILoc, DILoc->getLine());
+    EnumerateI32(DILoc, DILoc->getColumn());
+    EnumerateMDNodeOperands(DILoc);
+  }
+  else if (auto *DIF = dyn_cast<DIFile>(MD)) {
+    EnumerateI32(DIF, DW_TAG(dwarf::DW_TAG_file_type));
+    EnumerateMDNodeOperands(DIF);
+    SmallVector<Metadata*, 2> file_node {{ DIF->getRawFilename(), DIF->getRawDirectory() }};
+    ((DIFile*)DIF)->contained_node = MDTuple::get(DIF->getContext(), file_node);
+    EnumerateMetadata(DIF->contained_node);
+  }
+  else if (auto *DICU = dyn_cast<DICompileUnit>(MD)) {
+    EnumerateI32(DICU, DW_TAG(dwarf::DW_TAG_compile_unit));
+    if(DICU->getFile()) {
+      // doesn't point to an actual DIFile node, but directly to { file, dir }
+      auto DIF = DICU->getFile();
+      EnumerateMDNodeOperands(DIF);
+      SmallVector<Metadata*, 2> file_node {{ DIF->getRawFilename(), DIF->getRawDirectory() }};
+      DIF->contained_node = MDTuple::get(DICU->getContext(), file_node);
+      EnumerateMetadata(DIF->contained_node);
+    }
+    EnumerateI32(DICU, DICU->getSourceLanguage());
+    if(DICU->getRawProducer()) EnumerateMetadata(DICU->getRawProducer());
+    EnumerateI1(DICU, DICU->isOptimized());
+    if(DICU->getRawFlags()) EnumerateMetadata(DICU->getRawFlags());
+    EnumerateI32(DICU, DICU->getRuntimeVersion());
+    if(DICU->getRawEnumTypes()) EnumerateMetadata(DICU->getRawEnumTypes());
+    if(DICU->getRawRetainedTypes()) EnumerateMetadata(DICU->getRawRetainedTypes());
+    //if(DICU->getRawSubprograms()) EnumerateMetadata(DICU->getRawSubprograms()); // TODO: fix subprograms
+    if(DICU->getRawGlobalVariables()) EnumerateMetadata(DICU->getRawGlobalVariables());
+    if(DICU->getRawImportedEntities()) EnumerateMetadata(DICU->getRawImportedEntities());
+    if(DICU->getRawSplitDebugFilename()) EnumerateMetadata(DICU->getRawSplitDebugFilename());
+    EnumerateI32(DICU, DICU->getEmissionKind());
+  }
+  else if (auto *DISP = dyn_cast<DISubprogram>(MD)) {
+    EnumerateI32(DISP, DW_TAG(dwarf::DW_TAG_subprogram));
+    if(DISP->getFile()) EnumerateMetadata(DISP->getFile());
+    if(DISP->getScope()) EnumerateMetadata(DISP->getScope());
+    if(DISP->getRawName()) EnumerateMetadata(DISP->getRawName());
+    if(DISP->getRawLinkageName()) EnumerateMetadata(DISP->getRawLinkageName());
+    EnumerateI32(DISP, DISP->getLine());
+    if(DISP->getType()) EnumerateMetadata(DISP->getType());
+    EnumerateI1(DISP, DISP->isLocalToUnit());
+    EnumerateI1(DISP, DISP->isDefinition());
+    EnumerateI32(DISP, DISP->getVirtuality());
+    EnumerateI32(DISP, DISP->getVirtualIndex());
+    if(DISP->getContainingType()) EnumerateMetadata(DISP->getContainingType());
+    EnumerateI32(DISP, DISP->getFlags());
+    EnumerateI1(DISP, DISP->isOptimized());
+    if(DISP->associated_function) {
+      EnumerateValue(DISP->associated_function);
+    }
+    if(DISP->getTemplateParams()) EnumerateMetadata(DISP->getTemplateParams().get());
+    if(DISP->getDeclaration()) EnumerateMetadata(DISP->getDeclaration());
+    
+    if(DISP->getVariables()) EnumerateMetadata(DISP->getVariables().get());
+    else {
+      auto empty_node = MDTuple::getTemporary(DISP->getContext(), {});
+      EnumerateMetadata(empty_node.get());
+    }
+    
+    EnumerateI32(DISP, DISP->getScopeLine());
+  }
+  else if(auto *DILB = dyn_cast<DILexicalBlock>(MD)) {
+    EnumerateI32(DILB, DW_TAG(dwarf::DW_TAG_lexical_block));
+    
+    static unsigned int unique_id = 0;
+    if(DILB->getFile()) EnumerateMetadata(DILB->getFile());
+    if(DILB->getScope()) EnumerateMetadata(DILB->getScope());
+    EnumerateI32(DILB, DILB->getLine());
+    EnumerateI32(DILB, DILB->getColumn());
+    EnumerateI32(DILB, 0);
+    EnumerateI32(DILB, unique_id++);
+  }
+  else if(auto *DIST = dyn_cast<DISubroutineType>(MD)) {
+    EnumerateI32(DIST, DW_TAG(dwarf::DW_TAG_subroutine_type));
+    
+    EnumerateI32(DIST, 0);
+    auto empty_str_node = MDString::get(DIST->getContext(), "");
+    EnumerateMetadata(empty_str_node);
+    EnumerateI64(DIST, 0);
+    EnumerateI32(DIST, DIST->getFlags());
+    if(DIST->getTypeArray()) EnumerateMetadata(DIST->getTypeArray().get());
+  }
+  else if (auto *N = dyn_cast<MDNode>(MD))
+    EnumerateMDNodeOperands(N);
+  else if (auto *C = dyn_cast<ConstantAsMetadata>(MD))
+    EnumerateValue(C->getValue());
+
+  HasMDString |= isa<MDString>(MD);
+  HasDILocation |= isa<DILocation>(MD);
+  HasGenericDINode |= isa<GenericDINode>(MD);
+
+  // Replace the dummy ID inserted above with the correct one.  MetadataMap may
+  // have changed by inserting operands, so we need a fresh lookup here.
+  MDs.push_back(MD);
+  MetadataMap[MD] = MDs.size();
+}
+
+/// EnumerateFunctionLocalMetadataa - Incorporate function-local metadata
+/// information reachable from the metadata.
+void ValueEnumerator32::EnumerateFunctionLocalMetadata(
+    const LocalAsMetadata *Local) {
+  // Check to see if it's already in!
+  unsigned &MetadataID = MetadataMap[Local];
+  if (MetadataID)
+    return;
+
+  MDs.push_back(Local);
+  MetadataID = MDs.size();
+
+  EnumerateValue(Local->getValue());
+
+  // Also, collect all function-local metadata for easy access.
+  FunctionLocalMDs.push_back(Local);
+}
+
+void ValueEnumerator32::EnumerateValue(const Value *V) {
+  assert(!V->getType()->isVoidTy() && "Can't insert void values!");
+  assert(!isa<MetadataAsValue>(V) && "EnumerateValue doesn't handle Metadata!");
+
+  // Check to see if it's already in!
+  unsigned &ValueID = ValueMap[V];
+  if (ValueID) {
+    // Increment use count.
+    Values[ValueID-1].second++;
+    return;
+  }
+
+  if (auto *GO = dyn_cast<GlobalObject>(V))
+    if (const Comdat *C = GO->getComdat())
+      Comdats.insert(C);
+
+  // Enumerate the type of this value.
+  EnumerateType(V->getType());
+
+  if (const Constant *C = dyn_cast<Constant>(V)) {
+    if (isa<GlobalValue>(C)) {
+      // Initializers for globals are handled explicitly elsewhere.
+    } else if (C->getNumOperands()) {
+      // If a constant has operands, enumerate them.  This makes sure that if a
+      // constant has uses (for example an array of const ints), that they are
+      // inserted also.
+
+      // We prefer to enumerate them with values before we enumerate the user
+      // itself.  This makes it more likely that we can avoid forward references
+      // in the reader.  We know that there can be no cycles in the constants
+      // graph that don't go through a global variable.
+      for (User::const_op_iterator I = C->op_begin(), E = C->op_end();
+           I != E; ++I)
+        if (!isa<BasicBlock>(*I)) // Don't enumerate BB operand to BlockAddress.
+          EnumerateValue(*I);
+
+      // Finally, add the value.  Doing this could make the ValueID reference be
+      // dangling, don't reuse it.
+      Values.push_back(std::make_pair(V, 1U));
+      ValueMap[V] = Values.size();
+      return;
+    }
+  }
+
+  // Add the value.
+  Values.push_back(std::make_pair(V, 1U));
+  ValueID = Values.size();
+}
+
+
+void ValueEnumerator32::EnumerateType(Type *Ty) {
+  unsigned *TypeID = &TypeMap[Ty];
+
+  // We've already seen this type.
+  if (*TypeID)
+    return;
+
+  // If it is a non-anonymous struct, mark the type as being visited so that we
+  // don't recursively visit it.  This is safe because we allow forward
+  // references of these in the bitcode reader.
+  if (StructType *STy = dyn_cast<StructType>(Ty))
+    if (!STy->isLiteral())
+      *TypeID = ~0U;
+
+  // Enumerate all of the subtypes before we enumerate this type.  This ensures
+  // that the type will be enumerated in an order that can be directly built.
+  for (Type *SubTy : Ty->subtypes())
+    EnumerateType(SubTy);
+
+  // Refresh the TypeID pointer in case the table rehashed.
+  TypeID = &TypeMap[Ty];
+
+  // Check to see if we got the pointer another way.  This can happen when
+  // enumerating recursive types that hit the base case deeper than they start.
+  //
+  // If this is actually a struct that we are treating as forward ref'able,
+  // then emit the definition now that all of its contents are available.
+  if (*TypeID && *TypeID != ~0U)
+    return;
+
+  // Add this type now that its contents are all happily enumerated.
+  Types.push_back(Ty);
+
+  *TypeID = Types.size();
+}
+
+// Enumerate the types for the specified value.  If the value is a constant,
+// walk through it, enumerating the types of the constant.
+void ValueEnumerator32::EnumerateOperandType(const Value *V) {
+  EnumerateType(V->getType());
+
+  if (auto *MD = dyn_cast<MetadataAsValue>(V)) {
+    assert(!isa<LocalAsMetadata>(MD->getMetadata()) &&
+           "Function-local metadata should be left for later");
+
+    EnumerateMetadata(MD->getMetadata());
+    return;
+  }
+
+  const Constant *C = dyn_cast<Constant>(V);
+  if (!C)
+    return;
+
+  // If this constant is already enumerated, ignore it, we know its type must
+  // be enumerated.
+  if (ValueMap.count(C))
+    return;
+
+  // This constant may have operands, make sure to enumerate the types in
+  // them.
+  for (const Value *Op : C->operands()) {
+    // Don't enumerate basic blocks here, this happens as operands to
+    // blockaddress.
+    if (isa<BasicBlock>(Op))
+      continue;
+
+    EnumerateOperandType(Op);
+  }
+}
+
+void ValueEnumerator32::EnumerateAttributes(AttributeSet PAL) {
+  if (PAL.isEmpty()) return;  // null is always 0.
+
+  // Do a lookup.
+  unsigned &Entry = AttributeMap[PAL];
+  if (Entry == 0) {
+    // Never saw this before, add it.
+    Attribute.push_back(PAL);
+    Entry = Attribute.size();
+  }
+
+  // Do lookups for all attribute groups.
+  for (unsigned i = 0, e = PAL.getNumSlots(); i != e; ++i) {
+    AttributeSet AS = PAL.getSlotAttributes(i);
+    unsigned &Entry = AttributeGroupMap[AS];
+    if (Entry == 0) {
+      AttributeGroups.push_back(AS);
+      Entry = AttributeGroups.size();
+    }
+  }
+}
+
+void ValueEnumerator32::incorporateFunction(const Function &F) {
+  InstructionCount = 0;
+  NumModuleValues = Values.size();
+  NumModuleMDs = MDs.size();
+
+  // Adding function arguments to the value table.
+  for (const auto &I : F.args())
+    EnumerateValue(&I);
+
+  FirstFuncConstantID = Values.size();
+
+  // Add all function-level constants to the value table.
+  for (const BasicBlock &BB : F) {
+    for (const Instruction &I : BB)
+      for (const Use &OI : I.operands()) {
+        if ((isa<Constant>(OI) && !isa<GlobalValue>(OI)) || isa<InlineAsm>(OI))
+          EnumerateValue(OI);
+      }
+    BasicBlocks.push_back(&BB);
+    ValueMap[&BB] = BasicBlocks.size();
+  }
+
+  // Optimize the constant layout.
+  OptimizeConstants(FirstFuncConstantID, Values.size());
+
+  // Add the function's parameter attributes so they are available for use in
+  // the function's instruction.
+  EnumerateAttributes(F.getAttributes());
+
+  FirstInstID = Values.size();
+
+  SmallVector<LocalAsMetadata *, 8> FnLocalMDVector;
+  // Add all of the instructions.
+  for (const BasicBlock &BB : F) {
+    for (const Instruction &I : BB) {
+      for (const Use &OI : I.operands()) {
+        if (auto *MD = dyn_cast<MetadataAsValue>(&OI))
+          if (auto *Local = dyn_cast<LocalAsMetadata>(MD->getMetadata()))
+            // Enumerate metadata after the instructions they might refer to.
+            FnLocalMDVector.push_back(Local);
+      }
+
+      if (!I.getType()->isVoidTy())
+        EnumerateValue(&I);
+    }
+  }
+
+  // Add all of the function-local metadata.
+  for (unsigned i = 0, e = FnLocalMDVector.size(); i != e; ++i)
+    EnumerateFunctionLocalMetadata(FnLocalMDVector[i]);
+}
+
+void ValueEnumerator32::purgeFunction() {
+  /// Remove purged values from the ValueMap.
+  for (unsigned i = NumModuleValues, e = Values.size(); i != e; ++i)
+    ValueMap.erase(Values[i].first);
+  for (unsigned i = NumModuleMDs, e = MDs.size(); i != e; ++i)
+    MetadataMap.erase(MDs[i]);
+  for (unsigned i = 0, e = BasicBlocks.size(); i != e; ++i)
+    ValueMap.erase(BasicBlocks[i]);
+
+  Values.resize(NumModuleValues);
+  MDs.resize(NumModuleMDs);
+  BasicBlocks.clear();
+  FunctionLocalMDs.clear();
+}
+
+static void IncorporateFunctionInfoGlobalBBIDs(const Function *F,
+                                 DenseMap<const BasicBlock*, unsigned> &IDMap) {
+  unsigned Counter = 0;
+  for (const BasicBlock &BB : *F)
+    IDMap[&BB] = ++Counter;
+}
+
+/// getGlobalBasicBlockID - This returns the function-specific ID for the
+/// specified basic block.  This is relatively expensive information, so it
+/// should only be used by rare constructs such as address-of-label.
+unsigned ValueEnumerator32::getGlobalBasicBlockID(const BasicBlock *BB) const {
+  unsigned &Idx = GlobalBasicBlockIDs[BB];
+  if (Idx != 0)
+    return Idx-1;
+
+  IncorporateFunctionInfoGlobalBBIDs(BB->getParent(), GlobalBasicBlockIDs);
+  return getGlobalBasicBlockID(BB);
+}
+
+uint64_t ValueEnumerator32::computeBitsRequiredForTypeIndicies() const {
+  return Log2_32_Ceil(getTypes().size() + 1);
+}
diff --git a/lib/Bitcode/Writer32/ValueEnumerator32.h b/lib/Bitcode/Writer32/ValueEnumerator32.h
new file mode 100644
index 0000000..89a50b9
--- /dev/null
+++ b/lib/Bitcode/Writer32/ValueEnumerator32.h
@@ -0,0 +1,202 @@
+//===-- Bitcode/Writer32/ValueEnumerator32.h - Number values ----*- C++ -*-===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+// This class gives values and types Unique ID's.
+//
+//===----------------------------------------------------------------------===//
+
+#ifndef LLVM_LIB_BITCODE_32_WRITER_VALUEENUMERATOR_H
+#define LLVM_LIB_BITCODE_32_WRITER_VALUEENUMERATOR_H
+
+#include "llvm/ADT/DenseMap.h"
+#include "llvm/ADT/SmallVector.h"
+#include "llvm/ADT/UniqueVector.h"
+#include "llvm/IR/Attributes.h"
+#include "llvm/IR/UseListOrder.h"
+#include <vector>
+
+namespace llvm {
+
+class Type;
+class Value;
+class Instruction;
+class BasicBlock;
+class Comdat;
+class Function;
+class Module;
+class Metadata;
+class LocalAsMetadata;
+class MDNode;
+class NamedMDNode;
+class AttributeSet;
+class ValueSymbolTable;
+class MDSymbolTable;
+class raw_ostream;
+
+class ValueEnumerator32 {
+public:
+  typedef std::vector<Type*> TypeList;
+
+  // For each value, we remember its Value* and occurrence frequency.
+  typedef std::vector<std::pair<const Value*, unsigned> > ValueList;
+
+  UseListOrderStack UseListOrders;
+
+private:
+  typedef DenseMap<Type*, unsigned> TypeMapType;
+  TypeMapType TypeMap;
+  TypeList Types;
+
+  typedef DenseMap<const Value*, unsigned> ValueMapType;
+  ValueMapType ValueMap;
+  ValueList Values;
+
+  typedef UniqueVector<const Comdat *> ComdatSetType;
+  ComdatSetType Comdats;
+
+  std::vector<const Metadata *> MDs;
+  SmallVector<const LocalAsMetadata *, 8> FunctionLocalMDs;
+  typedef DenseMap<const Metadata *, unsigned> MetadataMapType;
+  MetadataMapType MetadataMap;
+  bool HasMDString;
+  bool HasDILocation;
+  bool HasGenericDINode;
+
+  typedef DenseMap<AttributeSet, unsigned> AttributeGroupMapType;
+  AttributeGroupMapType AttributeGroupMap;
+  std::vector<AttributeSet> AttributeGroups;
+
+  typedef DenseMap<AttributeSet, unsigned> AttributeMapType;
+  AttributeMapType AttributeMap;
+  std::vector<AttributeSet> Attribute;
+
+  /// GlobalBasicBlockIDs - This map memoizes the basic block ID's referenced by
+  /// the "getGlobalBasicBlockID" method.
+  mutable DenseMap<const BasicBlock*, unsigned> GlobalBasicBlockIDs;
+
+  typedef DenseMap<const Instruction*, unsigned> InstructionMapType;
+  InstructionMapType InstructionMap;
+  unsigned InstructionCount;
+
+  /// BasicBlocks - This contains all the basic blocks for the currently
+  /// incorporated function.  Their reverse mapping is stored in ValueMap.
+  std::vector<const BasicBlock*> BasicBlocks;
+
+  /// When a function is incorporated, this is the size of the Values list
+  /// before incorporation.
+  unsigned NumModuleValues;
+
+  /// When a function is incorporated, this is the size of the Metadatas list
+  /// before incorporation.
+  unsigned NumModuleMDs;
+
+  unsigned FirstFuncConstantID;
+  unsigned FirstInstID;
+
+  ValueEnumerator32(const ValueEnumerator32 &) = delete;
+  void operator=(const ValueEnumerator32 &) = delete;
+public:
+  ValueEnumerator32(const Module &M);
+
+  void dump() const;
+  void print(raw_ostream &OS, const ValueMapType &Map, const char *Name) const;
+  void print(raw_ostream &OS, const MetadataMapType &Map,
+             const char *Name) const;
+
+  unsigned getValueID(const Value *V) const;
+  unsigned getMetadataID(const Metadata *MD) const;
+  unsigned getMetadataOrNullID(const Metadata *MD) const {
+    return MetadataMap.lookup(MD);
+  }
+  unsigned numMDs() const { return MDs.size(); }
+
+  bool hasMDString() const { return HasMDString; }
+  bool hasDILocation() const { return HasDILocation; }
+  bool hasGenericDINode() const { return HasGenericDINode; }
+
+  unsigned getTypeID(Type *T) const {
+    TypeMapType::const_iterator I = TypeMap.find(T);
+    assert(I != TypeMap.end() && "Type not in ValueEnumerator32!");
+    return I->second-1;
+  }
+
+  unsigned getInstructionID(const Instruction *I) const;
+  void setInstructionID(const Instruction *I);
+
+  unsigned getAttributeID(AttributeSet PAL) const {
+    if (PAL.isEmpty()) return 0;  // Null maps to zero.
+    AttributeMapType::const_iterator I = AttributeMap.find(PAL);
+    assert(I != AttributeMap.end() && "Attribute not in ValueEnumerator32!");
+    return I->second;
+  }
+
+  unsigned getAttributeGroupID(AttributeSet PAL) const {
+    if (PAL.isEmpty()) return 0;  // Null maps to zero.
+    AttributeGroupMapType::const_iterator I = AttributeGroupMap.find(PAL);
+    assert(I != AttributeGroupMap.end() && "Attribute not in ValueEnumerator32!");
+    return I->second;
+  }
+
+  /// getFunctionConstantRange - Return the range of values that corresponds to
+  /// function-local constants.
+  void getFunctionConstantRange(unsigned &Start, unsigned &End) const {
+    Start = FirstFuncConstantID;
+    End = FirstInstID;
+  }
+
+  const ValueList &getValues() const { return Values; }
+  const std::vector<const Metadata *> &getMDs() const { return MDs; }
+  const SmallVectorImpl<const LocalAsMetadata *> &getFunctionLocalMDs() const {
+    return FunctionLocalMDs;
+  }
+  const TypeList &getTypes() const { return Types; }
+  const std::vector<const BasicBlock*> &getBasicBlocks() const {
+    return BasicBlocks;
+  }
+  const std::vector<AttributeSet> &getAttributes() const {
+    return Attribute;
+  }
+  const std::vector<AttributeSet> &getAttributeGroups() const {
+    return AttributeGroups;
+  }
+
+  const ComdatSetType &getComdats() const { return Comdats; }
+  unsigned getComdatID(const Comdat *C) const;
+
+  /// getGlobalBasicBlockID - This returns the function-specific ID for the
+  /// specified basic block.  This is relatively expensive information, so it
+  /// should only be used by rare constructs such as address-of-label.
+  unsigned getGlobalBasicBlockID(const BasicBlock *BB) const;
+
+  /// incorporateFunction/purgeFunction - If you'd like to deal with a function,
+  /// use these two methods to get its data into the ValueEnumerator32!
+  ///
+  void incorporateFunction(const Function &F);
+  void purgeFunction();
+  uint64_t computeBitsRequiredForTypeIndicies() const;
+
+private:
+  void OptimizeConstants(unsigned CstStart, unsigned CstEnd);
+
+  void EnumerateMDNodeOperands(const MDNode *N);
+  void EnumerateMetadata(const Metadata *MD);
+  void EnumerateFunctionLocalMetadata(const LocalAsMetadata *Local);
+  void EnumerateNamedMDNode(const NamedMDNode *NMD);
+  void EnumerateValue(const Value *V);
+  void EnumerateType(Type *T);
+  void EnumerateOperandType(const Value *V);
+  void EnumerateAttributes(AttributeSet PAL);
+
+  void EnumerateValueSymbolTable(const ValueSymbolTable &ST);
+  void EnumerateNamedMetadata(const Module &M);
+};
+
+} // End llvm namespace
+
+#endif
diff --git a/lib/Bitcode/Writer35/BitWriter35.cpp b/lib/Bitcode/Writer35/BitWriter35.cpp
new file mode 100644
index 0000000..7b330f7
--- /dev/null
+++ b/lib/Bitcode/Writer35/BitWriter35.cpp
@@ -0,0 +1,49 @@
+//===-- BitWriter35.cpp ---------------------------------------------------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+
+#include "llvm-c/BitWriter.h"
+#include "llvm/Bitcode/ReaderWriter.h"
+#include "llvm/IR/Module.h"
+#include "llvm/Support/FileSystem.h"
+#include "llvm/Support/raw_ostream.h"
+using namespace llvm;
+
+
+/*===-- Operations on modules ---------------------------------------------===*/
+
+int LLVMWriteBitcode35ToFile(LLVMModuleRef M, const char *Path) {
+  std::error_code EC;
+  raw_fd_ostream OS(Path, EC, sys::fs::F_None);
+
+  if (EC)
+    return -1;
+
+  WriteBitcode35ToFile(unwrap(M), OS);
+  return 0;
+}
+
+int LLVMWriteBitcode35ToFD(LLVMModuleRef M, int FD, int ShouldClose,
+                           int Unbuffered) {
+  raw_fd_ostream OS(FD, ShouldClose, Unbuffered);
+
+  WriteBitcode35ToFile(unwrap(M), OS);
+  return 0;
+}
+
+int LLVMWriteBitcode35ToFileHandle(LLVMModuleRef M, int FileHandle) {
+  return LLVMWriteBitcode35ToFD(M, FileHandle, true, false);
+}
+
+LLVMMemoryBufferRef LLVMWriteBitcode35ToMemoryBuffer(LLVMModuleRef M) {
+  std::string Data;
+  raw_string_ostream OS(Data);
+
+  WriteBitcode35ToFile(unwrap(M), OS);
+  return wrap(MemoryBuffer::getMemBufferCopy(OS.str()).release());
+}
diff --git a/lib/Bitcode/Writer35/BitcodeWriter35.cpp b/lib/Bitcode/Writer35/BitcodeWriter35.cpp
new file mode 100644
index 0000000..d3407b4
--- /dev/null
+++ b/lib/Bitcode/Writer35/BitcodeWriter35.cpp
@@ -0,0 +1,2628 @@
+//===--- Bitcode/Writer35/BitcodeWriter35.cpp - Bitcode 3.5 Writer --------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+// Bitcode 3.5 writer implementation.
+//
+//===----------------------------------------------------------------------===//
+
+// enable errors when using > 3.5 bitcode enums from LLVMBitCodes.h
+#define LLVM_BITCODE_35 1
+
+#include "llvm/Bitcode/ReaderWriter.h"
+#include "ValueEnumerator35.h"
+#include "llvm/ADT/STLExtras.h"
+#include "llvm/ADT/Triple.h"
+#include "llvm/Bitcode/BitstreamWriter.h"
+#include "llvm/Bitcode/LLVMBitCodes.h"
+#include "llvm/IR/CallSite.h"
+#include "llvm/IR/Constants.h"
+#include "llvm/IR/DebugInfoMetadata.h"
+#include "llvm/IR/DerivedTypes.h"
+#include "llvm/IR/InlineAsm.h"
+#include "llvm/IR/Instructions.h"
+#include "llvm/IR/LLVMContext.h"
+#include "llvm/IR/IntrinsicInst.h"
+#include "llvm/IR/Module.h"
+#include "llvm/IR/Operator.h"
+#include "llvm/IR/UseListOrder.h"
+#include "llvm/IR/ValueSymbolTable.h"
+#include "llvm/Support/CommandLine.h"
+#include "llvm/Support/ErrorHandling.h"
+#include "llvm/Support/MathExtras.h"
+#include "llvm/Support/Program.h"
+#include "llvm/Support/raw_ostream.h"
+#include "llvm/Support/Dwarf.h"
+#include <cctype>
+#include <map>
+using namespace llvm;
+
+/// These are manifest constants used by the bitcode writer. They do not need to
+/// be kept in sync with the reader, but need to be consistent within this file.
+enum {
+  // VALUE_SYMTAB_BLOCK abbrev id's.
+  VST_ENTRY_8_ABBREV = bitc::FIRST_APPLICATION_ABBREV,
+  VST_ENTRY_7_ABBREV,
+  VST_ENTRY_6_ABBREV,
+  VST_BBENTRY_6_ABBREV,
+
+  // CONSTANTS_BLOCK abbrev id's.
+  CONSTANTS_SETTYPE_ABBREV = bitc::FIRST_APPLICATION_ABBREV,
+  CONSTANTS_INTEGER_ABBREV,
+  CONSTANTS_CE_CAST_Abbrev,
+  CONSTANTS_NULL_Abbrev,
+
+  // FUNCTION_BLOCK abbrev id's.
+  FUNCTION_INST_LOAD_ABBREV = bitc::FIRST_APPLICATION_ABBREV,
+  FUNCTION_INST_BINOP_ABBREV,
+  FUNCTION_INST_BINOP_FLAGS_ABBREV,
+  FUNCTION_INST_CAST_ABBREV,
+  FUNCTION_INST_RET_VOID_ABBREV,
+  FUNCTION_INST_RET_VAL_ABBREV,
+  FUNCTION_INST_UNREACHABLE_ABBREV,
+  FUNCTION_INST_GEP_ABBREV BC38,
+};
+
+static unsigned GetEncodedCastOpcode(unsigned Opcode) {
+  switch (Opcode) {
+  default: llvm_unreachable("Unknown cast instruction!");
+  case Instruction::Trunc   : return bitc::CAST_TRUNC;
+  case Instruction::ZExt    : return bitc::CAST_ZEXT;
+  case Instruction::SExt    : return bitc::CAST_SEXT;
+  case Instruction::FPToUI  : return bitc::CAST_FPTOUI;
+  case Instruction::FPToSI  : return bitc::CAST_FPTOSI;
+  case Instruction::UIToFP  : return bitc::CAST_UITOFP;
+  case Instruction::SIToFP  : return bitc::CAST_SITOFP;
+  case Instruction::FPTrunc : return bitc::CAST_FPTRUNC;
+  case Instruction::FPExt   : return bitc::CAST_FPEXT;
+  case Instruction::PtrToInt: return bitc::CAST_PTRTOINT;
+  case Instruction::IntToPtr: return bitc::CAST_INTTOPTR;
+  case Instruction::BitCast : return bitc::CAST_BITCAST;
+  case Instruction::AddrSpaceCast: return bitc::CAST_ADDRSPACECAST;
+  }
+}
+
+static unsigned GetEncodedBinaryOpcode(unsigned Opcode) {
+  switch (Opcode) {
+  default: llvm_unreachable("Unknown binary instruction!");
+  case Instruction::Add:
+  case Instruction::FAdd: return bitc::BINOP_ADD;
+  case Instruction::Sub:
+  case Instruction::FSub: return bitc::BINOP_SUB;
+  case Instruction::Mul:
+  case Instruction::FMul: return bitc::BINOP_MUL;
+  case Instruction::UDiv: return bitc::BINOP_UDIV;
+  case Instruction::FDiv:
+  case Instruction::SDiv: return bitc::BINOP_SDIV;
+  case Instruction::URem: return bitc::BINOP_UREM;
+  case Instruction::FRem:
+  case Instruction::SRem: return bitc::BINOP_SREM;
+  case Instruction::Shl:  return bitc::BINOP_SHL;
+  case Instruction::LShr: return bitc::BINOP_LSHR;
+  case Instruction::AShr: return bitc::BINOP_ASHR;
+  case Instruction::And:  return bitc::BINOP_AND;
+  case Instruction::Or:   return bitc::BINOP_OR;
+  case Instruction::Xor:  return bitc::BINOP_XOR;
+  }
+}
+
+static unsigned GetEncodedRMWOperation(AtomicRMWInst::BinOp Op) {
+  switch (Op) {
+  default: llvm_unreachable("Unknown RMW operation!");
+  case AtomicRMWInst::Xchg: return bitc::RMW_XCHG;
+  case AtomicRMWInst::Add: return bitc::RMW_ADD;
+  case AtomicRMWInst::Sub: return bitc::RMW_SUB;
+  case AtomicRMWInst::And: return bitc::RMW_AND;
+  case AtomicRMWInst::Nand: return bitc::RMW_NAND;
+  case AtomicRMWInst::Or: return bitc::RMW_OR;
+  case AtomicRMWInst::Xor: return bitc::RMW_XOR;
+  case AtomicRMWInst::Max: return bitc::RMW_MAX;
+  case AtomicRMWInst::Min: return bitc::RMW_MIN;
+  case AtomicRMWInst::UMax: return bitc::RMW_UMAX;
+  case AtomicRMWInst::UMin: return bitc::RMW_UMIN;
+  }
+}
+
+static unsigned GetEncodedOrdering(AtomicOrdering Ordering) {
+  switch (Ordering) {
+  case AtomicOrdering::NotAtomic: return bitc::ORDERING_NOTATOMIC;
+  case AtomicOrdering::Unordered: return bitc::ORDERING_UNORDERED;
+  case AtomicOrdering::Monotonic: return bitc::ORDERING_MONOTONIC;
+  case AtomicOrdering::Acquire: return bitc::ORDERING_ACQUIRE;
+  case AtomicOrdering::Release: return bitc::ORDERING_RELEASE;
+  case AtomicOrdering::AcquireRelease: return bitc::ORDERING_ACQREL;
+  case AtomicOrdering::SequentiallyConsistent: return bitc::ORDERING_SEQCST;
+  }
+  llvm_unreachable("Invalid ordering");
+}
+
+static unsigned GetEncodedSynchScope(SynchronizationScope SynchScope) {
+  switch (SynchScope) {
+  case SingleThread: return bitc::SYNCHSCOPE_SINGLETHREAD;
+  case CrossThread: return bitc::SYNCHSCOPE_CROSSTHREAD;
+  }
+  llvm_unreachable("Invalid synch scope");
+}
+
+static void WriteStringRecord(unsigned Code, StringRef Str,
+                              unsigned AbbrevToUse, BitstreamWriter &Stream) {
+  SmallVector<unsigned, 64> Vals;
+
+  // Code: [strchar x N]
+  for (unsigned i = 0, e = Str.size(); i != e; ++i) {
+    if (AbbrevToUse && !BitCodeAbbrevOp::isChar6(Str[i]))
+      AbbrevToUse = 0;
+    Vals.push_back(Str[i]);
+  }
+
+  // Emit the finished record.
+  Stream.EmitRecord(Code, Vals, AbbrevToUse);
+}
+
+static uint64_t getAttrKindEncoding(Attribute::AttrKind Kind) {
+  switch (Kind) {
+  case Attribute::Alignment:
+    return bitc::ATTR_KIND_ALIGNMENT;
+  case Attribute::AllocSize:
+    return bitc::ATTR_KIND_INVALID; // not in 3.5
+  case Attribute::AlwaysInline:
+    return bitc::ATTR_KIND_ALWAYS_INLINE;
+  case Attribute::ArgMemOnly:
+    return bitc::ATTR_KIND_INVALID; // not in 3.5
+  case Attribute::Builtin:
+    return bitc::ATTR_KIND_BUILTIN;
+  case Attribute::ByVal:
+    return bitc::ATTR_KIND_BY_VAL;
+  case Attribute::Convergent:
+    return bitc::ATTR_KIND_INVALID; // not in 3.5
+  case Attribute::InAlloca:
+    return bitc::ATTR_KIND_INVALID; // technically in 3.5, but not supported by Metal
+  case Attribute::Cold:
+    return bitc::ATTR_KIND_COLD;
+  case Attribute::InaccessibleMemOnly:
+    return bitc::ATTR_KIND_INVALID; // not in 3.5
+  case Attribute::InaccessibleMemOrArgMemOnly:
+    return bitc::ATTR_KIND_INVALID; // not in 3.5
+  case Attribute::InlineHint:
+    return bitc::ATTR_KIND_INLINE_HINT;
+  case Attribute::InReg:
+    return bitc::ATTR_KIND_IN_REG;
+  case Attribute::JumpTable:
+    return bitc::ATTR_KIND_INVALID; // technically in 3.5, but not supported by Metal
+  case Attribute::MinSize:
+    return bitc::ATTR_KIND_MIN_SIZE;
+  case Attribute::Naked:
+    return bitc::ATTR_KIND_NAKED;
+  case Attribute::Nest:
+    return bitc::ATTR_KIND_NEST;
+  case Attribute::NoAlias:
+    return bitc::ATTR_KIND_NO_ALIAS;
+  case Attribute::NoBuiltin:
+    return bitc::ATTR_KIND_NO_BUILTIN;
+  case Attribute::NoCapture:
+    return bitc::ATTR_KIND_NO_CAPTURE;
+  case Attribute::NoDuplicate:
+    return bitc::ATTR_KIND_NO_DUPLICATE;
+  case Attribute::NoImplicitFloat:
+    return bitc::ATTR_KIND_NO_IMPLICIT_FLOAT;
+  case Attribute::NoInline:
+    return bitc::ATTR_KIND_NO_INLINE;
+  case Attribute::NoRecurse:
+    return bitc::ATTR_KIND_INVALID; // not in 3.5
+  case Attribute::NonLazyBind:
+    return bitc::ATTR_KIND_NON_LAZY_BIND;
+  case Attribute::NonNull:
+    return bitc::ATTR_KIND_INVALID; // technically in 3.5, but not supported by Metal
+  case Attribute::Dereferenceable:
+    return bitc::ATTR_KIND_INVALID; // technically in 3.5, but not supported by Metal
+  case Attribute::DereferenceableOrNull:
+    return bitc::ATTR_KIND_INVALID; // not in 3.5
+  case Attribute::NoRedZone:
+    return bitc::ATTR_KIND_NO_RED_ZONE;
+  case Attribute::NoReturn:
+    return bitc::ATTR_KIND_NO_RETURN;
+  case Attribute::NoUnwind:
+    return bitc::ATTR_KIND_NO_UNWIND;
+  case Attribute::OptimizeForSize:
+    return bitc::ATTR_KIND_OPTIMIZE_FOR_SIZE;
+  case Attribute::OptimizeNone:
+    return bitc::ATTR_KIND_OPTIMIZE_NONE;
+  case Attribute::ReadNone:
+    return bitc::ATTR_KIND_READ_NONE;
+  case Attribute::ReadOnly:
+    return bitc::ATTR_KIND_READ_ONLY;
+  case Attribute::Returned:
+    return bitc::ATTR_KIND_RETURNED;
+  case Attribute::ReturnsTwice:
+    return bitc::ATTR_KIND_RETURNS_TWICE;
+  case Attribute::SExt:
+    return bitc::ATTR_KIND_S_EXT;
+  case Attribute::StackAlignment:
+    return bitc::ATTR_KIND_STACK_ALIGNMENT;
+  case Attribute::StackProtect:
+    return bitc::ATTR_KIND_STACK_PROTECT;
+  case Attribute::StackProtectReq:
+    return bitc::ATTR_KIND_STACK_PROTECT_REQ;
+  case Attribute::StackProtectStrong:
+    return bitc::ATTR_KIND_STACK_PROTECT_STRONG;
+  case Attribute::SafeStack:
+    return bitc::ATTR_KIND_INVALID; // not in 3.5
+  case Attribute::StructRet:
+    return bitc::ATTR_KIND_STRUCT_RET;
+  case Attribute::SanitizeAddress:
+    return bitc::ATTR_KIND_SANITIZE_ADDRESS;
+  case Attribute::SanitizeThread:
+    return bitc::ATTR_KIND_SANITIZE_THREAD;
+  case Attribute::SanitizeMemory:
+    return bitc::ATTR_KIND_SANITIZE_MEMORY;
+  case Attribute::SwiftError:
+    return bitc::ATTR_KIND_INVALID; // not in 3.5
+  case Attribute::SwiftSelf:
+    return bitc::ATTR_KIND_INVALID; // not in 3.5
+  case Attribute::UWTable:
+    return bitc::ATTR_KIND_UW_TABLE;
+  case Attribute::WriteOnly:
+    return bitc::ATTR_KIND_INVALID; // not in 3.5
+  case Attribute::ZExt:
+    return bitc::ATTR_KIND_Z_EXT;
+  case Attribute::EndAttrKinds:
+    llvm_unreachable("Can not encode end-attribute kinds marker.");
+  case Attribute::None:
+    llvm_unreachable("Can not encode none-attribute.");
+  }
+
+  llvm_unreachable("Trying to encode unknown attribute");
+}
+
+// due to the necessity to drop attributes that aren't supported by earlier llvm versions (3.5),
+// attribute sets can become empty, which is invalid under certain circumstances
+// -> provide an easy method to count the attributes that will actually be accepted by the earlier llvm version
+static uint32_t compute_valid_attribute_count(const AttributeSet& AS) {
+  uint32_t count = 0;
+  for (AttributeSet::iterator I = AS.begin(0), E = AS.end(0); I != E; ++I) {
+    Attribute Attr = *I;
+    if (Attr.isEnumAttribute() || Attr.isIntAttribute()) {
+      // ignore dropped/invalid attrs
+      if (getAttrKindEncoding(Attr.getKindAsEnum()) != bitc::ATTR_KIND_INVALID) {
+        ++count;
+      }
+    }
+    // string
+    else ++count;
+  }
+  return count;
+}
+
+static void WriteAttributeGroupTable(const ValueEnumerator35 &VE,
+                                     BitstreamWriter &Stream) {
+  const std::vector<AttributeSet> &AttrGrps = VE.getAttributeGroups();
+  if (AttrGrps.empty()) return;
+
+  Stream.EnterSubblock(bitc::PARAMATTR_GROUP_BLOCK_ID, 3);
+
+  SmallVector<uint64_t, 64> Record;
+  for (unsigned i = 0, e = AttrGrps.size(); i != e; ++i) {
+    AttributeSet AS = AttrGrps[i];
+    for (unsigned i = 0, e = AS.getNumSlots(); i != e; ++i) {
+      AttributeSet A = AS.getSlotAttributes(i);
+
+      // if the valid/emitted attribute set is empty, it's invalid to emit anything here at all
+      if (compute_valid_attribute_count(A) == 0) continue;
+
+      Record.push_back(VE.getAttributeGroupID(A));
+      Record.push_back(AS.getSlotIndex(i));
+
+      for (AttributeSet::iterator I = AS.begin(0), E = AS.end(0);
+           I != E; ++I) {
+        Attribute Attr = *I;
+        if (Attr.isEnumAttribute()) {
+          const auto attr_enc = getAttrKindEncoding(Attr.getKindAsEnum());
+          if (attr_enc != bitc::ATTR_KIND_INVALID) {
+            Record.push_back(0);
+            Record.push_back(attr_enc);
+          }
+        } else if (Attr.isIntAttribute()) {
+          const auto attr_enc = getAttrKindEncoding(Attr.getKindAsEnum());
+          if (attr_enc != bitc::ATTR_KIND_INVALID) {
+            Record.push_back(1);
+            Record.push_back(attr_enc);
+            Record.push_back(Attr.getValueAsInt());
+          }
+        } else {
+          StringRef Kind = Attr.getKindAsString();
+          StringRef Val = Attr.getValueAsString();
+
+          Record.push_back(Val.empty() ? 3 : 4);
+          Record.append(Kind.begin(), Kind.end());
+          Record.push_back(0);
+          if (!Val.empty()) {
+            Record.append(Val.begin(), Val.end());
+            Record.push_back(0);
+          }
+        }
+      }
+
+      Stream.EmitRecord(bitc::PARAMATTR_GRP_CODE_ENTRY, Record);
+      Record.clear();
+    }
+  }
+
+  Stream.ExitBlock();
+}
+
+static void WriteAttributeTable(const ValueEnumerator35 &VE,
+                                BitstreamWriter &Stream) {
+  const std::vector<AttributeSet> &Attrs = VE.getAttributes();
+  if (Attrs.empty()) return;
+
+  Stream.EnterSubblock(bitc::PARAMATTR_BLOCK_ID, 3);
+
+  SmallVector<uint64_t, 64> Record;
+  for (unsigned i = 0, e = Attrs.size(); i != e; ++i) {
+    const AttributeSet &A = Attrs[i];
+    for (unsigned i = 0, e = A.getNumSlots(); i != e; ++i) {
+      AttributeSet AS = A.getSlotAttributes(i);
+      // while not technically necessary, ignore/drop this attribute group if it has no valid/emitted attributes
+      if (compute_valid_attribute_count(AS) == 0) continue;
+      Record.push_back(VE.getAttributeGroupID(AS));
+    }
+
+    Stream.EmitRecord(bitc::PARAMATTR_CODE_ENTRY, Record);
+    Record.clear();
+  }
+
+  Stream.ExitBlock();
+}
+
+/// WriteTypeTable - Write out the type table for a module.
+static void WriteTypeTable(const ValueEnumerator35 &VE, BitstreamWriter &Stream) {
+  const ValueEnumerator35::TypeList &TypeList = VE.getTypes();
+
+  Stream.EnterSubblock(bitc::TYPE_BLOCK_ID_NEW, 4 /*count from # abbrevs */);
+  SmallVector<uint64_t, 64> TypeVals;
+
+  uint64_t NumBits = VE.computeBitsRequiredForTypeIndicies();
+
+  // Abbrev for TYPE_CODE_POINTER.
+  BitCodeAbbrev *Abbv = new BitCodeAbbrev();
+  Abbv->Add(BitCodeAbbrevOp(bitc::TYPE_CODE_POINTER));
+  Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, NumBits));
+  Abbv->Add(BitCodeAbbrevOp(0));  // Addrspace = 0
+  unsigned PtrAbbrev = Stream.EmitAbbrev(Abbv);
+
+  // Abbrev for TYPE_CODE_FUNCTION.
+  Abbv = new BitCodeAbbrev();
+  Abbv->Add(BitCodeAbbrevOp(bitc::TYPE_CODE_FUNCTION));
+  Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, 1));  // isvararg
+  Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Array));
+  Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, NumBits));
+
+  unsigned FunctionAbbrev = Stream.EmitAbbrev(Abbv);
+
+  // Abbrev for TYPE_CODE_STRUCT_ANON.
+  Abbv = new BitCodeAbbrev();
+  Abbv->Add(BitCodeAbbrevOp(bitc::TYPE_CODE_STRUCT_ANON));
+  Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, 1));  // ispacked
+  Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Array));
+  Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, NumBits));
+
+  unsigned StructAnonAbbrev = Stream.EmitAbbrev(Abbv);
+
+  // Abbrev for TYPE_CODE_STRUCT_NAME.
+  Abbv = new BitCodeAbbrev();
+  Abbv->Add(BitCodeAbbrevOp(bitc::TYPE_CODE_STRUCT_NAME));
+  Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Array));
+  Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Char6));
+  unsigned StructNameAbbrev = Stream.EmitAbbrev(Abbv);
+
+  // Abbrev for TYPE_CODE_STRUCT_NAMED.
+  Abbv = new BitCodeAbbrev();
+  Abbv->Add(BitCodeAbbrevOp(bitc::TYPE_CODE_STRUCT_NAMED));
+  Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, 1));  // ispacked
+  Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Array));
+  Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, NumBits));
+
+  unsigned StructNamedAbbrev = Stream.EmitAbbrev(Abbv);
+
+  // Abbrev for TYPE_CODE_ARRAY.
+  Abbv = new BitCodeAbbrev();
+  Abbv->Add(BitCodeAbbrevOp(bitc::TYPE_CODE_ARRAY));
+  Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::VBR, 8));   // size
+  Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, NumBits));
+
+  unsigned ArrayAbbrev = Stream.EmitAbbrev(Abbv);
+
+  // don't emit token types for 3.5
+  unsigned int ignored_types = 0;
+  for (const auto& type : TypeList) {
+    if (type->getTypeID() == Type::TokenTyID) {
+      ++ignored_types;
+    }
+  }
+
+  // Emit an entry count so the reader can reserve space.
+  TypeVals.push_back(TypeList.size() - ignored_types);
+  Stream.EmitRecord(bitc::TYPE_CODE_NUMENTRY, TypeVals);
+  TypeVals.clear();
+
+  // Loop over all of the types, emitting each in turn.
+  for (unsigned i = 0, e = TypeList.size(); i != e; ++i) {
+    Type *T = TypeList[i];
+    int AbbrevToUse = 0;
+    unsigned Code = 0;
+
+    // not in 3.5
+    if (T->getTypeID() == Type::TokenTyID) continue;
+
+    switch (T->getTypeID()) {
+    case Type::VoidTyID:      Code = bitc::TYPE_CODE_VOID;      break;
+    case Type::HalfTyID:      Code = bitc::TYPE_CODE_HALF;      break;
+    case Type::FloatTyID:     Code = bitc::TYPE_CODE_FLOAT;     break;
+    case Type::DoubleTyID:    Code = bitc::TYPE_CODE_DOUBLE;    break;
+    case Type::X86_FP80TyID:  Code = bitc::TYPE_CODE_X86_FP80;  break;
+    case Type::FP128TyID:     Code = bitc::TYPE_CODE_FP128;     break;
+    case Type::PPC_FP128TyID: Code = bitc::TYPE_CODE_PPC_FP128; break;
+    case Type::LabelTyID:     Code = bitc::TYPE_CODE_LABEL;     break;
+    case Type::MetadataTyID:  Code = bitc::TYPE_CODE_METADATA;  break;
+    case Type::X86_MMXTyID:   Code = bitc::TYPE_CODE_X86_MMX;   break;
+    case Type::TokenTyID: break; // already handled
+    case Type::IntegerTyID:
+      // INTEGER: [width]
+      Code = bitc::TYPE_CODE_INTEGER;
+      TypeVals.push_back(cast<IntegerType>(T)->getBitWidth());
+      break;
+    case Type::PointerTyID: {
+      PointerType *PTy = cast<PointerType>(T);
+      // POINTER: [pointee type, address space]
+      Code = bitc::TYPE_CODE_POINTER;
+      TypeVals.push_back(VE.getTypeID(PTy->getElementType()));
+      unsigned AddressSpace = PTy->getAddressSpace();
+      TypeVals.push_back(AddressSpace);
+      if (AddressSpace == 0) AbbrevToUse = PtrAbbrev;
+      break;
+    }
+    case Type::FunctionTyID: {
+      FunctionType *FT = cast<FunctionType>(T);
+      // FUNCTION: [isvararg, retty, paramty x N]
+      Code = bitc::TYPE_CODE_FUNCTION;
+      TypeVals.push_back(FT->isVarArg());
+      TypeVals.push_back(VE.getTypeID(FT->getReturnType()));
+      for (unsigned i = 0, e = FT->getNumParams(); i != e; ++i)
+        TypeVals.push_back(VE.getTypeID(FT->getParamType(i)));
+      AbbrevToUse = FunctionAbbrev;
+      break;
+    }
+    case Type::StructTyID: {
+      StructType *ST = cast<StructType>(T);
+      // STRUCT: [ispacked, eltty x N]
+      TypeVals.push_back(ST->isPacked());
+      // Output all of the element types.
+      for (StructType::element_iterator I = ST->element_begin(),
+           E = ST->element_end(); I != E; ++I)
+        TypeVals.push_back(VE.getTypeID(*I));
+
+      if (ST->isLiteral()) {
+        Code = bitc::TYPE_CODE_STRUCT_ANON;
+        AbbrevToUse = StructAnonAbbrev;
+      } else {
+        if (ST->isOpaque()) {
+          Code = bitc::TYPE_CODE_OPAQUE;
+        } else {
+          Code = bitc::TYPE_CODE_STRUCT_NAMED;
+          AbbrevToUse = StructNamedAbbrev;
+        }
+
+        // Emit the name if it is present.
+        if (!ST->getName().empty())
+          WriteStringRecord(bitc::TYPE_CODE_STRUCT_NAME, ST->getName(),
+                            StructNameAbbrev, Stream);
+      }
+      break;
+    }
+    case Type::ArrayTyID: {
+      ArrayType *AT = cast<ArrayType>(T);
+      // ARRAY: [numelts, eltty]
+      Code = bitc::TYPE_CODE_ARRAY;
+      TypeVals.push_back(AT->getNumElements());
+      TypeVals.push_back(VE.getTypeID(AT->getElementType()));
+      AbbrevToUse = ArrayAbbrev;
+      break;
+    }
+    case Type::VectorTyID: {
+      VectorType *VT = cast<VectorType>(T);
+      // VECTOR [numelts, eltty]
+      Code = bitc::TYPE_CODE_VECTOR;
+      TypeVals.push_back(VT->getNumElements());
+      TypeVals.push_back(VE.getTypeID(VT->getElementType()));
+      break;
+    }
+    }
+
+    // Emit the finished record.
+    Stream.EmitRecord(Code, TypeVals, AbbrevToUse);
+    TypeVals.clear();
+  }
+
+  Stream.ExitBlock();
+}
+
+static unsigned getEncodedLinkage(const GlobalValue &GV) {
+  switch (GV.getLinkage()) {
+  case GlobalValue::ExternalLinkage:                 return 0;
+  case GlobalValue::WeakAnyLinkage:                  return 1;
+  case GlobalValue::AppendingLinkage:                return 2;
+  case GlobalValue::InternalLinkage:                 return 3;
+  case GlobalValue::LinkOnceAnyLinkage:              return 4;
+  case GlobalValue::ExternalWeakLinkage:             return 7;
+  case GlobalValue::CommonLinkage:                   return 8;
+  case GlobalValue::PrivateLinkage:                  return 9;
+  case GlobalValue::WeakODRLinkage:                  return 10;
+  case GlobalValue::LinkOnceODRLinkage:              return 11;
+  case GlobalValue::AvailableExternallyLinkage:      return 12;
+  }
+  llvm_unreachable("Invalid linkage");
+}
+
+static unsigned getEncodedVisibility(const GlobalValue &GV) {
+  switch (GV.getVisibility()) {
+  case GlobalValue::DefaultVisibility:   return 0;
+  case GlobalValue::HiddenVisibility:    return 1;
+  case GlobalValue::ProtectedVisibility: return 2;
+  }
+  llvm_unreachable("Invalid visibility");
+}
+
+static unsigned getEncodedDLLStorageClass(const GlobalValue &GV) {
+  switch (GV.getDLLStorageClass()) {
+  case GlobalValue::DefaultStorageClass:   return 0;
+  case GlobalValue::DLLImportStorageClass: return 1;
+  case GlobalValue::DLLExportStorageClass: return 2;
+  }
+  llvm_unreachable("Invalid DLL storage class");
+}
+
+static unsigned getEncodedThreadLocalMode(const GlobalValue &GV) {
+  switch (GV.getThreadLocalMode()) {
+    case GlobalVariable::NotThreadLocal:         return 0;
+    case GlobalVariable::GeneralDynamicTLSModel: return 1;
+    case GlobalVariable::LocalDynamicTLSModel:   return 2;
+    case GlobalVariable::InitialExecTLSModel:    return 3;
+    case GlobalVariable::LocalExecTLSModel:      return 4;
+  }
+  llvm_unreachable("Invalid TLS model");
+}
+
+static unsigned getEncodedComdatSelectionKind(const Comdat &C) {
+  switch (C.getSelectionKind()) {
+  case Comdat::Any:
+    return bitc::COMDAT_SELECTION_KIND_ANY;
+  case Comdat::ExactMatch:
+    return bitc::COMDAT_SELECTION_KIND_EXACT_MATCH;
+  case Comdat::Largest:
+    return bitc::COMDAT_SELECTION_KIND_LARGEST;
+  case Comdat::NoDuplicates:
+    return bitc::COMDAT_SELECTION_KIND_NO_DUPLICATES;
+  case Comdat::SameSize:
+    return bitc::COMDAT_SELECTION_KIND_SAME_SIZE;
+  }
+  llvm_unreachable("Invalid selection kind");
+}
+
+static void writeComdats(const ValueEnumerator35 &VE, BitstreamWriter &Stream) {
+  SmallVector<uint16_t, 64> Vals;
+  for (const Comdat *C : VE.getComdats()) {
+    // COMDAT: [selection_kind, name]
+    Vals.push_back(getEncodedComdatSelectionKind(*C));
+    size_t Size = C->getName().size();
+    assert(isUInt<16>(Size));
+    Vals.push_back(Size);
+    for (char Chr : C->getName())
+      Vals.push_back((unsigned char)Chr);
+    Stream.EmitRecord(bitc::MODULE_CODE_COMDAT, Vals, /*AbbrevToUse=*/0);
+    Vals.clear();
+  }
+}
+
+/// Emit top-level description of module, including target triple, inline asm,
+/// descriptors for global variables, and function prototype info.
+/// Returns the bit offset to backpatch with the location of the real VST.
+static uint64_t WriteModuleInfo(const Module *M, const ValueEnumerator35 &VE,
+                                BitstreamWriter &Stream) {
+  // Emit various pieces of data attached to a module.
+  if (!M->getTargetTriple().empty())
+    WriteStringRecord(bitc::MODULE_CODE_TRIPLE, M->getTargetTriple(),
+                      0/*TODO*/, Stream);
+  const std::string &DL = M->getDataLayoutStr();
+  if (!DL.empty())
+    WriteStringRecord(bitc::MODULE_CODE_DATALAYOUT, DL, 0 /*TODO*/, Stream);
+  if (!M->getModuleInlineAsm().empty())
+    WriteStringRecord(bitc::MODULE_CODE_ASM, M->getModuleInlineAsm(),
+                      0/*TODO*/, Stream);
+
+  // Emit information about sections and GC, computing how many there are. Also
+  // compute the maximum alignment value.
+  std::map<std::string, unsigned> SectionMap;
+  std::map<std::string, unsigned> GCMap;
+  unsigned MaxAlignment = 0;
+  unsigned MaxGlobalType = 0;
+  for (const GlobalValue &GV : M->globals()) {
+    MaxAlignment = std::max(MaxAlignment, GV.getAlignment());
+    MaxGlobalType = std::max(MaxGlobalType, VE.getTypeID(GV.getType()));
+    if (GV.hasSection()) {
+      // Give section names unique ID's.
+      unsigned &Entry = SectionMap[GV.getSection()];
+      if (!Entry) {
+        WriteStringRecord(bitc::MODULE_CODE_SECTIONNAME, GV.getSection(),
+                          0/*TODO*/, Stream);
+        Entry = SectionMap.size();
+      }
+    }
+  }
+  for (const Function &F : *M) {
+    MaxAlignment = std::max(MaxAlignment, F.getAlignment());
+    if (F.hasSection()) {
+      // Give section names unique ID's.
+      unsigned &Entry = SectionMap[F.getSection()];
+      if (!Entry) {
+        WriteStringRecord(bitc::MODULE_CODE_SECTIONNAME, F.getSection(),
+                          0/*TODO*/, Stream);
+        Entry = SectionMap.size();
+      }
+    }
+    if (F.hasGC()) {
+      // Same for GC names.
+      unsigned &Entry = GCMap[F.getGC()];
+      if (!Entry) {
+        WriteStringRecord(bitc::MODULE_CODE_GCNAME, F.getGC(),
+                          0/*TODO*/, Stream);
+        Entry = GCMap.size();
+      }
+    }
+  }
+
+  // Emit abbrev for globals, now that we know # sections and max alignment.
+  unsigned SimpleGVarAbbrev = 0;
+  if (!M->global_empty()) {
+    // Add an abbrev for common globals with no visibility or thread localness.
+    BitCodeAbbrev *Abbv = new BitCodeAbbrev();
+    Abbv->Add(BitCodeAbbrevOp(bitc::MODULE_CODE_GLOBALVAR));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed,
+                              Log2_32_Ceil(MaxGlobalType+1)));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, 1));      // Constant.
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::VBR, 6));        // Initializer.
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, 4));      // Linkage.
+    if (MaxAlignment == 0)                                      // Alignment.
+      Abbv->Add(BitCodeAbbrevOp(0));
+    else {
+      unsigned MaxEncAlignment = Log2_32(MaxAlignment)+1;
+      Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed,
+                               Log2_32_Ceil(MaxEncAlignment+1)));
+    }
+    if (SectionMap.empty())                                    // Section.
+      Abbv->Add(BitCodeAbbrevOp(0));
+    else
+      Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed,
+                               Log2_32_Ceil(SectionMap.size()+1)));
+    // Don't bother emitting vis + thread local.
+    SimpleGVarAbbrev = Stream.EmitAbbrev(Abbv);
+  }
+
+  // Emit the global variable information.
+  SmallVector<unsigned, 64> Vals;
+  for (const GlobalVariable &GV : M->globals()) {
+    unsigned AbbrevToUse = 0;
+
+    // GLOBALVAR: [type, isconst, initid,
+    //             linkage, alignment, section, visibility, threadlocal,
+    //             unnamed_addr, externally_initialized, dllstorageclass]
+    Vals.push_back(VE.getTypeID(GV.getType()));
+    Vals.push_back(GV.isConstant());
+    Vals.push_back(GV.isDeclaration() ? 0 :
+                   (VE.getValueID(GV.getInitializer()) + 1));
+    Vals.push_back(getEncodedLinkage(GV));
+    Vals.push_back(Log2_32(GV.getAlignment())+1);
+    Vals.push_back(GV.hasSection() ? SectionMap[GV.getSection()] : 0);
+    if (GV.isThreadLocal() ||
+        GV.getVisibility() != GlobalValue::DefaultVisibility ||
+        GV.hasGlobalUnnamedAddr() || GV.isExternallyInitialized() ||
+        GV.getDLLStorageClass() != GlobalValue::DefaultStorageClass ||
+        GV.hasComdat()) {
+      Vals.push_back(getEncodedVisibility(GV));
+      Vals.push_back(getEncodedThreadLocalMode(GV));
+      Vals.push_back(GV.hasGlobalUnnamedAddr());
+      Vals.push_back(GV.isExternallyInitialized());
+      Vals.push_back(getEncodedDLLStorageClass(GV));
+      Vals.push_back(GV.hasComdat() ? VE.getComdatID(GV.getComdat()) : 0);
+    } else {
+      AbbrevToUse = SimpleGVarAbbrev;
+    }
+
+    Stream.EmitRecord(bitc::MODULE_CODE_GLOBALVAR, Vals, AbbrevToUse);
+    Vals.clear();
+  }
+
+  // Emit the function proto information.
+  for (const Function &F : *M) {
+    // FUNCTION:  [type, callingconv, isproto, linkage, paramattrs, alignment,
+    //             section, visibility, gc, unnamed_addr, prefix]
+    Vals.push_back(VE.getTypeID(F.getType()));
+    Vals.push_back(F.getCallingConv());
+    Vals.push_back(F.isDeclaration());
+    Vals.push_back(getEncodedLinkage(F));
+    Vals.push_back(VE.getAttributeID(F.getAttributes()));
+    Vals.push_back(Log2_32(F.getAlignment())+1);
+    Vals.push_back(F.hasSection() ? SectionMap[F.getSection()] : 0);
+    Vals.push_back(getEncodedVisibility(F));
+    Vals.push_back(F.hasGC() ? GCMap[F.getGC()] : 0);
+    Vals.push_back(F.hasGlobalUnnamedAddr());
+    Vals.push_back(F.hasPrefixData() ? (VE.getValueID(F.getPrefixData()) + 1)
+                                      : 0);
+    Vals.push_back(getEncodedDLLStorageClass(F));
+    Vals.push_back(F.hasComdat() ? VE.getComdatID(F.getComdat()) : 0);
+
+    unsigned AbbrevToUse = 0;
+    Stream.EmitRecord(bitc::MODULE_CODE_FUNCTION, Vals, AbbrevToUse);
+    Vals.clear();
+  }
+
+  // Emit the alias information.
+  for (const GlobalAlias &A : M->aliases()) {
+    // ALIAS: [alias type, aliasee val#, linkage, visibility]
+    Vals.push_back(VE.getTypeID(A.getType()));
+    Vals.push_back(VE.getValueID(A.getAliasee()));
+    Vals.push_back(getEncodedLinkage(A));
+    Vals.push_back(getEncodedVisibility(A));
+    Vals.push_back(getEncodedDLLStorageClass(A));
+    Vals.push_back(getEncodedThreadLocalMode(A));
+    Vals.push_back(A.hasGlobalUnnamedAddr());
+    unsigned AbbrevToUse = 0;
+    Stream.EmitRecord(bitc::MODULE_CODE_ALIAS_OLD, Vals, AbbrevToUse);
+    Vals.clear();
+  }
+
+  return 0;
+}
+
+static uint64_t GetOptimizationFlags(const Value *V) {
+  uint64_t Flags = 0;
+
+  if (const auto *OBO = dyn_cast<OverflowingBinaryOperator>(V)) {
+    if (OBO->hasNoSignedWrap())
+      Flags |= 1 << bitc::OBO_NO_SIGNED_WRAP;
+    if (OBO->hasNoUnsignedWrap())
+      Flags |= 1 << bitc::OBO_NO_UNSIGNED_WRAP;
+  } else if (const auto *PEO = dyn_cast<PossiblyExactOperator>(V)) {
+    if (PEO->isExact())
+      Flags |= 1 << bitc::PEO_EXACT;
+  } else if (const auto *FPMO = dyn_cast<FPMathOperator>(V)) {
+    if (FPMO->hasUnsafeAlgebra())
+      Flags |= FastMathFlags::UnsafeAlgebra;
+    if (FPMO->hasNoNaNs())
+      Flags |= FastMathFlags::NoNaNs;
+    if (FPMO->hasNoInfs())
+      Flags |= FastMathFlags::NoInfs;
+    if (FPMO->hasNoSignedZeros())
+      Flags |= FastMathFlags::NoSignedZeros;
+    if (FPMO->hasAllowReciprocal())
+      Flags |= FastMathFlags::AllowReciprocal;
+  }
+
+  return Flags;
+}
+
+static void WriteValueAsMetadata(const ValueAsMetadata *MD,
+                                 const ValueEnumerator35 &VE,
+                                 BitstreamWriter &Stream,
+                                 SmallVectorImpl<uint64_t> &Record,
+                                 const bool func_local = false) {
+  // Mimic an MDNode with a value as one operand.
+  Value *V = MD->getValue();
+  Record.push_back(VE.getTypeID(V->getType()));
+  Record.push_back(VE.getValueID(V));
+  Stream.EmitRecord(!func_local ? bitc::METADATA_OLD_NODE : bitc::METADATA_OLD_FN_NODE, Record, 0);
+  Record.clear();
+}
+
+// NOTE: similar to WriteMDNode from 3.5 (however, no function-local in here!)
+static void WriteMDTuple(const MDTuple *N, const ValueEnumerator35 &VE,
+                         BitstreamWriter &Stream,
+                         SmallVectorImpl<uint64_t> &Record, unsigned Abbrev) {
+  for (unsigned i = 0, e = N->getNumOperands(); i != e; ++i) {
+    const Metadata* op = N->getOperand(i);
+    if (op == nullptr) {
+      Record.push_back(VE.getTypeID(Type::getVoidTy(N->getContext())));
+      Record.push_back(0);
+      continue;
+    }
+    
+    switch (op->getMetadataID()) {
+      case Metadata::LocalAsMetadataKind:
+        assert(false && "Unexpected function-local metadata");
+        break;
+      case Metadata::ConstantAsMetadataKind: {
+        auto V = dyn_cast<ConstantAsMetadata>(op)->getValue();
+        Record.push_back(VE.getTypeID(V->getType()));
+        Record.push_back(VE.getValueID(V));
+        break;
+      }
+      default:
+        Record.push_back(VE.getTypeID(Type::getMetadataTy(N->getContext())));
+        Record.push_back(VE.getMetadataID(op));
+        break;
+    }
+  }
+  Stream.EmitRecord(bitc::METADATA_OLD_NODE, Record, Abbrev);
+  Record.clear();
+}
+
+// DI* helper functions/macros
+static void WriteDI_UNIMPLEMENTED(BitstreamWriter &Stream) {
+  SmallVector<uint64_t, 1> empty_record;
+  Stream.EmitRecord(bitc::METADATA_OLD_NODE, empty_record, 0);
+}
+
+#define DI_TYPE_I1() Record.push_back(VE.getTypeID(Type::getInt1Ty(N->getContext())))
+#define DI_I1(val) { DI_TYPE_I1(); Record.push_back(VE.getValueID(ConstantInt::get(llvm::Type::getInt1Ty(N->getContext()), val))); }
+
+#define DI_TYPE_I32() Record.push_back(VE.getTypeID(Type::getInt32Ty(N->getContext())))
+#define DI_I32(val) { DI_TYPE_I32(); Record.push_back(VE.getValueID(ConstantInt::get(llvm::Type::getInt32Ty(N->getContext()), val))); }
+
+#define DI_TYPE_I64() Record.push_back(VE.getTypeID(Type::getInt64Ty(N->getContext())))
+#define DI_I64(val) { DI_TYPE_I64(); Record.push_back(VE.getValueID(ConstantInt::get(llvm::Type::getInt64Ty(N->getContext()), val))); }
+
+#define DI_TYPE_META() Record.push_back(VE.getTypeID(Type::getMetadataTy(N->getContext())))
+#define DI_META(val) { DI_TYPE_META(); Record.push_back(VE.getMetadataID(val)); }
+
+#define DI_TYPE_VOID() Record.push_back(VE.getTypeID(Type::getVoidTy(N->getContext())))
+#define DI_NULL() { DI_TYPE_VOID(); Record.push_back(0); }
+
+#define DI_FUNC(func) { Record.push_back(VE.getTypeID(func->getType())); Record.push_back(VE.getValueID(func)); }
+
+#define DI_TAG(tag) { DI_TYPE_I32(); Record.push_back(VE.getValueID(GetTagConstant(N->getContext(), tag))); }
+
+#define DI_META_OR_NULL(val) if(val) DI_META(val) else DI_NULL()
+
+// from 3.5 DIBuilder.cpp
+static Constant *GetTagConstant(LLVMContext &VMContext, unsigned Tag) {
+  assert((Tag & 0xffff0000 /* LLVMDebugVersionMask */) == 0 &&
+         "Tag too large for debug encoding!");
+  return ConstantInt::get(Type::getInt32Ty(VMContext), Tag | (12 << 16) /* LLVMDebugVersion */);
+}
+
+static void WriteDILocation(const DILocation *N, const ValueEnumerator35 &VE,
+                            BitstreamWriter &Stream,
+                            SmallVectorImpl<uint64_t> &Record,
+                            unsigned Abbrev) {
+  DI_I32(N->getLine());
+  DI_I32(N->getColumn());
+  DI_META(N->getScope());
+  DI_META_OR_NULL(N->getInlinedAt());
+
+  Stream.EmitRecord(bitc::METADATA_OLD_NODE, Record, Abbrev);
+  Record.clear();
+}
+
+// NOTE: not in 3.5
+static void WriteGenericDINode(const GenericDINode *,
+                               const ValueEnumerator35 &,
+                               BitstreamWriter &Stream,
+                               SmallVectorImpl<uint64_t> &,
+                               unsigned) {
+  WriteDI_UNIMPLEMENTED(Stream);
+}
+
+#if 0
+static uint64_t rotateSign(int64_t I) {
+  uint64_t U = I;
+  return I < 0 ? ~(U << 1) : U << 1;
+}
+#endif
+
+static void WriteDISubrange(const DISubrange *N, const ValueEnumerator35 &,
+                            BitstreamWriter &Stream,
+                            SmallVectorImpl<uint64_t> &Record,
+                            unsigned Abbrev) {
+#if 1
+  WriteDI_UNIMPLEMENTED(Stream);
+#else
+  Record.push_back(N->getCount());
+  Record.push_back(rotateSign(N->getLowerBound()));
+
+  Stream.EmitRecord(bitc::METADATA_OLD_NODE, Record, Abbrev);
+  Record.clear();
+#endif
+}
+
+static void WriteDIEnumerator(const DIEnumerator *N, const ValueEnumerator35 &VE,
+                              BitstreamWriter &Stream,
+                              SmallVectorImpl<uint64_t> &Record,
+                              unsigned Abbrev) {
+#if 1
+  WriteDI_UNIMPLEMENTED(Stream);
+#else
+  Record.push_back(rotateSign(N->getValue()));
+  Record.push_back(VE.getMetadataOrNullID(N->getRawName()));
+
+  Stream.EmitRecord(bitc::METADATA_OLD_NODE, Record, Abbrev);
+  Record.clear();
+#endif
+}
+
+static void WriteDIBasicType(const DIBasicType *N, const ValueEnumerator35 &VE,
+                             BitstreamWriter &Stream,
+                             SmallVectorImpl<uint64_t> &Record,
+                             unsigned Abbrev) {
+#if 1
+  WriteDI_UNIMPLEMENTED(Stream);
+#else
+  Record.push_back(N->getTag());
+  Record.push_back(VE.getMetadataOrNullID(N->getRawName()));
+  Record.push_back(N->getSizeInBits());
+  Record.push_back(N->getAlignInBits());
+  Record.push_back(N->getEncoding());
+
+  Stream.EmitRecord(bitc::METADATA_OLD_NODE, Record, Abbrev);
+  Record.clear();
+#endif
+}
+
+static void WriteDIDerivedType(const DIDerivedType *N,
+                               const ValueEnumerator35 &VE,
+                               BitstreamWriter &Stream,
+                               SmallVectorImpl<uint64_t> &Record,
+                               unsigned Abbrev) {
+#if 1
+  WriteDI_UNIMPLEMENTED(Stream);
+#else
+  Record.push_back(N->getTag());
+  Record.push_back(VE.getMetadataOrNullID(N->getRawName()));
+  Record.push_back(VE.getMetadataOrNullID(N->getFile()));
+  Record.push_back(N->getLine());
+  Record.push_back(VE.getMetadataOrNullID(N->getScope()));
+  Record.push_back(VE.getMetadataOrNullID(N->getBaseType()));
+  Record.push_back(N->getSizeInBits());
+  Record.push_back(N->getAlignInBits());
+  Record.push_back(N->getOffsetInBits());
+  Record.push_back(N->getFlags());
+  Record.push_back(VE.getMetadataOrNullID(N->getExtraData()));
+
+  Stream.EmitRecord(bitc::METADATA_OLD_NODE, Record, Abbrev);
+  Record.clear();
+#endif
+}
+
+static void WriteDICompositeType(const DICompositeType *N,
+                                 const ValueEnumerator35 &VE,
+                                 BitstreamWriter &Stream,
+                                 SmallVectorImpl<uint64_t> &Record,
+                                 unsigned Abbrev) {
+#if 1
+  WriteDI_UNIMPLEMENTED(Stream);
+#else
+  Record.push_back(N->getTag());
+  Record.push_back(VE.getMetadataOrNullID(N->getRawName()));
+  Record.push_back(VE.getMetadataOrNullID(N->getFile()));
+  Record.push_back(N->getLine());
+  Record.push_back(VE.getMetadataOrNullID(N->getScope()));
+  Record.push_back(VE.getMetadataOrNullID(N->getBaseType()));
+  Record.push_back(N->getSizeInBits());
+  Record.push_back(N->getAlignInBits());
+  Record.push_back(N->getOffsetInBits());
+  Record.push_back(N->getFlags());
+  Record.push_back(VE.getMetadataOrNullID(N->getElements().get()));
+  Record.push_back(N->getRuntimeLang());
+  Record.push_back(VE.getMetadataOrNullID(N->getVTableHolder()));
+  Record.push_back(VE.getMetadataOrNullID(N->getTemplateParams().get()));
+  Record.push_back(VE.getMetadataOrNullID(N->getRawIdentifier()));
+
+  Stream.EmitRecord(bitc::METADATA_OLD_NODE, Record, Abbrev);
+  Record.clear();
+#endif
+}
+
+static void WriteDISubroutineType(const DISubroutineType *N,
+                                  const ValueEnumerator35 &VE,
+                                  BitstreamWriter &Stream,
+                                  SmallVectorImpl<uint64_t> &Record,
+                                  unsigned Abbrev) {
+  DI_TAG(dwarf::DW_TAG_subroutine_type);
+
+  DI_I32(0);
+  DI_NULL();
+  auto empty_str_node = MDString::get(N->getContext(), "");
+  DI_META(empty_str_node);
+  DI_I32(0);
+  DI_I64(0);
+  DI_I64(0);
+  DI_I64(0);
+  DI_I32(N->getFlags());
+  DI_NULL();
+  DI_META_OR_NULL(N->getTypeArray().get());
+  DI_I32(0);
+  DI_NULL();
+  DI_NULL();
+  DI_NULL();
+
+  Stream.EmitRecord(bitc::METADATA_OLD_NODE, Record, Abbrev);
+  Record.clear();
+}
+
+static void WriteDIFile(const DIFile *N, const ValueEnumerator35 &VE,
+                        BitstreamWriter &Stream,
+                        SmallVectorImpl<uint64_t> &Record, unsigned Abbrev) {
+  // NOTE: { file, dir } node will already have been written
+  DI_TAG(dwarf::DW_TAG_file_type);
+
+  DI_META(N->contained_node);
+
+  Stream.EmitRecord(bitc::METADATA_OLD_NODE, Record, Abbrev);
+  Record.clear();
+}
+
+static void WriteDICompileUnit(const DICompileUnit *N,
+                               const ValueEnumerator35 &VE,
+                               BitstreamWriter &Stream,
+                               SmallVectorImpl<uint64_t> &Record,
+                               unsigned Abbrev) {
+  assert(N->isDistinct() && "Expected distinct compile units");
+
+  DI_TAG(dwarf::DW_TAG_compile_unit);
+
+  if (N->getFile()) {
+    // not an actual DIFile node, but directly points to a { file, dir } node
+    DI_META(N->getFile()->contained_node);
+  } else DI_NULL()
+
+  DI_I32(N->getSourceLanguage());
+  DI_META_OR_NULL(N->getRawProducer());
+  DI_I1(N->isOptimized());
+  DI_META_OR_NULL(N->getRawFlags());
+  DI_I32(N->getRuntimeVersion());
+  DI_META_OR_NULL(N->getEnumTypes().get());
+  DI_META_OR_NULL(N->getRetainedTypes().get());
+  DI_META_OR_NULL(/*N->getSubprograms().get()*/ nullptr); // TODO: fix this, subprogram <-> cu ownership switched in 3.9
+  DI_META_OR_NULL(N->getGlobalVariables().get());
+  DI_META_OR_NULL(N->getImportedEntities().get());
+  DI_META_OR_NULL(N->getRawSplitDebugFilename());
+  DI_I32(N->getEmissionKind());
+  // NOTE: no macros or dwarf id
+
+  Stream.EmitRecord(bitc::METADATA_OLD_NODE, Record, Abbrev);
+  Record.clear();
+}
+
+static void WriteDISubprogram(const DISubprogram *N, const ValueEnumerator35 &VE,
+                              BitstreamWriter &Stream,
+                              SmallVectorImpl<uint64_t> &Record,
+                              unsigned Abbrev) {
+  DI_TAG(dwarf::DW_TAG_subprogram);
+
+  DI_META_OR_NULL(N->getFile());
+  DI_META_OR_NULL(N->getScope());
+  DI_META_OR_NULL(N->getRawName());
+  DI_META_OR_NULL(N->getRawName());
+  DI_META_OR_NULL(N->getRawLinkageName());
+  DI_I32(N->getLine());
+  DI_META_OR_NULL(N->getType());
+  DI_I1(N->isLocalToUnit());
+  DI_I1(N->isDefinition());
+  DI_I32(N->getVirtuality());
+  DI_I32(N->getVirtualIndex());
+  DI_META_OR_NULL(N->getContainingType());
+  DI_I32(N->getFlags());
+  DI_I1(N->isOptimized());
+  if (N->associated_function) {
+    DI_FUNC(N->associated_function);
+  }
+  else DI_NULL();
+  DI_META_OR_NULL(N->getTemplateParams().get());
+  DI_META_OR_NULL(N->getDeclaration());
+  // TODO: always pointing to an empty node if non-existent?
+  if (N->getVariables()) {
+    DI_META(N->getVariables().get());
+  }
+  else {
+    auto empty_node = MDTuple::getTemporary(N->getContext(), {});
+    DI_META(empty_node.get());
+  }
+  DI_I32(N->getScopeLine());
+
+  Stream.EmitRecord(bitc::METADATA_OLD_NODE, Record, Abbrev);
+  Record.clear();
+}
+
+static void WriteDILexicalBlock(const DILexicalBlock *N,
+                                const ValueEnumerator35 &VE,
+                                BitstreamWriter &Stream,
+                                SmallVectorImpl<uint64_t> &Record,
+                                unsigned Abbrev) {
+  DI_TAG(dwarf::DW_TAG_lexical_block);
+
+  static unsigned int unique_id = 0;
+  DI_META_OR_NULL(N->getFile());
+  DI_META_OR_NULL(N->getScope());
+  DI_I32(N->getLine());
+  DI_I32(N->getColumn());
+  DI_I32(0); // NOTE: no discriminator (also 0 in 3.5)
+  DI_I32(unique_id++);
+
+  Stream.EmitRecord(bitc::METADATA_OLD_NODE, Record, Abbrev);
+  Record.clear();
+}
+
+static void WriteDILexicalBlockFile(const DILexicalBlockFile *N,
+                                    const ValueEnumerator35 &VE,
+                                    BitstreamWriter &Stream,
+                                    SmallVectorImpl<uint64_t> &Record,
+                                    unsigned Abbrev) {
+#if 1
+  WriteDI_UNIMPLEMENTED(Stream);
+#else
+  Record.push_back(VE.getMetadataOrNullID(N->getScope()));
+  Record.push_back(VE.getMetadataOrNullID(N->getFile()));
+  Record.push_back(N->getDiscriminator());
+
+  Stream.EmitRecord(bitc::METADATA_OLD_NODE, Record, Abbrev);
+  Record.clear();
+#endif
+}
+
+static void WriteDINamespace(const DINamespace *N, const ValueEnumerator35 &VE,
+                             BitstreamWriter &Stream,
+                             SmallVectorImpl<uint64_t> &Record,
+                             unsigned Abbrev) {
+#if 1
+  WriteDI_UNIMPLEMENTED(Stream);
+#else
+  Record.push_back(VE.getMetadataOrNullID(N->getScope()));
+  Record.push_back(VE.getMetadataOrNullID(N->getFile()));
+  Record.push_back(VE.getMetadataOrNullID(N->getRawName()));
+  Record.push_back(N->getLine());
+
+  Stream.EmitRecord(bitc::METADATA_OLD_NODE, Record, Abbrev);
+  Record.clear();
+#endif
+}
+
+// NOTE: not in 3.5
+static void WriteDIMacro(const DIMacro *, const ValueEnumerator35 &,
+                         BitstreamWriter &Stream,
+                         SmallVectorImpl<uint64_t> &, unsigned) {
+  WriteDI_UNIMPLEMENTED(Stream);
+}
+
+// NOTE: not in 3.5
+static void WriteDIMacroFile(const DIMacroFile *, const ValueEnumerator35 &,
+                             BitstreamWriter &Stream,
+                             SmallVectorImpl<uint64_t> &,
+                             unsigned) {
+  WriteDI_UNIMPLEMENTED(Stream);
+}
+
+// NOTE: not in 3.5
+static void WriteDIModule(const DIModule *, const ValueEnumerator35 &,
+                          BitstreamWriter &Stream,
+                          SmallVectorImpl<uint64_t> &, unsigned ) {
+  WriteDI_UNIMPLEMENTED(Stream);
+}
+
+static void WriteDITemplateTypeParameter(const DITemplateTypeParameter *N,
+                                         const ValueEnumerator35 &VE,
+                                         BitstreamWriter &Stream,
+                                         SmallVectorImpl<uint64_t> &Record,
+                                         unsigned Abbrev) {
+#if 1
+  WriteDI_UNIMPLEMENTED(Stream);
+#else
+  Record.push_back(VE.getMetadataOrNullID(N->getRawName()));
+  Record.push_back(VE.getMetadataOrNullID(N->getType()));
+
+  Stream.EmitRecord(bitc::METADATA_OLD_NODE, Record, Abbrev);
+  Record.clear();
+#endif
+}
+
+static void WriteDITemplateValueParameter(const DITemplateValueParameter *N,
+                                          const ValueEnumerator35 &VE,
+                                          BitstreamWriter &Stream,
+                                          SmallVectorImpl<uint64_t> &Record,
+                                          unsigned Abbrev) {
+#if 1
+  WriteDI_UNIMPLEMENTED(Stream);
+#else
+  Record.push_back(N->getTag());
+  Record.push_back(VE.getMetadataOrNullID(N->getRawName()));
+  Record.push_back(VE.getMetadataOrNullID(N->getType()));
+  Record.push_back(VE.getMetadataOrNullID(N->getValue()));
+
+  Stream.EmitRecord(bitc::METADATA_OLD_NODE, Record, Abbrev);
+  Record.clear();
+#endif
+}
+
+static void WriteDIGlobalVariable(const DIGlobalVariable *N,
+                                  const ValueEnumerator35 &VE,
+                                  BitstreamWriter &Stream,
+                                  SmallVectorImpl<uint64_t> &Record,
+                                  unsigned Abbrev) {
+#if 1
+  WriteDI_UNIMPLEMENTED(Stream);
+#else
+  Record.push_back(VE.getMetadataOrNullID(N->getScope()));
+  Record.push_back(VE.getMetadataOrNullID(N->getRawName()));
+  Record.push_back(VE.getMetadataOrNullID(N->getRawLinkageName()));
+  Record.push_back(VE.getMetadataOrNullID(N->getFile()));
+  Record.push_back(N->getLine());
+  Record.push_back(VE.getMetadataOrNullID(N->getType()));
+  Record.push_back(N->isLocalToUnit());
+  Record.push_back(N->isDefinition());
+  Record.push_back(VE.getMetadataOrNullID(N->getRawVariable()));
+  Record.push_back(VE.getMetadataOrNullID(N->getStaticDataMemberDeclaration()));
+
+  Stream.EmitRecord(bitc::METADATA_OLD_NODE, Record, Abbrev);
+  Record.clear();
+#endif
+}
+
+// NOTE: not in 3.5
+static void WriteDILocalVariable(const DILocalVariable *,
+                                 const ValueEnumerator35 &,
+                                 BitstreamWriter &Stream,
+                                 SmallVectorImpl<uint64_t> &,
+                                 unsigned) {
+  WriteDI_UNIMPLEMENTED(Stream);
+}
+
+// NOTE: not in 3.5
+static void WriteDIExpression(const DIExpression *, const ValueEnumerator35 &,
+                              BitstreamWriter &Stream,
+                              SmallVectorImpl<uint64_t> &,
+                              unsigned) {
+  WriteDI_UNIMPLEMENTED(Stream);
+}
+
+// NOTE: not supported, since there is no objective-c
+static void WriteDIObjCProperty(const DIObjCProperty *,
+                                const ValueEnumerator35 &,
+                                BitstreamWriter &Stream,
+                                SmallVectorImpl<uint64_t> &,
+                                unsigned) {
+  WriteDI_UNIMPLEMENTED(Stream);
+}
+
+static void WriteDIImportedEntity(const DIImportedEntity *N,
+                                  const ValueEnumerator35 &VE,
+                                  BitstreamWriter &Stream,
+                                  SmallVectorImpl<uint64_t> &Record,
+                                  unsigned Abbrev) {
+#if 1
+  WriteDI_UNIMPLEMENTED(Stream);
+#else
+  Record.push_back(N->getTag());
+  Record.push_back(VE.getMetadataOrNullID(N->getScope()));
+  Record.push_back(VE.getMetadataOrNullID(N->getEntity()));
+  Record.push_back(N->getLine());
+  Record.push_back(VE.getMetadataOrNullID(N->getRawName()));
+
+  Stream.EmitRecord(bitc::METADATA_OLD_NODE, Record, Abbrev);
+  Record.clear();
+#endif
+}
+
+static void WriteModuleMetadata(const Module *M,
+                                const ValueEnumerator35 &VE,
+                                BitstreamWriter &Stream) {
+  const auto &MDs = VE.getMDs();
+  if (MDs.empty() && M->named_metadata_empty())
+    return;
+
+  // NOTE: always present with AIR/SPIR (no need for StartedMetadataBlock)
+  Stream.EnterSubblock(bitc::METADATA_BLOCK_ID, 3);
+
+  unsigned MDSAbbrev = 0;
+  if (VE.hasMDString()) {
+    // Abbrev for METADATA_STRING_OLD.
+    BitCodeAbbrev *Abbv = new BitCodeAbbrev();
+    Abbv->Add(BitCodeAbbrevOp(bitc::METADATA_STRING_OLD));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Array));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, 8));
+    MDSAbbrev = Stream.EmitAbbrev(Abbv);
+  }
+
+  SmallVector<uint64_t, 64> Record;
+  for (const Metadata *MD : MDs) {
+    if (const MDNode *N = dyn_cast<MDNode>(MD)) {
+      assert(N->isResolved() && "Expected forward references to be resolved");
+
+      // NOTE: no function-local in here
+      // NOTE: no abbreviations in here
+      switch (N->getMetadataID()) {
+      default:
+        llvm_unreachable("Invalid MDNode subclass");
+#define HANDLE_MDNODE_LEAF(CLASS)                                              \
+  case Metadata::CLASS##Kind:                                                  \
+    Write##CLASS(cast<CLASS>(N), VE, Stream, Record, 0);                       \
+    continue;
+#include "llvm/IR/Metadata.def"
+      }
+    } else if (const auto *MDC = dyn_cast<ConstantAsMetadata>(MD)) {
+      WriteValueAsMetadata(MDC, VE, Stream, Record);
+    } else if (const MDString *MDS = dyn_cast<MDString>(MD)) {
+      // Code: [strchar x N]
+      Record.append(MDS->bytes_begin(), MDS->bytes_end());
+
+      // Emit the finished record.
+      Stream.EmitRecord(bitc::METADATA_STRING_OLD, Record, MDSAbbrev);
+      Record.clear();
+    } else {
+      assert(false && "unhandled MD type");
+    }
+  }
+
+  // Write named metadata.
+  for (const NamedMDNode &NMD : M->named_metadata()) {
+    // Write name.
+    StringRef Str = NMD.getName();
+    Record.append(Str.bytes_begin(), Str.bytes_end());
+    Stream.EmitRecord(bitc::METADATA_NAME, Record, 0);
+    Record.clear();
+
+    // Write named metadata operands.
+    for (const MDNode *N : NMD.operands())
+      Record.push_back(VE.getMetadataID(N));
+    Stream.EmitRecord(bitc::METADATA_NAMED_NODE, Record, 0);
+    Record.clear();
+  }
+
+  Stream.ExitBlock();
+}
+
+static void WriteFunctionLocalMetadata(const Function &F,
+                                       const ValueEnumerator35 &VE,
+                                       BitstreamWriter &Stream) {
+  bool StartedMetadataBlock = false;
+  SmallVector<uint64_t, 64> Record;
+  const SmallVectorImpl<const LocalAsMetadata *> &MDs =
+      VE.getFunctionLocalMDs();
+  for (unsigned i = 0, e = MDs.size(); i != e; ++i) {
+    assert(MDs[i] && "Expected valid function-local metadata");
+    if (!StartedMetadataBlock) {
+      Stream.EnterSubblock(bitc::METADATA_BLOCK_ID, 3);
+      StartedMetadataBlock = true;
+    }
+    WriteValueAsMetadata(MDs[i], VE, Stream, Record, true);
+  }
+
+  if (StartedMetadataBlock)
+    Stream.ExitBlock();
+}
+
+static void WriteMetadataAttachment(const Function &F,
+                                    const ValueEnumerator35 &VE,
+                                    BitstreamWriter &Stream) {
+  Stream.EnterSubblock(bitc::METADATA_ATTACHMENT_ID, 3);
+
+  SmallVector<uint64_t, 64> Record;
+
+  // Write metadata attachments
+  // METADATA_ATTACHMENT - [m x [value, [n x [id, mdnode]]]
+  SmallVector<std::pair<unsigned, MDNode *>, 4> MDs;
+
+  for (const BasicBlock &BB : F)
+    for (const Instruction &I : BB) {
+      MDs.clear();
+      I.getAllMetadataOtherThanDebugLoc(MDs);
+
+      // If no metadata, ignore instruction.
+      if (MDs.empty()) continue;
+
+      Record.push_back(VE.getInstructionID(&I));
+
+      for (unsigned i = 0, e = MDs.size(); i != e; ++i) {
+        Record.push_back(MDs[i].first);
+        Record.push_back(VE.getMetadataID(MDs[i].second));
+      }
+      Stream.EmitRecord(bitc::METADATA_ATTACHMENT, Record, 0);
+      Record.clear();
+    }
+
+  Stream.ExitBlock();
+}
+
+static void WriteModuleMetadataStore(const Module *M, BitstreamWriter &Stream) {
+  SmallVector<uint64_t, 64> Record;
+
+  // Write metadata kinds
+  // METADATA_KIND - [n x [id, name]]
+  SmallVector<StringRef, 8> Names;
+  M->getMDKindNames(Names);
+
+  if (Names.empty()) return;
+
+  Stream.EnterSubblock(bitc::METADATA_BLOCK_ID, 3);
+
+  for (unsigned MDKindID = 0, e = Names.size(); MDKindID != e; ++MDKindID) {
+    Record.push_back(MDKindID);
+    StringRef KName = Names[MDKindID];
+    Record.append(KName.begin(), KName.end());
+
+    Stream.EmitRecord(bitc::METADATA_KIND, Record, 0);
+    Record.clear();
+  }
+
+  Stream.ExitBlock();
+}
+
+static void emitSignedInt64(SmallVectorImpl<uint64_t> &Vals, uint64_t V) {
+  if ((int64_t)V >= 0)
+    Vals.push_back(V << 1);
+  else
+    Vals.push_back((-V << 1) | 1);
+}
+
+static void WriteConstants(unsigned FirstVal, unsigned LastVal,
+                           const ValueEnumerator35 &VE,
+                           BitstreamWriter &Stream, bool isGlobal) {
+  if (FirstVal == LastVal) return;
+
+  Stream.EnterSubblock(bitc::CONSTANTS_BLOCK_ID, 4);
+
+  unsigned AggregateAbbrev = 0;
+  unsigned String8Abbrev = 0;
+  unsigned CString7Abbrev = 0;
+  unsigned CString6Abbrev = 0;
+  // If this is a constant pool for the module, emit module-specific abbrevs.
+  if (isGlobal) {
+    // Abbrev for CST_CODE_AGGREGATE.
+    BitCodeAbbrev *Abbv = new BitCodeAbbrev();
+    Abbv->Add(BitCodeAbbrevOp(bitc::CST_CODE_AGGREGATE));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Array));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, Log2_32_Ceil(LastVal+1)));
+    AggregateAbbrev = Stream.EmitAbbrev(Abbv);
+
+    // Abbrev for CST_CODE_STRING.
+    Abbv = new BitCodeAbbrev();
+    Abbv->Add(BitCodeAbbrevOp(bitc::CST_CODE_STRING));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Array));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, 8));
+    String8Abbrev = Stream.EmitAbbrev(Abbv);
+    // Abbrev for CST_CODE_CSTRING.
+    Abbv = new BitCodeAbbrev();
+    Abbv->Add(BitCodeAbbrevOp(bitc::CST_CODE_CSTRING));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Array));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, 7));
+    CString7Abbrev = Stream.EmitAbbrev(Abbv);
+    // Abbrev for CST_CODE_CSTRING.
+    Abbv = new BitCodeAbbrev();
+    Abbv->Add(BitCodeAbbrevOp(bitc::CST_CODE_CSTRING));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Array));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Char6));
+    CString6Abbrev = Stream.EmitAbbrev(Abbv);
+  }
+
+  SmallVector<uint64_t, 64> Record;
+
+  const ValueEnumerator35::ValueList &Vals = VE.getValues();
+  Type *LastTy = nullptr;
+  for (unsigned i = FirstVal; i != LastVal; ++i) {
+    const Value *V = Vals[i].first;
+    // If we need to switch types, do so now.
+    if (V->getType() != LastTy) {
+      LastTy = V->getType();
+      Record.push_back(VE.getTypeID(LastTy));
+      Stream.EmitRecord(bitc::CST_CODE_SETTYPE, Record,
+                        CONSTANTS_SETTYPE_ABBREV);
+      Record.clear();
+    }
+
+    if (const InlineAsm *IA = dyn_cast<InlineAsm>(V)) {
+      Record.push_back(unsigned(IA->hasSideEffects()) |
+                       unsigned(IA->isAlignStack()) << 1 |
+                       unsigned(IA->getDialect()&1) << 2);
+
+      // Add the asm string.
+      const std::string &AsmStr = IA->getAsmString();
+      Record.push_back(AsmStr.size());
+      Record.append(AsmStr.begin(), AsmStr.end());
+
+      // Add the constraint string.
+      const std::string &ConstraintStr = IA->getConstraintString();
+      Record.push_back(ConstraintStr.size());
+      Record.append(ConstraintStr.begin(), ConstraintStr.end());
+      Stream.EmitRecord(bitc::CST_CODE_INLINEASM, Record);
+      Record.clear();
+      continue;
+    }
+    const Constant *C = cast<Constant>(V);
+    unsigned Code = -1U;
+    unsigned AbbrevToUse = 0;
+    if (C->isNullValue()) {
+      Code = bitc::CST_CODE_NULL;
+    } else if (isa<UndefValue>(C)) {
+      Code = bitc::CST_CODE_UNDEF;
+    } else if (const ConstantInt *IV = dyn_cast<ConstantInt>(C)) {
+      if (IV->getBitWidth() <= 64) {
+        uint64_t V = IV->getSExtValue();
+        emitSignedInt64(Record, V);
+        Code = bitc::CST_CODE_INTEGER;
+        AbbrevToUse = CONSTANTS_INTEGER_ABBREV;
+      } else {                             // Wide integers, > 64 bits in size.
+        // We have an arbitrary precision integer value to write whose
+        // bit width is > 64. However, in canonical unsigned integer
+        // format it is likely that the high bits are going to be zero.
+        // So, we only write the number of active words.
+        unsigned NWords = IV->getValue().getActiveWords();
+        const uint64_t *RawWords = IV->getValue().getRawData();
+        for (unsigned i = 0; i != NWords; ++i) {
+          emitSignedInt64(Record, RawWords[i]);
+        }
+        Code = bitc::CST_CODE_WIDE_INTEGER;
+      }
+    } else if (const ConstantFP *CFP = dyn_cast<ConstantFP>(C)) {
+      Code = bitc::CST_CODE_FLOAT;
+      Type *Ty = CFP->getType();
+      if (Ty->isHalfTy() || Ty->isFloatTy() || Ty->isDoubleTy()) {
+        Record.push_back(CFP->getValueAPF().bitcastToAPInt().getZExtValue());
+      } else if (Ty->isX86_FP80Ty()) {
+        // api needed to prevent premature destruction
+        // bits are not in the same order as a normal i80 APInt, compensate.
+        APInt api = CFP->getValueAPF().bitcastToAPInt();
+        const uint64_t *p = api.getRawData();
+        Record.push_back((p[1] << 48) | (p[0] >> 16));
+        Record.push_back(p[0] & 0xffffLL);
+      } else if (Ty->isFP128Ty() || Ty->isPPC_FP128Ty()) {
+        APInt api = CFP->getValueAPF().bitcastToAPInt();
+        const uint64_t *p = api.getRawData();
+        Record.push_back(p[0]);
+        Record.push_back(p[1]);
+      } else {
+        assert (0 && "Unknown FP type!");
+      }
+    } else if (isa<ConstantDataSequential>(C) &&
+               cast<ConstantDataSequential>(C)->isString()) {
+      const ConstantDataSequential *Str = cast<ConstantDataSequential>(C);
+      // Emit constant strings specially.
+      unsigned NumElts = Str->getNumElements();
+      // If this is a null-terminated string, use the denser CSTRING encoding.
+      if (Str->isCString()) {
+        Code = bitc::CST_CODE_CSTRING;
+        --NumElts;  // Don't encode the null, which isn't allowed by char6.
+      } else {
+        Code = bitc::CST_CODE_STRING;
+        AbbrevToUse = String8Abbrev;
+      }
+      bool isCStr7 = Code == bitc::CST_CODE_CSTRING;
+      bool isCStrChar6 = Code == bitc::CST_CODE_CSTRING;
+      for (unsigned i = 0; i != NumElts; ++i) {
+        unsigned char V = Str->getElementAsInteger(i);
+        Record.push_back(V);
+        isCStr7 &= (V & 128) == 0;
+        if (isCStrChar6)
+          isCStrChar6 = BitCodeAbbrevOp::isChar6(V);
+      }
+
+      if (isCStrChar6)
+        AbbrevToUse = CString6Abbrev;
+      else if (isCStr7)
+        AbbrevToUse = CString7Abbrev;
+    } else if (const ConstantDataSequential *CDS =
+                  dyn_cast<ConstantDataSequential>(C)) {
+      Code = bitc::CST_CODE_DATA;
+      Type *EltTy = CDS->getType()->getElementType();
+      if (isa<IntegerType>(EltTy)) {
+        for (unsigned i = 0, e = CDS->getNumElements(); i != e; ++i)
+          Record.push_back(CDS->getElementAsInteger(i));
+      } else if (EltTy->isFloatTy()) {
+        for (unsigned i = 0, e = CDS->getNumElements(); i != e; ++i) {
+          union { float F; uint32_t I; };
+          F = CDS->getElementAsFloat(i);
+          Record.push_back(I);
+        }
+      } else {
+        assert(EltTy->isDoubleTy() && "Unknown ConstantData element type");
+        for (unsigned i = 0, e = CDS->getNumElements(); i != e; ++i) {
+          union { double F; uint64_t I; };
+          F = CDS->getElementAsDouble(i);
+          Record.push_back(I);
+        }
+      }
+    } else if (isa<ConstantArray>(C) || isa<ConstantStruct>(C) ||
+               isa<ConstantVector>(C)) {
+      Code = bitc::CST_CODE_AGGREGATE;
+      for (const Value *Op : C->operands())
+        Record.push_back(VE.getValueID(Op));
+      AbbrevToUse = AggregateAbbrev;
+    } else if (const ConstantExpr *CE = dyn_cast<ConstantExpr>(C)) {
+      switch (CE->getOpcode()) {
+      default:
+        if (Instruction::isCast(CE->getOpcode())) {
+          Code = bitc::CST_CODE_CE_CAST;
+          Record.push_back(GetEncodedCastOpcode(CE->getOpcode()));
+          Record.push_back(VE.getTypeID(C->getOperand(0)->getType()));
+          Record.push_back(VE.getValueID(C->getOperand(0)));
+          AbbrevToUse = CONSTANTS_CE_CAST_Abbrev;
+        } else {
+          assert(CE->getNumOperands() == 2 && "Unknown constant expr!");
+          Code = bitc::CST_CODE_CE_BINOP;
+          Record.push_back(GetEncodedBinaryOpcode(CE->getOpcode()));
+          Record.push_back(VE.getValueID(C->getOperand(0)));
+          Record.push_back(VE.getValueID(C->getOperand(1)));
+          uint64_t Flags = GetOptimizationFlags(CE);
+          if (Flags != 0)
+            Record.push_back(Flags);
+        }
+        break;
+      case Instruction::GetElementPtr: {
+        Code = bitc::CST_CODE_CE_GEP;
+        const auto *GO = cast<GEPOperator>(C);
+        if (GO->isInBounds())
+          Code = bitc::CST_CODE_CE_INBOUNDS_GEP;
+        for (unsigned i = 0, e = CE->getNumOperands(); i != e; ++i) {
+          Record.push_back(VE.getTypeID(C->getOperand(i)->getType()));
+          Record.push_back(VE.getValueID(C->getOperand(i)));
+        }
+        break;
+      }
+      case Instruction::Select:
+        Code = bitc::CST_CODE_CE_SELECT;
+        Record.push_back(VE.getValueID(C->getOperand(0)));
+        Record.push_back(VE.getValueID(C->getOperand(1)));
+        Record.push_back(VE.getValueID(C->getOperand(2)));
+        break;
+      case Instruction::ExtractElement:
+        Code = bitc::CST_CODE_CE_EXTRACTELT;
+        Record.push_back(VE.getTypeID(C->getOperand(0)->getType()));
+        Record.push_back(VE.getValueID(C->getOperand(0)));
+        Record.push_back(VE.getTypeID(C->getOperand(1)->getType()));
+        Record.push_back(VE.getValueID(C->getOperand(1)));
+        break;
+      case Instruction::InsertElement:
+        Code = bitc::CST_CODE_CE_INSERTELT;
+        Record.push_back(VE.getValueID(C->getOperand(0)));
+        Record.push_back(VE.getValueID(C->getOperand(1)));
+        Record.push_back(VE.getTypeID(C->getOperand(2)->getType()));
+        Record.push_back(VE.getValueID(C->getOperand(2)));
+        break;
+      case Instruction::ShuffleVector:
+        // If the return type and argument types are the same, this is a
+        // standard shufflevector instruction.  If the types are different,
+        // then the shuffle is widening or truncating the input vectors, and
+        // the argument type must also be encoded.
+        if (C->getType() == C->getOperand(0)->getType()) {
+          Code = bitc::CST_CODE_CE_SHUFFLEVEC;
+        } else {
+          Code = bitc::CST_CODE_CE_SHUFVEC_EX;
+          Record.push_back(VE.getTypeID(C->getOperand(0)->getType()));
+        }
+        Record.push_back(VE.getValueID(C->getOperand(0)));
+        Record.push_back(VE.getValueID(C->getOperand(1)));
+        Record.push_back(VE.getValueID(C->getOperand(2)));
+        break;
+      case Instruction::ICmp:
+      case Instruction::FCmp:
+        Code = bitc::CST_CODE_CE_CMP;
+        Record.push_back(VE.getTypeID(C->getOperand(0)->getType()));
+        Record.push_back(VE.getValueID(C->getOperand(0)));
+        Record.push_back(VE.getValueID(C->getOperand(1)));
+        Record.push_back(CE->getPredicate());
+        break;
+      }
+    } else if (const BlockAddress *BA = dyn_cast<BlockAddress>(C)) {
+      Code = bitc::CST_CODE_BLOCKADDRESS;
+      Record.push_back(VE.getTypeID(BA->getFunction()->getType()));
+      Record.push_back(VE.getValueID(BA->getFunction()));
+      Record.push_back(VE.getGlobalBasicBlockID(BA->getBasicBlock()));
+    } else {
+#ifndef NDEBUG
+      C->dump();
+#endif
+      llvm_unreachable("Unknown constant!");
+    }
+    Stream.EmitRecord(Code, Record, AbbrevToUse);
+    Record.clear();
+  }
+
+  Stream.ExitBlock();
+}
+
+static void WriteModuleConstants(const ValueEnumerator35 &VE,
+                                 BitstreamWriter &Stream) {
+  const ValueEnumerator35::ValueList &Vals = VE.getValues();
+
+  // Find the first constant to emit, which is the first non-globalvalue value.
+  // We know globalvalues have been emitted by WriteModuleInfo.
+  for (unsigned i = 0, e = Vals.size(); i != e; ++i) {
+    if (!isa<GlobalValue>(Vals[i].first)) {
+      WriteConstants(i, Vals.size(), VE, Stream, true);
+      return;
+    }
+  }
+}
+
+/// PushValueAndType - The file has to encode both the value and type id for
+/// many values, because we need to know what type to create for forward
+/// references.  However, most operands are not forward references, so this type
+/// field is not needed.
+///
+/// This function adds V's value ID to Vals.  If the value ID is higher than the
+/// instruction ID, then it is a forward reference, and it also includes the
+/// type ID.  The value ID that is written is encoded relative to the InstID.
+static bool PushValueAndType(const Value *V, unsigned InstID,
+                             SmallVectorImpl<unsigned> &Vals,
+                             ValueEnumerator35 &VE) {
+  unsigned ValID = VE.getValueID(V);
+  // Make encoding relative to the InstID.
+  Vals.push_back(InstID - ValID);
+  if (ValID >= InstID) {
+    Vals.push_back(VE.getTypeID(V->getType()));
+    return true;
+  }
+  return false;
+}
+
+/// pushValue - Like PushValueAndType, but where the type of the value is
+/// omitted (perhaps it was already encoded in an earlier operand).
+static void pushValue(const Value *V, unsigned InstID,
+                      SmallVectorImpl<unsigned> &Vals,
+                      ValueEnumerator35 &VE) {
+  unsigned ValID = VE.getValueID(V);
+  Vals.push_back(InstID - ValID);
+}
+
+static void pushValueSigned(const Value *V, unsigned InstID,
+                            SmallVectorImpl<uint64_t> &Vals,
+                            ValueEnumerator35 &VE) {
+  unsigned ValID = VE.getValueID(V);
+  int64_t diff = ((int32_t)InstID - (int32_t)ValID);
+  emitSignedInt64(Vals, diff);
+}
+
+/// WriteInstruction - Emit an instruction to the specified stream.
+static void WriteInstruction(const Instruction &I, unsigned InstID,
+                             ValueEnumerator35 &VE, BitstreamWriter &Stream,
+                             SmallVectorImpl<unsigned> &Vals) {
+  unsigned Code = 0;
+  unsigned AbbrevToUse = 0;
+  VE.setInstructionID(&I);
+  switch (I.getOpcode()) {
+  default:
+    if (Instruction::isCast(I.getOpcode())) {
+      Code = bitc::FUNC_CODE_INST_CAST;
+      if (!PushValueAndType(I.getOperand(0), InstID, Vals, VE))
+        AbbrevToUse = FUNCTION_INST_CAST_ABBREV;
+      Vals.push_back(VE.getTypeID(I.getType()));
+      Vals.push_back(GetEncodedCastOpcode(I.getOpcode()));
+    } else {
+      assert(isa<BinaryOperator>(I) && "Unknown instruction!");
+      Code = bitc::FUNC_CODE_INST_BINOP;
+      if (!PushValueAndType(I.getOperand(0), InstID, Vals, VE))
+        AbbrevToUse = FUNCTION_INST_BINOP_ABBREV;
+      pushValue(I.getOperand(1), InstID, Vals, VE);
+      Vals.push_back(GetEncodedBinaryOpcode(I.getOpcode()));
+      uint64_t Flags = GetOptimizationFlags(&I);
+      if (Flags != 0) {
+        if (AbbrevToUse == FUNCTION_INST_BINOP_ABBREV)
+          AbbrevToUse = FUNCTION_INST_BINOP_FLAGS_ABBREV;
+        Vals.push_back(Flags);
+      }
+    }
+    break;
+
+  case Instruction::GetElementPtr: {
+    Code = bitc::FUNC_CODE_INST_GEP_OLD;
+    //AbbrevToUse = FUNCTION_INST_GEP_ABBREV;
+    auto &GEPInst = cast<GetElementPtrInst>(I);
+    if (GEPInst.isInBounds())
+      Code = bitc::FUNC_CODE_INST_INBOUNDS_GEP_OLD;
+    for (unsigned i = 0, e = I.getNumOperands(); i != e; ++i)
+      PushValueAndType(I.getOperand(i), InstID, Vals, VE);
+    break;
+  }
+  case Instruction::ExtractValue: {
+    Code = bitc::FUNC_CODE_INST_EXTRACTVAL;
+    PushValueAndType(I.getOperand(0), InstID, Vals, VE);
+    const ExtractValueInst *EVI = cast<ExtractValueInst>(&I);
+    Vals.append(EVI->idx_begin(), EVI->idx_end());
+    break;
+  }
+  case Instruction::InsertValue: {
+    Code = bitc::FUNC_CODE_INST_INSERTVAL;
+    PushValueAndType(I.getOperand(0), InstID, Vals, VE);
+    PushValueAndType(I.getOperand(1), InstID, Vals, VE);
+    const InsertValueInst *IVI = cast<InsertValueInst>(&I);
+    Vals.append(IVI->idx_begin(), IVI->idx_end());
+    break;
+  }
+  case Instruction::Select:
+    Code = bitc::FUNC_CODE_INST_VSELECT;
+    PushValueAndType(I.getOperand(1), InstID, Vals, VE);
+    pushValue(I.getOperand(2), InstID, Vals, VE);
+    PushValueAndType(I.getOperand(0), InstID, Vals, VE);
+    break;
+  case Instruction::ExtractElement:
+    Code = bitc::FUNC_CODE_INST_EXTRACTELT;
+    PushValueAndType(I.getOperand(0), InstID, Vals, VE);
+    PushValueAndType(I.getOperand(1), InstID, Vals, VE);
+    break;
+  case Instruction::InsertElement:
+    Code = bitc::FUNC_CODE_INST_INSERTELT;
+    PushValueAndType(I.getOperand(0), InstID, Vals, VE);
+    pushValue(I.getOperand(1), InstID, Vals, VE);
+    PushValueAndType(I.getOperand(2), InstID, Vals, VE);
+    break;
+  case Instruction::ShuffleVector:
+    Code = bitc::FUNC_CODE_INST_SHUFFLEVEC;
+    PushValueAndType(I.getOperand(0), InstID, Vals, VE);
+    pushValue(I.getOperand(1), InstID, Vals, VE);
+    pushValue(I.getOperand(2), InstID, Vals, VE);
+    break;
+  case Instruction::ICmp:
+  case Instruction::FCmp: {
+    // compare returning Int1Ty or vector of Int1Ty
+    Code = bitc::FUNC_CODE_INST_CMP2;
+    PushValueAndType(I.getOperand(0), InstID, Vals, VE);
+    pushValue(I.getOperand(1), InstID, Vals, VE);
+    Vals.push_back(cast<CmpInst>(I).getPredicate());
+    break;
+  }
+
+  case Instruction::Ret:
+    {
+      Code = bitc::FUNC_CODE_INST_RET;
+      unsigned NumOperands = I.getNumOperands();
+      if (NumOperands == 0)
+        AbbrevToUse = FUNCTION_INST_RET_VOID_ABBREV;
+      else if (NumOperands == 1) {
+        if (!PushValueAndType(I.getOperand(0), InstID, Vals, VE))
+          AbbrevToUse = FUNCTION_INST_RET_VAL_ABBREV;
+      } else {
+        for (unsigned i = 0, e = NumOperands; i != e; ++i)
+          PushValueAndType(I.getOperand(i), InstID, Vals, VE);
+      }
+    }
+    break;
+  case Instruction::Br:
+    {
+      Code = bitc::FUNC_CODE_INST_BR;
+      const BranchInst &II = cast<BranchInst>(I);
+      Vals.push_back(VE.getValueID(II.getSuccessor(0)));
+      if (II.isConditional()) {
+        Vals.push_back(VE.getValueID(II.getSuccessor(1)));
+        pushValue(II.getCondition(), InstID, Vals, VE);
+      }
+    }
+    break;
+  case Instruction::Switch:
+    {
+      Code = bitc::FUNC_CODE_INST_SWITCH;
+      const SwitchInst &SI = cast<SwitchInst>(I);
+      Vals.push_back(VE.getTypeID(SI.getCondition()->getType()));
+      pushValue(SI.getCondition(), InstID, Vals, VE);
+      Vals.push_back(VE.getValueID(SI.getDefaultDest()));
+      for (SwitchInst::ConstCaseIt Case : SI.cases()) {
+        Vals.push_back(VE.getValueID(Case.getCaseValue()));
+        Vals.push_back(VE.getValueID(Case.getCaseSuccessor()));
+      }
+    }
+    break;
+  case Instruction::IndirectBr:
+    Code = bitc::FUNC_CODE_INST_INDIRECTBR;
+    Vals.push_back(VE.getTypeID(I.getOperand(0)->getType()));
+    // Encode the address operand as relative, but not the basic blocks.
+    pushValue(I.getOperand(0), InstID, Vals, VE);
+    for (unsigned i = 1, e = I.getNumOperands(); i != e; ++i)
+      Vals.push_back(VE.getValueID(I.getOperand(i)));
+    break;
+
+  case Instruction::Invoke: {
+    const InvokeInst *II = cast<InvokeInst>(&I);
+    const Value *Callee = II->getCalledValue();
+    FunctionType *FTy = II->getFunctionType();
+
+    Code = bitc::FUNC_CODE_INST_INVOKE;
+
+    Vals.push_back(VE.getAttributeID(II->getAttributes()));
+    Vals.push_back(II->getCallingConv());
+    Vals.push_back(VE.getValueID(II->getNormalDest()));
+    Vals.push_back(VE.getValueID(II->getUnwindDest()));
+    PushValueAndType(Callee, InstID, Vals, VE);
+
+    // Emit value #'s for the fixed parameters.
+    for (unsigned i = 0, e = FTy->getNumParams(); i != e; ++i)
+      pushValue(I.getOperand(i), InstID, Vals, VE);  // fixed param.
+
+    // Emit type/value pairs for varargs params.
+    if (FTy->isVarArg()) {
+      for (unsigned i = FTy->getNumParams(), e = I.getNumOperands()-3;
+           i != e; ++i)
+        PushValueAndType(I.getOperand(i), InstID, Vals, VE); // vararg
+    }
+    break;
+  }
+  case Instruction::Resume:
+    Code = bitc::FUNC_CODE_INST_RESUME;
+    PushValueAndType(I.getOperand(0), InstID, Vals, VE);
+    break;
+  case Instruction::CleanupRet:
+  case Instruction::CatchRet:
+  case Instruction::CleanupPad:
+  case Instruction::CatchPad:
+  case Instruction::CatchSwitch:
+    // all unsupported in 3.5
+    assert(false && "encountered unsupported instruction (these need to be filtered out before writing 3.5 bitcode)");
+    return;
+  case Instruction::Unreachable:
+    Code = bitc::FUNC_CODE_INST_UNREACHABLE;
+    AbbrevToUse = FUNCTION_INST_UNREACHABLE_ABBREV;
+    break;
+
+  case Instruction::PHI: {
+    const PHINode &PN = cast<PHINode>(I);
+    Code = bitc::FUNC_CODE_INST_PHI;
+    // With the newer instruction encoding, forward references could give
+    // negative valued IDs.  This is most common for PHIs, so we use
+    // signed VBRs.
+    SmallVector<uint64_t, 128> Vals64;
+    Vals64.push_back(VE.getTypeID(PN.getType()));
+    for (unsigned i = 0, e = PN.getNumIncomingValues(); i != e; ++i) {
+      pushValueSigned(PN.getIncomingValue(i), InstID, Vals64, VE);
+      Vals64.push_back(VE.getValueID(PN.getIncomingBlock(i)));
+    }
+    // Emit a Vals64 vector and exit.
+    Stream.EmitRecord(Code, Vals64, AbbrevToUse);
+    Vals64.clear();
+    return;
+  }
+
+  case Instruction::LandingPad: {
+    const LandingPadInst &LP = cast<LandingPadInst>(I);
+    Code = bitc::FUNC_CODE_INST_LANDINGPAD_OLD;
+    Vals.push_back(VE.getTypeID(LP.getType()));
+    PushValueAndType(LP.getFunction()->getPersonalityFn(), InstID, Vals, VE);
+    Vals.push_back(LP.isCleanup());
+    Vals.push_back(LP.getNumClauses());
+    for (unsigned I = 0, E = LP.getNumClauses(); I != E; ++I) {
+      if (LP.isCatch(I))
+        Vals.push_back(LandingPadInst::Catch);
+      else
+        Vals.push_back(LandingPadInst::Filter);
+      PushValueAndType(LP.getClause(I), InstID, Vals, VE);
+    }
+    break;
+  }
+
+  case Instruction::Alloca: {
+    Code = bitc::FUNC_CODE_INST_ALLOCA;
+    const AllocaInst &AI = cast<AllocaInst>(I);
+    Vals.push_back(VE.getTypeID(I.getType()));
+    Vals.push_back(VE.getTypeID(I.getOperand(0)->getType()));
+    Vals.push_back(VE.getValueID(I.getOperand(0))); // size.
+    unsigned AlignRecord = Log2_32(AI.getAlignment()) + 1;
+    assert(Log2_32(Value::MaximumAlignment) + 1 < 1 << 5 &&
+           "not enough bits for maximum alignment");
+    assert(AlignRecord < 1 << 5 && "alignment greater than 1 << 64");
+    AlignRecord |= AI.isUsedWithInAlloca() << 5;
+    Vals.push_back(AlignRecord);
+    break;
+  }
+
+  case Instruction::Load:
+    if (cast<LoadInst>(I).isAtomic()) {
+      Code = bitc::FUNC_CODE_INST_LOADATOMIC;
+      PushValueAndType(I.getOperand(0), InstID, Vals, VE);
+    } else {
+      Code = bitc::FUNC_CODE_INST_LOAD;
+      if (!PushValueAndType(I.getOperand(0), InstID, Vals, VE))  // ptr
+        AbbrevToUse = FUNCTION_INST_LOAD_ABBREV;
+    }
+    Vals.push_back(Log2_32(cast<LoadInst>(I).getAlignment())+1);
+    Vals.push_back(cast<LoadInst>(I).isVolatile());
+    if (cast<LoadInst>(I).isAtomic()) {
+      Vals.push_back(GetEncodedOrdering(cast<LoadInst>(I).getOrdering()));
+      Vals.push_back(GetEncodedSynchScope(cast<LoadInst>(I).getSynchScope()));
+    }
+    break;
+  case Instruction::Store:
+    if (cast<StoreInst>(I).isAtomic())
+      Code = bitc::FUNC_CODE_INST_STOREATOMIC_OLD;
+    else
+      Code = bitc::FUNC_CODE_INST_STORE_OLD;
+    PushValueAndType(I.getOperand(1), InstID, Vals, VE);  // ptrty + ptr
+    pushValue(I.getOperand(0), InstID, Vals, VE);         // val.
+    Vals.push_back(Log2_32(cast<StoreInst>(I).getAlignment())+1);
+    Vals.push_back(cast<StoreInst>(I).isVolatile());
+    if (cast<StoreInst>(I).isAtomic()) {
+      Vals.push_back(GetEncodedOrdering(cast<StoreInst>(I).getOrdering()));
+      Vals.push_back(GetEncodedSynchScope(cast<StoreInst>(I).getSynchScope()));
+    }
+    break;
+  case Instruction::AtomicCmpXchg:
+    Code = bitc::FUNC_CODE_INST_CMPXCHG_OLD;
+    PushValueAndType(I.getOperand(0), InstID, Vals, VE);  // ptrty + ptr
+    pushValue(I.getOperand(1), InstID, Vals, VE);         // cmp.
+    pushValue(I.getOperand(2), InstID, Vals, VE);         // newval.
+    Vals.push_back(cast<AtomicCmpXchgInst>(I).isVolatile());
+    Vals.push_back(GetEncodedOrdering(
+                     cast<AtomicCmpXchgInst>(I).getSuccessOrdering()));
+    Vals.push_back(GetEncodedSynchScope(
+                     cast<AtomicCmpXchgInst>(I).getSynchScope()));
+    Vals.push_back(GetEncodedOrdering(
+                     cast<AtomicCmpXchgInst>(I).getFailureOrdering()));
+    Vals.push_back(cast<AtomicCmpXchgInst>(I).isWeak());
+    break;
+  case Instruction::AtomicRMW:
+    Code = bitc::FUNC_CODE_INST_ATOMICRMW;
+    PushValueAndType(I.getOperand(0), InstID, Vals, VE);  // ptrty + ptr
+    pushValue(I.getOperand(1), InstID, Vals, VE);         // val.
+    Vals.push_back(GetEncodedRMWOperation(
+                     cast<AtomicRMWInst>(I).getOperation()));
+    Vals.push_back(cast<AtomicRMWInst>(I).isVolatile());
+    Vals.push_back(GetEncodedOrdering(cast<AtomicRMWInst>(I).getOrdering()));
+    Vals.push_back(GetEncodedSynchScope(
+                     cast<AtomicRMWInst>(I).getSynchScope()));
+    break;
+  case Instruction::Fence:
+    Code = bitc::FUNC_CODE_INST_FENCE;
+    Vals.push_back(GetEncodedOrdering(cast<FenceInst>(I).getOrdering()));
+    Vals.push_back(GetEncodedSynchScope(cast<FenceInst>(I).getSynchScope()));
+    break;
+  case Instruction::Call: {
+    const CallInst &CI = cast<CallInst>(I);
+    FunctionType *FTy = CI.getFunctionType();
+
+    Code = bitc::FUNC_CODE_INST_CALL;
+
+    Vals.push_back(VE.getAttributeID(CI.getAttributes()));
+    Vals.push_back(CI.getCallingConv() << bitc::CALL_CCONV |
+                   unsigned(CI.isTailCall()) << bitc::CALL_TAIL |
+                   unsigned(CI.isMustTailCall()) << bitc::CALL_MUSTTAIL);
+
+    PushValueAndType(CI.getCalledValue(), InstID, Vals, VE);  // Callee
+
+    // Emit value #'s for the fixed parameters.
+    for (unsigned i = 0, e = FTy->getNumParams(); i != e; ++i) {
+      // Check for labels (can happen with asm labels).
+      if (FTy->getParamType(i)->isLabelTy())
+        Vals.push_back(VE.getValueID(CI.getArgOperand(i)));
+      else
+        pushValue(CI.getArgOperand(i), InstID, Vals, VE);  // fixed param.
+    }
+
+    // Emit type/value pairs for varargs params.
+    if (FTy->isVarArg()) {
+      for (unsigned i = FTy->getNumParams(), e = CI.getNumArgOperands();
+           i != e; ++i)
+        PushValueAndType(CI.getArgOperand(i), InstID, Vals, VE);  // varargs
+    }
+    break;
+  }
+  case Instruction::VAArg:
+    Code = bitc::FUNC_CODE_INST_VAARG;
+    Vals.push_back(VE.getTypeID(I.getOperand(0)->getType()));   // valistty
+    pushValue(I.getOperand(0), InstID, Vals, VE); // valist.
+    Vals.push_back(VE.getTypeID(I.getType())); // restype.
+    break;
+  }
+
+  Stream.EmitRecord(Code, Vals, AbbrevToUse);
+  Vals.clear();
+}
+
+enum StringEncoding { SE_Char6, SE_Fixed7, SE_Fixed8 };
+
+/// Determine the encoding to use for the given string name and length.
+static StringEncoding getStringEncoding(const char *Str, unsigned StrLen) {
+  bool isChar6 = true;
+  for (const char *C = Str, *E = C + StrLen; C != E; ++C) {
+    if (isChar6)
+      isChar6 = BitCodeAbbrevOp::isChar6(*C);
+    if ((unsigned char)*C & 128)
+      // don't bother scanning the rest.
+      return SE_Fixed8;
+  }
+  if (isChar6)
+    return SE_Char6;
+  else
+    return SE_Fixed7;
+}
+
+/// Emit names for globals/functions etc. The VSTOffsetPlaceholder,
+/// BitcodeStartBit and FunctionIndex are only passed for the module-level
+/// VST, where we are including a function bitcode index and need to
+/// backpatch the VST forward declaration record.
+static void WriteValueSymbolTable(
+    const ValueSymbolTable &VST, const ValueEnumerator35 &VE,
+    BitstreamWriter &Stream, uint64_t VSTOffsetPlaceholder = 0,
+    uint64_t BitcodeStartBit = 0
+// TODO: is this necessary? handle it?
+// -> new one: DenseMap<const Function *, uint64_t> *FunctionToBitcodeIndex
+    /*DenseMap<const Function *, std::unique_ptr<FunctionInfo>> *FunctionIndex =
+        nullptr*/) {
+  if (VST.empty()) {
+    // WriteValueSymbolTableForwardDecl should have returned early as
+    // well. Ensure this handling remains in sync by asserting that
+    // the placeholder offset is not set.
+    assert(VSTOffsetPlaceholder == 0);
+    return;
+  }
+
+  // TODO: necessary/wanted for 3.5?
+  if (VSTOffsetPlaceholder > 0) {
+    // Get the offset of the VST we are writing, and backpatch it into
+    // the VST forward declaration record.
+    uint64_t VSTOffset = Stream.GetCurrentBitNo();
+    // The BitcodeStartBit was the stream offset of the actual bitcode
+    // (e.g. excluding any initial darwin header).
+    VSTOffset -= BitcodeStartBit;
+    assert((VSTOffset & 31) == 0 && "VST block not 32-bit aligned");
+    Stream.BackpatchWord(VSTOffsetPlaceholder, VSTOffset / 32);
+  }
+
+  Stream.EnterSubblock(bitc::VALUE_SYMTAB_BLOCK_ID, 4);
+
+  // FIXME: Set up the abbrev, we know how many values there are!
+  // FIXME: We know if the type names can use 7-bit ascii.
+  SmallVector<unsigned, 64> NameVals;
+
+  for (const ValueName &Name : VST) {
+    // Figure out the encoding to use for the name.
+    StringEncoding Bits =
+        getStringEncoding(Name.getKeyData(), Name.getKeyLength());
+
+    unsigned AbbrevToUse = VST_ENTRY_8_ABBREV;
+    NameVals.push_back(VE.getValueID(Name.getValue()));
+
+    // VST_ENTRY:   [valueid, namechar x N]
+    // VST_BBENTRY: [bbid, namechar x N]
+    unsigned Code;
+    if (isa<BasicBlock>(Name.getValue())) {
+      Code = bitc::VST_CODE_BBENTRY;
+      if (Bits == SE_Char6)
+        AbbrevToUse = VST_BBENTRY_6_ABBREV;
+    } else {
+      Code = bitc::VST_CODE_ENTRY;
+      if (Bits == SE_Char6)
+        AbbrevToUse = VST_ENTRY_6_ABBREV;
+      else if (Bits == SE_Fixed7)
+        AbbrevToUse = VST_ENTRY_7_ABBREV;
+    }
+
+    for (const auto P : Name.getKey())
+      NameVals.push_back((unsigned char)P);
+
+    // Emit the finished record.
+    Stream.EmitRecord(Code, NameVals, AbbrevToUse);
+    NameVals.clear();
+  }
+  Stream.ExitBlock();
+}
+
+/// Emit a function body to the module stream.
+static void WriteFunction(
+    const Function &F, ValueEnumerator35 &VE, BitstreamWriter &Stream) {
+  Stream.EnterSubblock(bitc::FUNCTION_BLOCK_ID, 4);
+  VE.incorporateFunction(F);
+
+  SmallVector<unsigned, 64> Vals;
+
+  // Emit the number of basic blocks, so the reader can create them ahead of
+  // time.
+  Vals.push_back(VE.getBasicBlocks().size());
+  Stream.EmitRecord(bitc::FUNC_CODE_DECLAREBLOCKS, Vals);
+  Vals.clear();
+
+  // If there are function-local constants, emit them now.
+  unsigned CstStart, CstEnd;
+  VE.getFunctionConstantRange(CstStart, CstEnd);
+  WriteConstants(CstStart, CstEnd, VE, Stream, false);
+
+  // If there is function-local metadata, emit it now.
+  WriteFunctionLocalMetadata(F, VE, Stream);
+
+  // Keep a running idea of what the instruction ID is.
+  unsigned InstID = CstEnd;
+
+  bool NeedsMetadataAttachment = false;
+
+  DILocation *LastDL = nullptr;
+  unsigned NumInsts = 0;
+
+  // Finally, emit all the instructions, in order.
+  for (Function::const_iterator BB = F.begin(), E = F.end(); BB != E; ++BB)
+    for (BasicBlock::const_iterator I = BB->begin(), E = BB->end();
+         I != E; ++I) {
+      WriteInstruction(*I, InstID, VE, Stream, Vals);
+
+      if (!isa<DbgInfoIntrinsic>(I))
+        ++NumInsts;
+
+      if (!I->getType()->isVoidTy())
+        ++InstID;
+
+      // If the instruction has metadata, write a metadata attachment later.
+      NeedsMetadataAttachment |= I->hasMetadataOtherThanDebugLoc();
+
+      // If the instruction has a debug location, emit it.
+      DILocation *DL = I->getDebugLoc();
+      if (!DL)
+        continue;
+
+      if (DL == LastDL) {
+        // Just repeat the same debug loc as last time.
+        Stream.EmitRecord(bitc::FUNC_CODE_DEBUG_LOC_AGAIN, Vals);
+        continue;
+      }
+
+      Vals.push_back(DL->getLine());
+      Vals.push_back(DL->getColumn());
+      Vals.push_back(VE.getMetadataOrNullID(DL->getScope()));
+      Vals.push_back(VE.getMetadataOrNullID(DL->getInlinedAt()));
+      Stream.EmitRecord(bitc::FUNC_CODE_DEBUG_LOC, Vals);
+      Vals.clear();
+
+      LastDL = DL;
+    }
+
+  // Emit names for all the instructions etc.
+  WriteValueSymbolTable(F.getValueSymbolTable(), VE, Stream);
+
+  if (NeedsMetadataAttachment)
+    WriteMetadataAttachment(F, VE, Stream);
+  VE.purgeFunction();
+  Stream.ExitBlock();
+}
+
+// Emit blockinfo, which defines the standard abbreviations etc.
+static void WriteBlockInfo(const ValueEnumerator35 &VE, BitstreamWriter &Stream) {
+  // We only want to emit block info records for blocks that have multiple
+  // instances: CONSTANTS_BLOCK, FUNCTION_BLOCK and VALUE_SYMTAB_BLOCK.
+  // Other blocks can define their abbrevs inline.
+  Stream.EnterBlockInfoBlock(2);
+
+  { // 8-bit fixed-width VST_ENTRY/VST_BBENTRY strings.
+    BitCodeAbbrev *Abbv = new BitCodeAbbrev();
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, 3));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::VBR, 8));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Array));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, 8));
+    if (Stream.EmitBlockInfoAbbrev(bitc::VALUE_SYMTAB_BLOCK_ID,
+                                   Abbv) != VST_ENTRY_8_ABBREV)
+      llvm_unreachable("Unexpected abbrev ordering!");
+  }
+
+  { // 7-bit fixed width VST_ENTRY strings.
+    BitCodeAbbrev *Abbv = new BitCodeAbbrev();
+    Abbv->Add(BitCodeAbbrevOp(bitc::VST_CODE_ENTRY));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::VBR, 8));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Array));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, 7));
+    if (Stream.EmitBlockInfoAbbrev(bitc::VALUE_SYMTAB_BLOCK_ID,
+                                   Abbv) != VST_ENTRY_7_ABBREV)
+      llvm_unreachable("Unexpected abbrev ordering!");
+  }
+  { // 6-bit char6 VST_ENTRY strings.
+    BitCodeAbbrev *Abbv = new BitCodeAbbrev();
+    Abbv->Add(BitCodeAbbrevOp(bitc::VST_CODE_ENTRY));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::VBR, 8));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Array));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Char6));
+    if (Stream.EmitBlockInfoAbbrev(bitc::VALUE_SYMTAB_BLOCK_ID,
+                                   Abbv) != VST_ENTRY_6_ABBREV)
+      llvm_unreachable("Unexpected abbrev ordering!");
+  }
+  { // 6-bit char6 VST_BBENTRY strings.
+    BitCodeAbbrev *Abbv = new BitCodeAbbrev();
+    Abbv->Add(BitCodeAbbrevOp(bitc::VST_CODE_BBENTRY));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::VBR, 8));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Array));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Char6));
+    if (Stream.EmitBlockInfoAbbrev(bitc::VALUE_SYMTAB_BLOCK_ID,
+                                   Abbv) != VST_BBENTRY_6_ABBREV)
+      llvm_unreachable("Unexpected abbrev ordering!");
+  }
+
+
+
+  { // SETTYPE abbrev for CONSTANTS_BLOCK.
+    BitCodeAbbrev *Abbv = new BitCodeAbbrev();
+    Abbv->Add(BitCodeAbbrevOp(bitc::CST_CODE_SETTYPE));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed,
+                              VE.computeBitsRequiredForTypeIndicies()));
+    if (Stream.EmitBlockInfoAbbrev(bitc::CONSTANTS_BLOCK_ID,
+                                   Abbv) != CONSTANTS_SETTYPE_ABBREV)
+      llvm_unreachable("Unexpected abbrev ordering!");
+  }
+
+  { // INTEGER abbrev for CONSTANTS_BLOCK.
+    BitCodeAbbrev *Abbv = new BitCodeAbbrev();
+    Abbv->Add(BitCodeAbbrevOp(bitc::CST_CODE_INTEGER));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::VBR, 8));
+    if (Stream.EmitBlockInfoAbbrev(bitc::CONSTANTS_BLOCK_ID,
+                                   Abbv) != CONSTANTS_INTEGER_ABBREV)
+      llvm_unreachable("Unexpected abbrev ordering!");
+  }
+
+  { // CE_CAST abbrev for CONSTANTS_BLOCK.
+    BitCodeAbbrev *Abbv = new BitCodeAbbrev();
+    Abbv->Add(BitCodeAbbrevOp(bitc::CST_CODE_CE_CAST));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, 4));  // cast opc
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed,       // typeid
+                              VE.computeBitsRequiredForTypeIndicies()));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::VBR, 8));    // value id
+
+    if (Stream.EmitBlockInfoAbbrev(bitc::CONSTANTS_BLOCK_ID,
+                                   Abbv) != CONSTANTS_CE_CAST_Abbrev)
+      llvm_unreachable("Unexpected abbrev ordering!");
+  }
+  { // NULL abbrev for CONSTANTS_BLOCK.
+    BitCodeAbbrev *Abbv = new BitCodeAbbrev();
+    Abbv->Add(BitCodeAbbrevOp(bitc::CST_CODE_NULL));
+    if (Stream.EmitBlockInfoAbbrev(bitc::CONSTANTS_BLOCK_ID,
+                                   Abbv) != CONSTANTS_NULL_Abbrev)
+      llvm_unreachable("Unexpected abbrev ordering!");
+  }
+
+  // FIXME: This should only use space for first class types!
+
+  { // INST_LOAD abbrev for FUNCTION_BLOCK.
+    BitCodeAbbrev *Abbv = new BitCodeAbbrev();
+    Abbv->Add(BitCodeAbbrevOp(bitc::FUNC_CODE_INST_LOAD));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::VBR, 6)); // Ptr
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::VBR, 4)); // Align
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, 1)); // volatile
+    if (Stream.EmitBlockInfoAbbrev(bitc::FUNCTION_BLOCK_ID,
+                                   Abbv) != FUNCTION_INST_LOAD_ABBREV)
+      llvm_unreachable("Unexpected abbrev ordering!");
+  }
+  { // INST_BINOP abbrev for FUNCTION_BLOCK.
+    BitCodeAbbrev *Abbv = new BitCodeAbbrev();
+    Abbv->Add(BitCodeAbbrevOp(bitc::FUNC_CODE_INST_BINOP));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::VBR, 6)); // LHS
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::VBR, 6)); // RHS
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, 4)); // opc
+    if (Stream.EmitBlockInfoAbbrev(bitc::FUNCTION_BLOCK_ID,
+                                   Abbv) != FUNCTION_INST_BINOP_ABBREV)
+      llvm_unreachable("Unexpected abbrev ordering!");
+  }
+  { // INST_BINOP_FLAGS abbrev for FUNCTION_BLOCK.
+    BitCodeAbbrev *Abbv = new BitCodeAbbrev();
+    Abbv->Add(BitCodeAbbrevOp(bitc::FUNC_CODE_INST_BINOP));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::VBR, 6)); // LHS
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::VBR, 6)); // RHS
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, 4)); // opc
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, 7)); // flags
+    if (Stream.EmitBlockInfoAbbrev(bitc::FUNCTION_BLOCK_ID,
+                                   Abbv) != FUNCTION_INST_BINOP_FLAGS_ABBREV)
+      llvm_unreachable("Unexpected abbrev ordering!");
+  }
+  { // INST_CAST abbrev for FUNCTION_BLOCK.
+    BitCodeAbbrev *Abbv = new BitCodeAbbrev();
+    Abbv->Add(BitCodeAbbrevOp(bitc::FUNC_CODE_INST_CAST));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::VBR, 6));    // OpVal
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed,       // dest ty
+                              VE.computeBitsRequiredForTypeIndicies()));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::Fixed, 4));  // opc
+    if (Stream.EmitBlockInfoAbbrev(bitc::FUNCTION_BLOCK_ID,
+                                   Abbv) != FUNCTION_INST_CAST_ABBREV)
+      llvm_unreachable("Unexpected abbrev ordering!");
+  }
+
+  { // INST_RET abbrev for FUNCTION_BLOCK.
+    BitCodeAbbrev *Abbv = new BitCodeAbbrev();
+    Abbv->Add(BitCodeAbbrevOp(bitc::FUNC_CODE_INST_RET));
+    if (Stream.EmitBlockInfoAbbrev(bitc::FUNCTION_BLOCK_ID,
+                                   Abbv) != FUNCTION_INST_RET_VOID_ABBREV)
+      llvm_unreachable("Unexpected abbrev ordering!");
+  }
+  { // INST_RET abbrev for FUNCTION_BLOCK.
+    BitCodeAbbrev *Abbv = new BitCodeAbbrev();
+    Abbv->Add(BitCodeAbbrevOp(bitc::FUNC_CODE_INST_RET));
+    Abbv->Add(BitCodeAbbrevOp(BitCodeAbbrevOp::VBR, 6)); // ValID
+    if (Stream.EmitBlockInfoAbbrev(bitc::FUNCTION_BLOCK_ID,
+                                   Abbv) != FUNCTION_INST_RET_VAL_ABBREV)
+      llvm_unreachable("Unexpected abbrev ordering!");
+  }
+  { // INST_UNREACHABLE abbrev for FUNCTION_BLOCK.
+    BitCodeAbbrev *Abbv = new BitCodeAbbrev();
+    Abbv->Add(BitCodeAbbrevOp(bitc::FUNC_CODE_INST_UNREACHABLE));
+    if (Stream.EmitBlockInfoAbbrev(bitc::FUNCTION_BLOCK_ID,
+                                   Abbv) != FUNCTION_INST_UNREACHABLE_ABBREV)
+      llvm_unreachable("Unexpected abbrev ordering!");
+  }
+
+  Stream.ExitBlock();
+}
+
+/// WriteModule - Emit the specified module to the bitstream.
+static void WriteModule(const Module *M, BitstreamWriter &Stream) {
+  Stream.EnterSubblock(bitc::MODULE_BLOCK_ID, 3);
+
+  SmallVector<unsigned, 1> Vals;
+  unsigned CurVersion = 1;
+  Vals.push_back(CurVersion);
+  Stream.EmitRecord(bitc::MODULE_CODE_VERSION, Vals);
+
+  // Analyze the module, enumerating globals, functions, etc.
+  ValueEnumerator35 VE(*M);
+
+  // Emit blockinfo, which defines the standard abbreviations etc.
+  WriteBlockInfo(VE, Stream);
+
+  // Emit information about attribute groups.
+  WriteAttributeGroupTable(VE, Stream);
+
+  // Emit information about parameter attributes.
+  WriteAttributeTable(VE, Stream);
+
+  // Emit information describing all of the types in the module.
+  WriteTypeTable(VE, Stream);
+
+  writeComdats(VE, Stream);
+
+  // Emit top-level description of module, including target triple, inline asm,
+  // descriptors for global variables, and function prototype info.
+  WriteModuleInfo(M, VE, Stream);
+
+  // Emit constants.
+  WriteModuleConstants(VE, Stream);
+
+  // Emit metadata.
+  WriteModuleMetadata(M, VE, Stream);
+
+  // Emit metadata.
+  WriteModuleMetadataStore(M, Stream);
+
+  // Emit names for globals/functions etc.
+  WriteValueSymbolTable(M->getValueSymbolTable(), VE, Stream);
+
+  // Emit function bodies.
+  for (Module::const_iterator F = M->begin(), E = M->end(); F != E; ++F)
+    if (!F->isDeclaration())
+      WriteFunction(*F, VE, Stream);
+
+  Stream.ExitBlock();
+}
+
+/// EmitDarwinBCHeader - If generating a bc file on darwin, we have to emit a
+/// header and trailer to make it compatible with the system archiver.  To do
+/// this we emit the following header, and then emit a trailer that pads the
+/// file out to be a multiple of 16 bytes.
+///
+/// struct bc_header {
+///   uint32_t Magic;         // 0x0B17C0DE
+///   uint32_t Version;       // Version, currently always 0.
+///   uint32_t BitcodeOffset; // Offset to traditional bitcode file.
+///   uint32_t BitcodeSize;   // Size of traditional bitcode file.
+///   uint32_t CPUType;       // CPU specifier.
+///   ... potentially more later ...
+/// };
+enum {
+  DarwinBCSizeFieldOffset = 3*4, // Offset to bitcode_size.
+  DarwinBCHeaderSize = 5*4
+};
+
+static void WriteInt32ToBuffer(uint32_t Value, SmallVectorImpl<char> &Buffer,
+                               uint32_t &Position) {
+  support::endian::write32le(&Buffer[Position], Value);
+  Position += 4;
+}
+
+static void EmitDarwinBCHeaderAndTrailer(SmallVectorImpl<char> &Buffer,
+                                         const Triple &TT) {
+  unsigned CPUType = ~0U;
+
+  // Match x86_64-*, i[3-9]86-*, powerpc-*, powerpc64-*, arm-*, thumb-*,
+  // armv[0-9]-*, thumbv[0-9]-*, armv5te-*, or armv6t2-*. The CPUType is a magic
+  // number from /usr/include/mach/machine.h.  It is ok to reproduce the
+  // specific constants here because they are implicitly part of the Darwin ABI.
+  enum {
+    DARWIN_CPU_ARCH_ABI64      = 0x01000000,
+    DARWIN_CPU_TYPE_X86        = 7,
+    DARWIN_CPU_TYPE_ARM        = 12,
+    DARWIN_CPU_TYPE_POWERPC    = 18
+  };
+
+  Triple::ArchType Arch = TT.getArch();
+  if (Arch == Triple::x86_64)
+    CPUType = DARWIN_CPU_TYPE_X86 | DARWIN_CPU_ARCH_ABI64;
+  else if (Arch == Triple::x86)
+    CPUType = DARWIN_CPU_TYPE_X86;
+  else if (Arch == Triple::ppc)
+    CPUType = DARWIN_CPU_TYPE_POWERPC;
+  else if (Arch == Triple::ppc64)
+    CPUType = DARWIN_CPU_TYPE_POWERPC | DARWIN_CPU_ARCH_ABI64;
+  else if (Arch == Triple::arm || Arch == Triple::thumb)
+    CPUType = DARWIN_CPU_TYPE_ARM;
+
+  // Traditional Bitcode starts after header.
+  assert(Buffer.size() >= DarwinBCHeaderSize &&
+         "Expected header size to be reserved");
+  unsigned BCOffset = DarwinBCHeaderSize;
+  unsigned BCSize = Buffer.size()-DarwinBCHeaderSize;
+
+  // Write the magic and version.
+  unsigned Position = 0;
+  WriteInt32ToBuffer(0x0B17C0DE , Buffer, Position);
+  WriteInt32ToBuffer(0          , Buffer, Position); // Version.
+  WriteInt32ToBuffer(BCOffset   , Buffer, Position);
+  WriteInt32ToBuffer(BCSize     , Buffer, Position);
+  WriteInt32ToBuffer(CPUType    , Buffer, Position);
+
+  // If the file is not a multiple of 16 bytes, insert dummy padding.
+  while (Buffer.size() & 15)
+    Buffer.push_back(0);
+}
+
+/// Helper to write the header common to all bitcode files.
+static void WriteBitcodeHeader(BitstreamWriter &Stream) {
+  // Emit the file header.
+  Stream.Emit((unsigned)'B', 8);
+  Stream.Emit((unsigned)'C', 8);
+  Stream.Emit(0x0, 4);
+  Stream.Emit(0xC, 4);
+  Stream.Emit(0xE, 4);
+  Stream.Emit(0xD, 4);
+}
+
+/// WriteBitcodeToFile - Write the specified module to the specified output
+/// stream.
+void llvm::WriteBitcode35ToFile(const Module *M, raw_ostream &Out) {
+  SmallVector<char, 0> Buffer;
+  Buffer.reserve(256*1024);
+
+  // swap out DEBUG_METADATA_VERSION if it is present (yes, this is evil)
+  // NOTE: doesn't affect IOS_METAL_DEBUG_METADATA_VERSION, this is already correct
+  StringRef debug_info_version_str = "Debug Info Version";
+  if (auto debug_info_node = M->getModuleFlag(debug_info_version_str)) {
+    if (auto debug_info_version = dyn_cast<ConstantAsMetadata>(debug_info_node)) {
+      if(auto version_int = dyn_cast<ConstantInt>(debug_info_version->getValue())) {
+        if(version_int->getZExtValue() == DEBUG_METADATA_VERSION) {
+          // slightly awkward, the agony is real
+          NamedMDNode* module_flags = ((Module*)M)->getOrInsertModuleFlagsMetadata();
+          for(unsigned int i = 0, count = module_flags->getNumOperands(); i < count; ++i) {
+            auto Flag = module_flags->getOperand(i);
+            if (Flag->getNumOperands() >= 3 &&
+                dyn_cast_or_null<MDString>(Flag->getOperand(1)) &&
+                cast<MDString>(Flag->getOperand(1))->getString() == debug_info_version_str) {
+              Metadata *Ops[3] = {
+                ConstantAsMetadata::get(ConstantInt::get(Type::getInt32Ty(M->getContext()), llvm::Module::Warning)),
+                MDString::get(M->getContext(), debug_info_version_str),
+                ConstantAsMetadata::get(ConstantInt::get(Type::getInt32Ty(M->getContext()), DEBUG_METADATA_VERSION_35))
+              };
+              module_flags->setOperand(i, MDNode::get(M->getContext(), Ops));
+              break;
+            }
+          }
+        }
+      }
+    }
+  }
+
+  // If this is darwin or another generic macho target, reserve space for the
+  // header.
+  Triple TT(M->getTargetTriple());
+  if (TT.isOSDarwin())
+    Buffer.insert(Buffer.begin(), DarwinBCHeaderSize, 0);
+
+  // Emit the module into the buffer.
+  {
+    BitstreamWriter Stream(Buffer);
+
+    // Emit the file header.
+    WriteBitcodeHeader(Stream);
+
+    // Emit the module.
+    WriteModule(M, Stream);
+  }
+
+  if (TT.isOSDarwin())
+    EmitDarwinBCHeaderAndTrailer(Buffer, TT);
+
+  // Write the generated bitstream to "Out".
+  Out.write((char*)&Buffer.front(), Buffer.size());
+}
diff --git a/lib/Bitcode/Writer35/BitcodeWriterPass35.cpp b/lib/Bitcode/Writer35/BitcodeWriterPass35.cpp
new file mode 100644
index 0000000..cd443e8
--- /dev/null
+++ b/lib/Bitcode/Writer35/BitcodeWriterPass35.cpp
@@ -0,0 +1,48 @@
+//===- BitcodeWriterPass35.cpp - Bitcode 3.5 writing pass -----------------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+// BitcodeWriter35Pass implementation.
+//
+//===----------------------------------------------------------------------===//
+
+#include "llvm/Bitcode/BitcodeWriterPass.h"
+#include "llvm/Bitcode/ReaderWriter.h"
+#include "llvm/IR/Module.h"
+#include "llvm/IR/PassManager.h"
+#include "llvm/Pass.h"
+using namespace llvm;
+
+PreservedAnalyses Bitcode35WriterPass::run(Module &M) {
+  WriteBitcode35ToFile(&M, OS);
+  return PreservedAnalyses::all();
+}
+
+namespace {
+  class WriteBitcode35Pass : public ModulePass {
+    raw_ostream &OS; // raw_ostream to print on
+
+  public:
+    static char ID; // Pass identification, replacement for typeid
+    explicit WriteBitcode35Pass(raw_ostream &o)
+        : ModulePass(ID), OS(o) {}
+
+    const char *getPassName() const override { return "Bitcode 3.5 Writer"; }
+
+    bool runOnModule(Module &M) override {
+      WriteBitcode35ToFile(&M, OS);
+      return false;
+    }
+  };
+}
+
+char WriteBitcode35Pass::ID = 0;
+
+ModulePass *llvm::createBitcode35WriterPass(raw_ostream &Str) {
+  return new WriteBitcode35Pass(Str);
+}
diff --git a/lib/Bitcode/Writer35/CMakeLists.txt b/lib/Bitcode/Writer35/CMakeLists.txt
new file mode 100644
index 0000000..0cbd182
--- /dev/null
+++ b/lib/Bitcode/Writer35/CMakeLists.txt
@@ -0,0 +1,9 @@
+add_llvm_library(LLVMBitWriter35
+  BitWriter35.cpp
+  BitcodeWriter35.cpp
+  BitcodeWriterPass35.cpp
+  ValueEnumerator35.cpp
+
+  DEPENDS
+  intrinsics_gen
+  )
diff --git a/lib/Bitcode/Writer35/LLVMBuild.txt b/lib/Bitcode/Writer35/LLVMBuild.txt
new file mode 100644
index 0000000..626e76a
--- /dev/null
+++ b/lib/Bitcode/Writer35/LLVMBuild.txt
@@ -0,0 +1,22 @@
+;===- ./lib/Bitcode/Writer35/LLVMBuild.txt ---------------------*- Conf -*--===;
+;
+;                     The LLVM Compiler Infrastructure
+;
+; This file is distributed under the University of Illinois Open Source
+; License. See LICENSE.TXT for details.
+;
+;===------------------------------------------------------------------------===;
+;
+; This is an LLVMBuild description file for the components in this subdirectory.
+;
+; For more information on the LLVMBuild system, please see:
+;
+;   http://llvm.org/docs/LLVMBuild.html
+;
+;===------------------------------------------------------------------------===;
+
+[component_0]
+type = Library
+name = BitWriter35
+parent = Bitcode
+required_libraries = Core Support
diff --git a/lib/Bitcode/Writer35/Makefile b/lib/Bitcode/Writer35/Makefile
new file mode 100644
index 0000000..a984073
--- /dev/null
+++ b/lib/Bitcode/Writer35/Makefile
@@ -0,0 +1,15 @@
+##===- lib/Bitcode/Writer35/Makefile -----------------------*- Makefile -*-===##
+#
+#                     The LLVM Compiler Infrastructure
+#
+# This file is distributed under the University of Illinois Open Source
+# License. See LICENSE.TXT for details.
+#
+##===----------------------------------------------------------------------===##
+
+LEVEL = ../../..
+LIBRARYNAME = LLVMBitWriter35
+BUILD_ARCHIVE = 1
+
+include $(LEVEL)/Makefile.common
+
diff --git a/lib/Bitcode/Writer35/ValueEnumerator35.cpp b/lib/Bitcode/Writer35/ValueEnumerator35.cpp
new file mode 100644
index 0000000..ff273c9
--- /dev/null
+++ b/lib/Bitcode/Writer35/ValueEnumerator35.cpp
@@ -0,0 +1,645 @@
+//===- ValueEnumerator35.cpp - Number values and types for bitcode writer -===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+// This file implements the ValueEnumerator35 class.
+//
+//===----------------------------------------------------------------------===//
+
+#include "ValueEnumerator35.h"
+#include "llvm/ADT/STLExtras.h"
+#include "llvm/ADT/SmallPtrSet.h"
+#include "llvm/IR/Constants.h"
+#include "llvm/IR/DebugInfoMetadata.h"
+#include "llvm/IR/DerivedTypes.h"
+#include "llvm/IR/Instructions.h"
+#include "llvm/IR/Module.h"
+#include "llvm/IR/UseListOrder.h"
+#include "llvm/IR/ValueSymbolTable.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/raw_ostream.h"
+#include <algorithm>
+using namespace llvm;
+
+static bool isIntOrIntVectorValue(const std::pair<const Value*, unsigned> &V) {
+  return V.first->getType()->isIntOrIntVectorTy();
+}
+
+ValueEnumerator35::ValueEnumerator35(const Module &M)
+    : HasMDString(false), HasDILocation(false), HasGenericDINode(false) {
+  // Enumerate the global variables.
+  for (const GlobalVariable &GV : M.globals())
+    EnumerateValue(&GV);
+
+  // Enumerate the functions.
+  for (const Function & F : M) {
+    EnumerateValue(&F);
+    EnumerateAttributes(F.getAttributes());
+  }
+
+  // Enumerate the aliases.
+  for (const GlobalAlias &GA : M.aliases())
+    EnumerateValue(&GA);
+
+  // Remember what is the cutoff between globalvalue's and other constants.
+  unsigned FirstConstant = Values.size();
+
+  // Enumerate the global variable initializers.
+  for (const GlobalVariable &GV : M.globals())
+    if (GV.hasInitializer())
+      EnumerateValue(GV.getInitializer());
+
+  // Enumerate the aliasees.
+  for (const GlobalAlias &GA : M.aliases())
+    EnumerateValue(GA.getAliasee());
+
+  // Enumerate any optional Function data.
+  for (const Function &F : M)
+    for (const Use &U : F.operands())
+      EnumerateValue(U.get());
+
+  // Enumerate the metadata type.
+  //
+  // TODO: Move this to ValueEnumerator35::EnumerateOperandType() once bitcode
+  // only encodes the metadata type when it's used as a value.
+  EnumerateType(Type::getMetadataTy(M.getContext()));
+
+  // Insert constants and metadata that are named at module level into the slot
+  // pool so that the module symbol table can refer to them...
+  EnumerateValueSymbolTable(M.getValueSymbolTable());
+  EnumerateNamedMetadata(M);
+
+  SmallVector<std::pair<unsigned, MDNode *>, 8> MDs;
+
+  // Enumerate types used by function bodies and argument lists.
+  for (const Function &F : M) {
+    for (const Argument &A : F.args())
+      EnumerateType(A.getType());
+
+    for (const BasicBlock &BB : F)
+      for (const Instruction &I : BB) {
+        for (const Use &Op : I.operands()) {
+          auto *MD = dyn_cast<MetadataAsValue>(&Op);
+          if (!MD) {
+            EnumerateOperandType(Op);
+            continue;
+          }
+
+          // Local metadata is enumerated during function-incorporation.
+          if (isa<LocalAsMetadata>(MD->getMetadata()))
+            continue;
+
+          EnumerateMetadata(MD->getMetadata());
+        }
+        EnumerateType(I.getType());
+        if (const CallInst *CI = dyn_cast<CallInst>(&I))
+          EnumerateAttributes(CI->getAttributes());
+        else if (const InvokeInst *II = dyn_cast<InvokeInst>(&I))
+          EnumerateAttributes(II->getAttributes());
+
+        // Enumerate metadata attached with this instruction.
+        MDs.clear();
+        I.getAllMetadataOtherThanDebugLoc(MDs);
+        for (unsigned i = 0, e = MDs.size(); i != e; ++i)
+          EnumerateMetadata(MDs[i].second);
+
+        // Don't enumerate the location directly -- it has a special record
+        // type -- but enumerate its operands.
+        if (DILocation *L = I.getDebugLoc())
+          EnumerateMDNodeOperands(L);
+      }
+  }
+
+  // Optimize constant ordering.
+  OptimizeConstants(FirstConstant, Values.size());
+}
+
+unsigned ValueEnumerator35::getInstructionID(const Instruction *Inst) const {
+  InstructionMapType::const_iterator I = InstructionMap.find(Inst);
+  assert(I != InstructionMap.end() && "Instruction is not mapped!");
+  return I->second;
+}
+
+unsigned ValueEnumerator35::getComdatID(const Comdat *C) const {
+  unsigned ComdatID = Comdats.idFor(C);
+  assert(ComdatID && "Comdat not found!");
+  return ComdatID;
+}
+
+void ValueEnumerator35::setInstructionID(const Instruction *I) {
+  InstructionMap[I] = InstructionCount++;
+}
+
+unsigned ValueEnumerator35::getMetadataID(const Metadata *MD) const {
+  auto ID = getMetadataOrNullID(MD);
+#if 0
+  if(ID == 0) {
+    errs() << "invalid MD: ";
+    if(MD) errs() << MD;
+    else errs() << "nullptr";
+    errs() << "\n";
+  }
+#endif
+  assert(ID != 0 && "Metadata not in slotcalculator!");
+  return ID - 1;
+}
+
+unsigned ValueEnumerator35::getValueID(const Value *V) const {
+  if (auto *MD = dyn_cast<MetadataAsValue>(V))
+    return getMetadataID(MD->getMetadata());
+
+  ValueMapType::const_iterator I = ValueMap.find(V);
+#if 0
+  if(I == ValueMap.end()) {
+    errs() << "invalid value: " << *V << "\n";
+  }
+#endif
+  assert(I != ValueMap.end() && "Value not in slotcalculator!");
+  return I->second-1;
+}
+
+void ValueEnumerator35::dump() const {
+  print(dbgs(), ValueMap, "Default");
+  dbgs() << '\n';
+  print(dbgs(), MetadataMap, "MetaData");
+  dbgs() << '\n';
+}
+
+void ValueEnumerator35::print(raw_ostream &OS, const ValueMapType &Map,
+                              const char *Name) const {
+
+  OS << "Map Name: " << Name << "\n";
+  OS << "Size: " << Map.size() << "\n";
+  for (ValueMapType::const_iterator I = Map.begin(),
+         E = Map.end(); I != E; ++I) {
+
+    const Value *V = I->first;
+    if (V->hasName())
+      OS << "Value: " << V->getName();
+    else
+      OS << "Value: [null]\n";
+    V->dump();
+
+    OS << " Uses(" << std::distance(V->use_begin(),V->use_end()) << "):";
+    for (const Use &U : V->uses()) {
+      if (&U != &*V->use_begin())
+        OS << ",";
+      if(U->hasName())
+        OS << " " << U->getName();
+      else
+        OS << " [null]";
+
+    }
+    OS <<  "\n\n";
+  }
+}
+
+void ValueEnumerator35::print(raw_ostream &OS, const MetadataMapType &Map,
+                              const char *Name) const {
+
+  OS << "Map Name: " << Name << "\n";
+  OS << "Size: " << Map.size() << "\n";
+  for (auto I = Map.begin(), E = Map.end(); I != E; ++I) {
+    const Metadata *MD = I->first;
+    OS << "Metadata: slot = " << I->second << "\n";
+    MD->print(OS);
+  }
+}
+
+/// OptimizeConstants - Reorder constant pool for denser encoding.
+void ValueEnumerator35::OptimizeConstants(unsigned CstStart, unsigned CstEnd) {
+  if (CstStart == CstEnd || CstStart+1 == CstEnd) return;
+
+  std::stable_sort(Values.begin() + CstStart, Values.begin() + CstEnd,
+                   [this](const std::pair<const Value *, unsigned> &LHS,
+                          const std::pair<const Value *, unsigned> &RHS) {
+    // Sort by plane.
+    if (LHS.first->getType() != RHS.first->getType())
+      return getTypeID(LHS.first->getType()) < getTypeID(RHS.first->getType());
+    // Then by frequency.
+    return LHS.second > RHS.second;
+  });
+
+  // Ensure that integer and vector of integer constants are at the start of the
+  // constant pool.  This is important so that GEP structure indices come before
+  // gep constant exprs.
+  std::partition(Values.begin()+CstStart, Values.begin()+CstEnd,
+                 isIntOrIntVectorValue);
+
+  // Rebuild the modified portion of ValueMap.
+  for (; CstStart != CstEnd; ++CstStart)
+    ValueMap[Values[CstStart].first] = CstStart+1;
+}
+
+
+/// EnumerateValueSymbolTable - Insert all of the values in the specified symbol
+/// table into the values table.
+void ValueEnumerator35::EnumerateValueSymbolTable(const ValueSymbolTable &VST) {
+  for (ValueSymbolTable::const_iterator VI = VST.begin(), VE = VST.end();
+       VI != VE; ++VI)
+    EnumerateValue(VI->getValue());
+}
+
+/// Insert all of the values referenced by named metadata in the specified
+/// module.
+void ValueEnumerator35::EnumerateNamedMetadata(const Module &M) {
+  for (const auto &I : M.named_metadata())
+    EnumerateNamedMDNode(&I);
+}
+
+void ValueEnumerator35::EnumerateNamedMDNode(const NamedMDNode *MD) {
+  for (unsigned i = 0, e = MD->getNumOperands(); i != e; ++i)
+    EnumerateMetadata(MD->getOperand(i));
+}
+
+/// EnumerateMDNodeOperands - Enumerate all non-function-local values
+/// and types referenced by the given MDNode.
+void ValueEnumerator35::EnumerateMDNodeOperands(const MDNode *N) {
+  for (unsigned i = 0, e = N->getNumOperands(); i != e; ++i) {
+    const Metadata* MD = N->getOperand(i);
+    if (!MD) {
+      EnumerateType(Type::getVoidTy(N->getContext()));
+      continue;
+    }
+    assert(!isa<LocalAsMetadata>(MD) && "MDNodes cannot be function-local");
+    if(isa<MDNode>(MD) || isa<MDString>(MD)) {
+      EnumerateMetadata(MD);
+    } else if(auto* V = dyn_cast<ValueAsMetadata>(MD)) {
+      EnumerateValue(V->getValue());
+    }
+  }
+}
+
+#define EnumerateI1(DI_obj, val) EnumerateValue(ConstantInt::get(Type::getInt1Ty(DI_obj->getContext()), val))
+#define EnumerateI32(DI_obj, val) EnumerateValue(ConstantInt::get(Type::getInt32Ty(DI_obj->getContext()), val))
+#define EnumerateI64(DI_obj, val) EnumerateValue(ConstantInt::get(Type::getInt64Ty(DI_obj->getContext()), val))
+#define DW_TAG(tag) (tag | (12 << 16))
+
+void ValueEnumerator35::EnumerateMetadata(const Metadata *MD) {
+  assert(
+      (isa<MDNode>(MD) || isa<MDString>(MD) || isa<ConstantAsMetadata>(MD)) &&
+      "Invalid metadata kind");
+
+  // Insert a dummy ID to block the co-recursive call to
+  // EnumerateMDNodeOperands() from re-visiting MD in a cyclic graph.
+  //
+  // Return early if there's already an ID.
+  if (!MetadataMap.insert(std::make_pair(MD, 0)).second)
+    return;
+
+  // Visit operands first to minimize RAUW.
+  // NOTE: debug info must be handled manually (this is different to 3.8 handling)
+  if (auto *DILoc = dyn_cast<DILocation>(MD)) {
+    EnumerateI32(DILoc, DILoc->getLine());
+    EnumerateI32(DILoc, DILoc->getColumn());
+    EnumerateMDNodeOperands(DILoc);
+  }
+  else if (auto *DIF = dyn_cast<DIFile>(MD)) {
+    EnumerateI32(DIF, DW_TAG(dwarf::DW_TAG_file_type));
+    EnumerateMDNodeOperands(DIF);
+    SmallVector<Metadata*, 2> file_node {{ DIF->getRawFilename(), DIF->getRawDirectory() }};
+    ((DIFile*)DIF)->contained_node = MDTuple::get(DIF->getContext(), file_node);
+    EnumerateMetadata(DIF->contained_node);
+  }
+  else if (auto *DICU = dyn_cast<DICompileUnit>(MD)) {
+    EnumerateI32(DICU, DW_TAG(dwarf::DW_TAG_compile_unit));
+    if(DICU->getFile()) {
+      // doesn't point to an actual DIFile node, but directly to { file, dir }
+      auto DIF = DICU->getFile();
+      EnumerateMDNodeOperands(DIF);
+      SmallVector<Metadata*, 2> file_node {{ DIF->getRawFilename(), DIF->getRawDirectory() }};
+      DIF->contained_node = MDTuple::get(DICU->getContext(), file_node);
+      EnumerateMetadata(DIF->contained_node);
+    }
+    EnumerateI32(DICU, DICU->getSourceLanguage());
+    if(DICU->getRawProducer()) EnumerateMetadata(DICU->getRawProducer());
+    EnumerateI1(DICU, DICU->isOptimized());
+    if(DICU->getRawFlags()) EnumerateMetadata(DICU->getRawFlags());
+    EnumerateI32(DICU, DICU->getRuntimeVersion());
+    if(DICU->getRawEnumTypes()) EnumerateMetadata(DICU->getRawEnumTypes());
+    if(DICU->getRawRetainedTypes()) EnumerateMetadata(DICU->getRawRetainedTypes());
+    //if(DICU->getRawSubprograms()) EnumerateMetadata(DICU->getRawSubprograms()); // TODO: fix subprograms
+    if(DICU->getRawGlobalVariables()) EnumerateMetadata(DICU->getRawGlobalVariables());
+    if(DICU->getRawImportedEntities()) EnumerateMetadata(DICU->getRawImportedEntities());
+    if(DICU->getRawSplitDebugFilename()) EnumerateMetadata(DICU->getRawSplitDebugFilename());
+    EnumerateI32(DICU, DICU->getEmissionKind());
+  }
+  else if (auto *DISP = dyn_cast<DISubprogram>(MD)) {
+    EnumerateI32(DISP, DW_TAG(dwarf::DW_TAG_subprogram));
+    if(DISP->getFile()) EnumerateMetadata(DISP->getFile());
+    if(DISP->getScope()) EnumerateMetadata(DISP->getScope());
+    if(DISP->getRawName()) EnumerateMetadata(DISP->getRawName());
+    if(DISP->getRawLinkageName()) EnumerateMetadata(DISP->getRawLinkageName());
+    EnumerateI32(DISP, DISP->getLine());
+    if(DISP->getType()) EnumerateMetadata(DISP->getType());
+    EnumerateI1(DISP, DISP->isLocalToUnit());
+    EnumerateI1(DISP, DISP->isDefinition());
+    EnumerateI32(DISP, DISP->getVirtuality());
+    EnumerateI32(DISP, DISP->getVirtualIndex());
+    if(DISP->getContainingType()) EnumerateMetadata(DISP->getContainingType());
+    EnumerateI32(DISP, DISP->getFlags());
+    EnumerateI1(DISP, DISP->isOptimized());
+    if(DISP->associated_function) {
+      EnumerateValue(DISP->associated_function);
+    }
+    if(DISP->getTemplateParams()) EnumerateMetadata(DISP->getTemplateParams().get());
+    if(DISP->getDeclaration()) EnumerateMetadata(DISP->getDeclaration());
+    
+    if(DISP->getVariables()) EnumerateMetadata(DISP->getVariables().get());
+    else {
+      auto empty_node = MDTuple::getTemporary(DISP->getContext(), {});
+      EnumerateMetadata(empty_node.get());
+    }
+    
+    EnumerateI32(DISP, DISP->getScopeLine());
+  }
+  else if(auto *DILB = dyn_cast<DILexicalBlock>(MD)) {
+    EnumerateI32(DILB, DW_TAG(dwarf::DW_TAG_lexical_block));
+    
+    static unsigned int unique_id = 0;
+    if(DILB->getFile()) EnumerateMetadata(DILB->getFile());
+    if(DILB->getScope()) EnumerateMetadata(DILB->getScope());
+    EnumerateI32(DILB, DILB->getLine());
+    EnumerateI32(DILB, DILB->getColumn());
+    EnumerateI32(DILB, 0);
+    EnumerateI32(DILB, unique_id++);
+  }
+  else if(auto *DIST = dyn_cast<DISubroutineType>(MD)) {
+    EnumerateI32(DIST, DW_TAG(dwarf::DW_TAG_subroutine_type));
+    
+    EnumerateI32(DIST, 0);
+    auto empty_str_node = MDString::get(DIST->getContext(), "");
+    EnumerateMetadata(empty_str_node);
+    EnumerateI64(DIST, 0);
+    EnumerateI32(DIST, DIST->getFlags());
+    if(DIST->getTypeArray()) EnumerateMetadata(DIST->getTypeArray().get());
+  }
+  else if (auto *N = dyn_cast<MDNode>(MD))
+    EnumerateMDNodeOperands(N);
+  else if (auto *C = dyn_cast<ConstantAsMetadata>(MD))
+    EnumerateValue(C->getValue());
+
+  HasMDString |= isa<MDString>(MD);
+  HasDILocation |= isa<DILocation>(MD);
+  HasGenericDINode |= isa<GenericDINode>(MD);
+
+  // Replace the dummy ID inserted above with the correct one.  MetadataMap may
+  // have changed by inserting operands, so we need a fresh lookup here.
+  MDs.push_back(MD);
+  MetadataMap[MD] = MDs.size();
+}
+
+/// EnumerateFunctionLocalMetadataa - Incorporate function-local metadata
+/// information reachable from the metadata.
+void ValueEnumerator35::EnumerateFunctionLocalMetadata(
+    const LocalAsMetadata *Local) {
+  // Check to see if it's already in!
+  unsigned &MetadataID = MetadataMap[Local];
+  if (MetadataID)
+    return;
+
+  MDs.push_back(Local);
+  MetadataID = MDs.size();
+
+  EnumerateValue(Local->getValue());
+
+  // Also, collect all function-local metadata for easy access.
+  FunctionLocalMDs.push_back(Local);
+}
+
+void ValueEnumerator35::EnumerateValue(const Value *V) {
+  assert(!V->getType()->isVoidTy() && "Can't insert void values!");
+  assert(!isa<MetadataAsValue>(V) && "EnumerateValue doesn't handle Metadata!");
+
+  // Check to see if it's already in!
+  unsigned &ValueID = ValueMap[V];
+  if (ValueID) {
+    // Increment use count.
+    Values[ValueID-1].second++;
+    return;
+  }
+
+  if (auto *GO = dyn_cast<GlobalObject>(V))
+    if (const Comdat *C = GO->getComdat())
+      Comdats.insert(C);
+
+  // Enumerate the type of this value.
+  EnumerateType(V->getType());
+
+  if (const Constant *C = dyn_cast<Constant>(V)) {
+    if (isa<GlobalValue>(C)) {
+      // Initializers for globals are handled explicitly elsewhere.
+    } else if (C->getNumOperands()) {
+      // If a constant has operands, enumerate them.  This makes sure that if a
+      // constant has uses (for example an array of const ints), that they are
+      // inserted also.
+
+      // We prefer to enumerate them with values before we enumerate the user
+      // itself.  This makes it more likely that we can avoid forward references
+      // in the reader.  We know that there can be no cycles in the constants
+      // graph that don't go through a global variable.
+      for (User::const_op_iterator I = C->op_begin(), E = C->op_end();
+           I != E; ++I)
+        if (!isa<BasicBlock>(*I)) // Don't enumerate BB operand to BlockAddress.
+          EnumerateValue(*I);
+
+      // Finally, add the value.  Doing this could make the ValueID reference be
+      // dangling, don't reuse it.
+      Values.push_back(std::make_pair(V, 1U));
+      ValueMap[V] = Values.size();
+      return;
+    }
+  }
+
+  // Add the value.
+  Values.push_back(std::make_pair(V, 1U));
+  ValueID = Values.size();
+}
+
+
+void ValueEnumerator35::EnumerateType(Type *Ty) {
+  unsigned *TypeID = &TypeMap[Ty];
+
+  // We've already seen this type.
+  if (*TypeID)
+    return;
+
+  // If it is a non-anonymous struct, mark the type as being visited so that we
+  // don't recursively visit it.  This is safe because we allow forward
+  // references of these in the bitcode reader.
+  if (StructType *STy = dyn_cast<StructType>(Ty))
+    if (!STy->isLiteral())
+      *TypeID = ~0U;
+
+  // Enumerate all of the subtypes before we enumerate this type.  This ensures
+  // that the type will be enumerated in an order that can be directly built.
+  for (Type *SubTy : Ty->subtypes())
+    EnumerateType(SubTy);
+
+  // Refresh the TypeID pointer in case the table rehashed.
+  TypeID = &TypeMap[Ty];
+
+  // Check to see if we got the pointer another way.  This can happen when
+  // enumerating recursive types that hit the base case deeper than they start.
+  //
+  // If this is actually a struct that we are treating as forward ref'able,
+  // then emit the definition now that all of its contents are available.
+  if (*TypeID && *TypeID != ~0U)
+    return;
+
+  // Add this type now that its contents are all happily enumerated.
+  Types.push_back(Ty);
+
+  *TypeID = Types.size();
+}
+
+// Enumerate the types for the specified value.  If the value is a constant,
+// walk through it, enumerating the types of the constant.
+void ValueEnumerator35::EnumerateOperandType(const Value *V) {
+  EnumerateType(V->getType());
+
+  if (auto *MD = dyn_cast<MetadataAsValue>(V)) {
+    assert(!isa<LocalAsMetadata>(MD->getMetadata()) &&
+           "Function-local metadata should be left for later");
+
+    EnumerateMetadata(MD->getMetadata());
+    return;
+  }
+
+  const Constant *C = dyn_cast<Constant>(V);
+  if (!C)
+    return;
+
+  // If this constant is already enumerated, ignore it, we know its type must
+  // be enumerated.
+  if (ValueMap.count(C))
+    return;
+
+  // This constant may have operands, make sure to enumerate the types in
+  // them.
+  for (const Value *Op : C->operands()) {
+    // Don't enumerate basic blocks here, this happens as operands to
+    // blockaddress.
+    if (isa<BasicBlock>(Op))
+      continue;
+
+    EnumerateOperandType(Op);
+  }
+}
+
+void ValueEnumerator35::EnumerateAttributes(AttributeSet PAL) {
+  if (PAL.isEmpty()) return;  // null is always 0.
+
+  // Do a lookup.
+  unsigned &Entry = AttributeMap[PAL];
+  if (Entry == 0) {
+    // Never saw this before, add it.
+    Attribute.push_back(PAL);
+    Entry = Attribute.size();
+  }
+
+  // Do lookups for all attribute groups.
+  for (unsigned i = 0, e = PAL.getNumSlots(); i != e; ++i) {
+    AttributeSet AS = PAL.getSlotAttributes(i);
+    unsigned &Entry = AttributeGroupMap[AS];
+    if (Entry == 0) {
+      AttributeGroups.push_back(AS);
+      Entry = AttributeGroups.size();
+    }
+  }
+}
+
+void ValueEnumerator35::incorporateFunction(const Function &F) {
+  InstructionCount = 0;
+  NumModuleValues = Values.size();
+  NumModuleMDs = MDs.size();
+
+  // Adding function arguments to the value table.
+  for (const auto &I : F.args())
+    EnumerateValue(&I);
+
+  FirstFuncConstantID = Values.size();
+
+  // Add all function-level constants to the value table.
+  for (const BasicBlock &BB : F) {
+    for (const Instruction &I : BB)
+      for (const Use &OI : I.operands()) {
+        if ((isa<Constant>(OI) && !isa<GlobalValue>(OI)) || isa<InlineAsm>(OI))
+          EnumerateValue(OI);
+      }
+    BasicBlocks.push_back(&BB);
+    ValueMap[&BB] = BasicBlocks.size();
+  }
+
+  // Optimize the constant layout.
+  OptimizeConstants(FirstFuncConstantID, Values.size());
+
+  // Add the function's parameter attributes so they are available for use in
+  // the function's instruction.
+  EnumerateAttributes(F.getAttributes());
+
+  FirstInstID = Values.size();
+
+  SmallVector<LocalAsMetadata *, 8> FnLocalMDVector;
+  // Add all of the instructions.
+  for (const BasicBlock &BB : F) {
+    for (const Instruction &I : BB) {
+      for (const Use &OI : I.operands()) {
+        if (auto *MD = dyn_cast<MetadataAsValue>(&OI))
+          if (auto *Local = dyn_cast<LocalAsMetadata>(MD->getMetadata()))
+            // Enumerate metadata after the instructions they might refer to.
+            FnLocalMDVector.push_back(Local);
+      }
+
+      if (!I.getType()->isVoidTy())
+        EnumerateValue(&I);
+    }
+  }
+
+  // Add all of the function-local metadata.
+  for (unsigned i = 0, e = FnLocalMDVector.size(); i != e; ++i)
+    EnumerateFunctionLocalMetadata(FnLocalMDVector[i]);
+}
+
+void ValueEnumerator35::purgeFunction() {
+  /// Remove purged values from the ValueMap.
+  for (unsigned i = NumModuleValues, e = Values.size(); i != e; ++i)
+    ValueMap.erase(Values[i].first);
+  for (unsigned i = NumModuleMDs, e = MDs.size(); i != e; ++i)
+    MetadataMap.erase(MDs[i]);
+  for (unsigned i = 0, e = BasicBlocks.size(); i != e; ++i)
+    ValueMap.erase(BasicBlocks[i]);
+
+  Values.resize(NumModuleValues);
+  MDs.resize(NumModuleMDs);
+  BasicBlocks.clear();
+  FunctionLocalMDs.clear();
+}
+
+static void IncorporateFunctionInfoGlobalBBIDs(const Function *F,
+                                 DenseMap<const BasicBlock*, unsigned> &IDMap) {
+  unsigned Counter = 0;
+  for (const BasicBlock &BB : *F)
+    IDMap[&BB] = ++Counter;
+}
+
+/// getGlobalBasicBlockID - This returns the function-specific ID for the
+/// specified basic block.  This is relatively expensive information, so it
+/// should only be used by rare constructs such as address-of-label.
+unsigned ValueEnumerator35::getGlobalBasicBlockID(const BasicBlock *BB) const {
+  unsigned &Idx = GlobalBasicBlockIDs[BB];
+  if (Idx != 0)
+    return Idx-1;
+
+  IncorporateFunctionInfoGlobalBBIDs(BB->getParent(), GlobalBasicBlockIDs);
+  return getGlobalBasicBlockID(BB);
+}
+
+uint64_t ValueEnumerator35::computeBitsRequiredForTypeIndicies() const {
+  return Log2_32_Ceil(getTypes().size() + 1);
+}
diff --git a/lib/Bitcode/Writer35/ValueEnumerator35.h b/lib/Bitcode/Writer35/ValueEnumerator35.h
new file mode 100644
index 0000000..d2a1cca
--- /dev/null
+++ b/lib/Bitcode/Writer35/ValueEnumerator35.h
@@ -0,0 +1,202 @@
+//===-- Bitcode/Writer35/ValueEnumerator35.h - Number values ----*- C++ -*-===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+// This class gives values and types Unique ID's.
+//
+//===----------------------------------------------------------------------===//
+
+#ifndef LLVM_LIB_BITCODE_35_WRITER_VALUEENUMERATOR_H
+#define LLVM_LIB_BITCODE_35_WRITER_VALUEENUMERATOR_H
+
+#include "llvm/ADT/DenseMap.h"
+#include "llvm/ADT/SmallVector.h"
+#include "llvm/ADT/UniqueVector.h"
+#include "llvm/IR/Attributes.h"
+#include "llvm/IR/UseListOrder.h"
+#include <vector>
+
+namespace llvm {
+
+class Type;
+class Value;
+class Instruction;
+class BasicBlock;
+class Comdat;
+class Function;
+class Module;
+class Metadata;
+class LocalAsMetadata;
+class MDNode;
+class NamedMDNode;
+class AttributeSet;
+class ValueSymbolTable;
+class MDSymbolTable;
+class raw_ostream;
+
+class ValueEnumerator35 {
+public:
+  typedef std::vector<Type*> TypeList;
+
+  // For each value, we remember its Value* and occurrence frequency.
+  typedef std::vector<std::pair<const Value*, unsigned> > ValueList;
+
+  UseListOrderStack UseListOrders;
+
+private:
+  typedef DenseMap<Type*, unsigned> TypeMapType;
+  TypeMapType TypeMap;
+  TypeList Types;
+
+  typedef DenseMap<const Value*, unsigned> ValueMapType;
+  ValueMapType ValueMap;
+  ValueList Values;
+
+  typedef UniqueVector<const Comdat *> ComdatSetType;
+  ComdatSetType Comdats;
+
+  std::vector<const Metadata *> MDs;
+  SmallVector<const LocalAsMetadata *, 8> FunctionLocalMDs;
+  typedef DenseMap<const Metadata *, unsigned> MetadataMapType;
+  MetadataMapType MetadataMap;
+  bool HasMDString;
+  bool HasDILocation;
+  bool HasGenericDINode;
+
+  typedef DenseMap<AttributeSet, unsigned> AttributeGroupMapType;
+  AttributeGroupMapType AttributeGroupMap;
+  std::vector<AttributeSet> AttributeGroups;
+
+  typedef DenseMap<AttributeSet, unsigned> AttributeMapType;
+  AttributeMapType AttributeMap;
+  std::vector<AttributeSet> Attribute;
+
+  /// GlobalBasicBlockIDs - This map memoizes the basic block ID's referenced by
+  /// the "getGlobalBasicBlockID" method.
+  mutable DenseMap<const BasicBlock*, unsigned> GlobalBasicBlockIDs;
+
+  typedef DenseMap<const Instruction*, unsigned> InstructionMapType;
+  InstructionMapType InstructionMap;
+  unsigned InstructionCount;
+
+  /// BasicBlocks - This contains all the basic blocks for the currently
+  /// incorporated function.  Their reverse mapping is stored in ValueMap.
+  std::vector<const BasicBlock*> BasicBlocks;
+
+  /// When a function is incorporated, this is the size of the Values list
+  /// before incorporation.
+  unsigned NumModuleValues;
+
+  /// When a function is incorporated, this is the size of the Metadatas list
+  /// before incorporation.
+  unsigned NumModuleMDs;
+
+  unsigned FirstFuncConstantID;
+  unsigned FirstInstID;
+
+  ValueEnumerator35(const ValueEnumerator35 &) = delete;
+  void operator=(const ValueEnumerator35 &) = delete;
+public:
+  ValueEnumerator35(const Module &M);
+
+  void dump() const;
+  void print(raw_ostream &OS, const ValueMapType &Map, const char *Name) const;
+  void print(raw_ostream &OS, const MetadataMapType &Map,
+             const char *Name) const;
+
+  unsigned getValueID(const Value *V) const;
+  unsigned getMetadataID(const Metadata *MD) const;
+  unsigned getMetadataOrNullID(const Metadata *MD) const {
+    return MetadataMap.lookup(MD);
+  }
+  unsigned numMDs() const { return MDs.size(); }
+
+  bool hasMDString() const { return HasMDString; }
+  bool hasDILocation() const { return HasDILocation; }
+  bool hasGenericDINode() const { return HasGenericDINode; }
+
+  unsigned getTypeID(Type *T) const {
+    TypeMapType::const_iterator I = TypeMap.find(T);
+    assert(I != TypeMap.end() && "Type not in ValueEnumerator35!");
+    return I->second-1;
+  }
+
+  unsigned getInstructionID(const Instruction *I) const;
+  void setInstructionID(const Instruction *I);
+
+  unsigned getAttributeID(AttributeSet PAL) const {
+    if (PAL.isEmpty()) return 0;  // Null maps to zero.
+    AttributeMapType::const_iterator I = AttributeMap.find(PAL);
+    assert(I != AttributeMap.end() && "Attribute not in ValueEnumerator35!");
+    return I->second;
+  }
+
+  unsigned getAttributeGroupID(AttributeSet PAL) const {
+    if (PAL.isEmpty()) return 0;  // Null maps to zero.
+    AttributeGroupMapType::const_iterator I = AttributeGroupMap.find(PAL);
+    assert(I != AttributeGroupMap.end() && "Attribute not in ValueEnumerator35!");
+    return I->second;
+  }
+
+  /// getFunctionConstantRange - Return the range of values that corresponds to
+  /// function-local constants.
+  void getFunctionConstantRange(unsigned &Start, unsigned &End) const {
+    Start = FirstFuncConstantID;
+    End = FirstInstID;
+  }
+
+  const ValueList &getValues() const { return Values; }
+  const std::vector<const Metadata *> &getMDs() const { return MDs; }
+  const SmallVectorImpl<const LocalAsMetadata *> &getFunctionLocalMDs() const {
+    return FunctionLocalMDs;
+  }
+  const TypeList &getTypes() const { return Types; }
+  const std::vector<const BasicBlock*> &getBasicBlocks() const {
+    return BasicBlocks;
+  }
+  const std::vector<AttributeSet> &getAttributes() const {
+    return Attribute;
+  }
+  const std::vector<AttributeSet> &getAttributeGroups() const {
+    return AttributeGroups;
+  }
+
+  const ComdatSetType &getComdats() const { return Comdats; }
+  unsigned getComdatID(const Comdat *C) const;
+
+  /// getGlobalBasicBlockID - This returns the function-specific ID for the
+  /// specified basic block.  This is relatively expensive information, so it
+  /// should only be used by rare constructs such as address-of-label.
+  unsigned getGlobalBasicBlockID(const BasicBlock *BB) const;
+
+  /// incorporateFunction/purgeFunction - If you'd like to deal with a function,
+  /// use these two methods to get its data into the ValueEnumerator35!
+  ///
+  void incorporateFunction(const Function &F);
+  void purgeFunction();
+  uint64_t computeBitsRequiredForTypeIndicies() const;
+
+private:
+  void OptimizeConstants(unsigned CstStart, unsigned CstEnd);
+
+  void EnumerateMDNodeOperands(const MDNode *N);
+  void EnumerateMetadata(const Metadata *MD);
+  void EnumerateFunctionLocalMetadata(const LocalAsMetadata *Local);
+  void EnumerateNamedMDNode(const NamedMDNode *NMD);
+  void EnumerateValue(const Value *V);
+  void EnumerateType(Type *T);
+  void EnumerateOperandType(const Value *V);
+  void EnumerateAttributes(AttributeSet PAL);
+
+  void EnumerateValueSymbolTable(const ValueSymbolTable &ST);
+  void EnumerateNamedMetadata(const Module &M);
+};
+
+} // End llvm namespace
+
+#endif
diff --git a/lib/CMakeLists.txt b/lib/CMakeLists.txt
index 9449421..e87da39 100644
--- a/lib/CMakeLists.txt
+++ b/lib/CMakeLists.txt
@@ -21,3 +21,5 @@ add_subdirectory(ProfileData)
 add_subdirectory(Fuzzer)
 add_subdirectory(Passes)
 add_subdirectory(LibDriver)
+add_subdirectory(SPIRV)
+add_subdirectory(SPIRVerifier)
diff --git a/lib/IR/AsmWriter.cpp b/lib/IR/AsmWriter.cpp
index 828767e..ebc7ee1 100644
--- a/lib/IR/AsmWriter.cpp
+++ b/lib/IR/AsmWriter.cpp
@@ -20,6 +20,7 @@
 #include "llvm/ADT/SetVector.h"
 #include "llvm/ADT/SmallString.h"
 #include "llvm/ADT/StringExtras.h"
+#include "llvm/ADT/Triple.h"
 #include "llvm/IR/AssemblyAnnotationWriter.h"
 #include "llvm/IR/CFG.h"
 #include "llvm/IR/CallingConv.h"
@@ -323,8 +324,10 @@ static void PrintCallingConv(unsigned cc, raw_ostream &Out) {
   case CallingConv::PTX_Device:    Out << "ptx_device"; break;
   case CallingConv::X86_64_SysV:   Out << "x86_64_sysvcc"; break;
   case CallingConv::X86_64_Win64:  Out << "x86_64_win64cc"; break;
-  case CallingConv::SPIR_FUNC:     Out << "spir_func"; break;
-  case CallingConv::SPIR_KERNEL:   Out << "spir_kernel"; break;
+  case CallingConv::FLOOR_FUNC:    Out << "floor_func"; break;
+  case CallingConv::FLOOR_VERTEX:  Out << "floor_vertex"; break;
+  case CallingConv::FLOOR_FRAGMENT:Out << "floor_fragment"; break;
+  case CallingConv::FLOOR_KERNEL:  Out << "floor_kernel"; break;
   case CallingConv::Swift:         Out << "swiftcc"; break;
   case CallingConv::X86_INTR:      Out << "x86_intrcc"; break;
   case CallingConv::HHVM:          Out << "hhvmcc"; break;
@@ -2441,13 +2444,23 @@ void AssemblyWriter::printGlobal(const GlobalVariable *GV) {
   PrintVisibility(GV->getVisibility(), Out);
   PrintDLLStorageClass(GV->getDLLStorageClass(), Out);
   PrintThreadLocalModel(GV->getThreadLocalMode(), Out);
+
+  // metal/air requires unnamed_addr to come after addrspace
+  // -> only add it here for anyone else
+  const bool is_air64 = (llvm::Triple(TheModule->getTargetTriple()).getArch() == Triple::air64);
   StringRef UA = getUnnamedAddrEncoding(GV->getUnnamedAddr());
-  if (!UA.empty())
+  if (!UA.empty() && !is_air64)
       Out << UA << ' ';
 
   if (unsigned AddressSpace = GV->getType()->getAddressSpace())
     Out << "addrspace(" << AddressSpace << ") ";
+
+  // insert after the addrspace for metal/air
+  if (!UA.empty() && is_air64)
+      Out << UA << ' ';
+
   if (GV->isExternallyInitialized()) Out << "externally_initialized ";
+
   Out << (GV->isConstant() ? "constant " : "global ");
   TypePrinter.print(GV->getValueType(), Out);
 
diff --git a/lib/IR/AutoUpgrade.cpp b/lib/IR/AutoUpgrade.cpp
index 883cf29..b2f73dc 100644
--- a/lib/IR/AutoUpgrade.cpp
+++ b/lib/IR/AutoUpgrade.cpp
@@ -1464,7 +1464,8 @@ Value *llvm::UpgradeBitCastExpr(unsigned Opc, Constant *C, Type *DestTy) {
 /// info. Return true if module is modified.
 bool llvm::UpgradeDebugInfo(Module &M) {
   unsigned Version = getDebugMetadataVersionFromModule(M);
-  if (Version == DEBUG_METADATA_VERSION)
+  if (Version == DEBUG_METADATA_VERSION ||
+      Version == IOS_METAL_DEBUG_METADATA_VERSION)
     return false;
 
   bool RetCode = StripDebugInfo(M);
diff --git a/lib/IR/BasicBlock.cpp b/lib/IR/BasicBlock.cpp
index 4640b4f..b5f9a0d 100644
--- a/lib/IR/BasicBlock.cpp
+++ b/lib/IR/BasicBlock.cpp
@@ -224,7 +224,7 @@ void BasicBlock::dropAllReferences() {
 /// If this basic block has a single predecessor block,
 /// return the block, otherwise return a null pointer.
 BasicBlock *BasicBlock::getSinglePredecessor() {
-  pred_iterator PI = pred_begin(this), E = pred_end(this);
+  auto PI = ::pred_begin(this), E = ::pred_end(this);
   if (PI == E) return nullptr;         // No preds.
   BasicBlock *ThePred = *PI;
   ++PI;
@@ -237,7 +237,7 @@ BasicBlock *BasicBlock::getSinglePredecessor() {
 /// multiple edges from the unique predecessor to this block (for example
 /// a switch statement with multiple cases having the same destination).
 BasicBlock *BasicBlock::getUniquePredecessor() {
-  pred_iterator PI = pred_begin(this), E = pred_end(this);
+  auto PI = ::pred_begin(this), E = ::pred_end(this);
   if (PI == E) return nullptr; // No preds.
   BasicBlock *PredBB = *PI;
   ++PI;
@@ -251,7 +251,7 @@ BasicBlock *BasicBlock::getUniquePredecessor() {
 }
 
 BasicBlock *BasicBlock::getSingleSuccessor() {
-  succ_iterator SI = succ_begin(this), E = succ_end(this);
+  auto SI = ::succ_begin(this), E = ::succ_end(this);
   if (SI == E) return nullptr; // no successors
   BasicBlock *TheSucc = *SI;
   ++SI;
@@ -259,7 +259,7 @@ BasicBlock *BasicBlock::getSingleSuccessor() {
 }
 
 BasicBlock *BasicBlock::getUniqueSuccessor() {
-  succ_iterator SI = succ_begin(this), E = succ_end(this);
+  auto SI = ::succ_begin(this), E = ::succ_end(this);
   if (SI == E) return nullptr; // No successors
   BasicBlock *SuccBB = *SI;
   ++SI;
@@ -281,7 +281,7 @@ BasicBlock *BasicBlock::getUniqueSuccessor() {
 void BasicBlock::removePredecessor(BasicBlock *Pred,
                                    bool DontDeleteUselessPHIs) {
   assert((hasNUsesOrMore(16)||// Reduce cost of this assertion for complex CFGs.
-          find(pred_begin(this), pred_end(this), Pred) != pred_end(this)) &&
+          find(::pred_begin(this), ::pred_end(this), Pred) != ::pred_end(this)) &&
          "removePredecessor: BB is not a predecessor!");
 
   if (InstList.empty()) return;
@@ -394,7 +394,7 @@ BasicBlock *BasicBlock::splitBasicBlock(iterator I, const Twine &BBName) {
   // successors.  If there were PHI nodes in the successors, then they need to
   // know that incoming branches will be from New, not from Old.
   //
-  for (succ_iterator I = succ_begin(New), E = succ_end(New); I != E; ++I) {
+  for (succ_iterator I = ::succ_begin(New), E = ::succ_end(New); I != E; ++I) {
     // Loop over any phi nodes in the basic block, updating the BB field of
     // incoming values...
     BasicBlock *Successor = *I;
diff --git a/lib/IR/Constants.cpp b/lib/IR/Constants.cpp
index d8d55b4..43f215e 100644
--- a/lib/IR/Constants.cpp
+++ b/lib/IR/Constants.cpp
@@ -1459,7 +1459,8 @@ Constant *ConstantExpr::getCast(unsigned oc, Constant *C, Type *Ty,
   Instruction::CastOps opc = Instruction::CastOps(oc);
   assert(Instruction::isCast(opc) && "opcode out of range");
   assert(C && Ty && "Null arguments to getCast");
-  assert(CastInst::castIsValid(opc, C, Ty) && "Invalid constantexpr cast!");
+  // TODO: fix this!
+  //assert(CastInst::castIsValid(opc, C, Ty) && "Invalid constantexpr cast!");
 
   switch (opc) {
   default:
diff --git a/lib/IR/DataLayout.cpp b/lib/IR/DataLayout.cpp
index d7ed730..1f45bfd 100644
--- a/lib/IR/DataLayout.cpp
+++ b/lib/IR/DataLayout.cpp
@@ -71,6 +71,19 @@ StructLayout::StructLayout(StructType *ST, const DataLayout &DL) {
     IsPadded = true;
     StructSize = alignTo(StructSize, StructAlignment);
   }
+
+  // fix up graphics return types (densely pack vector types)
+  if (ST->isGraphicsReturnType()) {
+    uint64_t offset_fix = 0;
+    for (uint32_t i = 0; i < NumElements; ++i) {
+      MemberOffsets[i] -= offset_fix;
+
+      const auto type = ST->getElementType(i);
+      if (type->isVectorTy()) {
+        offset_fix += DL.getABITypeAlignment(type) - DL.getTypeStoreSize(type);
+      }
+    }
+  }
 }
 
 
diff --git a/lib/IR/Instructions.cpp b/lib/IR/Instructions.cpp
index 5355f1a..90ca87e 100644
--- a/lib/IR/Instructions.cpp
+++ b/lib/IR/Instructions.cpp
@@ -257,11 +257,13 @@ void CallInst::init(FunctionType *FTy, Value *Func, ArrayRef<Value *> Args,
           (FTy->isVarArg() && Args.size() > FTy->getNumParams())) &&
          "Calling a function with bad signature!");
 
+#if 0 // TODO: disabled for now, need to ignore address space mismatches
   for (unsigned i = 0; i != Args.size(); ++i)
     assert((i >= FTy->getNumParams() || 
             FTy->getParamType(i) == Args[i]->getType()) &&
            "Calling a function with a bad signature!");
 #endif
+#endif
 
   std::copy(Args.begin(), Args.end(), op_begin());
 
diff --git a/lib/IR/Metadata.cpp b/lib/IR/Metadata.cpp
index ad95bff..7b24d49 100644
--- a/lib/IR/Metadata.cpp
+++ b/lib/IR/Metadata.cpp
@@ -1382,6 +1382,11 @@ void GlobalObject::getAllMetadata(
 void GlobalObject::clearMetadata() {
   if (!hasMetadata())
     return;
+  if (auto F = dyn_cast<Function>(this)) {
+    if (F->getSubprogram()) {
+      F->getSubprogram()->associated_function = nullptr;
+    }
+  }
   getContext().pImpl->GlobalObjectMetadata.erase(this);
   setHasMetadataHashEntry(false);
 }
@@ -1439,6 +1444,7 @@ void GlobalObject::addTypeMetadata(unsigned Offset, Metadata *TypeID) {
 
 void Function::setSubprogram(DISubprogram *SP) {
   setMetadata(LLVMContext::MD_dbg, SP);
+  if(SP) SP->associated_function = this;
 }
 
 DISubprogram *Function::getSubprogram() const {
diff --git a/lib/IR/Verifier.cpp b/lib/IR/Verifier.cpp
index 189450d..c23675b 100644
--- a/lib/IR/Verifier.cpp
+++ b/lib/IR/Verifier.cpp
@@ -2566,10 +2566,17 @@ void Verifier::verifyCallSite(CallSite CS) {
            "Incorrect number of arguments passed to called function!", I);
 
   // Verify that all arguments to the call match the function type.
-  for (unsigned i = 0, e = FTy->getNumParams(); i != e; ++i)
-    Assert(CS.getArgument(i)->getType() == FTy->getParamType(i),
+  // Note that address space mismatches will be fixed later.
+  for (unsigned i = 0, e = FTy->getNumParams(); i != e; ++i) {
+    Assert(CS.getArgument(i)->getType() == FTy->getParamType(i) ||
+           (CS.getArgument(i)->getType()->isPointerTy() &&
+            FTy->getParamType(i)->isPointerTy() &&
+            PointerType::get(cast<PointerType>(CS.getArgument(i)->getType())->getElementType(),
+                             FTy->getParamType(i)->getPointerAddressSpace()) ==
+            FTy->getParamType(i)),
            "Call parameter type does not match function signature!",
            CS.getArgument(i), FTy->getParamType(i), I);
+  }
 
   AttributeSet Attrs = CS.getAttributes();
 
diff --git a/lib/LLVMBuild.txt b/lib/LLVMBuild.txt
index 50bf690..8091ca1 100644
--- a/lib/LLVMBuild.txt
+++ b/lib/LLVMBuild.txt
@@ -35,6 +35,8 @@ subdirectories =
  Option
  Passes
  ProfileData
+ SPIRV
+ SPIRVerifier
  Support
  TableGen
  Target
diff --git a/lib/SPIRV/CMakeLists.txt b/lib/SPIRV/CMakeLists.txt
new file mode 100644
index 0000000..50b991d
--- /dev/null
+++ b/lib/SPIRV/CMakeLists.txt
@@ -0,0 +1,44 @@
+include_directories( ${CMAKE_CURRENT_SOURCE_DIR}/libSPIRV
+  ${CMAKE_CURRENT_SOURCE_DIR}/Mangler
+  ${CMAKE_CURRENT_SOURCE_DIR}/..)
+
+option(SPIRV_USE_LLVM_API "Enable usage of LLVM API for libSPIRV." ON)
+if ( SPIRV_USE_LLVM_API )
+  add_definitions(-D_SPIRV_LLVM_API)
+  # silence numerous warnings
+  set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -Wno-gnu-zero-variadic-macro-arguments -Wno-inconsistent-missing-override -Wno-c99-extensions")
+endif()
+
+add_llvm_library(LLVMSPIRVLib
+  libSPIRV/SPIRVBasicBlock.cpp
+  libSPIRV/SPIRVDebug.cpp
+  libSPIRV/SPIRVDecorate.cpp
+  libSPIRV/SPIRVEntry.cpp
+  libSPIRV/SPIRVFunction.cpp
+  libSPIRV/SPIRVInstruction.cpp
+  libSPIRV/SPIRVModule.cpp
+  libSPIRV/SPIRVStream.cpp
+  libSPIRV/SPIRVType.cpp
+  libSPIRV/SPIRVValue.cpp
+  Mangler/FunctionDescriptor.cpp
+  Mangler/Mangler.cpp
+  Mangler/ManglingUtils.cpp
+  Mangler/ParameterType.cpp
+  OCL20To12.cpp
+  OCL20ToSPIRV.cpp
+  OCL21ToSPIRV.cpp
+  OCLTypeToSPIRV.cpp
+  OCLUtil.cpp
+  SPIRVLowerBool.cpp
+  SPIRVLowerConstExpr.cpp
+  SPIRVLowerOCLBlocks.cpp
+  SPIRVReader.cpp
+  SPIRVRegularizeLLVM.cpp
+  SPIRVToOCL20.cpp
+  SPIRVUtil.cpp
+  SPIRVWriter.cpp
+  SPIRVWriterPass.cpp
+  TransOCLMD.cpp
+  )
+
+add_dependencies(LLVMSPIRVLib intrinsics_gen)
diff --git a/lib/SPIRV/LLVMBuild.txt b/lib/SPIRV/LLVMBuild.txt
new file mode 100644
index 0000000..539b617
--- /dev/null
+++ b/lib/SPIRV/LLVMBuild.txt
@@ -0,0 +1,23 @@
+;===- ./lib/Target/SPIRV/Common/LLVMBuild.txt ------------------*- Conf -*--===;
+;
+;                     The LLVM Compiler Infrastructure
+;
+; This file is distributed under the University of Illinois Open Source
+; License. See LICENSE.TXT for details.
+;
+;===------------------------------------------------------------------------===;
+;
+; This is an LLVMBuild description file for the components in this subdirectory.
+;
+; For more information on the LLVMBuild system, please see:
+;
+;   http://llvm.org/docs/LLVMBuild.html
+;
+;===------------------------------------------------------------------------===;
+
+[component_0]
+type = Library
+name = SPIRVLib
+parent = Libraries
+required_libraries = Core Support Analysis IPO
+
diff --git a/lib/SPIRV/Makefile b/lib/SPIRV/Makefile
new file mode 100644
index 0000000..4bd2edd
--- /dev/null
+++ b/lib/SPIRV/Makefile
@@ -0,0 +1,49 @@
+##===- lib/SPIRV/Makefile ----------------------------------*- Makefile -*-===##
+#
+#                     The LLVM Compiler Infrastructure
+#
+# This file is distributed under the University of Illinois Open Source
+# License. See LICENSE.TXT for details.
+#
+##===----------------------------------------------------------------------===##
+
+LEVEL = ../..
+LIBRARYNAME = LLVMSPIRVLib
+BUILD_ARCHIVE := 1
+
+CXX.Flags += -Wno-gnu-zero-variadic-macro-arguments
+CXX.Flags += -I$(LLVM_SRC_ROOT)/lib/SPIRV/libSPIRV
+CXX.Flags += -I$(LLVM_SRC_ROOT)/lib/SPIRV/Mangler
+CXX.Flags += -D_SPIRV_LLVM_API
+
+SOURCES := libSPIRV/SPIRVBasicBlock.cpp \
+  libSPIRV/SPIRVDebug.cpp \
+  libSPIRV/SPIRVDecorate.cpp \
+  libSPIRV/SPIRVEntry.cpp \
+  libSPIRV/SPIRVFunction.cpp \
+  libSPIRV/SPIRVInstruction.cpp \
+  libSPIRV/SPIRVModule.cpp \
+  libSPIRV/SPIRVStream.cpp \
+  libSPIRV/SPIRVType.cpp \
+  libSPIRV/SPIRVValue.cpp \
+  Mangler/FunctionDescriptor.cpp \
+  Mangler/Mangler.cpp \
+  Mangler/ManglingUtils.cpp \
+  Mangler/ParameterType.cpp \
+  OCL20To12.cpp \
+  OCL20ToSPIRV.cpp \
+  OCL21ToSPIRV.cpp \
+  OCLTypeToSPIRV.cpp \
+  OCLUtil.cpp \
+  SPIRVLowerBool.cpp \
+  SPIRVLowerConstExpr.cpp \
+  SPIRVLowerOCLBlocks.cpp \
+  SPIRVReader.cpp \
+  SPIRVRegularizeLLVM.cpp \
+  SPIRVToOCL20.cpp \
+  SPIRVUtil.cpp \
+  SPIRVWriter.cpp \
+  SPIRVWriterPass.cpp \
+  TransOCLMD.cpp
+
+include $(LEVEL)/Makefile.common
diff --git a/lib/SPIRV/Mangler/FunctionDescriptor.cpp b/lib/SPIRV/Mangler/FunctionDescriptor.cpp
new file mode 100644
index 0000000..24d1b25
--- /dev/null
+++ b/lib/SPIRV/Mangler/FunctionDescriptor.cpp
@@ -0,0 +1,95 @@
+//===---------------------- FunctionDescriptor.cpp -----------------------===//
+//
+//                              SPIR Tools
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===---------------------------------------------------------------------===//
+/*
+ * Contributed by: Intel Corporation.
+ */
+
+#include "FunctionDescriptor.h"
+#include "ParameterType.h"
+#include <sstream>
+
+namespace SPIR {
+
+std::string FunctionDescriptor::nullString() {
+  return std::string("<invalid>");
+}
+
+std::string FunctionDescriptor::toString() const {
+  std::stringstream stream;
+  if (isNull()) {
+    return FunctionDescriptor::nullString();
+  }
+  stream << name << "(";
+  size_t paramCount = parameters.size();
+  if (paramCount > 0) {
+    for (size_t i = 0; i < paramCount - 1; ++i)
+      stream << parameters[i]->toString() << ", ";
+    stream << parameters[paramCount - 1]->toString();
+  }
+  stream << ")";
+  return stream.str();
+}
+
+static bool equal(const TypeVector &l, const TypeVector &r) {
+  if (&l == &r)
+    return true;
+  if (l.size() != r.size())
+    return false;
+  TypeVector::const_iterator itl = l.begin(), itr = r.begin(), endl = l.end();
+  while (itl != endl) {
+    if (!(*itl)->equals(*itr))
+      return false;
+    ++itl;
+    ++itr;
+  }
+  return true;
+}
+
+//
+// FunctionDescriptor
+//
+
+bool FunctionDescriptor::operator==(const FunctionDescriptor &that) const {
+  if (this == &that)
+    return true;
+  if (name != that.name)
+    return false;
+  return equal(parameters, that.parameters);
+}
+
+bool FunctionDescriptor::operator<(const FunctionDescriptor &that) const {
+  int strCmp = name.compare(that.name);
+  if (strCmp)
+    return (strCmp < 0);
+  size_t len = parameters.size(), thatLen = that.parameters.size();
+  if (len != thatLen)
+    return len < thatLen;
+  TypeVector::const_iterator it = parameters.begin(), e = parameters.end(),
+                             thatit = that.parameters.begin();
+  while (it != e) {
+    int cmp = (*it)->toString().compare((*thatit)->toString());
+    if (cmp)
+      return (cmp < 0);
+    ++thatit;
+    ++it;
+  }
+  return false;
+}
+
+bool FunctionDescriptor::isNull() const {
+  return (name.empty() && parameters.empty());
+}
+
+FunctionDescriptor FunctionDescriptor::null() {
+  FunctionDescriptor fd;
+  fd.name = "";
+  return fd;
+}
+
+} // End SPIR namespace
diff --git a/lib/SPIRV/Mangler/FunctionDescriptor.h b/lib/SPIRV/Mangler/FunctionDescriptor.h
new file mode 100644
index 0000000..d3acff9
--- /dev/null
+++ b/lib/SPIRV/Mangler/FunctionDescriptor.h
@@ -0,0 +1,55 @@
+//===----------------------- FunctionDescriptor.h ------------------------===//
+//
+//                              SPIR Tools
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===---------------------------------------------------------------------===//
+/*
+ * Contributed by: Intel Corporation.
+ */
+
+#ifndef __FUNCTION_DESCRIPTOR_H__
+#define __FUNCTION_DESCRIPTOR_H__
+
+#include "ParameterType.h"
+#include "Refcount.h"
+#include <string>
+#include <vector>
+
+namespace SPIR {
+typedef std::vector<RefCount<ParamType>> TypeVector;
+
+struct FunctionDescriptor {
+  /// @brief Returns a human readable string representation of the function's
+  ///        prototype.
+  /// @returns std::string representing the function's prototype.
+  std::string toString() const;
+
+  /// The name of the function (stripped).
+  std::string name;
+  /// Parameter list of the function.
+  TypeVector parameters;
+
+  bool operator==(const FunctionDescriptor &) const;
+
+  /// @brief Enables function descriptors to serve as keys in stl maps.
+  bool operator<(const FunctionDescriptor &) const;
+  bool isNull() const;
+
+  /// @brief Create a singular value, that represents a 'null'
+  /// FunctionDescriptor.
+  static FunctionDescriptor null();
+
+  static std::string nullString();
+};
+
+template <typename T>
+std::ostream &operator<<(T &o, const SPIR::FunctionDescriptor &fd) {
+  o << fd.toString();
+  return o;
+}
+} // End SPIR namespace
+
+#endif //__FUNCTION_DESCRIPTOR_H__
diff --git a/lib/SPIRV/Mangler/Mangler.cpp b/lib/SPIRV/Mangler/Mangler.cpp
new file mode 100644
index 0000000..505fd30
--- /dev/null
+++ b/lib/SPIRV/Mangler/Mangler.cpp
@@ -0,0 +1,201 @@
+//===--------------------------- Mangler.cpp -----------------------------===//
+//
+//                              SPIR Tools
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===---------------------------------------------------------------------===//
+/*
+ * Contributed by: Intel Corporation.
+ */
+
+#include "FunctionDescriptor.h"
+#include "ManglingUtils.h"
+#include "NameMangleAPI.h"
+#include "ParameterType.h"
+#include "SPIRVInternal.h"
+#include <algorithm>
+#include <string>
+#include <sstream>
+#include <map>
+
+// According to IA64 name mangling spec,
+// builtin vector types should not be substituted
+// This is a workaround till this gets fixed in CLang
+#define ENABLE_MANGLER_VECTOR_SUBSTITUTION 1
+
+namespace SPIR {
+
+class MangleVisitor : public TypeVisitor {
+public:
+  MangleVisitor(SPIRversion ver, std::stringstream &s)
+      : TypeVisitor(ver), m_stream(s), seqId(0) {}
+
+  //
+  // mangle substitution methods
+  //
+  void mangleSequenceID(unsigned SeqID) {
+    if (SeqID == 1)
+      m_stream << '0';
+    else if (SeqID > 1) {
+      std::string bstr;
+      std::string charset = "0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ";
+      SeqID--;
+      bstr.reserve(7);
+      for (; SeqID != 0; SeqID /= 36)
+        bstr += charset.substr(SeqID % 36, 1);
+      std::reverse(bstr.begin(), bstr.end());
+      m_stream << bstr;
+    }
+    m_stream << '_';
+  }
+
+  bool mangleSubstitution(const ParamType *type, std::string typeStr) {
+    size_t fpos;
+    std::stringstream thistypeStr;
+    thistypeStr << typeStr;
+    if ((fpos = m_stream.str().find(typeStr)) != std::string::npos) {
+      const char *nType;
+      if (const PointerType *p = SPIR::dyn_cast<PointerType>(type)) {
+        if ((nType =
+                 mangledPrimitiveStringfromName(p->getPointee()->toString())))
+          thistypeStr << nType;
+      }
+#if defined(ENABLE_MANGLER_VECTOR_SUBSTITUTION)
+      else if (const VectorType *pVec = SPIR::dyn_cast<VectorType>(type)) {
+        if ((nType = mangledPrimitiveStringfromName(
+                 pVec->getScalarType()->toString())))
+          thistypeStr << nType;
+      }
+#endif
+      std::map<std::string, unsigned>::iterator I =
+          substitutions.find(thistypeStr.str());
+      if (I == substitutions.end())
+        return false;
+
+      unsigned SeqID = I->second;
+      m_stream << 'S';
+      mangleSequenceID(SeqID);
+      return true;
+    }
+    return false;
+  }
+
+  //
+  // Visit methods
+  //
+  MangleError visit(const PrimitiveType *t) {
+    m_stream << mangledPrimitiveString(t->getPrimitive());
+    return MANGLE_SUCCESS;
+  }
+
+  MangleError visit(const PointerType *p) {
+    size_t fpos = m_stream.str().size();
+    std::string qualStr;
+    MangleError me = MANGLE_SUCCESS;
+    for (unsigned int i = ATTR_QUALIFIER_FIRST; i <= ATTR_QUALIFIER_LAST; i++) {
+      TypeAttributeEnum qualifier = (TypeAttributeEnum)i;
+      if (p->hasQualifier(qualifier)) {
+        qualStr += getMangledAttribute(qualifier);
+      }
+    }
+    qualStr += getMangledAttribute((p->getAddressSpace()));
+    if (!mangleSubstitution(p, "P" + qualStr)) {
+      // A pointee type is substituted when it is a user type, a vector type
+      // (but see a comment in the beginning of this file), a pointer type,
+      // or a primitive type with qualifiers (addr. space and/or CV qualifiers).
+      // So, stream "P", type qualifiers
+      m_stream << "P" << qualStr;
+      // and the pointee type itself.
+      me = p->getPointee()->accept(this);
+      // The type qualifiers plus a pointee type is a substitutable entity
+      if (qualStr.length() > 0)
+        substitutions[m_stream.str().substr(fpos + 1)] = seqId++;
+      // The complete pointer type is substitutable as well
+      substitutions[m_stream.str().substr(fpos)] = seqId++;
+    }
+    return me;
+  }
+
+  MangleError visit(const VectorType *v) {
+    size_t index = m_stream.str().size();
+    std::stringstream typeStr;
+    typeStr << "Dv" << v->getLength() << "_";
+    MangleError me = MANGLE_SUCCESS;
+#if defined(ENABLE_MANGLER_VECTOR_SUBSTITUTION)
+    if (!mangleSubstitution(v, typeStr.str()))
+#endif
+    {
+      m_stream << typeStr.str();
+      me = v->getScalarType()->accept(this);
+      substitutions[m_stream.str().substr(index)] = seqId++;
+    }
+    return me;
+  }
+
+  MangleError visit(const AtomicType *p) {
+    m_stream << "U"
+             << "7_Atomic";
+    return p->getBaseType()->accept(this);
+  }
+
+  MangleError visit(const BlockType *p) {
+    m_stream << "U"
+             << "13block_pointerFv";
+    if (p->getNumOfParams() == 0)
+      m_stream << "v";
+    else
+      for (unsigned int i = 0; i < p->getNumOfParams(); ++i) {
+        MangleError err = p->getParam(i)->accept(this);
+        if (err != MANGLE_SUCCESS) {
+          return err;
+        }
+      }
+    m_stream << "E";
+    return MANGLE_SUCCESS;
+  }
+
+  MangleError visit(const UserDefinedType *pTy) {
+    std::string name = pTy->toString();
+    m_stream << name.size() << name;
+    return MANGLE_SUCCESS;
+  }
+
+private:
+  // Holds the mangled string representing the prototype of the function.
+  std::stringstream &m_stream;
+  unsigned seqId;
+  std::map<std::string, unsigned> substitutions;
+};
+
+//
+// NameMangler
+//
+NameMangler::NameMangler(SPIRversion version) : m_spir_version(version){};
+
+MangleError NameMangler::mangle(const FunctionDescriptor &fd,
+                                std::string &mangledName) {
+  if (fd.isNull()) {
+    mangledName.assign(FunctionDescriptor::nullString());
+    return MANGLE_NULL_FUNC_DESCRIPTOR;
+  }
+  std::stringstream ret;
+  ret << "_Z" << fd.name.length() << fd.name;
+  MangleVisitor visitor(m_spir_version, ret);
+  for (unsigned int i = 0; i < fd.parameters.size(); ++i) {
+    MangleError err = fd.parameters[i]->accept(&visitor);
+    if (err == MANGLE_TYPE_NOT_SUPPORTED) {
+      mangledName.assign("Type ");
+      mangledName.append(fd.parameters[i]->toString());
+      mangledName.append(" is not supported in ");
+      std::string ver = getSPIRVersionAsString(m_spir_version);
+      mangledName.append(ver);
+      return err;
+    }
+  }
+  mangledName.assign(ret.str());
+  return MANGLE_SUCCESS;
+}
+
+} // End SPIR namespace
diff --git a/lib/SPIRV/Mangler/ManglingUtils.cpp b/lib/SPIRV/Mangler/ManglingUtils.cpp
new file mode 100644
index 0000000..ab84e4c
--- /dev/null
+++ b/lib/SPIRV/Mangler/ManglingUtils.cpp
@@ -0,0 +1,197 @@
+//===------------------------- ManglingUtils.cpp -------------------------===//
+//
+//                              SPIR Tools
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===---------------------------------------------------------------------===//
+/*
+ * Contributed by: Intel Corporation.
+ */
+
+#include "ManglingUtils.h"
+
+namespace SPIR {
+
+// String represenration for the primitive types.
+static const char *PrimitiveNames[PRIMITIVE_NUM] = {
+    "bool",
+    "uchar",
+    "char",
+    "ushort",
+    "short",
+    "uint",
+    "int",
+    "ulong",
+    "long",
+    "half",
+    "float",
+    "double",
+    "void",
+    "...",
+    "image1d_t",
+    "image1d_array_t",
+    "image1d_buffer_t",
+    "image2d_t",
+    "image2d_array_t",
+    "image3d_t",
+    "image2d_msaa_t",
+    "image2d_array_msaa_t",
+    "image2d_msaa_depth_t",
+    "image2d_array_msaa_depth_t",
+    "image2d_depth_t",
+    "image2d_array_depth_t",
+    "imagecube_t",
+    "imagecube_array_t",
+    "imagecube_depth_t",
+    "imagecube_array_depth_t",
+    "event_t",
+    "pipe_t",
+    "reserve_id_t",
+    "queue_t",
+    "ndrange_t",
+    "clk_event_t",
+    "sampler_t",
+    "kernel_enqueue_flags_t",
+    "clk_profiling_info",
+};
+
+const char *mangledTypes[PRIMITIVE_NUM] = {
+    "b",                           // BOOL
+    "h",                           // UCHAR
+    "c",                           // CHAR
+    "t",                           // USHORT
+    "s",                           // SHORT
+    "j",                           // UINT
+    "i",                           // INT
+    "m",                           // ULONG
+    "l",                           // LONG
+    "Dh",                          // HALF
+    "f",                           // FLOAT
+    "d",                           // DOUBLE
+    "v",                           // VOID
+    "z",                           // VarArg
+    "11ocl_image1d",               // PRIMITIVE_IMAGE_1D_T
+    "16ocl_image1darray",          // PRIMITIVE_IMAGE_1D_ARRAY_T
+    "17ocl_image1dbuffer",         // PRIMITIVE_IMAGE_1D_BUFFER_T
+    "11ocl_image2d",               // PRIMITIVE_IMAGE_2D_T
+    "16ocl_image2darray",          // PRIMITIVE_IMAGE_2D_ARRAY_T
+    "11ocl_image3d",               // PRIMITIVE_IMAGE_3D_T
+    "15ocl_image2dmsaa",           // PRIMITIVE_IMAGE_2D_MSAA_T
+    "20ocl_image2darraymsaa",      // PRIMITIVE_IMAGE_2D_ARRAY_MSAA_T
+    "20ocl_image2dmsaadepth",      // PRIMITIVE_IMAGE_2D_MSAA_DEPTH_T
+    "25ocl_image2darraymsaadepth", // PRIMITIVE_IMAGE_2D_ARRAY_MSAA_DEPTH_T
+    "16ocl_image2ddepth",          // PRIMITIVE_IMAGE_2D_DEPTH_T
+    "21ocl_image2darraydepth",     // PRIMITIVE_IMAGE_2D_ARRAY_DEPTH_T
+    "13ocl_imagecube",             // PRIMITIVE_IMAGE_CUBE_T
+    "18ocl_imagecubearray",        // PRIMITIVE_IMAGE_CUBE_ARRAY_T
+    "18ocl_imagecubedepth",        // PRIMITIVE_IMAGE_CUBE_DEPTH_T
+    "23ocl_imagecubearraydepth",   // PRIMITIVE_IMAGE_CUBE_ARRAY_DEPTH_T
+    "9ocl_event",                  // PRIMITIVE_EVENT_T
+    "8ocl_pipe",                   // PRIMITIVE_PIPE_T
+    "13ocl_reserveid",             // PRIMITIVE_RESERVE_ID_T
+    "9ocl_queue",                  // PRIMITIVE_QUEUE_T
+    "9ndrange_t",                  // PRIMITIVE_NDRANGE_T
+    "12ocl_clkevent",              // PRIMITIVE_CLK_EVENT_T
+    "11ocl_sampler",               // PRIMITIVE_SAMPLER_T
+#if defined(SPIRV_SPIR20_MANGLING_REQUIREMENTS)
+    "i", // PRIMITIVE_KERNEL_ENQUEUE_FLAGS_T
+    "i", // PRIMITIVE_CLK_PROFILING_INFO
+#else
+    "22kernel_enqueue_flags_t", // PRIMITIVE_KERNEL_ENQUEUE_FLAGS_T
+    "18clk_profiling_info",     // PRIMITIVE_CLK_PROFILING_INFO
+#endif
+};
+
+const char *readableAttribute[ATTR_NUM] = {
+    "restrict", "volatile",   "const",   "__private",
+    "__global", "__constant", "__local", "__generic",
+};
+
+const char *mangledAttribute[ATTR_NUM] = {
+    "r", "V", "K", "", "U3AS1", "U3AS2", "U3AS3", "U3AS4",
+};
+
+// SPIR supported version - stated version is oldest supported version.
+static const SPIRversion primitiveSupportedVersions[PRIMITIVE_NUM] = {
+    SPIR12, // BOOL
+    SPIR12, // UCHAR
+    SPIR12, // CHAR
+    SPIR12, // USHORT
+    SPIR12, // SHORT
+    SPIR12, // UINT
+    SPIR12, // INT
+    SPIR12, // ULONG
+    SPIR12, // LONG
+    SPIR12, // HALF
+    SPIR12, // FLOAT
+    SPIR12, // DOUBLE
+    SPIR12, // VOID
+    SPIR12, // VarArg
+    SPIR12, // PRIMITIVE_IMAGE_1D_T
+    SPIR12, // PRIMITIVE_IMAGE_1D_ARRAY_T
+    SPIR12, // PRIMITIVE_IMAGE_1D_BUFFER_T
+    SPIR12, // PRIMITIVE_IMAGE_2D_T
+    SPIR12, // PRIMITIVE_IMAGE_2D_ARRAY_T
+    SPIR12, // PRIMITIVE_IMAGE_3D_T
+    SPIR12, // PRIMITIVE_IMAGE_2D_MSAA_T
+    SPIR12, // PRIMITIVE_IMAGE_2D_ARRAY_MSAA_T
+    SPIR12, // PRIMITIVE_IMAGE_2D_MSAA_DEPTH_T
+    SPIR12, // PRIMITIVE_IMAGE_2D_ARRAY_MSAA_DEPTH_T
+    SPIR12, // PRIMITIVE_IMAGE_2D_DEPTH_T
+    SPIR12, // PRIMITIVE_IMAGE_2D_ARRAY_DEPTH_T
+    SPIR20, // PRIMITIVE_IMAGE_CUBE_T
+    SPIR20, // PRIMITIVE_IMAGE_CUBE_ARRAY_T
+    SPIR20, // PRIMITIVE_IMAGE_CUBE_DEPTH_T
+    SPIR20, // PRIMITIVE_IMAGE_CUBE_ARRAY_DEPTH_T
+    SPIR12, // PRIMITIVE_EVENT_T
+    SPIR20, // PRIMITIVE_PIPE_T
+    SPIR20, // PRIMITIVE_RESERVE_ID_T
+    SPIR20, // PRIMITIVE_QUEUE_T
+    SPIR20, // PRIMITIVE_NDRANGE_T
+    SPIR20, // PRIMITIVE_CLK_EVENT_T
+    SPIR12  // PRIMITIVE_SAMPLER_T
+};
+
+const char *mangledPrimitiveString(TypePrimitiveEnum t) {
+  return mangledTypes[t];
+}
+
+const char *readablePrimitiveString(TypePrimitiveEnum t) {
+  return PrimitiveNames[t];
+}
+
+const char *getMangledAttribute(TypeAttributeEnum attribute) {
+  return mangledAttribute[attribute];
+}
+
+const char *getReadableAttribute(TypeAttributeEnum attribute) {
+  return readableAttribute[attribute];
+}
+
+SPIRversion getSupportedVersion(TypePrimitiveEnum t) {
+  return primitiveSupportedVersions[t];
+}
+
+const char *mangledPrimitiveStringfromName(std::string type) {
+  for (size_t i = 0; i < (sizeof(PrimitiveNames) / sizeof(PrimitiveNames[0]));
+       i++)
+    if (type.compare(PrimitiveNames[i]) == 0)
+      return mangledTypes[i];
+  return NULL;
+}
+
+const char *getSPIRVersionAsString(SPIRversion version) {
+  switch (version) {
+  case SPIR12:
+    return "SPIR 1.2";
+  case SPIR20:
+    return "SPIR 2.0";
+  default:
+    assert(false && "Unknown SPIR Version");
+    return "Unknown SPIR Version";
+  }
+}
+
+} // End SPIR namespace
diff --git a/lib/SPIRV/Mangler/ManglingUtils.h b/lib/SPIRV/Mangler/ManglingUtils.h
new file mode 100644
index 0000000..0e89f40
--- /dev/null
+++ b/lib/SPIRV/Mangler/ManglingUtils.h
@@ -0,0 +1,32 @@
+//===------------------------- ManglingUtils.h ---------------------------===//
+//
+//                              SPIR Tools
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===---------------------------------------------------------------------===//
+/*
+ * Contributed by: Intel Corporation.
+ */
+
+#ifndef __MANGLING_UTILS_H__
+#define __MANGLING_UTILS_H__
+
+#include "ParameterType.h"
+
+namespace SPIR {
+
+const char *mangledPrimitiveString(TypePrimitiveEnum primitive);
+const char *readablePrimitiveString(TypePrimitiveEnum primitive);
+
+const char *getMangledAttribute(TypeAttributeEnum attribute);
+const char *getReadableAttribute(TypeAttributeEnum attribute);
+
+SPIRversion getSupportedVersion(TypePrimitiveEnum t);
+const char *getSPIRVersionAsString(SPIRversion version);
+
+const char *mangledPrimitiveStringfromName(std::string type);
+} // End SPIR namespace
+
+#endif //__MANGLING_UTILS_H__
diff --git a/lib/SPIRV/Mangler/NameMangleAPI.h b/lib/SPIRV/Mangler/NameMangleAPI.h
new file mode 100644
index 0000000..9615ceb
--- /dev/null
+++ b/lib/SPIRV/Mangler/NameMangleAPI.h
@@ -0,0 +1,41 @@
+//===------------------------- NameMangleAPI.h ---------------------------===//
+//
+//                              SPIR Tools
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===---------------------------------------------------------------------===//
+/*
+ * Contributed by: Intel Corporation.
+ */
+#ifndef __NAME_MANGLE_API_H__
+#define __NAME_MANGLE_API_H__
+
+#include "FunctionDescriptor.h"
+#include <string>
+
+namespace SPIR {
+struct NameMangler {
+
+  /// @brief Constructor.
+  /// @param SPIRversion spir version to mangle according to.
+  NameMangler(SPIRversion);
+
+  /// @brief Converts the given function descriptor to string that represents
+  ///        the function's prototype.
+  ///        The mangling algorithm is based on Itanium mangling algorithm
+  ///        (http://sourcery.mentor.com/public/cxx-abi/abi.html#mangling), with
+  ///        SPIR extensions.
+  /// @param FunctionDescriptor function to be mangled.
+  /// @param std::string the mangled name if the mangling succeeds,
+  ///        the error otherwise.
+  /// @return MangleError enum representing the status - success or the error.
+  MangleError mangle(const FunctionDescriptor &, std::string &);
+
+private:
+  SPIRversion m_spir_version;
+};
+} // End SPIR namespace
+
+#endif //__NAME_MANGLE_API_H__
diff --git a/lib/SPIRV/Mangler/ParameterType.cpp b/lib/SPIRV/Mangler/ParameterType.cpp
new file mode 100644
index 0000000..6cb2427
--- /dev/null
+++ b/lib/SPIRV/Mangler/ParameterType.cpp
@@ -0,0 +1,236 @@
+//===------------------------ ParameterType.cpp --------------------------===//
+//
+//                              SPIR Tools
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===---------------------------------------------------------------------===//
+/*
+ * Contributed by: Intel Corporation.
+ */
+#include "ParameterType.h"
+#include "ManglingUtils.h"
+#include <assert.h>
+#include <cctype>
+#include <sstream>
+
+namespace SPIR {
+//
+// Primitive Type
+//
+
+PrimitiveType::PrimitiveType(TypePrimitiveEnum primitive)
+    : ParamType(TYPE_ID_PRIMITIVE), m_primitive(primitive) {}
+
+MangleError PrimitiveType::accept(TypeVisitor *visitor) const {
+  if (getSupportedVersion(this->getPrimitive()) >= SPIR20 &&
+      visitor->spirVer < SPIR20) {
+    return MANGLE_TYPE_NOT_SUPPORTED;
+  }
+  return visitor->visit(this);
+}
+
+std::string PrimitiveType::toString() const {
+  assert((m_primitive >= PRIMITIVE_FIRST && m_primitive <= PRIMITIVE_LAST) &&
+         "illegal primitive");
+  std::stringstream myName;
+  myName << readablePrimitiveString(m_primitive);
+  return myName.str();
+}
+
+bool PrimitiveType::equals(const ParamType *type) const {
+  const PrimitiveType *p = SPIR::dyn_cast<PrimitiveType>(type);
+  return p && (m_primitive == p->m_primitive);
+}
+
+//
+// Pointer Type
+//
+
+PointerType::PointerType(const RefParamType type)
+    : ParamType(TYPE_ID_POINTER), m_pType(type) {
+  for (unsigned int i = ATTR_QUALIFIER_FIRST; i <= ATTR_QUALIFIER_LAST; i++) {
+    setQualifier((TypeAttributeEnum)i, false);
+  }
+  m_address_space = ATTR_PRIVATE;
+}
+
+MangleError PointerType::accept(TypeVisitor *visitor) const {
+  return visitor->visit(this);
+}
+
+void PointerType::setAddressSpace(TypeAttributeEnum attr) {
+  if (attr < ATTR_ADDR_SPACE_FIRST || attr > ATTR_ADDR_SPACE_LAST) {
+    return;
+  }
+  m_address_space = attr;
+}
+
+TypeAttributeEnum PointerType::getAddressSpace() const {
+  return m_address_space;
+}
+
+void PointerType::setQualifier(TypeAttributeEnum qual, bool enabled) {
+  if (qual < ATTR_QUALIFIER_FIRST || qual > ATTR_QUALIFIER_LAST) {
+    return;
+  }
+  m_qualifiers[qual - ATTR_QUALIFIER_FIRST] = enabled;
+}
+
+bool PointerType::hasQualifier(TypeAttributeEnum qual) const {
+  if (qual < ATTR_QUALIFIER_FIRST || qual > ATTR_QUALIFIER_LAST) {
+    return false;
+  }
+  return m_qualifiers[qual - ATTR_QUALIFIER_FIRST];
+}
+
+std::string PointerType::toString() const {
+  std::stringstream myName;
+  for (unsigned int i = ATTR_QUALIFIER_FIRST; i <= ATTR_QUALIFIER_LAST; i++) {
+    TypeAttributeEnum qual = (TypeAttributeEnum)i;
+    if (hasQualifier(qual)) {
+      myName << getReadableAttribute(qual) << " ";
+    }
+  }
+  myName << getReadableAttribute(TypeAttributeEnum(m_address_space)) << " ";
+  myName << getPointee()->toString() << " *";
+  return myName.str();
+}
+
+bool PointerType::equals(const ParamType *type) const {
+  const PointerType *p = SPIR::dyn_cast<PointerType>(type);
+  if (!p) {
+    return false;
+  }
+  if (getAddressSpace() != p->getAddressSpace()) {
+    return false;
+  }
+  for (unsigned int i = ATTR_QUALIFIER_FIRST; i <= ATTR_QUALIFIER_LAST; i++) {
+    TypeAttributeEnum qual = (TypeAttributeEnum)i;
+    if (hasQualifier(qual) != p->hasQualifier(qual)) {
+      return false;
+    }
+  }
+  return (*getPointee()).equals(&*(p->getPointee()));
+}
+
+//
+// Vector Type
+//
+
+VectorType::VectorType(const RefParamType type, int len)
+    : ParamType(TYPE_ID_VECTOR), m_pType(type), m_len(len) {}
+
+MangleError VectorType::accept(TypeVisitor *visitor) const {
+  return visitor->visit(this);
+}
+
+std::string VectorType::toString() const {
+  std::stringstream myName;
+  myName << getScalarType()->toString();
+  myName << m_len;
+  return myName.str();
+}
+
+bool VectorType::equals(const ParamType *type) const {
+  const VectorType *pVec = SPIR::dyn_cast<VectorType>(type);
+  return pVec && (m_len == pVec->m_len) &&
+         (*getScalarType()).equals(&*(pVec->getScalarType()));
+}
+
+//
+// Atomic Type
+//
+
+AtomicType::AtomicType(const RefParamType type)
+    : ParamType(TYPE_ID_ATOMIC), m_pType(type) {}
+
+MangleError AtomicType::accept(TypeVisitor *visitor) const {
+  if (visitor->spirVer < SPIR20) {
+    return MANGLE_TYPE_NOT_SUPPORTED;
+  }
+  return visitor->visit(this);
+}
+
+std::string AtomicType::toString() const {
+  std::stringstream myName;
+  myName << "atomic_" << getBaseType()->toString();
+  return myName.str();
+}
+
+bool AtomicType::equals(const ParamType *type) const {
+  const AtomicType *a = dyn_cast<AtomicType>(type);
+  return (a && (*getBaseType()).equals(&*(a->getBaseType())));
+}
+
+//
+// Block Type
+//
+
+BlockType::BlockType() : ParamType(TYPE_ID_BLOCK) {}
+
+MangleError BlockType::accept(TypeVisitor *visitor) const {
+  if (visitor->spirVer < SPIR20) {
+    return MANGLE_TYPE_NOT_SUPPORTED;
+  }
+  return visitor->visit(this);
+}
+
+std::string BlockType::toString() const {
+  std::stringstream myName;
+  myName << "void (";
+  for (unsigned int i = 0; i < getNumOfParams(); ++i) {
+    if (i > 0)
+      myName << ", ";
+    myName << m_params[i]->toString();
+  }
+  myName << ")*";
+  return myName.str();
+}
+
+bool BlockType::equals(const ParamType *type) const {
+  const BlockType *pBlock = dyn_cast<BlockType>(type);
+  if (!pBlock || getNumOfParams() != pBlock->getNumOfParams()) {
+    return false;
+  }
+  for (unsigned int i = 0; i < getNumOfParams(); ++i) {
+    if (!getParam(i)->equals(&*pBlock->getParam(i))) {
+      return false;
+    }
+  }
+  return true;
+}
+
+//
+// User Defined Type
+//
+UserDefinedType::UserDefinedType(const std::string &name)
+    : ParamType(TYPE_ID_STRUCTURE), m_name(name) {}
+
+MangleError UserDefinedType::accept(TypeVisitor *visitor) const {
+  return visitor->visit(this);
+}
+
+std::string UserDefinedType::toString() const {
+  std::stringstream myName;
+  myName << m_name;
+  return myName.str();
+}
+
+bool UserDefinedType::equals(const ParamType *pType) const {
+  const UserDefinedType *pTy = SPIR::dyn_cast<UserDefinedType>(pType);
+  return pTy && (m_name == pTy->m_name);
+}
+
+//
+// Static enums
+//
+const TypeEnum PrimitiveType::enumTy = TYPE_ID_PRIMITIVE;
+const TypeEnum PointerType::enumTy = TYPE_ID_POINTER;
+const TypeEnum VectorType::enumTy = TYPE_ID_VECTOR;
+const TypeEnum AtomicType::enumTy = TYPE_ID_ATOMIC;
+const TypeEnum BlockType::enumTy = TYPE_ID_BLOCK;
+const TypeEnum UserDefinedType::enumTy = TYPE_ID_STRUCTURE;
+
+} // End SPIR namespace
diff --git a/lib/SPIRV/Mangler/ParameterType.h b/lib/SPIRV/Mangler/ParameterType.h
new file mode 100644
index 0000000..cd787c19
--- /dev/null
+++ b/lib/SPIRV/Mangler/ParameterType.h
@@ -0,0 +1,454 @@
+//===------------------------- ParameterType.h ---------------------------===//
+//
+//                              SPIR Tools
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===---------------------------------------------------------------------===//
+/*
+ * Contributed by: Intel Corporation.
+ */
+
+#ifndef __PARAMETER_TYPE_H__
+#define __PARAMETER_TYPE_H__
+
+#include "Refcount.h"
+#include <string>
+#include <vector>
+
+// The Type class hierarchy models the different types in OCL.
+
+namespace SPIR {
+
+// Supported SPIR versions
+enum SPIRversion { SPIR12 = 1, SPIR20 = 2 };
+
+// Error Status values
+enum MangleError {
+  MANGLE_SUCCESS,
+  MANGLE_TYPE_NOT_SUPPORTED,
+  MANGLE_NULL_FUNC_DESCRIPTOR
+};
+
+enum TypePrimitiveEnum {
+  PRIMITIVE_FIRST,
+  PRIMITIVE_BOOL = PRIMITIVE_FIRST,
+  PRIMITIVE_UCHAR,
+  PRIMITIVE_CHAR,
+  PRIMITIVE_USHORT,
+  PRIMITIVE_SHORT,
+  PRIMITIVE_UINT,
+  PRIMITIVE_INT,
+  PRIMITIVE_ULONG,
+  PRIMITIVE_LONG,
+  PRIMITIVE_HALF,
+  PRIMITIVE_FLOAT,
+  PRIMITIVE_DOUBLE,
+  PRIMITIVE_VOID,
+  PRIMITIVE_VAR_ARG,
+  PRIMITIVE_STRUCT_FIRST,
+  PRIMITIVE_IMAGE_1D_T = PRIMITIVE_STRUCT_FIRST,
+  PRIMITIVE_IMAGE_1D_ARRAY_T,
+  PRIMITIVE_IMAGE_1D_BUFFER_T,
+  PRIMITIVE_IMAGE_2D_T,
+  PRIMITIVE_IMAGE_2D_ARRAY_T,
+  PRIMITIVE_IMAGE_3D_T,
+  PRIMITIVE_IMAGE_2D_MSAA_T,
+  PRIMITIVE_IMAGE_2D_ARRAY_MSAA_T,
+  PRIMITIVE_IMAGE_2D_MSAA_DEPTH_T,
+  PRIMITIVE_IMAGE_2D_ARRAY_MSAA_DEPTH_T,
+  PRIMITIVE_IMAGE_2D_DEPTH_T,
+  PRIMITIVE_IMAGE_2D_ARRAY_DEPTH_T,
+  PRIMITIVE_IMAGE_CUBE_T,
+  PRIMITIVE_IMAGE_CUBE_ARRAY_T,
+  PRIMITIVE_IMAGE_CUBE_DEPTH_T,
+  PRIMITIVE_IMAGE_CUBE_ARRAY_DEPTH_T,
+  PRIMITIVE_EVENT_T,
+  PRIMITIVE_PIPE_T,
+  PRIMITIVE_RESERVE_ID_T,
+  PRIMITIVE_QUEUE_T,
+  PRIMITIVE_NDRANGE_T,
+  PRIMITIVE_CLK_EVENT_T,
+  PRIMITIVE_STRUCT_LAST = PRIMITIVE_CLK_EVENT_T,
+  PRIMITIVE_SAMPLER_T,
+  PRIMITIVE_KERNEL_ENQUEUE_FLAGS_T,
+  PRIMITIVE_CLK_PROFILING_INFO,
+  PRIMITIVE_LAST = PRIMITIVE_CLK_PROFILING_INFO,
+  PRIMITIVE_NONE,
+  // Keep this at the end.
+  PRIMITIVE_NUM = PRIMITIVE_NONE
+};
+
+enum TypeEnum {
+  TYPE_ID_PRIMITIVE,
+  TYPE_ID_POINTER,
+  TYPE_ID_VECTOR,
+  TYPE_ID_ATOMIC,
+  TYPE_ID_BLOCK,
+  TYPE_ID_STRUCTURE
+};
+
+enum TypeAttributeEnum {
+  ATTR_QUALIFIER_FIRST = 0,
+  ATTR_RESTRICT = ATTR_QUALIFIER_FIRST,
+  ATTR_VOLATILE,
+  ATTR_CONST,
+  ATTR_QUALIFIER_LAST = ATTR_CONST,
+  ATTR_ADDR_SPACE_FIRST,
+  ATTR_PRIVATE = ATTR_ADDR_SPACE_FIRST,
+  ATTR_GLOBAL,
+  ATTR_CONSTANT,
+  ATTR_LOCAL,
+  ATTR_GENERIC,
+  ATTR_ADDR_SPACE_LAST = ATTR_GENERIC,
+  ATTR_NONE,
+  ATTR_NUM = ATTR_NONE
+};
+
+// Forward declaration for abstract structure.
+struct ParamType;
+typedef RefCount<ParamType> RefParamType;
+
+// Forward declaration for abstract structure.
+struct TypeVisitor;
+
+struct ParamType {
+  /// @brief Constructor.
+  /// @param TypeEnum type id.
+  ParamType(TypeEnum typeId) : m_typeId(typeId){};
+
+  /// @brief Destructor.
+  virtual ~ParamType(){};
+
+  /// Abstract Methods ///
+
+  /// @brief Visitor service method. (see TypeVisitor for more details).
+  ///        When overridden in subclasses, preform a 'double dispatch' to the
+  ///        appropriate visit method in the given visitor.
+  /// @param TypeVisitor type visitor.
+  virtual MangleError accept(TypeVisitor *) const = 0;
+
+  /// @brief Returns a string representation of the underlying type.
+  /// @return type as string.
+  virtual std::string toString() const = 0;
+
+  /// @brief Returns true if given param type is equal to this type.
+  /// @param ParamType given param type.
+  /// @return true if given param type is equal to this type and false
+  /// otherwise.
+  virtual bool equals(const ParamType *) const = 0;
+
+  /// Common Base-Class Methods ///
+
+  /// @brief Returns type id of underlying type.
+  /// @return type id.
+  TypeEnum getTypeId() const { return m_typeId; }
+
+private:
+  // @brief Default Constructor.
+  ParamType();
+
+protected:
+  /// An enumeration to identify the type id of this instance.
+  TypeEnum m_typeId;
+};
+
+struct PrimitiveType : public ParamType {
+  /// An enumeration to identify the type id of this class.
+  const static TypeEnum enumTy;
+
+  /// @brief Constructor.
+  /// @param TypePrimitiveEnum primitive id.
+  PrimitiveType(TypePrimitiveEnum);
+
+  /// Implementation of Abstract Methods ///
+
+  /// @brief Visitor service method. (see TypeVisitor for more details).
+  ///        When overridden in subclasses, preform a 'double dispatch' to the
+  ///        appropriate visit method in the given visitor.
+  /// @param TypeVisitor type visitor.
+  MangleError accept(TypeVisitor *) const;
+
+  /// @brief Returns a string representation of the underlying type.
+  /// @return type as string.
+  std::string toString() const;
+
+  /// @brief Returns true if given param type is equal to this type.
+  /// @param ParamType given param type.
+  /// @return true if given param type is equal to this type and false
+  /// otherwise.
+  bool equals(const ParamType *) const;
+
+  /// Non-Common Methods ///
+
+  /// @brief Returns the primitive enumeration of the type.
+  /// @return primitive type.
+  TypePrimitiveEnum getPrimitive() const { return m_primitive; }
+
+protected:
+  /// An enumeration to identify the primitive type.
+  TypePrimitiveEnum m_primitive;
+};
+
+struct PointerType : public ParamType {
+  /// An enumeration to identify the type id of this class.
+  const static TypeEnum enumTy;
+
+  /// @brief Constructor.
+  /// @param RefParamType the type of pointee (that the pointer points at).
+  PointerType(const RefParamType type);
+
+  /// Implementation of Abstract Methods ///
+
+  /// @brief Visitor service method. (see TypeVisitor for more details).
+  ///        When overridden in subclasses, preform a 'double dispatch' to the
+  ///        appropriate visit method in the given visitor.
+  /// @param TypeVisitor type visitor
+  MangleError accept(TypeVisitor *) const;
+
+  /// @brief Returns a string representation of the underlying type.
+  /// @return type as string.
+  std::string toString() const;
+
+  /// @brief Returns true if given param type is equal to this type.
+  /// @param ParamType given param type.
+  /// @return true if given param type is equal to this type and false
+  /// otherwise.
+  bool equals(const ParamType *) const;
+
+  /// Non-Common Methods ///
+
+  /// @brief Returns the type the pointer is pointing at.
+  /// @return pointee type.
+  const RefParamType &getPointee() const { return m_pType; }
+
+  /// @brief Sets the address space attribute - default is __private
+  /// @param TypeAttributeEnum address space attribute id.
+  void setAddressSpace(TypeAttributeEnum attr);
+
+  /// @brief Returns the pointer's address space.
+  /// @return pointer's address space.
+  TypeAttributeEnum getAddressSpace() const;
+
+  /// @brief Adds or removes a pointer's qualifier.
+  /// @param TypeAttributeEnum qual - qualifier to add/remove.
+  /// @param bool enabled - true if qualifier should exist false otherwise.
+  ///        default is set to false.
+  void setQualifier(TypeAttributeEnum qual, bool enabled);
+
+  /// @brief Checks if the pointer has a certain qualifier.
+  /// @param TypeAttributeEnum qual - qualifier to check.
+  /// @return true if the qualifier exists and false otherwise.
+  bool hasQualifier(TypeAttributeEnum qual) const;
+
+private:
+  /// The type this pointer is pointing at.
+  RefParamType m_pType;
+  /// Array of the pointer's enabled type qualifiers.
+  bool m_qualifiers[ATTR_QUALIFIER_LAST - ATTR_QUALIFIER_FIRST + 1];
+  /// Pointer's address space.
+  TypeAttributeEnum m_address_space;
+};
+
+struct VectorType : public ParamType {
+  /// An enumeration to identify the type id of this class.
+  const static TypeEnum enumTy;
+
+  /// @brief Constructor.
+  /// @param RefParamType the type of each scalar element in the vector.
+  /// @param int the length of the vector.
+  VectorType(const RefParamType type, int len);
+
+  /// Implementation of Abstract Methods ///
+
+  /// @brief Visitor service method. (see TypeVisitor for more details).
+  ///        When overridden in subclasses, preform a 'double dispatch' to the
+  ///        appropriate visit method in the given visitor.
+  /// @param TypeVisitor type visitor.
+  MangleError accept(TypeVisitor *) const;
+
+  /// @brief Returns a string representation of the underlying type.
+  /// @return type as string.
+  std::string toString() const;
+
+  /// @brief Returns true if given param type is equal to this type.
+  /// @param ParamType given param type.
+  /// @return true if given param type is equal to this type and false
+  /// otherwise.
+  bool equals(const ParamType *) const;
+
+  /// Non-Common Methods ///
+
+  /// @brief Returns the type the vector is packing.
+  /// @return scalar type.
+  const RefParamType &getScalarType() const { return m_pType; }
+
+  /// @brief Returns the length of the vector type.
+  /// @return vector type length.
+  int getLength() const { return m_len; }
+
+private:
+  /// The scalar type of this vector type.
+  RefParamType m_pType;
+  /// The length of the vector.
+  int m_len;
+};
+
+struct AtomicType : public ParamType {
+  /// an enumeration to identify the type id of this class
+  const static TypeEnum enumTy;
+
+  /// @brief Constructor
+  /// @param RefParamType the type refernced as atomic.
+  AtomicType(const RefParamType type);
+
+  /// Implementation of Abstract Methods ///
+
+  /// @brief visitor service method. (see TypeVisitor for more details).
+  ///       When overridden in subclasses, preform a 'double dispatch' to the
+  ///       appropriate visit method in the given visitor.
+  /// @param TypeVisitor type visitor
+  MangleError accept(TypeVisitor *) const;
+
+  /// @brief returns a string representation of the underlying type.
+  /// @return type as string
+  std::string toString() const;
+
+  /// @brief returns true if given param type is equal to this type.
+  /// @param ParamType given param type
+  /// @return true if given param type is equal to this type and false otherwise
+  bool equals(const ParamType *) const;
+
+  /// Non-Common Methods ///
+
+  /// @brief returns the base type of the atomic parameter.
+  /// @return base type
+  const RefParamType &getBaseType() const { return m_pType; }
+
+private:
+  /// the type this pointer is pointing at
+  RefParamType m_pType;
+};
+
+struct BlockType : public ParamType {
+  /// an enumeration to identify the type id of this class
+  const static TypeEnum enumTy;
+
+  ///@brief Constructor
+  BlockType();
+
+  /// Implementation of Abstract Methods ///
+
+  /// @brief visitor service method. (see TypeVisitor for more details).
+  ///       When overridden in subclasses, preform a 'double dispatch' to the
+  ///       appropriate visit method in the given visitor.
+  /// @param TypeVisitor type visitor
+  MangleError accept(TypeVisitor *) const;
+
+  /// @brief returns a string representation of the underlying type.
+  /// @return type as string
+  std::string toString() const;
+
+  /// @brief returns true if given param type is equal to this type.
+  /// @param ParamType given param type
+  /// @return true if given param type is equal to this type and false otherwise
+  bool equals(const ParamType *) const;
+
+  /// Non-Common Methods ///
+
+  /// @brief returns the number of parameters of the block.
+  /// @return parameters count
+  unsigned int getNumOfParams() const { return (unsigned int)m_params.size(); }
+
+  ///@brief returns the type of parameter "index" of the block.
+  // @param index the sequential number of the queried parameter
+  ///@return parameter type
+  const RefParamType &getParam(unsigned int index) const {
+    assert(m_params.size() > index && "index is OOB");
+    return m_params[index];
+  }
+
+  ///@brief set the type of parameter "index" of the block.
+  // @param index the sequential number of the queried parameter
+  // @param type the parameter type
+  void setParam(unsigned int index, RefParamType type) {
+    if (index < getNumOfParams()) {
+      m_params[index] = type;
+    } else if (index == getNumOfParams()) {
+      m_params.push_back(type);
+    } else {
+      assert(false && "index is OOB");
+    }
+  }
+
+protected:
+  /// an enumeration to identify the primitive type
+  std::vector<RefParamType> m_params;
+};
+
+struct UserDefinedType : public ParamType {
+  /// An enumeration to identify the type id of this class.
+  const static TypeEnum enumTy;
+
+  /// @brief Constructor.
+  UserDefinedType(const std::string &);
+
+  /// Implementation of Abstract Methods ///
+
+  /// @brief Visitor service method. (see TypeVisitor for more details).
+  ///        When overridden in subclasses, preform a 'double dispatch' to the
+  ///        appropriate visit method in the given visitor.
+  /// @param TypeVisitor type visitor.
+  MangleError accept(TypeVisitor *) const;
+
+  /// @brief Returns a string representation of the underlying type.
+  /// @return type as string.
+  std::string toString() const;
+
+  /// @brief Returns true if given param type is equal to this type.
+  /// @param ParamType given param type.
+  /// @return true if given param type is equal to this type and false
+  /// otherwise.
+  bool equals(const ParamType *) const;
+
+protected:
+  /// The name of the user defined type.
+  std::string m_name;
+};
+
+/// @brief Can be overridden so an object of static type Type* will
+///        dispatch the correct visit method according to its dynamic type.
+struct TypeVisitor {
+  SPIRversion spirVer;
+  TypeVisitor(SPIRversion ver) : spirVer(ver) {}
+  virtual ~TypeVisitor() {}
+  virtual MangleError visit(const PrimitiveType *) = 0;
+  virtual MangleError visit(const VectorType *) = 0;
+  virtual MangleError visit(const PointerType *) = 0;
+  virtual MangleError visit(const AtomicType *) = 0;
+  virtual MangleError visit(const BlockType *) = 0;
+  virtual MangleError visit(const UserDefinedType *) = 0;
+};
+
+/// @brief Template dynamic cast function for ParamType derived classes.
+/// @param ParamType given param type.
+/// @return required casting type if given param type is an instance if
+//          that type, NULL otherwise.
+template <typename T> T *dyn_cast(ParamType *pType) {
+  assert(pType && "dyn_cast does not support casting of NULL");
+  return (T::enumTy == pType->getTypeId()) ? (T *)pType : NULL;
+}
+
+/// @brief Template dynamic cast function for ParamType derived classes
+///        (the constant version).
+/// @param ParamType given param type.
+/// @return required casting type if given param type is an instance if
+//          that type, NULL otherwise.
+template <typename T> const T *dyn_cast(const ParamType *pType) {
+  assert(pType && "dyn_cast does not support casting of NULL");
+  return (T::enumTy == pType->getTypeId()) ? (const T *)pType : NULL;
+}
+
+} // End SPIR namespace
+#endif //__PARAMETER_TYPE_H__
diff --git a/lib/SPIRV/Mangler/README.md b/lib/SPIRV/Mangler/README.md
new file mode 100644
index 0000000..917c355
--- /dev/null
+++ b/lib/SPIRV/Mangler/README.md
@@ -0,0 +1,16 @@
+Contributed by: Intel Corporation.
+
+SPIR Name Mangler
+=================
+
+The NameMangler Library Converts the given function descriptor to a string
+that represents the function's prototype.
+
+The mangling algorithm is based on clang 3.0 Itanium mangling algorithm
+(http://sourcery.mentor.com/public/cxx-abi/abi.html#mangling).
+
+The algorithm is adapted to support mangling of SPIR built-in
+functions and was tested on SPIR built-ins only.
+
+The mangler supports mangling according to SPIR 1.2 and SPIR 2.0
+For usage examples see unittest/spir_name_mangler.
diff --git a/lib/SPIRV/Mangler/Refcount.h b/lib/SPIRV/Mangler/Refcount.h
new file mode 100644
index 0000000..e8995b7
--- /dev/null
+++ b/lib/SPIRV/Mangler/Refcount.h
@@ -0,0 +1,100 @@
+//===--------------------------- Refcount.h ------------------------------===//
+//
+//                              SPIR Tools
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===---------------------------------------------------------------------===//
+/*
+ * Contributed by: Intel Corporation
+ */
+
+#ifndef __REF_COUNT_H__
+#define __REF_COUNT_H__
+
+#include <assert.h>
+
+namespace SPIR {
+
+template <typename T> class RefCount {
+public:
+  RefCount() : m_refCount(0), m_ptr(0) {}
+
+  RefCount(T *ptr) : m_ptr(ptr) { m_refCount = new int(1); }
+
+  RefCount(const RefCount<T> &other) { cpy(other); }
+
+  ~RefCount() {
+    if (m_refCount)
+      dispose();
+  }
+
+  RefCount &operator=(const RefCount<T> &other) {
+    if (this == &other)
+      return *this;
+    if (m_refCount)
+      dispose();
+    cpy(other);
+    return *this;
+  }
+
+  void init(T *ptr) {
+    assert(!m_ptr && "overrunning non NULL pointer");
+    assert(!m_refCount && "overrunning non NULL pointer");
+    m_refCount = new int(1);
+    m_ptr = ptr;
+  }
+
+  bool isNull() const { return (!m_ptr); }
+
+  // Pointer access
+  const T &operator*() const {
+    sanity();
+    return *m_ptr;
+  }
+
+  T &operator*() {
+    sanity();
+    return *m_ptr;
+  }
+
+  operator T *() { return m_ptr; }
+
+  operator const T *() const { return m_ptr; }
+
+  T *operator->() { return m_ptr; }
+
+  const T *operator->() const { return m_ptr; }
+
+private:
+  void sanity() const {
+    assert(m_ptr && "NULL pointer");
+    assert(m_refCount && "NULL ref counter");
+    assert(*m_refCount && "zero ref counter");
+  }
+
+  void cpy(const RefCount<T> &other) {
+    m_refCount = other.m_refCount;
+    m_ptr = other.m_ptr;
+    if (m_refCount)
+      ++*m_refCount;
+  }
+
+  void dispose() {
+    sanity();
+    if (0 == --*m_refCount) {
+      delete m_refCount;
+      delete m_ptr;
+      m_ptr = 0;
+      m_refCount = 0;
+    }
+  }
+
+  int *m_refCount;
+  T *m_ptr;
+}; // End RefCount
+
+} // End SPIR namespace
+
+#endif //__REF_COUNT_H__
diff --git a/lib/SPIRV/OCL20To12.cpp b/lib/SPIRV/OCL20To12.cpp
new file mode 100644
index 0000000..08dc3a1
--- /dev/null
+++ b/lib/SPIRV/OCL20To12.cpp
@@ -0,0 +1,137 @@
+//===- OCL20To12.cpp - Transform OCL 2.0 builtins to OCL 1.2 builtins -----===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+//
+// This file implements transform OCL 2.0 builtins to OCL 1.2 builtins.
+//
+//===----------------------------------------------------------------------===//
+#define DEBUG_TYPE "ocl20to12"
+
+#include "SPIRVInternal.h"
+#include "OCLUtil.h"
+#include "llvm/ADT/StringSwitch.h"
+#include "llvm/IR/InstVisitor.h"
+#include "llvm/IR/Instructions.h"
+#include "llvm/IR/IRBuilder.h"
+#include "llvm/IR/Verifier.h"
+#include "llvm/Pass.h"
+#include "llvm/PassSupport.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/ErrorHandling.h"
+#include "llvm/Support/raw_ostream.h"
+
+using namespace llvm;
+using namespace SPIRV;
+using namespace OCLUtil;
+
+namespace SPIRV {
+class OCL20To12 : public ModulePass, public InstVisitor<OCL20To12> {
+public:
+  OCL20To12() : ModulePass(ID), M(nullptr), Ctx(nullptr) {
+    initializeOCL20To12Pass(*PassRegistry::getPassRegistry());
+  }
+  virtual bool runOnModule(Module &M);
+  virtual void visitCallInst(CallInst &CI);
+
+  /// Transform atomic_work_item_fence to mem_fence.
+  ///   atomic_work_item_fence(flag, relaxed, work_group) =>
+  ///       mem_fence(flag)
+  void visitCallAtomicWorkItemFence(CallInst *CI);
+
+  static char ID;
+
+private:
+  Module *M;
+  LLVMContext *Ctx;
+};
+
+char OCL20To12::ID = 0;
+
+bool OCL20To12::runOnModule(Module &Module) {
+  M = &Module;
+  if (getOCLVersion(M) >= kOCLVer::CL20)
+    return false;
+
+  Ctx = &M->getContext();
+  visit(*M);
+
+  DEBUG(dbgs() << "After OCL20To12:\n" << *M);
+
+  std::string Err;
+  raw_string_ostream ErrorOS(Err);
+  if (verifyModule(*M, &ErrorOS)) {
+    DEBUG(errs() << "Fails to verify module: " << ErrorOS.str());
+  }
+  return true;
+}
+
+void OCL20To12::visitCallInst(CallInst &CI) {
+  DEBUG(dbgs() << "[visistCallInst] " << CI << '\n');
+  auto F = CI.getCalledFunction();
+  if (!F)
+    return;
+
+  auto MangledName = F->getName();
+  std::string DemangledName;
+  if (!oclIsBuiltin(MangledName, &DemangledName))
+    return;
+  DEBUG(dbgs() << "DemangledName = " << DemangledName.c_str() << '\n');
+
+  if (DemangledName == kOCLBuiltinName::AtomicWorkItemFence) {
+    visitCallAtomicWorkItemFence(&CI);
+    return;
+  }
+}
+
+void OCL20To12::visitCallAtomicWorkItemFence(CallInst *CI) {
+  auto Lit = getAtomicWorkItemFenceLiterals(CI);
+  if (std::get<1>(Lit) != OCLLegacyAtomicMemOrder ||
+      std::get<2>(Lit) != OCLLegacyAtomicMemScope)
+    report_fatal_error("OCL 2.0 builtin atomic_work_item_fence used in 1.2",
+                       false);
+
+  AttributeSet Attrs = CI->getCalledFunction()->getAttributes();
+  mutateCallInstOCL(M, CI,
+                    [=](CallInst *, std::vector<Value *> &Args) {
+                      Args.resize(1);
+                      Args[0] = getInt32(M, std::get<0>(Lit));
+                      return kOCLBuiltinName::MemFence;
+                    },
+                    &Attrs);
+}
+}
+
+INITIALIZE_PASS(OCL20To12, "ocl20to12",
+                "Translate OCL 2.0 builtins to OCL 1.2 builtins", false, false)
+
+ModulePass *llvm::createOCL20To12() { return new OCL20To12(); }
diff --git a/lib/SPIRV/OCL20ToSPIRV.cpp b/lib/SPIRV/OCL20ToSPIRV.cpp
new file mode 100644
index 0000000..9cf4ef3
--- /dev/null
+++ b/lib/SPIRV/OCL20ToSPIRV.cpp
@@ -0,0 +1,1493 @@
+//===- OCL20ToSPIRV.cpp - Transform OCL20/GLSL to SPIR-V builtins - C++ -*-===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+//
+// This file implements translation of OCL20 / GLSL builtin functions.
+//
+//===----------------------------------------------------------------------===//
+#define DEBUG_TYPE "cl20tospv"
+
+#include "SPIRVInternal.h"
+#include "OCLUtil.h"
+#include "OCLTypeToSPIRV.h"
+
+#include "llvm/ADT/StringSwitch.h"
+#include "llvm/IR/InstVisitor.h"
+#include "llvm/IR/Instructions.h"
+#include "llvm/IR/Instruction.h"
+#include "llvm/IR/IRBuilder.h"
+#include "llvm/IR/Verifier.h"
+#include "llvm/Pass.h"
+#include "llvm/PassSupport.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/raw_ostream.h"
+
+#include <set>
+
+using namespace llvm;
+using namespace SPIRV;
+using namespace OCLUtil;
+
+namespace SPIRV {
+static size_t getOCLCpp11AtomicMaxNumOps(StringRef Name) {
+  return StringSwitch<size_t>(Name)
+      .Cases("load", "flag_test_and_set", "flag_clear", 3)
+      .Cases("store", "exchange", 4)
+      .StartsWith("compare_exchange", 6)
+      .StartsWith("fetch", 4)
+      .Default(0);
+}
+
+class OCL20ToSPIRV : public ModulePass, public InstVisitor<OCL20ToSPIRV> {
+public:
+  OCL20ToSPIRV() : ModulePass(ID), M(nullptr), Ctx(nullptr), CLVer(0) {
+    initializeOCL20ToSPIRVPass(*PassRegistry::getPassRegistry());
+  }
+  virtual bool runOnModule(Module &M);
+
+  void getAnalysisUsage(AnalysisUsage &AU) const {
+    AU.addRequired<OCLTypeToSPIRV>();
+  }
+
+  virtual void visitCallInst(CallInst &CI);
+
+  /// Transform barrier/work_group_barrier/sub_group_barrier
+  ///     to __spirv_ControlBarrier.
+  /// barrier(flag) =>
+  ///   __spirv_ControlBarrier(workgroup, workgroup, map(flag))
+  /// work_group_barrier(scope, flag) =>
+  ///   __spirv_ControlBarrier(workgroup, map(scope), map(flag))
+  /// sub_group_barrier(scope, flag) =>
+  ///   __spirv_ControlBarrier(subgroup, map(scope), map(flag))
+  void visitCallBarrier(CallInst *CI);
+
+  /// Erase useless convert functions.
+  /// \return true if the call instruction is erased.
+  bool eraseUselessConvert(CallInst *Call, const std::string &MangledName,
+                           const std::string &DeMangledName);
+
+  /// Transform convert_ to
+  ///   __spirv_{CastOpName}_R{TargeTyName}{_sat}{_rt[p|n|z|e]}
+  void visitCallConvert(CallInst *CI, StringRef MangledName,
+                        const std::string &DemangledName);
+
+  /// Transform async_work_group{_strided}_copy.
+  /// async_work_group_copy(dst, src, n, event)
+  ///   => async_work_group_strided_copy(dst, src, n, 1, event)
+  /// async_work_group_strided_copy(dst, src, n, stride, event)
+  ///   => __spirv_AsyncGroupCopy(ScopeWorkGroup, dst, src, n, stride, event)
+  void visitCallAsyncWorkGroupCopy(CallInst *CI,
+                                   const std::string &DemangledName);
+
+  /// Transform OCL builtin function to SPIR-V builtin function.
+  void transBuiltin(CallInst *CI, OCLBuiltinTransInfo &Info);
+
+  /// Transform OCL work item builtin functions to SPIR-V builtin variables.
+  void transWorkItemBuiltinsToVariables();
+
+  /// Transform atomic_work_item_fence/mem_fence to __spirv_MemoryBarrier.
+  /// func(flag, order, scope) =>
+  ///   __spirv_MemoryBarrier(map(scope), map(flag)|map(order))
+  void transMemoryBarrier(CallInst *CI, AtomicWorkItemFenceLiterals);
+
+  /// Transform all to __spirv_Op(All|Any).  Note that the types mismatch so
+  // some extra code is emitted to convert between the two.
+  void visitCallAllAny(spv::Op OC, CallInst *CI);
+
+  /// Transform atomic_* to __spirv_Atomic*.
+  /// atomic_x(ptr_arg, args, order, scope) =>
+  ///   __spirv_AtomicY(ptr_arg, map(order), map(scope), args)
+  void transAtomicBuiltin(CallInst *CI, OCLBuiltinTransInfo &Info);
+
+  /// Transform atomic_work_item_fence to __spirv_MemoryBarrier.
+  /// atomic_work_item_fence(flag, order, scope) =>
+  ///   __spirv_MemoryBarrier(map(scope), map(flag)|map(order))
+  void visitCallAtomicWorkItemFence(CallInst *CI);
+
+  /// Transform atomic_compare_exchange call.
+  /// In atomic_compare_exchange, the expected value parameter is a pointer.
+  /// However in SPIR-V it is a value. The transformation adds a load
+  /// instruction, result of which is passed to atomic_compare_exchange as
+  /// argument.
+  /// The transformation adds a store instruction after the call, to update the
+  /// value in expected with the value pointed to by object. Though, it is not
+  /// necessary in case they are equal, this approach makes result code simpler.
+  /// Also ICmp instruction is added, because the call must return result of
+  /// comparison.
+  /// \returns the call instruction of atomic_compare_exchange_strong.
+  CallInst *visitCallAtomicCmpXchg(CallInst *CI,
+                                   const std::string &DemangledName);
+
+  /// Transform atomic_init.
+  /// atomic_init(p, x) => store p, x
+  void visitCallAtomicInit(CallInst *CI);
+
+  /// Transform legacy OCL 1.x atomic builtins to SPIR-V builtins for extensions
+  ///   cl_khr_int64_base_atomics
+  ///   cl_khr_int64_extended_atomics
+  /// Do nothing if the called function is not a legacy atomic builtin.
+  void visitCallAtomicLegacy(CallInst *CI, StringRef MangledName,
+                             const std::string &DemangledName);
+
+  /// Transform OCL 2.0 C++11 atomic builtins to SPIR-V builtins.
+  /// Do nothing if the called function is not a C++11 atomic builtin.
+  void visitCallAtomicCpp11(CallInst *CI, StringRef MangledName,
+                            const std::string &DemangledName);
+
+  /// Transform OCL builtin function to SPIR-V builtin function.
+  /// Assuming there is a simple name mapping without argument changes.
+  /// Should be called at last.
+  void visitCallBuiltinSimple(CallInst *CI, StringRef MangledName,
+                              const std::string &DemangledName);
+
+  /// Transform get_image_{width|height|depth|dim}.
+  /// get_image_xxx(...) =>
+  ///   dimension = __spirv_ImageQuerySizeLod_R{ReturnType}(...);
+  ///   return dimension.{x|y|z};
+  void visitCallGetImageSize(CallInst *CI, StringRef MangledName,
+                             const std::string &DemangledName);
+
+  /// Transform {work|sub}_group_x =>
+  ///   __spirv_{OpName}
+  ///
+  /// Special handling of work_group_broadcast.
+  ///   work_group_broadcast(a, x, y, z)
+  ///     =>
+  ///   __spirv_GroupBroadcast(a, vec3(x, y, z))
+
+  void visitCallGroupBuiltin(CallInst *CI, StringRef MangledName,
+                             const std::string &DemangledName);
+
+  /// Transform mem_fence to __spirv_MemoryBarrier.
+  /// mem_fence(flag) => __spirv_MemoryBarrier(Workgroup, map(flag))
+  void visitCallMemFence(CallInst *CI);
+
+  void visitCallNDRange(CallInst *CI, const std::string &DemangledName);
+
+  /// Transform OCL pipe builtin function to SPIR-V pipe builtin function.
+  void visitCallPipeBuiltin(CallInst *CI, StringRef MangledName,
+                            const std::string &DemangledName);
+
+  /// Transform read_image with sampler arguments.
+  /// read_image(image, sampler, ...) =>
+  ///   sampled_image = __spirv_SampledImage(image, sampler);
+  ///   return __spirv_ImageSampleExplicitLod_R{ReturnType}(sampled_image, ...);
+  void visitCallReadImageWithSampler(CallInst *CI, StringRef MangledName,
+                                     const std::string &DemangledName);
+
+  /// Transform read_image with msaa image arguments.
+  /// Sample argument must be acoded as Image Operand.
+  void visitCallReadImageMSAA(CallInst *CI, StringRef MangledName,
+                              const std::string &DemangledName);
+
+  /// Transform {read|write}_image without sampler arguments.
+  void visitCallReadWriteImage(CallInst *CI, StringRef MangledName,
+                               const std::string &DemangledName);
+
+  /// Transform to_{global|local|private}.
+  ///
+  /// T* a = ...;
+  /// addr T* b = to_addr(a);
+  ///   =>
+  /// i8* x = cast<i8*>(a);
+  /// addr i8* y = __spirv_GenericCastToPtr_ToAddr(x);
+  /// addr T* b = cast<addr T*>(y);
+  void visitCallToAddr(CallInst *CI, StringRef MangledName,
+                       const std::string &DemangledName);
+
+  /// Transform return type of relatinal built-in functions like isnan, isfinite
+  /// to boolean values.
+  void visitCallRelational(CallInst *CI, const std::string &DemangledName);
+
+  /// Transform vector load/store functions to SPIR-V extended builtin
+  ///   functions
+  /// {vload|vstore{a}}{_half}{n}{_rte|_rtz|_rtp|_rtn} =>
+  ///   __spirv_ocl_{ExtendedInstructionOpCodeName}__R{ReturnType}
+  void visitCallVecLoadStore(CallInst *CI, StringRef MangledName,
+                             const std::string &DemangledName);
+
+  /// Transforms get_mem_fence built-in to SPIR-V function and aligns result
+  /// values with SPIR 1.2.
+  /// get_mem_fence(ptr) => __spirv_GenericPtrMemSemantics
+  /// GenericPtrMemSemantics valid values are 0x100, 0x200 and 0x300, where is
+  /// SPIR 1.2 defines them as 0x1, 0x2 and 0x3, so this function adjusts
+  /// GenericPtrMemSemantics results to SPIR 1.2 values.
+  void visitCallGetFence(CallInst *CI, StringRef MangledName,
+                         const std::string &DemangledName);
+
+  /// Transforms OpDot instructions with a scalar type to a fmul instruction
+  void visitCallDot(CallInst *CI);
+
+  /// Fixes for built-in functions with vector+scalar arguments that are
+  /// translated to the SPIR-V instructions where all arguments must have the
+  /// same type.
+  void visitCallScalToVec(CallInst *CI, StringRef MangledName,
+                          const std::string &DemangledName);
+
+  /// Transform get_image_channel_{order|data_type} built-in functions to
+  ///   __spirv_ocl_{ImageQueryOrder|ImageQueryFormat}
+  void visitCallGetImageChannel(CallInst *CI, StringRef MangledName,
+                                const std::string &DemangledName,
+                                unsigned int Offset);
+
+  void visitDbgInfoIntrinsic(DbgInfoIntrinsic &I) {
+    I.dropAllReferences();
+    I.eraseFromParent();
+  }
+  static char ID;
+
+private:
+  Module *M;
+  LLVMContext *Ctx;
+  unsigned CLVer; /// OpenCL version as major*10+minor
+  spv::SourceLanguage SrcLang;
+  std::set<Value *> ValuesToDelete;
+
+  ConstantInt *addInt32(int I) { return getInt32(M, I); }
+  ConstantInt *addSizet(uint64_t I) { return getSizet(M, I); }
+
+  /// Get vector width from OpenCL vload* function name.
+  SPIRVWord getVecLoadWidth(const std::string &DemangledName) {
+    SPIRVWord Width = 0;
+    if (DemangledName == "vloada_half")
+      Width = 1;
+    else {
+      unsigned Loc = 5;
+      if (DemangledName.find("vload_half") == 0)
+        Loc = 10;
+      else if (DemangledName.find("vloada_half") == 0)
+        Loc = 11;
+
+      std::stringstream SS(DemangledName.substr(Loc));
+      SS >> Width;
+    }
+    return Width;
+  }
+
+  /// Transform OpenCL vload/vstore function name.
+  void transVecLoadStoreName(std::string &DemangledName,
+                             const std::string &Stem, bool AlwaysN) {
+    auto HalfStem = Stem + "_half";
+    auto HalfStemR = HalfStem + "_r";
+    if (!AlwaysN && DemangledName == HalfStem)
+      return;
+    if (!AlwaysN && DemangledName.find(HalfStemR) == 0) {
+      DemangledName = HalfStemR;
+      return;
+    }
+    if (DemangledName.find(HalfStem) == 0) {
+      auto OldName = DemangledName;
+      DemangledName = HalfStem + "n";
+      if (OldName.find("_r") != std::string::npos)
+        DemangledName += "_r";
+      return;
+    }
+    if (DemangledName.find(Stem) == 0) {
+      DemangledName = Stem + "n";
+      return;
+    }
+  }
+};
+
+char OCL20ToSPIRV::ID = 0;
+
+bool OCL20ToSPIRV::runOnModule(Module &Module) {
+  M = &Module;
+  Ctx = &M->getContext();
+  auto Src = getSPIRVSource(&Module);
+  SrcLang = (spv::SourceLanguage)std::get<0>(Src);
+  if (SrcLang != spv::SourceLanguageOpenCL_C &&
+      SrcLang != spv::SourceLanguageGLSL)
+    return false;
+
+  CLVer = std::get<1>(Src);
+  if (CLVer > kOCLVer::CL20)
+    return false;
+
+  DEBUG(dbgs() << "Enter OCL20ToSPIRV:\n");
+
+  // as of now, Vulkan/SPIR-V/GLSL doesn't know constant/UniformConstant
+  // values/object,
+  // so replace all uses of the constant address space with the Function storage
+  // class
+  // NOTE: SPIRVWriter will also move all global constant vars to the inside of
+  // their
+  //       respective functions (users)
+  if (SrcLang == spv::SourceLanguageGLSL) {
+    SPIRSPIRVAddrSpaceMap::replace(SPIRAS_Constant, StorageClassFunction);
+  }
+
+  transWorkItemBuiltinsToVariables();
+
+  visit(*M);
+
+  for (auto &I : ValuesToDelete)
+    if (auto Inst = dyn_cast<Instruction>(I))
+      Inst->eraseFromParent();
+  for (auto &I : ValuesToDelete)
+    if (auto GV = dyn_cast<GlobalValue>(I))
+      GV->eraseFromParent();
+
+  DEBUG(dbgs() << "After OCL20ToSPIRV:\n" << *M);
+
+  std::string Err;
+  raw_string_ostream ErrorOS(Err);
+  if (verifyModule(*M, &ErrorOS)) {
+    DEBUG(errs() << "Fails to verify module: " << ErrorOS.str());
+  }
+  return true;
+}
+
+// The order of handling OCL builtin functions is important.
+// Workgroup functions need to be handled before pipe functions since
+// there are functions fall into both categories.
+void OCL20ToSPIRV::visitCallInst(CallInst &CI) {
+  DEBUG(dbgs() << "[visistCallInst] " << CI << '\n');
+  auto F = CI.getCalledFunction();
+  if (!F)
+    return;
+
+  auto MangledName = F->getName();
+  std::string DemangledName;
+  if (!oclIsBuiltin(MangledName, &DemangledName))
+    return;
+
+  DEBUG(dbgs() << "DemangledName: " << DemangledName << '\n');
+  if (DemangledName.find(kOCLBuiltinName::NDRangePrefix) == 0) {
+    visitCallNDRange(&CI, DemangledName);
+    return;
+  }
+  if (DemangledName == kOCLBuiltinName::All) {
+    visitCallAllAny(OpAll, &CI);
+    return;
+  }
+  if (DemangledName == kOCLBuiltinName::Any) {
+    visitCallAllAny(OpAny, &CI);
+    return;
+  }
+  if (DemangledName.find(kOCLBuiltinName::AsyncWorkGroupCopy) == 0 ||
+      DemangledName.find(kOCLBuiltinName::AsyncWorkGroupStridedCopy) == 0) {
+    visitCallAsyncWorkGroupCopy(&CI, DemangledName);
+    return;
+  }
+  if (DemangledName.find(kOCLBuiltinName::AtomicPrefix) == 0 ||
+      DemangledName.find(kOCLBuiltinName::AtomPrefix) == 0) {
+    auto PCI = &CI;
+    if (DemangledName == kOCLBuiltinName::AtomicInit) {
+      visitCallAtomicInit(PCI);
+      return;
+    }
+    if (DemangledName == kOCLBuiltinName::AtomicWorkItemFence) {
+      visitCallAtomicWorkItemFence(PCI);
+      return;
+    }
+    if (DemangledName == kOCLBuiltinName::AtomicCmpXchgWeak ||
+        DemangledName == kOCLBuiltinName::AtomicCmpXchgStrong ||
+        DemangledName == kOCLBuiltinName::AtomicCmpXchgWeakExplicit ||
+        DemangledName == kOCLBuiltinName::AtomicCmpXchgStrongExplicit) {
+      assert(CLVer == kOCLVer::CL20 && "Wrong version of OpenCL");
+      PCI = visitCallAtomicCmpXchg(PCI, DemangledName);
+    }
+    visitCallAtomicLegacy(PCI, MangledName, DemangledName);
+    visitCallAtomicCpp11(PCI, MangledName, DemangledName);
+    return;
+  }
+  if (DemangledName.find(kOCLBuiltinName::ConvertPrefix) == 0) {
+    visitCallConvert(&CI, MangledName, DemangledName);
+    return;
+  }
+  if (DemangledName == kOCLBuiltinName::GetImageWidth ||
+      DemangledName == kOCLBuiltinName::GetImageHeight ||
+      DemangledName == kOCLBuiltinName::GetImageDepth ||
+      DemangledName == kOCLBuiltinName::GetImageDim ||
+      DemangledName == kOCLBuiltinName::GetImageArraySize) {
+    visitCallGetImageSize(&CI, MangledName, DemangledName);
+    return;
+  }
+  if ((DemangledName.find(kOCLBuiltinName::WorkGroupPrefix) == 0 &&
+       DemangledName != kOCLBuiltinName::WorkGroupBarrier) ||
+      DemangledName == kOCLBuiltinName::WaitGroupEvent ||
+      (DemangledName.find(kOCLBuiltinName::SubGroupPrefix) == 0 &&
+       DemangledName != kOCLBuiltinName::SubGroupBarrier)) {
+    visitCallGroupBuiltin(&CI, MangledName, DemangledName);
+    return;
+  }
+  if (DemangledName.find(kOCLBuiltinName::Pipe) != std::string::npos) {
+    visitCallPipeBuiltin(&CI, MangledName, DemangledName);
+    return;
+  }
+  if (DemangledName == kOCLBuiltinName::MemFence) {
+    visitCallMemFence(&CI);
+    return;
+  }
+  if (DemangledName.find(kOCLBuiltinName::ReadImage) == 0) {
+    if (MangledName.find(kMangledName::Sampler) != StringRef::npos) {
+      visitCallReadImageWithSampler(&CI, MangledName, DemangledName);
+      return;
+    }
+    if (MangledName.find("msaa") != StringRef::npos) {
+      visitCallReadImageMSAA(&CI, MangledName, DemangledName);
+      return;
+    }
+  }
+  if (DemangledName.find(kOCLBuiltinName::ReadImage) == 0 ||
+      DemangledName.find(kOCLBuiltinName::WriteImage) == 0) {
+    visitCallReadWriteImage(&CI, MangledName, DemangledName);
+    return;
+  }
+  if (DemangledName == kOCLBuiltinName::ToGlobal ||
+      DemangledName == kOCLBuiltinName::ToLocal ||
+      DemangledName == kOCLBuiltinName::ToPrivate) {
+    visitCallToAddr(&CI, MangledName, DemangledName);
+    return;
+  }
+  if (DemangledName.find(kOCLBuiltinName::VLoadPrefix) == 0 ||
+      DemangledName.find(kOCLBuiltinName::VStorePrefix) == 0) {
+    visitCallVecLoadStore(&CI, MangledName, DemangledName);
+    return;
+  }
+  if (DemangledName == kOCLBuiltinName::IsFinite ||
+      DemangledName == kOCLBuiltinName::IsInf ||
+      DemangledName == kOCLBuiltinName::IsNan ||
+      DemangledName == kOCLBuiltinName::IsNormal ||
+      DemangledName == kOCLBuiltinName::Signbit) {
+    visitCallRelational(&CI, DemangledName);
+    return;
+  }
+  if (DemangledName == kOCLBuiltinName::WorkGroupBarrier ||
+      DemangledName == kOCLBuiltinName::Barrier) {
+    visitCallBarrier(&CI);
+    return;
+  }
+  if (DemangledName == kOCLBuiltinName::GetFence) {
+    visitCallGetFence(&CI, MangledName, DemangledName);
+    return;
+  }
+  if (DemangledName == kOCLBuiltinName::Dot &&
+      !(CI.getOperand(0)->getType()->isVectorTy())) {
+    visitCallDot(&CI);
+    return;
+  }
+  if (DemangledName == kOCLBuiltinName::FMin ||
+      DemangledName == kOCLBuiltinName::FMax ||
+      DemangledName == kOCLBuiltinName::FMod ||
+      DemangledName == kOCLBuiltinName::Min ||
+      DemangledName == kOCLBuiltinName::Max ||
+      DemangledName == kOCLBuiltinName::Step ||
+      DemangledName == kOCLBuiltinName::SmoothStep ||
+      DemangledName == kOCLBuiltinName::Clamp ||
+      DemangledName == kOCLBuiltinName::Mix) {
+    visitCallScalToVec(&CI, MangledName, DemangledName);
+    return;
+  }
+  if (DemangledName == kOCLBuiltinName::GetImageChannelDataType) {
+    visitCallGetImageChannel(&CI, MangledName, DemangledName,
+                             OCLImageChannelDataTypeOffset);
+    return;
+  }
+  if (DemangledName == kOCLBuiltinName::GetImageChannelOrder) {
+    visitCallGetImageChannel(&CI, MangledName, DemangledName,
+                             OCLImageChannelOrderOffset);
+    return;
+  }
+  visitCallBuiltinSimple(&CI, MangledName, DemangledName);
+}
+
+void OCL20ToSPIRV::visitCallNDRange(CallInst *CI,
+                                    const std::string &DemangledName) {
+  assert(DemangledName.find(kOCLBuiltinName::NDRangePrefix) == 0);
+  std::string lenStr = DemangledName.substr(8, 1);
+  auto Len = atoi(lenStr.c_str());
+  assert(Len >= 1 && Len <= 3);
+  // SPIR-V ndrange structure requires 3 members in the following order:
+  //   global work offset
+  //   global work size
+  //   local work size
+  // The arguments need to add missing members.
+  AttributeSet Attrs = CI->getCalledFunction()->getAttributes();
+  mutateCallInstSPIRV(
+      M, CI,
+      [=](CallInst *, std::vector<Value *> &Args) {
+        for (size_t I = 1, E = Args.size(); I != E; ++I)
+          Args[I] = getScalarOrArray(Args[I], Len, CI);
+        switch (Args.size()) {
+        case 2: {
+          // Has global work size.
+          auto T = Args[1]->getType();
+          auto C = getScalarOrArrayConstantInt(CI, T, Len, 0);
+          Args.push_back(C);
+          Args.push_back(C);
+        } break;
+        case 3: {
+          // Has global and local work size.
+          auto T = Args[1]->getType();
+          Args.push_back(getScalarOrArrayConstantInt(CI, T, Len, 0));
+        } break;
+        case 4: {
+          // Move offset arg to the end
+          auto OffsetPos = Args.begin() + 1;
+          Value *OffsetVal = *OffsetPos;
+          Args.erase(OffsetPos);
+          Args.push_back(OffsetVal);
+        } break;
+        default:
+          assert(0 && "Invalid number of arguments");
+        }
+        // Translate ndrange_ND into differently named SPIR-V decorated
+        // functions because
+        // they have array arugments of different dimension which mangled the
+        // same way.
+        return getSPIRVFuncName(OpBuildNDRange, "_" + lenStr + "D");
+      },
+      &Attrs);
+}
+
+void OCL20ToSPIRV::visitCallAsyncWorkGroupCopy(
+    CallInst *CI, const std::string &DemangledName) {
+  AttributeSet Attrs = CI->getCalledFunction()->getAttributes();
+  mutateCallInstSPIRV(M, CI,
+                      [=](CallInst *, std::vector<Value *> &Args) {
+                        if (DemangledName ==
+                            OCLUtil::kOCLBuiltinName::AsyncWorkGroupCopy) {
+                          Args.insert(Args.begin() + 3, addSizet(1));
+                        }
+                        Args.insert(Args.begin(), addInt32(ScopeWorkgroup));
+                        return getSPIRVFuncName(OpGroupAsyncCopy);
+                      },
+                      &Attrs);
+}
+
+CallInst *
+OCL20ToSPIRV::visitCallAtomicCmpXchg(CallInst *CI,
+                                     const std::string &DemangledName) {
+  AttributeSet Attrs = CI->getCalledFunction()->getAttributes();
+  Value *Expected = nullptr;
+  CallInst *NewCI = nullptr;
+  mutateCallInstOCL(
+      M, CI,
+      [&](CallInst *CI, std::vector<Value *> &Args, Type *&RetTy) {
+        Expected = Args[1]; // temporary save second argument.
+        Args[1] = new LoadInst(Args[1], "exp", false, CI);
+        RetTy = Args[2]->getType();
+        assert(Args[0]->getType()->getPointerElementType()->isIntegerTy() &&
+               Args[1]->getType()->isIntegerTy() &&
+               Args[2]->getType()->isIntegerTy() &&
+               "In SPIR-V 1.0 arguments of OpAtomicCompareExchange must be "
+               "an integer type scalars");
+        return kOCLBuiltinName::AtomicCmpXchgStrong;
+      },
+      [&](CallInst *NCI) -> Instruction * {
+        NewCI = NCI;
+        Instruction *Store = new StoreInst(NCI, Expected, NCI->getNextNode());
+        return new ICmpInst(Store->getNextNode(), CmpInst::ICMP_EQ, NCI,
+                            NCI->getArgOperand(1));
+      },
+      &Attrs);
+  return NewCI;
+}
+
+void OCL20ToSPIRV::visitCallAtomicInit(CallInst *CI) {
+  auto ST = new StoreInst(CI->getArgOperand(1), CI->getArgOperand(0), CI);
+  ST->takeName(CI);
+  CI->dropAllReferences();
+  CI->eraseFromParent();
+}
+
+void OCL20ToSPIRV::visitCallAllAny(spv::Op OC, CallInst *CI) {
+  AttributeSet Attrs = CI->getCalledFunction()->getAttributes();
+
+  auto Args = getArguments(CI);
+  assert(Args.size() == 1);
+
+  auto *ArgTy = Args[0]->getType();
+  auto Zero = Constant::getNullValue(Args[0]->getType());
+
+  auto *Cmp = CmpInst::Create(CmpInst::ICmp, CmpInst::ICMP_SLT, Args[0], Zero,
+                              "cast", CI);
+
+  if (!isa<VectorType>(ArgTy)) {
+    auto *Cast = CastInst::CreateZExtOrBitCast(Cmp, Type::getInt32Ty(*Ctx), "",
+                                               Cmp->getNextNode());
+    CI->replaceAllUsesWith(Cast);
+    CI->eraseFromParent();
+  } else {
+    mutateCallInstSPIRV(
+        M, CI,
+        [&](CallInst *, std::vector<Value *> &Args, Type *&Ret) {
+          Args[0] = Cmp;
+          Ret = Type::getInt1Ty(*Ctx);
+
+          return getSPIRVFuncName(OC);
+        },
+        [&](CallInst *CI) -> Instruction * {
+          return CastInst::CreateZExtOrBitCast(CI, Type::getInt32Ty(*Ctx), "",
+                                               CI->getNextNode());
+        },
+        &Attrs);
+  }
+}
+
+void OCL20ToSPIRV::visitCallAtomicWorkItemFence(CallInst *CI) {
+  transMemoryBarrier(CI, getAtomicWorkItemFenceLiterals(CI));
+}
+
+void OCL20ToSPIRV::visitCallMemFence(CallInst *CI) {
+  transMemoryBarrier(
+      CI,
+      std::make_tuple(cast<ConstantInt>(CI->getArgOperand(0))->getZExtValue(),
+                      OCLMO_relaxed, OCLMS_work_group));
+}
+
+void OCL20ToSPIRV::transMemoryBarrier(CallInst *CI,
+                                      AtomicWorkItemFenceLiterals Lit) {
+  AttributeSet Attrs = CI->getCalledFunction()->getAttributes();
+  mutateCallInstSPIRV(M, CI,
+                      [=](CallInst *, std::vector<Value *> &Args) {
+                        Args.resize(2);
+                        Args[0] = addInt32(map<Scope>(std::get<2>(Lit)));
+                        Args[1] = addInt32(mapOCLMemSemanticToSPIRV(
+                            std::get<0>(Lit), std::get<1>(Lit)));
+                        return getSPIRVFuncName(OpMemoryBarrier);
+                      },
+                      &Attrs);
+}
+
+void OCL20ToSPIRV::visitCallAtomicLegacy(CallInst *CI, StringRef MangledName,
+                                         const std::string &DemangledName) {
+  StringRef Stem = DemangledName;
+  if (Stem.startswith("atom_"))
+    Stem = Stem.drop_front(strlen("atom_"));
+  else if (Stem.startswith("atomic_"))
+    Stem = Stem.drop_front(strlen("atomic_"));
+  else
+    return;
+
+  std::string Sign;
+  std::string Postfix;
+  std::string Prefix;
+  if (Stem == "add" || Stem == "sub" || Stem == "and" || Stem == "or" ||
+      Stem == "xor" || Stem == "min" || Stem == "max") {
+    if ((Stem == "min" || Stem == "max") &&
+        isMangledTypeUnsigned(MangledName.back()))
+      Sign = 'u';
+    Prefix = "fetch_";
+    Postfix = "_explicit";
+  } else if (Stem == "xchg") {
+    Stem = "exchange";
+    Postfix = "_explicit";
+  } else if (Stem == "cmpxchg") {
+    Stem = "compare_exchange_strong";
+    Postfix = "_explicit";
+  } else if (Stem == "inc" || Stem == "dec") {
+    // do nothing
+  } else
+    return;
+
+  OCLBuiltinTransInfo Info;
+  Info.UniqName = "atomic_" + Prefix + Sign + Stem.str() + Postfix;
+  std::vector<int> PostOps;
+  PostOps.push_back(OCLLegacyAtomicMemOrder);
+  if (Stem.startswith("compare_exchange"))
+    PostOps.push_back(OCLLegacyAtomicMemOrder);
+  PostOps.push_back(OCLLegacyAtomicMemScope);
+
+  Info.PostProc = [=](std::vector<Value *> &Ops) {
+    for (auto &I : PostOps) {
+      Ops.push_back(addInt32(I));
+    }
+  };
+  transAtomicBuiltin(CI, Info);
+}
+
+void OCL20ToSPIRV::visitCallAtomicCpp11(CallInst *CI, StringRef MangledName,
+                                        const std::string &DemangledName) {
+  StringRef Stem = DemangledName;
+  if (Stem.startswith("atomic_"))
+    Stem = Stem.drop_front(strlen("atomic_"));
+  else
+    return;
+
+  std::string NewStem = Stem;
+  std::vector<int> PostOps;
+  if (Stem.startswith("store") || Stem.startswith("load") ||
+      Stem.startswith("exchange") || Stem.startswith("compare_exchange") ||
+      Stem.startswith("fetch") || Stem.startswith("flag")) {
+    if ((Stem.startswith("fetch_min") || Stem.startswith("fetch_max")) &&
+        containsUnsignedAtomicType(MangledName))
+      NewStem.insert(NewStem.begin() + strlen("fetch_"), 'u');
+
+    if (!Stem.endswith("_explicit")) {
+      NewStem = NewStem + "_explicit";
+      PostOps.push_back(OCLMO_seq_cst);
+      if (Stem.startswith("compare_exchange"))
+        PostOps.push_back(OCLMO_seq_cst);
+      PostOps.push_back(OCLMS_device);
+    } else {
+      auto MaxOps =
+          getOCLCpp11AtomicMaxNumOps(Stem.drop_back(strlen("_explicit")));
+      if (CI->getNumArgOperands() < MaxOps)
+        PostOps.push_back(OCLMS_device);
+    }
+  } else if (Stem == "work_item_fence") {
+    // do nothing
+  } else
+    return;
+
+  OCLBuiltinTransInfo Info;
+  Info.UniqName = std::string("atomic_") + NewStem;
+  Info.PostProc = [=](std::vector<Value *> &Ops) {
+    for (auto &I : PostOps) {
+      Ops.push_back(addInt32(I));
+    }
+  };
+
+  transAtomicBuiltin(CI, Info);
+}
+
+void OCL20ToSPIRV::transAtomicBuiltin(CallInst *CI, OCLBuiltinTransInfo &Info) {
+  AttributeSet Attrs = CI->getCalledFunction()->getAttributes();
+  mutateCallInstSPIRV(
+      M, CI,
+      [=](CallInst *CI, std::vector<Value *> &Args) {
+        Info.PostProc(Args);
+        // Order of args in OCL20:
+        // object, 0-2 other args, 1-2 order, scope
+        const size_t NumOrder =
+            getAtomicBuiltinNumMemoryOrderArgs(Info.UniqName);
+        const size_t ArgsCount = Args.size();
+        const size_t ScopeIdx = ArgsCount - 1;
+        const size_t OrderIdx = ScopeIdx - NumOrder;
+        Args[ScopeIdx] =
+            mapUInt(M, cast<ConstantInt>(Args[ScopeIdx]), [](unsigned I) {
+              return map<Scope>(static_cast<OCLScopeKind>(I));
+            });
+        for (size_t I = 0; I < NumOrder; ++I)
+          Args[OrderIdx + I] = mapUInt(
+              M, cast<ConstantInt>(Args[OrderIdx + I]),
+              [&Args, this](unsigned Ord) {
+                // add Vulkan/GLSL specific memory semantics
+                spv::MemorySemanticsMask memsem = spv::MemorySemanticsMaskNone;
+                if (SrcLang == spv::SourceLanguageGLSL) {
+                  switch (
+                      SPIRSPIRVAddrSpaceMap::map(static_cast<SPIRAddressSpace>(
+                          Args[0]->getType()->getPointerAddressSpace()))) {
+                  case spv::StorageClassUniform:
+                    memsem = spv::MemorySemanticsUniformMemoryMask;
+                    break;
+                  // TODO: no sub-group storage class? handled differently?
+                  case spv::StorageClassWorkgroup:
+                    memsem = spv::MemorySemanticsWorkgroupMemoryMask;
+                    break;
+                  case spv::StorageClassCrossWorkgroup:
+                    memsem = spv::MemorySemanticsCrossWorkgroupMemoryMask;
+                    break;
+                  case spv::StorageClassAtomicCounter:
+                    memsem = spv::MemorySemanticsAtomicCounterMemoryMask;
+                    break;
+                  case spv::StorageClassImage:
+                    memsem = spv::MemorySemanticsImageMemoryMask;
+                    break;
+                  default:
+                    break;
+                  }
+                }
+                return mapOCLMemSemanticToSPIRV(
+                           0, static_cast<OCLMemOrderKind>(Ord)) |
+                       memsem;
+              });
+        // Order of args in SPIR-V:
+        // object, scope, 1-2 order, 0-2 other args
+        std::swap(Args[1], Args[ScopeIdx]);
+        if (OrderIdx > 2) {
+          // For atomic_compare_exchange the swap above puts Comparator/Expected
+          // argument just where it should be, so don't move the last argument
+          // then.
+          int offset =
+              Info.UniqName.find("atomic_compare_exchange") == 0 ? 1 : 0;
+          std::rotate(Args.begin() + 2, Args.begin() + OrderIdx,
+                      Args.end() - offset);
+        }
+        return getSPIRVFuncName(OCLSPIRVBuiltinMap::map(Info.UniqName));
+      },
+      &Attrs);
+}
+
+void OCL20ToSPIRV::visitCallBarrier(CallInst *CI) {
+  auto Lit = getBarrierLiterals(CI);
+  AttributeSet Attrs = CI->getCalledFunction()->getAttributes();
+  mutateCallInstSPIRV(M, CI,
+                      [=](CallInst *, std::vector<Value *> &Args) {
+                        Args.resize(3);
+                        Args[0] = addInt32(map<Scope>(std::get<2>(Lit)));
+                        Args[1] = addInt32(map<Scope>(std::get<1>(Lit)));
+                        Args[2] = addInt32(
+                            mapOCLMemFenceFlagToSPIRV(std::get<0>(Lit)));
+                        return getSPIRVFuncName(OpControlBarrier);
+                      },
+                      &Attrs);
+}
+
+void OCL20ToSPIRV::visitCallConvert(CallInst *CI, StringRef MangledName,
+                                    const std::string &DemangledName) {
+  if (eraseUselessConvert(CI, MangledName, DemangledName))
+    return;
+  Op OC = OpNop;
+  auto TargetTy = CI->getType();
+  auto SrcTy = CI->getArgOperand(0)->getType();
+  if (isa<VectorType>(TargetTy))
+    TargetTy = TargetTy->getVectorElementType();
+  if (isa<VectorType>(SrcTy))
+    SrcTy = SrcTy->getVectorElementType();
+  auto IsTargetInt = isa<IntegerType>(TargetTy);
+
+  std::string TargetTyName =
+      DemangledName.substr(strlen(kOCLBuiltinName::ConvertPrefix));
+  auto FirstUnderscoreLoc = TargetTyName.find('_');
+  if (FirstUnderscoreLoc != std::string::npos)
+    TargetTyName = TargetTyName.substr(0, FirstUnderscoreLoc);
+  TargetTyName = std::string("_R") + TargetTyName;
+
+  std::string Sat =
+      DemangledName.find("_sat") != std::string::npos ? "_sat" : "";
+  auto TargetSigned = DemangledName[8] != 'u';
+  if (isa<IntegerType>(SrcTy)) {
+    bool Signed = isLastFuncParamSigned(MangledName);
+    if (IsTargetInt) {
+      if (!Sat.empty() && TargetSigned != Signed) {
+        OC = Signed ? OpSatConvertSToU : OpSatConvertUToS;
+        Sat = "";
+      } else
+        OC = Signed ? OpSConvert : OpUConvert;
+    } else
+      OC = Signed ? OpConvertSToF : OpConvertUToF;
+  } else {
+    if (IsTargetInt) {
+      OC = TargetSigned ? OpConvertFToS : OpConvertFToU;
+    } else
+      OC = OpFConvert;
+  }
+  auto Loc = DemangledName.find("_rt");
+  std::string Rounding;
+  if (Loc != std::string::npos && !(isa<IntegerType>(SrcTy) && IsTargetInt)) {
+    Rounding = DemangledName.substr(Loc, 4);
+  }
+  AttributeSet Attrs = CI->getCalledFunction()->getAttributes();
+  mutateCallInstSPIRV(M, CI,
+                      [=](CallInst *, std::vector<Value *> &Args) {
+                        return getSPIRVFuncName(OC,
+                                                TargetTyName + Sat + Rounding);
+                      },
+                      &Attrs);
+}
+
+void OCL20ToSPIRV::visitCallGroupBuiltin(CallInst *CI, StringRef MangledName,
+                                         const std::string &OrigDemangledName) {
+  auto F = CI->getCalledFunction();
+  std::vector<int> PreOps;
+  std::string DemangledName = OrigDemangledName;
+
+  if (DemangledName == kOCLBuiltinName::WorkGroupBarrier)
+    return;
+  if (DemangledName == kOCLBuiltinName::WaitGroupEvent) {
+    PreOps.push_back(ScopeWorkgroup);
+  } else if (DemangledName.find(kOCLBuiltinName::WorkGroupPrefix) == 0) {
+    DemangledName.erase(0, strlen(kOCLBuiltinName::WorkPrefix));
+    PreOps.push_back(ScopeWorkgroup);
+  } else if (DemangledName.find(kOCLBuiltinName::SubGroupPrefix) == 0) {
+    DemangledName.erase(0, strlen(kOCLBuiltinName::SubPrefix));
+    PreOps.push_back(ScopeSubgroup);
+  } else
+    return;
+
+  if (DemangledName != kOCLBuiltinName::WaitGroupEvent) {
+    StringRef GroupOp = DemangledName;
+    GroupOp = GroupOp.drop_front(strlen(kSPIRVName::GroupPrefix));
+    SPIRSPIRVGroupOperationMap::foreach_conditional([&](
+        const std::string &S, SPIRVGroupOperationKind G) {
+      if (!GroupOp.startswith(S))
+        return true; // continue
+      PreOps.push_back(G);
+      StringRef Op = GroupOp.drop_front(S.size() + 1);
+      assert(!Op.empty() && "Invalid OpenCL group builtin function");
+      char OpTyC = 0;
+      auto NeedSign = Op == "max" || Op == "min";
+      auto OpTy = F->getReturnType();
+      if (OpTy->isFloatingPointTy())
+        OpTyC = 'f';
+      else if (OpTy->isIntegerTy()) {
+        if (!NeedSign)
+          OpTyC = 'i';
+        else {
+          if (isLastFuncParamSigned(F->getName()))
+            OpTyC = 's';
+          else
+            OpTyC = 'u';
+        }
+      } else
+        llvm_unreachable("Invalid OpenCL group builtin argument type");
+
+      DemangledName = std::string(kSPIRVName::GroupPrefix) + OpTyC + Op.str();
+      return false; // break out of loop
+    });
+  }
+
+  bool IsGroupAllAny = (DemangledName.find("_all") != std::string::npos ||
+                        DemangledName.find("_any") != std::string::npos);
+
+  auto Consts = getInt32(M, PreOps);
+  OCLBuiltinTransInfo Info;
+  if (IsGroupAllAny)
+    Info.RetTy = Type::getInt1Ty(*Ctx);
+  Info.UniqName = DemangledName;
+  Info.PostProc = [=](std::vector<Value *> &Ops) {
+    if (IsGroupAllAny) {
+      IRBuilder<> IRB(CI);
+      Ops[0] =
+          IRB.CreateICmpNE(Ops[0], ConstantInt::get(Type::getInt32Ty(*Ctx), 0));
+    }
+    size_t E = Ops.size();
+    if (DemangledName == "group_broadcast" && E > 2) {
+      assert(E == 3 || E == 4);
+      makeVector(CI, Ops, std::make_pair(Ops.begin() + 1, Ops.end()));
+    }
+    Ops.insert(Ops.begin(), Consts.begin(), Consts.end());
+  };
+  transBuiltin(CI, Info);
+}
+
+void OCL20ToSPIRV::transBuiltin(CallInst *CI, OCLBuiltinTransInfo &Info) {
+  AttributeSet Attrs = CI->getCalledFunction()->getAttributes();
+  Op OC = OpNop;
+  unsigned ExtOp = ~0U;
+  const auto ext_kind =
+      (SrcLang == spv::SourceLanguageOpenCL_C ? SPIRVEIS_OpenCL
+                                              : SPIRVEIS_GLSL);
+  if (StringRef(Info.UniqName).startswith(kSPIRVName::Prefix))
+    return;
+  if (OCLSPIRVBuiltinMap::find(Info.UniqName, &OC))
+    Info.UniqName = getSPIRVFuncName(OC);
+  else if ((ExtOp = getExtOp(Info.MangledName, Info.UniqName, ext_kind)) != ~0U)
+    Info.UniqName = getSPIRVExtFuncName(ext_kind, ExtOp);
+  else
+    return;
+  if (!Info.RetTy)
+    mutateCallInstSPIRV(M, CI,
+                        [=](CallInst *, std::vector<Value *> &Args) {
+                          Info.PostProc(Args);
+                          return Info.UniqName + Info.Postfix;
+                        },
+                        &Attrs);
+  else
+    mutateCallInstSPIRV(
+        M, CI,
+        [=](CallInst *, std::vector<Value *> &Args, Type *&RetTy) {
+          Info.PostProc(Args);
+          RetTy = Info.RetTy;
+          return Info.UniqName + Info.Postfix;
+        },
+        [=](CallInst *NewCI) -> Instruction * {
+          if (NewCI->getType()->isIntegerTy() && CI->getType()->isIntegerTy())
+            return CastInst::CreateIntegerCast(NewCI, CI->getType(),
+                                               Info.isRetSigned, "", CI);
+          else
+            return CastInst::CreatePointerBitCastOrAddrSpaceCast(
+                NewCI, CI->getType(), "", CI);
+        },
+        &Attrs);
+}
+
+void OCL20ToSPIRV::visitCallPipeBuiltin(CallInst *CI, StringRef MangledName,
+                                        const std::string &DemangledName) {
+  std::string NewName = DemangledName;
+  // Transform OpenCL read_pipe/write_pipe builtin function names
+  // with reserve_id argument to reserved_read_pipe/reserved_write_pipe.
+  if ((DemangledName.find(kOCLBuiltinName::ReadPipe) == 0 ||
+       DemangledName.find(kOCLBuiltinName::WritePipe) == 0) &&
+      CI->getNumArgOperands() > 4)
+    NewName = std::string(kSPIRVName::ReservedPrefix) + DemangledName;
+  OCLBuiltinTransInfo Info;
+  Info.UniqName = NewName;
+  transBuiltin(CI, Info);
+}
+
+void OCL20ToSPIRV::visitCallReadImageMSAA(CallInst *CI, StringRef MangledName,
+                                          const std::string &DemangledName) {
+  assert(MangledName.find("msaa") != StringRef::npos);
+  AttributeSet Attrs = CI->getCalledFunction()->getAttributes();
+  mutateCallInstSPIRV(
+      M, CI,
+      [=](CallInst *, std::vector<Value *> &Args) {
+        Args.insert(Args.begin() + 2, getInt32(M, ImageOperandsSampleMask));
+        return getSPIRVFuncName(OpImageRead,
+                                std::string(kSPIRVPostfix::ExtDivider) +
+                                    getPostfixForReturnType(CI));
+      },
+      &Attrs);
+}
+
+void OCL20ToSPIRV::visitCallReadImageWithSampler(
+    CallInst *CI, StringRef MangledName, const std::string &DemangledName) {
+  assert(MangledName.find(kMangledName::Sampler) != StringRef::npos);
+  AttributeSet Attrs = CI->getCalledFunction()->getAttributes();
+  bool isRetScalar = !CI->getType()->isVectorTy();
+  mutateCallInstSPIRV(
+      M, CI,
+      [=](CallInst *, std::vector<Value *> &Args, Type *&Ret) {
+        auto ImageTy = getAnalysis<OCLTypeToSPIRV>().getAdaptedType(Args[0]);
+        if (isOCLImageType(ImageTy))
+          ImageTy = getSPIRVImageTypeFromOCL(M, ImageTy);
+        auto SampledImgTy = getSPIRVTypeByChangeBaseTypeName(
+            M, ImageTy, kSPIRVTypeName::Image, kSPIRVTypeName::SampledImg);
+        Value *SampledImgArgs[] = {Args[0], Args[1]};
+        auto SampledImg = addCallInstSPIRV(
+            M, getSPIRVFuncName(OpSampledImage), SampledImgTy, SampledImgArgs,
+            nullptr, CI, kSPIRVName::TempSampledImage);
+
+        Args[0] = SampledImg;
+        Args.erase(Args.begin() + 1, Args.begin() + 2);
+
+        switch (Args.size()) {
+        case 2: // no lod
+          Args.push_back(getInt32(M, ImageOperandsMask::ImageOperandsLodMask));
+          Args.push_back(getFloat32(M, 0.f));
+          break;
+        case 3: // explicit lod
+          Args.insert(Args.begin() + 2,
+                      getInt32(M, ImageOperandsMask::ImageOperandsLodMask));
+          break;
+        case 4: // gradient
+          Args.insert(Args.begin() + 2,
+                      getInt32(M, ImageOperandsMask::ImageOperandsGradMask));
+          break;
+        default:
+          assert(0 && "read_image* with unhandled number of args!");
+        }
+
+        // SPIR-V intruction always returns 4-element vector
+        if (isRetScalar)
+          Ret = VectorType::get(Ret, 4);
+        return getSPIRVFuncName(OpImageSampleExplicitLod,
+                                std::string(kSPIRVPostfix::ExtDivider) +
+                                    getPostfixForReturnType(Ret));
+      },
+      [&](CallInst *CI) -> Instruction * {
+        if (isRetScalar)
+          return ExtractElementInst::Create(CI, getSizet(M, 0), "",
+                                            CI->getNextNode());
+        return CI;
+      },
+      &Attrs);
+}
+
+void OCL20ToSPIRV::visitCallGetImageSize(CallInst *CI, StringRef MangledName,
+                                         const std::string &DemangledName) {
+  AttributeSet Attrs = CI->getCalledFunction()->getAttributes();
+  StringRef TyName;
+  SmallVector<StringRef, 4> SubStrs;
+  auto IsImg = isOCLImageType(CI->getArgOperand(0)->getType(), &TyName);
+  assert(IsImg);
+  std::string ImageTyName = TyName.str();
+  if (hasAccessQualifiedName(TyName))
+    ImageTyName.erase(ImageTyName.size() - 5, 3);
+  auto Desc = map<SPIRVTypeImageDescriptor>(ImageTyName);
+  unsigned Dim = getImageDimension(Desc.Dim) + Desc.Arrayed;
+  assert(Dim > 0 && "Invalid image dimension.");
+  mutateCallInstSPIRV(
+      M, CI,
+      [&](CallInst *, std::vector<Value *> &Args, Type *&Ret) {
+        assert(Args.size() == 1);
+        Ret = CI->getType()->isIntegerTy(64) ? Type::getInt64Ty(*Ctx)
+                                             : Type::getInt32Ty(*Ctx);
+        if (Dim > 1)
+          Ret = VectorType::get(Ret, Dim);
+        if (Desc.Dim == DimBuffer)
+          return getSPIRVFuncName(OpImageQuerySize, CI->getType());
+        else {
+          Args.push_back(getInt32(M, 0));
+          return getSPIRVFuncName(OpImageQuerySizeLod, CI->getType());
+        }
+      },
+      [&](CallInst *NCI) -> Instruction * {
+        if (Dim == 1)
+          return NCI;
+        if (DemangledName == kOCLBuiltinName::GetImageDim) {
+          if (Desc.Dim == Dim3D) {
+            auto ZeroVec = ConstantVector::getSplat(
+                3,
+                Constant::getNullValue(NCI->getType()->getVectorElementType()));
+            Constant *Index[] = {getInt32(M, 0), getInt32(M, 1), getInt32(M, 2),
+                                 getInt32(M, 3)};
+            return new ShuffleVectorInst(NCI, ZeroVec,
+                                         ConstantVector::get(Index), "", CI);
+
+          } else if (Desc.Dim == Dim2D && Desc.Arrayed) {
+            Constant *Index[] = {getInt32(M, 0), getInt32(M, 1)};
+            Constant *mask = ConstantVector::get(Index);
+            return new ShuffleVectorInst(NCI, UndefValue::get(NCI->getType()),
+                                         mask, NCI->getName(), CI);
+          }
+          return NCI;
+        }
+        unsigned I = StringSwitch<unsigned>(DemangledName)
+                         .Case(kOCLBuiltinName::GetImageWidth, 0)
+                         .Case(kOCLBuiltinName::GetImageHeight, 1)
+                         .Case(kOCLBuiltinName::GetImageDepth, 2)
+                         .Case(kOCLBuiltinName::GetImageArraySize, Dim - 1);
+        return ExtractElementInst::Create(NCI, getUInt32(M, I), "",
+                                          NCI->getNextNode());
+      },
+      &Attrs);
+}
+
+/// Remove trivial conversion functions
+bool OCL20ToSPIRV::eraseUselessConvert(CallInst *CI,
+                                       const std::string &MangledName,
+                                       const std::string &DemangledName) {
+  auto TargetTy = CI->getType();
+  auto SrcTy = CI->getArgOperand(0)->getType();
+  if (isa<VectorType>(TargetTy))
+    TargetTy = TargetTy->getVectorElementType();
+  if (isa<VectorType>(SrcTy))
+    SrcTy = SrcTy->getVectorElementType();
+  if (TargetTy == SrcTy) {
+    if (isa<IntegerType>(TargetTy) &&
+        DemangledName.find("_sat") != std::string::npos &&
+        isLastFuncParamSigned(MangledName) != (DemangledName[8] != 'u'))
+      return false;
+    CI->getArgOperand(0)->takeName(CI);
+    SPIRVDBG(dbgs() << "[regularizeOCLConvert] " << *CI << " <- "
+                    << *CI->getArgOperand(0) << '\n');
+    CI->replaceAllUsesWith(CI->getArgOperand(0));
+    ValuesToDelete.insert(CI);
+    ValuesToDelete.insert(CI->getCalledFunction());
+    return true;
+  }
+  return false;
+}
+
+void OCL20ToSPIRV::visitCallBuiltinSimple(CallInst *CI, StringRef MangledName,
+                                          const std::string &DemangledName) {
+  OCLBuiltinTransInfo Info;
+  Info.MangledName = MangledName.str();
+  Info.UniqName = DemangledName;
+  transBuiltin(CI, Info);
+}
+
+/// Translates OCL work-item builtin functions to SPIRV builtin variables.
+/// Function like get_global_id(i) -> x = load GlobalInvocationId; extract x, i
+/// Function like get_work_dim() -> load WorkDim
+void OCL20ToSPIRV::transWorkItemBuiltinsToVariables() {
+  DEBUG(dbgs() << "Enter transWorkItemBuiltinsToVariables\n");
+  std::vector<Function *> WorkList;
+  for (auto I = M->begin(), E = M->end(); I != E; ++I) {
+    std::string DemangledName;
+    if (!oclIsBuiltin(I->getName(), &DemangledName))
+      continue;
+    DEBUG(dbgs() << "Function demangled name: " << DemangledName << '\n');
+    std::string BuiltinVarName;
+    SPIRVBuiltinVariableKind BVKind;
+    if (!SPIRSPIRVBuiltinVariableMap::find(DemangledName, &BVKind))
+      continue;
+    BuiltinVarName =
+        std::string(kSPIRVName::Prefix) + SPIRVBuiltInNameMap::map(BVKind);
+    DEBUG(dbgs() << "builtin variable name: " << BuiltinVarName << '\n');
+    bool IsVec = I->getFunctionType()->getNumParams() > 0;
+    Type *GVType =
+        IsVec ? VectorType::get(I->getReturnType(), 3) : I->getReturnType();
+    auto BV = new GlobalVariable(
+        *M, GVType, true, GlobalValue::ExternalLinkage, nullptr, BuiltinVarName,
+        0, GlobalVariable::NotThreadLocal, SPIRAS_Constant);
+    std::vector<Instruction *> InstList;
+    for (auto UI = I->user_begin(), UE = I->user_end(); UI != UE; ++UI) {
+      auto CI = dyn_cast<CallInst>(*UI);
+      assert(CI && "invalid instruction");
+      Value *NewValue = new LoadInst(BV, "", CI);
+      DEBUG(dbgs() << "Transform: " << *CI << " => " << *NewValue << '\n');
+      if (IsVec) {
+        NewValue =
+            ExtractElementInst::Create(NewValue, CI->getArgOperand(0), "", CI);
+        DEBUG(dbgs() << *NewValue << '\n');
+      }
+      NewValue->takeName(CI);
+      CI->replaceAllUsesWith(NewValue);
+      InstList.push_back(CI);
+    }
+    for (auto &Inst : InstList) {
+      Inst->dropAllReferences();
+      Inst->removeFromParent();
+    }
+    WorkList.push_back(&*I);
+  }
+  for (auto &I : WorkList) {
+    I->dropAllReferences();
+    I->removeFromParent();
+  }
+}
+
+void OCL20ToSPIRV::visitCallReadWriteImage(CallInst *CI, StringRef MangledName,
+                                           const std::string &DemangledName) {
+  OCLBuiltinTransInfo Info;
+  if (DemangledName.find(kOCLBuiltinName::ReadImage) == 0)
+    Info.UniqName = kOCLBuiltinName::ReadImage;
+
+  if (DemangledName.find(kOCLBuiltinName::WriteImage) == 0) {
+    Info.UniqName = kOCLBuiltinName::WriteImage;
+    Info.PostProc = [&](std::vector<Value *> &Args) {
+      if (Args.size() == 4) // write with lod
+      {
+        auto Lod = Args[2];
+        Args.erase(Args.begin() + 2);
+        Args.push_back(getInt32(M, ImageOperandsMask::ImageOperandsLodMask));
+        Args.push_back(Lod);
+      }
+    };
+  }
+
+  transBuiltin(CI, Info);
+}
+
+void OCL20ToSPIRV::visitCallToAddr(CallInst *CI, StringRef MangledName,
+                                   const std::string &DemangledName) {
+  auto AddrSpace =
+      static_cast<SPIRAddressSpace>(CI->getType()->getPointerAddressSpace());
+  OCLBuiltinTransInfo Info;
+  Info.UniqName = DemangledName;
+  Info.Postfix = std::string(kSPIRVPostfix::Divider) + "To" +
+                 SPIRAddrSpaceCapitalizedNameMap::map(AddrSpace);
+  auto StorageClass = addInt32(SPIRSPIRVAddrSpaceMap::map(AddrSpace));
+  Info.RetTy = getInt8PtrTy(cast<PointerType>(CI->getType()));
+  Info.PostProc = [=](std::vector<Value *> &Ops) {
+    auto P = Ops.back();
+    Ops.pop_back();
+    Ops.push_back(castToInt8Ptr(P, CI));
+    Ops.push_back(StorageClass);
+  };
+  transBuiltin(CI, Info);
+}
+
+void OCL20ToSPIRV::visitCallRelational(CallInst *CI,
+                                       const std::string &DemangledName) {
+  AttributeSet Attrs = CI->getCalledFunction()->getAttributes();
+  Op OC = OpNop;
+  OCLSPIRVBuiltinMap::find(DemangledName, &OC);
+  std::string SPIRVName = getSPIRVFuncName(OC);
+  mutateCallInstSPIRV(
+      M, CI,
+      [=](CallInst *, std::vector<Value *> &Args, Type *&Ret) {
+        Ret = Type::getInt1Ty(*Ctx);
+        if (CI->getOperand(0)->getType()->isVectorTy())
+          Ret = VectorType::get(
+              Type::getInt1Ty(*Ctx),
+              CI->getOperand(0)->getType()->getVectorNumElements());
+        return SPIRVName;
+      },
+      [=](CallInst *NewCI) -> Instruction * {
+        Value *False = nullptr, *True = nullptr;
+        if (NewCI->getType()->isVectorTy()) {
+          Type *IntTy = Type::getInt32Ty(*Ctx);
+          if (cast<VectorType>(NewCI->getOperand(0)->getType())
+                  ->getElementType()
+                  ->isDoubleTy())
+            IntTy = Type::getInt64Ty(*Ctx);
+          if (cast<VectorType>(NewCI->getOperand(0)->getType())
+                  ->getElementType()
+                  ->isHalfTy())
+            IntTy = Type::getInt16Ty(*Ctx);
+          Type *VTy =
+              VectorType::get(IntTy, NewCI->getType()->getVectorNumElements());
+          False = Constant::getNullValue(VTy);
+          True = Constant::getAllOnesValue(VTy);
+        } else {
+          False = getInt32(M, 0);
+          True = getInt32(M, 1);
+        }
+        return SelectInst::Create(NewCI, True, False, "", NewCI->getNextNode());
+      },
+      &Attrs);
+}
+
+void OCL20ToSPIRV::visitCallVecLoadStore(CallInst *CI, StringRef MangledName,
+                                         const std::string &OrigDemangledName) {
+  std::vector<int> PreOps;
+  std::string DemangledName = OrigDemangledName;
+  if (DemangledName.find(kOCLBuiltinName::VLoadPrefix) == 0 &&
+      DemangledName != kOCLBuiltinName::VLoadHalf) {
+    SPIRVWord Width = getVecLoadWidth(DemangledName);
+    SPIRVDBG(spvdbgs() << "[visitCallVecLoadStore] DemangledName: "
+                       << DemangledName << " Width: " << Width << '\n');
+    PreOps.push_back(Width);
+  } else if (DemangledName.find(kOCLBuiltinName::RoundingPrefix) !=
+             std::string::npos) {
+    auto R = SPIRSPIRVFPRoundingModeMap::map(DemangledName.substr(
+        DemangledName.find(kOCLBuiltinName::RoundingPrefix) + 1, 3));
+    PreOps.push_back(R);
+  }
+
+  if (DemangledName.find(kOCLBuiltinName::VLoadAPrefix) == 0)
+    transVecLoadStoreName(DemangledName, kOCLBuiltinName::VLoadAPrefix, true);
+  else
+    transVecLoadStoreName(DemangledName, kOCLBuiltinName::VLoadPrefix, false);
+
+  if (DemangledName.find(kOCLBuiltinName::VStoreAPrefix) == 0)
+    transVecLoadStoreName(DemangledName, kOCLBuiltinName::VStoreAPrefix, true);
+  else
+    transVecLoadStoreName(DemangledName, kOCLBuiltinName::VStorePrefix, false);
+
+  auto Consts = getInt32(M, PreOps);
+  OCLBuiltinTransInfo Info;
+  Info.MangledName = MangledName;
+  Info.UniqName = DemangledName;
+  if (DemangledName.find(kOCLBuiltinName::VLoadPrefix) == 0)
+    Info.Postfix =
+        std::string(kSPIRVPostfix::ExtDivider) + getPostfixForReturnType(CI);
+  Info.PostProc = [=](std::vector<Value *> &Ops) {
+    Ops.insert(Ops.end(), Consts.begin(), Consts.end());
+  };
+  transBuiltin(CI, Info);
+}
+
+void OCL20ToSPIRV::visitCallGetFence(CallInst *CI, StringRef MangledName,
+                                     const std::string &DemangledName) {
+  AttributeSet Attrs = CI->getCalledFunction()->getAttributes();
+  Op OC = OpNop;
+  OCLSPIRVBuiltinMap::find(DemangledName, &OC);
+  std::string SPIRVName = getSPIRVFuncName(OC);
+  mutateCallInstSPIRV(M, CI, [=](CallInst *, std::vector<Value *> &Args,
+                                 Type *&Ret) { return SPIRVName; },
+                      [=](CallInst *NewCI) -> Instruction * {
+                        return BinaryOperator::CreateLShr(NewCI, getInt32(M, 8),
+                                                          "", CI);
+                      },
+                      &Attrs);
+}
+
+void OCL20ToSPIRV::visitCallDot(CallInst *CI) {
+  IRBuilder<> Builder(CI);
+  Value *FMulVal = Builder.CreateFMul(CI->getOperand(0), CI->getOperand(1));
+  CI->replaceAllUsesWith(FMulVal);
+  CI->dropAllReferences();
+  CI->removeFromParent();
+}
+
+void OCL20ToSPIRV::visitCallScalToVec(CallInst *CI, StringRef MangledName,
+                                      const std::string &DemangledName) {
+  // Check if all arguments have the same type - it's simple case.
+  auto Uniform = true;
+  auto IsArg0Vector = isa<VectorType>(CI->getOperand(0)->getType());
+  for (unsigned I = 1, E = CI->getNumArgOperands(); Uniform && (I != E); ++I) {
+    Uniform = isa<VectorType>(CI->getOperand(I)->getType()) == IsArg0Vector;
+  }
+  if (Uniform) {
+    visitCallBuiltinSimple(CI, MangledName, DemangledName);
+    return;
+  }
+
+  std::vector<unsigned int> VecPos;
+  std::vector<unsigned int> ScalarPos;
+  if (DemangledName == kOCLBuiltinName::FMin ||
+      DemangledName == kOCLBuiltinName::FMax ||
+      DemangledName == kOCLBuiltinName::FMod ||
+      DemangledName == kOCLBuiltinName::Min ||
+      DemangledName == kOCLBuiltinName::Max) {
+    VecPos.push_back(0);
+    ScalarPos.push_back(1);
+  } else if (DemangledName == kOCLBuiltinName::Clamp) {
+    VecPos.push_back(0);
+    ScalarPos.push_back(1);
+    ScalarPos.push_back(2);
+  } else if (DemangledName == kOCLBuiltinName::Mix) {
+    VecPos.push_back(0);
+    VecPos.push_back(1);
+    ScalarPos.push_back(2);
+  } else if (DemangledName == kOCLBuiltinName::Step) {
+    VecPos.push_back(1);
+    ScalarPos.push_back(0);
+  } else if (DemangledName == kOCLBuiltinName::SmoothStep) {
+    VecPos.push_back(2);
+    ScalarPos.push_back(0);
+    ScalarPos.push_back(1);
+  }
+
+  AttributeSet Attrs = CI->getCalledFunction()->getAttributes();
+  const auto ext_kind =
+      (SrcLang == spv::SourceLanguageOpenCL_C ? SPIRVEIS_OpenCL
+                                              : SPIRVEIS_GLSL);
+  mutateCallInstSPIRV(
+      M, CI,
+      [=](CallInst *, std::vector<Value *> &Args) {
+        Args.resize(VecPos.size() + ScalarPos.size());
+        for (auto I : VecPos) {
+          Args[I] = CI->getOperand(I);
+        }
+        auto VecArgWidth =
+            CI->getOperand(VecPos[0])->getType()->getVectorNumElements();
+        for (auto I : ScalarPos) {
+          Instruction *Inst = InsertElementInst::Create(
+              UndefValue::get(CI->getOperand(VecPos[0])->getType()),
+              CI->getOperand(I), getInt32(M, 0), "", CI);
+          Value *NewVec = new ShuffleVectorInst(
+              Inst, UndefValue::get(CI->getOperand(VecPos[0])->getType()),
+              ConstantVector::getSplat(VecArgWidth, getInt32(M, 0)), "", CI);
+
+          Args[I] = NewVec;
+        }
+        return getSPIRVExtFuncName(
+            ext_kind, getExtOp(MangledName, DemangledName, ext_kind));
+      },
+      &Attrs);
+}
+
+void OCL20ToSPIRV::visitCallGetImageChannel(CallInst *CI, StringRef MangledName,
+                                            const std::string &DemangledName,
+                                            unsigned int Offset) {
+  AttributeSet Attrs = CI->getCalledFunction()->getAttributes();
+  Op OC = OpNop;
+  OCLSPIRVBuiltinMap::find(DemangledName, &OC);
+  std::string SPIRVName = getSPIRVFuncName(OC);
+  mutateCallInstSPIRV(M, CI, [=](CallInst *, std::vector<Value *> &Args,
+                                 Type *&Ret) { return SPIRVName; },
+                      [=](CallInst *NewCI) -> Instruction * {
+                        return BinaryOperator::CreateAdd(
+                            NewCI, getInt32(M, Offset), "", CI);
+                      },
+                      &Attrs);
+}
+}
+
+INITIALIZE_PASS_BEGIN(OCL20ToSPIRV, "cl20tospv",
+                      "Transform OCL 2.0 / GLSL to SPIR-V", false, false)
+INITIALIZE_PASS_DEPENDENCY(OCLTypeToSPIRV)
+INITIALIZE_PASS_END(OCL20ToSPIRV, "cl20tospv",
+                    "Transform OCL 2.0 / GLSL to SPIR-V", false, false)
+
+ModulePass *llvm::createOCL20ToSPIRV() { return new OCL20ToSPIRV(); }
diff --git a/lib/SPIRV/OCL21ToSPIRV.cpp b/lib/SPIRV/OCL21ToSPIRV.cpp
new file mode 100644
index 0000000..bb78cc8
--- /dev/null
+++ b/lib/SPIRV/OCL21ToSPIRV.cpp
@@ -0,0 +1,241 @@
+//===- OCL21ToSPIRV.cpp - Transform OCL21 to SPIR-V builtins ----*- C++ -*-===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+//
+// This file implements translation of OCL21 builtin functions.
+//
+//===----------------------------------------------------------------------===//
+#define DEBUG_TYPE "cl21tospv"
+
+#include "SPIRVInternal.h"
+#include "OCLUtil.h"
+#include "llvm/ADT/StringSwitch.h"
+#include "llvm/IR/InstVisitor.h"
+#include "llvm/IR/Instructions.h"
+#include "llvm/IR/IRBuilder.h"
+#include "llvm/IR/Verifier.h"
+#include "llvm/Pass.h"
+#include "llvm/PassSupport.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/raw_ostream.h"
+
+#include <set>
+
+using namespace llvm;
+using namespace SPIRV;
+using namespace OCLUtil;
+
+namespace SPIRV {
+
+class OCL21ToSPIRV : public ModulePass, public InstVisitor<OCL21ToSPIRV> {
+public:
+  OCL21ToSPIRV() : ModulePass(ID), M(nullptr), Ctx(nullptr), CLVer(0) {
+    initializeOCL21ToSPIRVPass(*PassRegistry::getPassRegistry());
+  }
+  virtual bool runOnModule(Module &M);
+  virtual void visitCallInst(CallInst &CI);
+
+  /// Transform SPIR-V convert function
+  //    __spirv{N}Op{ConvertOpName}(src, dummy)
+  ///   =>
+  ///   __spirv_{ConvertOpName}_R{TargeTyName}
+  void visitCallConvert(CallInst *CI, StringRef MangledName, Op OC);
+
+  /// Transform SPIR-V decoration
+  ///   x = __spirv_{OpName};
+  ///   y = __spirv{N}Op{Decorate}(x, type, value, dummy)
+  ///   =>
+  ///   y = __spirv_{OpName}{Postfix(type,value)}
+  void visitCallDecorate(CallInst *CI, StringRef MangledName);
+
+  /// Transform sub_group_barrier to __spirv_ControlBarrier.
+  /// sub_group_barrier(scope, flag) =>
+  ///   __spirv_ControlBarrier(subgroup, map(scope), map(flag))
+  void visitCallSubGroupBarrier(CallInst *CI);
+
+  /// Transform OCL C++ builtin function to SPIR-V builtin function.
+  /// Assuming there is no argument changes.
+  /// Should be called at last.
+  void transBuiltin(CallInst *CI, Op OC);
+
+  static char ID;
+
+private:
+  ConstantInt *addInt32(int I) { return getInt32(M, I); }
+
+  Module *M;
+  LLVMContext *Ctx;
+  unsigned CLVer; /// OpenCL version as major*10+minor
+  std::set<Value *> ValuesToDelete;
+};
+
+char OCL21ToSPIRV::ID = 0;
+
+bool OCL21ToSPIRV::runOnModule(Module &Module) {
+  M = &Module;
+  Ctx = &M->getContext();
+
+  auto Src = getSPIRVSource(&Module);
+  if (std::get<0>(Src) != spv::SourceLanguageOpenCL_CPP)
+    return false;
+
+  CLVer = std::get<1>(Src);
+  if (CLVer < kOCLVer::CL21)
+    return false;
+
+  DEBUG(dbgs() << "Enter OCL21ToSPIRV:\n");
+  visit(*M);
+
+  for (auto &I : ValuesToDelete)
+    if (auto Inst = dyn_cast<Instruction>(I))
+      Inst->eraseFromParent();
+  for (auto &I : ValuesToDelete)
+    if (auto GV = dyn_cast<GlobalValue>(I))
+      GV->eraseFromParent();
+
+  DEBUG(dbgs() << "After OCL21ToSPIRV:\n" << *M);
+  std::string Err;
+  raw_string_ostream ErrorOS(Err);
+  if (verifyModule(*M, &ErrorOS)) {
+    DEBUG(errs() << "Fails to verify module: " << ErrorOS.str());
+  }
+  return true;
+}
+
+// The order of handling OCL builtin functions is important.
+// Workgroup functions need to be handled before pipe functions since
+// there are functions fall into both categories.
+void OCL21ToSPIRV::visitCallInst(CallInst &CI) {
+  DEBUG(dbgs() << "[visistCallInst] " << CI << '\n');
+  auto F = CI.getCalledFunction();
+  if (!F)
+    return;
+
+  auto MangledName = F->getName();
+  std::string DemangledName;
+
+  if (oclIsBuiltin(MangledName, &DemangledName)) {
+    if (DemangledName == kOCLBuiltinName::SubGroupBarrier) {
+      visitCallSubGroupBarrier(&CI);
+      return;
+    }
+  }
+
+  if (!oclIsBuiltin(MangledName, &DemangledName, true))
+    return;
+  DEBUG(dbgs() << "DemangledName:" << DemangledName << '\n');
+  StringRef Ref(DemangledName);
+
+  Op OC = OpNop;
+  if (!OpCodeNameMap::rfind(Ref.str(), &OC))
+    return;
+  DEBUG(dbgs() << "maps to opcode " << OC << '\n');
+
+  if (isCvtOpCode(OC)) {
+    visitCallConvert(&CI, MangledName, OC);
+    return;
+  }
+  if (OC == OpDecorate) {
+    visitCallDecorate(&CI, MangledName);
+    return;
+  }
+  transBuiltin(&CI, OC);
+}
+
+void OCL21ToSPIRV::visitCallConvert(CallInst *CI, StringRef MangledName,
+                                    Op OC) {
+  AttributeSet Attrs = CI->getCalledFunction()->getAttributes();
+  mutateCallInstSPIRV(
+      M, CI,
+      [=](CallInst *, std::vector<Value *> &Args) {
+        Args.pop_back();
+        return getSPIRVFuncName(
+            OC, kSPIRVPostfix::Divider +
+                    getPostfixForReturnType(CI, OC == OpSConvert ||
+                                                    OC == OpConvertFToS ||
+                                                    OC == OpSatConvertUToS));
+      },
+      &Attrs);
+  ValuesToDelete.insert(CI);
+  ValuesToDelete.insert(CI->getCalledFunction());
+}
+
+void OCL21ToSPIRV::visitCallDecorate(CallInst *CI, StringRef MangledName) {
+  auto Target = cast<CallInst>(CI->getArgOperand(0));
+  auto F = Target->getCalledFunction();
+  auto Name = F->getName().str();
+  std::string DemangledName;
+  oclIsBuiltin(Name, &DemangledName);
+  BuiltinFuncMangleInfo Info;
+  F->setName(mangleBuiltin(
+      DemangledName + kSPIRVPostfix::Divider +
+          getPostfix(getArgAsDecoration(CI, 1), getArgAsInt(CI, 2)),
+      getTypes(getArguments(CI)), &Info));
+  CI->replaceAllUsesWith(Target);
+  ValuesToDelete.insert(CI);
+  ValuesToDelete.insert(CI->getCalledFunction());
+}
+
+void OCL21ToSPIRV::visitCallSubGroupBarrier(CallInst *CI) {
+  DEBUG(dbgs() << "[visitCallSubGroupBarrier] " << *CI << '\n');
+  auto Lit = getBarrierLiterals(CI);
+  AttributeSet Attrs = CI->getCalledFunction()->getAttributes();
+  mutateCallInstSPIRV(M, CI,
+                      [=](CallInst *, std::vector<Value *> &Args) {
+                        Args.resize(3);
+                        Args[0] = addInt32(map<Scope>(std::get<2>(Lit)));
+                        Args[1] = addInt32(map<Scope>(std::get<1>(Lit)));
+                        Args[2] = addInt32(
+                            mapOCLMemFenceFlagToSPIRV(std::get<0>(Lit)));
+                        return getSPIRVFuncName(OpControlBarrier);
+                      },
+                      &Attrs);
+}
+
+void OCL21ToSPIRV::transBuiltin(CallInst *CI, Op OC) {
+  AttributeSet Attrs = CI->getCalledFunction()->getAttributes();
+  assert(OC != OpExtInst && "not supported");
+  mutateCallInstSPIRV(M, CI,
+                      [=](CallInst *, std::vector<Value *> &Args) {
+                        return getSPIRVFuncName(OC);
+                      },
+                      &Attrs);
+  ValuesToDelete.insert(CI);
+  ValuesToDelete.insert(CI->getCalledFunction());
+}
+}
+
+INITIALIZE_PASS(OCL21ToSPIRV, "cl21tospv", "Transform OCL 2.1 to SPIR-V", false,
+                false)
+
+ModulePass *llvm::createOCL21ToSPIRV() { return new OCL21ToSPIRV(); }
diff --git a/lib/SPIRV/OCLTypeToSPIRV.cpp b/lib/SPIRV/OCLTypeToSPIRV.cpp
new file mode 100644
index 0000000..f8b8387
--- /dev/null
+++ b/lib/SPIRV/OCLTypeToSPIRV.cpp
@@ -0,0 +1,342 @@
+//===- OCLTypeToSPIRV.cpp - Adapt types from OCL for SPIRV ------*- C++ -*-===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+//
+// This file implements adaptation of OCL types for SPIRV.
+//
+// It first maps kernel arguments of OCL opaque types to SPIR-V type, then
+// propagates the mapping to the uses of the kernel arguments.
+//
+//===----------------------------------------------------------------------===//
+#define DEBUG_TYPE "cltytospv"
+
+#include "OCLTypeToSPIRV.h"
+#include "SPIRVInternal.h"
+#include "OCLUtil.h"
+
+#include "llvm/Pass.h"
+#include "llvm/PassSupport.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/raw_ostream.h"
+
+#include <set>
+#include <iterator>
+
+using namespace llvm;
+using namespace SPIRV;
+using namespace OCLUtil;
+
+namespace SPIRV {
+
+char OCLTypeToSPIRV::ID = 0;
+
+OCLTypeToSPIRV::OCLTypeToSPIRV()
+    : ModulePass(ID), M(nullptr), Ctx(nullptr), CLVer(0) {
+  initializeOCLTypeToSPIRVPass(*PassRegistry::getPassRegistry());
+}
+
+void OCLTypeToSPIRV::getAnalysisUsage(AnalysisUsage &AU) const {
+  AU.setPreservesAll();
+}
+
+bool OCLTypeToSPIRV::runOnModule(Module &Module) {
+  DEBUG(dbgs() << "Enter OCLTypeToSPIRV:\n");
+  M = &Module;
+  Ctx = &M->getContext();
+  auto Src = getSPIRVSource(&Module);
+  if (std::get<0>(Src) != spv::SourceLanguageOpenCL_C)
+    return false;
+
+  for (auto &F : Module.functions())
+    adaptArgumentsByMetadata(&F);
+
+  adaptArgumentsBySamplerUse(Module);
+
+  while (!WorkSet.empty()) {
+    Function *F = *WorkSet.begin();
+    WorkSet.erase(WorkSet.begin());
+
+    adaptFunction(F);
+  }
+
+  return false;
+}
+
+void OCLTypeToSPIRV::addAdaptedType(Value *V, Type *T) {
+  DEBUG(dbgs() << "[add adapted type] "; V->printAsOperand(dbgs(), true, M);
+        dbgs() << " => " << *T << '\n');
+  AdaptedTy[V] = T;
+}
+
+void OCLTypeToSPIRV::addAdaptedType(Argument &A, Type *T) {
+  addAdaptedType(&A, T);
+}
+
+void OCLTypeToSPIRV::addWork(Function *F) {
+  DEBUG(dbgs() << "[add work] "; F->printAsOperand(dbgs(), true, M);
+        dbgs() << '\n');
+  WorkSet.insert(F);
+}
+
+/// Find index of \param V as argument of function call \param CI.
+static unsigned getArgIndex(CallInst *CI, Value *V) {
+  for (unsigned AI = 0, AE = CI->getNumArgOperands(); AI != AE; ++AI) {
+    if (CI->getArgOperand(AI) == V)
+      return AI;
+  }
+  llvm_unreachable("Not argument of function call");
+}
+
+/// Find index of \param V as argument of function call \param CI.
+static unsigned getArgIndex(Function *F, Value *V) {
+  auto A = F->arg_begin(), E = F->arg_end();
+  for (unsigned I = 0; A != E; ++I, ++A) {
+    if (&*A == &*V)
+      return I;
+  }
+  llvm_unreachable("Not argument of function");
+}
+
+/// Get i-th argument of a function.
+static Argument *getArg(Function *F, unsigned I) {
+  auto AI = F->arg_begin();
+  std::advance(AI, I);
+  return &*AI;
+}
+
+/// Create a new function type if \param F has arguments in AdaptedTy, and
+/// propagates the adapted arguments to functions called by \param F.
+void OCLTypeToSPIRV::adaptFunction(Function *F) {
+  DEBUG(dbgs() << "\n[work on function] "; F->printAsOperand(dbgs(), true, M);
+        dbgs() << '\n');
+  assert(AdaptedTy.count(F) == 0);
+
+  std::vector<Type *> ArgTys;
+  bool Changed = false;
+  for (auto &I : F->args()) {
+    auto Loc = AdaptedTy.find(&I);
+    auto Found = (Loc != AdaptedTy.end());
+    Changed |= Found;
+    ArgTys.push_back(Found ? Loc->second : I.getType());
+
+    if (Found) {
+      for (auto U : I.users()) {
+        if (auto CI = dyn_cast<CallInst>(U)) {
+          auto ArgIndex = getArgIndex(CI, &I);
+          auto CF = CI->getCalledFunction();
+          if (AdaptedTy.count(CF) == 0) {
+            addAdaptedType(getArg(CF, ArgIndex), Loc->second);
+            addWork(CF);
+          }
+        }
+      }
+    }
+  }
+
+  if (!Changed)
+    return;
+
+  auto FT = F->getFunctionType();
+  FT = FunctionType::get(FT->getReturnType(), ArgTys, FT->isVarArg());
+  addAdaptedType(F, FT);
+}
+
+MDNode *OCLTypeToSPIRV::getArgAccessQualifierMetadata(Function *F) {
+  return getArgMetadata(F, SPIR_MD_KERNEL_ARG_ACCESS_QUAL);
+}
+
+MDNode *OCLTypeToSPIRV::getKernelMetadata(Function *F) {
+  NamedMDNode *KernelMDs = M->getNamedMetadata(SPIR_MD_KERNELS);
+  if (!KernelMDs)
+    return nullptr;
+
+  for (unsigned I = 0, E = KernelMDs->getNumOperands(); I < E; ++I) {
+    MDNode *KernelMD = KernelMDs->getOperand(I);
+    if (KernelMD->getNumOperands() == 0)
+      continue;
+    Function *Kernel = mdconst::dyn_extract<Function>(KernelMD->getOperand(0));
+
+    if (Kernel == F)
+      return KernelMD;
+  }
+  return nullptr;
+}
+
+MDNode *OCLTypeToSPIRV::getArgMetadata(Function *F, const std::string &MDName) {
+  auto KernelMD = getKernelMetadata(F);
+  if (!KernelMD)
+    return nullptr;
+
+  for (unsigned MI = 1, ME = KernelMD->getNumOperands(); MI < ME; ++MI) {
+    MDNode *MD = dyn_cast<MDNode>(KernelMD->getOperand(MI));
+    if (!MD)
+      continue;
+    MDString *NameMD = dyn_cast<MDString>(MD->getOperand(0));
+    if (!NameMD)
+      continue;
+    StringRef Name = NameMD->getString();
+    if (Name == MDName) {
+      return MD;
+    }
+  }
+  return nullptr;
+}
+
+MDNode *OCLTypeToSPIRV::getArgBaseTypeMetadata(Function *F) {
+  return getArgMetadata(F, SPIR_MD_KERNEL_ARG_BASE_TYPE);
+}
+
+// Handle functions with sampler arguments that don't get called by
+// a kernel function.
+void OCLTypeToSPIRV::adaptArgumentsBySamplerUse(Module &M) {
+  SmallPtrSet<Function *, 5> Processed;
+
+  std::function<void(Function *, unsigned)> TraceArg = [&](Function *F,
+                                                           unsigned Idx) {
+    // If we have cycles in the call graph in the future, bail out
+    // if we've already processed this function.
+    if (Processed.insert(F).second == false)
+      return;
+
+    for (auto U : F->users()) {
+      auto *CI = dyn_cast<CallInst>(U);
+      if (!CI)
+        continue;
+
+      auto SamplerArg = CI->getArgOperand(Idx);
+      if (!isa<Argument>(SamplerArg) ||
+          AdaptedTy.count(SamplerArg) != 0) // Already traced this, move on.
+        continue;
+
+      if (isSPIRVType(SamplerArg->getType(), kSPIRVTypeName::Sampler))
+        return;
+
+      addAdaptedType(SamplerArg, getSamplerType(&M));
+      auto Caller = cast<Argument>(SamplerArg)->getParent();
+      addWork(Caller);
+      TraceArg(Caller, getArgIndex(Caller, SamplerArg));
+    }
+  };
+
+  for (auto &F : M) {
+    if (!F.empty()) // not decl
+      continue;
+    auto MangledName = F.getName();
+    std::string DemangledName;
+    if (!oclIsBuiltin(MangledName, &DemangledName, false))
+      continue;
+    if (DemangledName.find(kSPIRVName::SampledImage) == std::string::npos)
+      continue;
+
+    TraceArg(&F, 1);
+  }
+}
+
+/// Go through all kernel functions, get access qualifier for image and pipe
+/// types and use them to map the function arguments to the SPIR-V type.
+/// ToDo: Map other OpenCL opaque types to SPIR-V types.
+void OCLTypeToSPIRV::adaptArgumentsByMetadata(Function *F) {
+  auto TypeMD = getArgBaseTypeMetadata(F);
+  if (!TypeMD)
+    return;
+  bool Changed = false;
+  auto FT = F->getFunctionType();
+  auto PI = FT->param_begin();
+  auto Arg = F->arg_begin();
+  for (unsigned I = 1, E = TypeMD->getNumOperands(); I != E; ++I, ++PI, ++Arg) {
+    auto OCLTyStr = getMDOperandAsString(TypeMD, I);
+    auto NewTy = *PI;
+    if (OCLTyStr == OCL_TYPE_NAME_SAMPLER_T && !NewTy->isStructTy()) {
+      addAdaptedType(*Arg, getSamplerType(M));
+      Changed = true;
+    } else if (isPointerToOpaqueStructType(NewTy)) {
+      auto STName = NewTy->getPointerElementType()->getStructName();
+      if (STName.startswith(kSPR2TypeName::ImagePrefix) ||
+          STName == kSPR2TypeName::Pipe) {
+        auto Ty = STName.str();
+        auto AccMD = getArgAccessQualifierMetadata(F);
+        assert(AccMD && "Invalid access qualifier metadata");
+        auto AccStr = getMDOperandAsString(AccMD, I);
+        addAdaptedType(*Arg, getOrCreateOpaquePtrType(
+                                 M, mapOCLTypeNameToSPIRV(Ty, AccStr)));
+        Changed = true;
+      }
+    }
+  }
+  if (Changed)
+    addWork(F);
+}
+
+// OCL sampler, image and pipe type need to be regularized before converting
+// to SPIRV types.
+//
+// OCL sampler type is represented as i32 in LLVM, however in SPIRV it is
+// represented as OpTypeSampler. Also LLVM uses the same pipe type to
+// represent pipe types with different underlying data types, however
+// in SPIRV they are different types. OCL image and pipie types do not
+// encode access qualifier, which is part of SPIRV types for image and pipe.
+//
+// The function types in LLVM need to be regularized before translating
+// to SPIRV function types:
+//
+// sampler type as i32 -> opencl.sampler_t opaque type
+// opencl.pipe_t opaque type with underlying opencl type x and access
+//   qualifier y -> opencl.pipe_t.x.y opaque type
+// opencl.image_x opaque type with access qualifier y ->
+//   opencl.image_x.y opaque type
+//
+// The converter relies on kernel_arg_base_type to identify the sampler
+// type, the underlying data type of pipe type, and access qualifier for
+// image and pipe types. The FE is responsible to generate the correct
+// kernel_arg_base_type metadata.
+//
+// Alternatively,the FE may choose to use opencl.sampler_t to represent
+// sampler type, use opencl.pipe_t.x.y to represent pipe type with underlying
+// opencl data type x and access qualifier y, and use opencl.image_x.y to
+// represent image_x type with access qualifier y.
+//
+Type *OCLTypeToSPIRV::getAdaptedType(Value *V) {
+  auto Loc = AdaptedTy.find(V);
+  if (Loc != AdaptedTy.end())
+    return Loc->second;
+
+  if (auto F = dyn_cast<Function>(V))
+    return F->getFunctionType();
+  return V->getType();
+}
+}
+
+INITIALIZE_PASS(OCLTypeToSPIRV, "cltytospv", "Adapt OCL types for SPIR-V",
+                false, true)
+
+ModulePass *llvm::createOCLTypeToSPIRV() { return new OCLTypeToSPIRV(); }
diff --git a/lib/SPIRV/OCLTypeToSPIRV.h b/lib/SPIRV/OCLTypeToSPIRV.h
new file mode 100644
index 0000000..c8a22f7
--- /dev/null
+++ b/lib/SPIRV/OCLTypeToSPIRV.h
@@ -0,0 +1,85 @@
+//===- OCLTypeToSPIRV.h - Adapt types from OCL for SPIRV --------*- C++ -*-===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+//
+// This file implements adaptation of OCL types for SPIRV. It does not modify
+// the module. Instead, it returns adapted function type based on kernel
+// argument metadata. Later LLVM/SPIRV translator will translate the adapted
+// type instead of the original type.
+//
+//===----------------------------------------------------------------------===//
+#include "llvm/Support/SPIRV.h"
+#include "llvm/Pass.h"
+#include "llvm/IR/LLVMContext.h"
+#include "llvm/IR/Function.h"
+
+#include <map>
+#include <set>
+
+using namespace llvm;
+
+namespace SPIRV {
+
+class OCLTypeToSPIRV : public ModulePass {
+public:
+  OCLTypeToSPIRV();
+  virtual void getAnalysisUsage(AnalysisUsage &AU) const;
+  virtual bool runOnModule(Module &M);
+
+  /// \return Adapted type based on kernel argument metadata. If \p V is
+  ///   a function, returns function type.
+  /// E.g. for a function with argument of read only opencl.image_2d_t* type
+  /// returns a function with argument of type opencl.image2d_t.read_only*.
+  Type *getAdaptedType(Value *V);
+
+  static char ID;
+
+private:
+  Module *M;
+  LLVMContext *Ctx;
+  unsigned CLVer;
+  std::map<Value *, Type *> AdaptedTy; // Adapted types for values
+  std::set<Function *> WorkSet;        // Functions to be adapted
+
+  MDNode *getArgBaseTypeMetadata(Function *);
+  MDNode *getArgAccessQualifierMetadata(Function *);
+  MDNode *getArgMetadata(Function *, const std::string &MDName);
+  MDNode *getKernelMetadata(Function *F);
+  void adaptArgumentsByMetadata(Function *F);
+  void adaptArgumentsBySamplerUse(Module &M);
+  void adaptFunction(Function *F);
+  void addAdaptedType(Value *V, Type *T);
+  void addAdaptedType(Argument &A, Type *T);
+  void addWork(Function *F);
+};
+}
diff --git a/lib/SPIRV/OCLUtil.cpp b/lib/SPIRV/OCLUtil.cpp
new file mode 100644
index 0000000..fad2177
--- /dev/null
+++ b/lib/SPIRV/OCLUtil.cpp
@@ -0,0 +1,617 @@
+//===- OCLUtil.cpp - OCL Utilities ----------------------------------------===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+//
+// This file implements OCL utility functions.
+//
+//===----------------------------------------------------------------------===//
+#define DEBUG_TYPE "oclutil"
+
+#include "SPIRVInternal.h"
+#include "OCLUtil.h"
+#include "SPIRVEntry.h"
+#include "SPIRVFunction.h"
+#include "SPIRVInstruction.h"
+#include "llvm/ADT/StringSwitch.h"
+#include "llvm/IR/InstVisitor.h"
+#include "llvm/IR/Instructions.h"
+#include "llvm/IR/IRBuilder.h"
+#include "llvm/IR/Verifier.h"
+#include "llvm/Pass.h"
+#include "llvm/PassSupport.h"
+#include "llvm/Support/CommandLine.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/raw_ostream.h"
+
+using namespace llvm;
+using namespace SPIRV;
+
+namespace OCLUtil {
+
+#ifndef SPIRV_OCL_SPECIAL_TYPES_DEFAULT_ADDR_SPACE
+#define SPIRV_OCL_SPECIAL_TYPES_DEFAULT_ADDR_SPACE SPIRAS_Private
+#endif
+
+#ifndef SPIRV_QUEUE_T_ADDR_SPACE
+#define SPIRV_QUEUE_T_ADDR_SPACE SPIRV_OCL_SPECIAL_TYPES_DEFAULT_ADDR_SPACE
+#endif
+
+#ifndef SPIRV_EVENT_T_ADDR_SPACE
+#define SPIRV_EVENT_T_ADDR_SPACE SPIRV_OCL_SPECIAL_TYPES_DEFAULT_ADDR_SPACE
+#endif
+
+#ifndef SPIRV_CLK_EVENT_T_ADDR_SPACE
+#define SPIRV_CLK_EVENT_T_ADDR_SPACE SPIRV_OCL_SPECIAL_TYPES_DEFAULT_ADDR_SPACE
+#endif
+
+#ifndef SPIRV_RESERVE_ID_T_ADDR_SPACE
+#define SPIRV_RESERVE_ID_T_ADDR_SPACE SPIRV_OCL_SPECIAL_TYPES_DEFAULT_ADDR_SPACE
+#endif
+// Excerpt from SPIR 2.0 spec.:
+//   Pipe objects are represented using pointers to the opaque %opencl.pipe LLVM
+//   structure type
+//   which reside in the global address space.
+#ifndef SPIRV_PIPE_ADDR_SPACE
+#define SPIRV_PIPE_ADDR_SPACE SPIRAS_Global
+#endif
+// Excerpt from SPIR 2.0 spec.:
+//   Note: Images data types reside in global memory and hence should be marked
+//   as such in the
+//   "kernel arg addr space" metadata.
+#ifndef SPIRV_IMAGE_ADDR_SPACE
+#define SPIRV_IMAGE_ADDR_SPACE SPIRAS_Global
+#endif
+
+///////////////////////////////////////////////////////////////////////////////
+//
+// Functions for getting builtin call info
+//
+///////////////////////////////////////////////////////////////////////////////
+AtomicWorkItemFenceLiterals getAtomicWorkItemFenceLiterals(CallInst *CI) {
+  return std::make_tuple(getArgAsInt(CI, 0),
+                         static_cast<OCLMemOrderKind>(getArgAsInt(CI, 1)),
+                         static_cast<OCLScopeKind>(getArgAsInt(CI, 2)));
+}
+
+size_t getAtomicBuiltinNumMemoryOrderArgs(StringRef Name) {
+  if (Name.startswith("atomic_compare_exchange"))
+    return 2;
+  return 1;
+}
+
+BarrierLiterals getBarrierLiterals(CallInst *CI) {
+  auto N = CI->getNumArgOperands();
+  assert(N == 1 || N == 2);
+
+  std::string DemangledName;
+  if (!oclIsBuiltin(CI->getCalledFunction()->getName(), &DemangledName)) {
+    assert(0 &&
+           "call must a builtin (work_group_barrier or sub_group_barrier)");
+  }
+
+  OCLScopeKind scope = OCLMS_work_group;
+  if (DemangledName == kOCLBuiltinName::SubGroupBarrier) {
+    scope = OCLMS_sub_group;
+  }
+
+  return std::make_tuple(getArgAsInt(CI, 0),
+                         N == 1 ? OCLMS_work_group
+                                : static_cast<OCLScopeKind>(getArgAsInt(CI, 1)),
+                         scope);
+}
+
+unsigned getExtOp(StringRef OrigName, const std::string &GivenDemangledName,
+                  SPIRVExtInstSetKind ext_kind) {
+  std::string DemangledName = GivenDemangledName;
+  if (!oclIsBuiltin(OrigName, DemangledName.empty() ? &DemangledName : nullptr))
+    return ~0U;
+  DEBUG(dbgs() << "getExtOp: demangled name: " << DemangledName << '\n');
+  if (ext_kind == SPIRVExtInstSetKind::SPIRVEIS_OpenCL) {
+    OCLExtOpKind EOC;
+    bool Found = OCLExtOpMap::rfind(DemangledName, &EOC);
+    if (!Found) {
+      std::string Prefix;
+      switch (LastFuncParamType(OrigName)) {
+      case ParamType::UNSIGNED:
+        Prefix = "u_";
+        break;
+      case ParamType::SIGNED:
+        Prefix = "s_";
+        break;
+      case ParamType::FLOAT:
+        Prefix = "f";
+        break;
+      default:
+        llvm_unreachable("unknown mangling!");
+      }
+      Found = OCLExtOpMap::rfind(Prefix + DemangledName, &EOC);
+    }
+    if (Found)
+      return EOC;
+    else
+      return ~0U;
+  } else if (ext_kind == SPIRVExtInstSetKind::SPIRVEIS_GLSL) {
+    GLSLExtOpKind EGLSL;
+    bool Found = GLSLExtOpMap::rfind(DemangledName, &EGLSL);
+    if (!Found) {
+      std::string Prefix;
+      switch (LastFuncParamType(OrigName)) {
+      case ParamType::UNSIGNED:
+        Prefix = "u_";
+        break;
+      case ParamType::SIGNED:
+        Prefix = "s_";
+        break;
+      case ParamType::FLOAT:
+        Prefix = "f";
+        break;
+      default:
+        llvm_unreachable("unknown mangling!");
+      }
+      Found = GLSLExtOpMap::rfind(Prefix + DemangledName, &EGLSL);
+    }
+    if (Found)
+      return EGLSL;
+    else
+      return ~0U;
+  }
+  llvm_unreachable("invalid ext set");
+}
+
+///////////////////////////////////////////////////////////////////////////////
+//
+// Functions for getting module info
+//
+///////////////////////////////////////////////////////////////////////////////
+
+unsigned encodeOCLVer(unsigned short Major, unsigned char Minor,
+                      unsigned char Rev) {
+  return (Major * 100 + Minor) * 1000 + Rev;
+}
+
+std::tuple<unsigned short, unsigned char, unsigned char>
+decodeOCLVer(unsigned Ver) {
+  unsigned short Major = Ver / 100000;
+  unsigned char Minor = (Ver % 100000) / 1000;
+  unsigned char Rev = Ver % 1000;
+  return std::make_tuple(Major, Minor, Rev);
+}
+
+unsigned getOCLVersion(Module *M, bool AllowMulti) {
+  NamedMDNode *NamedMD = M->getNamedMetadata(kSPIR2MD::OCLVer);
+  if (!NamedMD)
+    return 0;
+  assert(NamedMD->getNumOperands() > 0 && "Invalid SPIR");
+  if (!AllowMulti && NamedMD->getNumOperands() != 1)
+    report_fatal_error("Multiple OCL version metadata not allowed");
+
+  // If the module was linked with another module, there may be multiple
+  // operands.
+  auto getVer = [=](unsigned I) {
+    auto MD = NamedMD->getOperand(I);
+    return std::make_pair(getMDOperandAsInt(MD, 0), getMDOperandAsInt(MD, 1));
+  };
+  auto Ver = getVer(0);
+  for (unsigned I = 1, E = NamedMD->getNumOperands(); I != E; ++I)
+    if (Ver != getVer(I))
+      report_fatal_error("OCL version mismatch");
+
+  return encodeOCLVer(Ver.first, Ver.second, 0);
+}
+
+void decodeMDNode(MDNode *N, unsigned &X, unsigned &Y, unsigned &Z) {
+  if (N == NULL)
+    return;
+  X = getMDOperandAsInt(N, 1);
+  Y = getMDOperandAsInt(N, 2);
+  Z = getMDOperandAsInt(N, 3);
+}
+
+/// Encode LLVM type by SPIR-V execution mode VecTypeHint
+unsigned encodeVecTypeHint(Type *Ty) {
+  if (Ty->isHalfTy())
+    return 4;
+  if (Ty->isFloatTy())
+    return 5;
+  if (Ty->isDoubleTy())
+    return 6;
+  if (IntegerType *intTy = dyn_cast<IntegerType>(Ty)) {
+    switch (intTy->getIntegerBitWidth()) {
+    case 8:
+      return 0;
+    case 16:
+      return 1;
+    case 32:
+      return 2;
+    case 64:
+      return 3;
+    default:
+      llvm_unreachable("invalid integer type");
+    }
+  }
+  if (VectorType *VecTy = dyn_cast<VectorType>(Ty)) {
+    Type *EleTy = VecTy->getElementType();
+    unsigned Size = VecTy->getVectorNumElements();
+    return Size << 16 | encodeVecTypeHint(EleTy);
+  }
+  llvm_unreachable("invalid type");
+}
+
+Type *decodeVecTypeHint(LLVMContext &C, unsigned code) {
+  unsigned VecWidth = code >> 16;
+  unsigned Scalar = code & 0xFFFF;
+  Type *ST = nullptr;
+  switch (Scalar) {
+  case 0:
+  case 1:
+  case 2:
+  case 3:
+    ST = IntegerType::get(C, 1 << (3 + Scalar));
+    break;
+  case 4:
+    ST = Type::getHalfTy(C);
+    break;
+  case 5:
+    ST = Type::getFloatTy(C);
+    break;
+  case 6:
+    ST = Type::getDoubleTy(C);
+    break;
+  default:
+    llvm_unreachable("Invalid vec type hint");
+  }
+  if (VecWidth < 1)
+    return ST;
+  return VectorType::get(ST, VecWidth);
+}
+
+unsigned transVecTypeHint(MDNode *Node) {
+  return encodeVecTypeHint(getMDOperandAsType(Node, 1));
+}
+
+SPIRAddressSpace getOCLOpaqueTypeAddrSpace(Op OpCode) {
+  switch (OpCode) {
+  case OpTypeQueue:
+    return SPIRV_QUEUE_T_ADDR_SPACE;
+  case OpTypeEvent:
+    return SPIRV_EVENT_T_ADDR_SPACE;
+  case OpTypeDeviceEvent:
+    return SPIRV_CLK_EVENT_T_ADDR_SPACE;
+  case OpTypeReserveId:
+    return SPIRV_RESERVE_ID_T_ADDR_SPACE;
+  case OpTypePipe:
+  case OpTypePipeStorage:
+    return SPIRV_PIPE_ADDR_SPACE;
+  case OpTypeImage:
+  case OpTypeSampledImage:
+    return SPIRV_IMAGE_ADDR_SPACE;
+  default:
+    assert(false && "No address space is determined for some OCL type");
+    return SPIRV_OCL_SPECIAL_TYPES_DEFAULT_ADDR_SPACE;
+  }
+}
+
+static SPIR::TypeAttributeEnum mapAddrSpaceEnums(SPIRAddressSpace addrspace) {
+  switch (addrspace) {
+  case SPIRAS_Private:
+    return SPIR::ATTR_PRIVATE;
+  case SPIRAS_Global:
+    return SPIR::ATTR_GLOBAL;
+  case SPIRAS_Constant:
+    return SPIR::ATTR_CONSTANT;
+  case SPIRAS_Local:
+    return SPIR::ATTR_LOCAL;
+  case SPIRAS_Generic:
+    return SPIR::ATTR_GENERIC;
+  default:
+    llvm_unreachable("Invalid addrspace enum member");
+  }
+}
+
+SPIR::TypeAttributeEnum
+getOCLOpaqueTypeAddrSpace(SPIR::TypePrimitiveEnum prim) {
+  switch (prim) {
+  case SPIR::PRIMITIVE_QUEUE_T:
+    return mapAddrSpaceEnums(SPIRV_QUEUE_T_ADDR_SPACE);
+  case SPIR::PRIMITIVE_EVENT_T:
+    return mapAddrSpaceEnums(SPIRV_EVENT_T_ADDR_SPACE);
+  case SPIR::PRIMITIVE_CLK_EVENT_T:
+    return mapAddrSpaceEnums(SPIRV_CLK_EVENT_T_ADDR_SPACE);
+  case SPIR::PRIMITIVE_RESERVE_ID_T:
+    return mapAddrSpaceEnums(SPIRV_RESERVE_ID_T_ADDR_SPACE);
+  case SPIR::PRIMITIVE_PIPE_T:
+    return mapAddrSpaceEnums(SPIRV_PIPE_ADDR_SPACE);
+  case SPIR::PRIMITIVE_IMAGE_1D_T:
+  case SPIR::PRIMITIVE_IMAGE_1D_ARRAY_T:
+  case SPIR::PRIMITIVE_IMAGE_1D_BUFFER_T:
+  case SPIR::PRIMITIVE_IMAGE_2D_T:
+  case SPIR::PRIMITIVE_IMAGE_2D_ARRAY_T:
+  case SPIR::PRIMITIVE_IMAGE_3D_T:
+  case SPIR::PRIMITIVE_IMAGE_2D_MSAA_T:
+  case SPIR::PRIMITIVE_IMAGE_2D_ARRAY_MSAA_T:
+  case SPIR::PRIMITIVE_IMAGE_2D_MSAA_DEPTH_T:
+  case SPIR::PRIMITIVE_IMAGE_2D_ARRAY_MSAA_DEPTH_T:
+  case SPIR::PRIMITIVE_IMAGE_2D_DEPTH_T:
+  case SPIR::PRIMITIVE_IMAGE_2D_ARRAY_DEPTH_T:
+  case SPIR::PRIMITIVE_IMAGE_CUBE_T:
+  case SPIR::PRIMITIVE_IMAGE_CUBE_ARRAY_T:
+  case SPIR::PRIMITIVE_IMAGE_CUBE_DEPTH_T:
+  case SPIR::PRIMITIVE_IMAGE_CUBE_ARRAY_DEPTH_T:
+    return mapAddrSpaceEnums(SPIRV_IMAGE_ADDR_SPACE);
+  default:
+    llvm_unreachable("No address space is determined for a SPIR primitive");
+  }
+}
+
+// Fetch type of invoke function passed to device execution built-ins
+static FunctionType *getBlockInvokeTy(Function *F, unsigned blockIdx) {
+  auto params = F->getFunctionType()->params();
+  PointerType *funcPtr = cast<PointerType>(params[blockIdx]);
+  return cast<FunctionType>(funcPtr->getElementType());
+}
+
+class OCLBuiltinFuncMangleInfo : public SPIRV::BuiltinFuncMangleInfo {
+public:
+  OCLBuiltinFuncMangleInfo(Function *f) : F(f) {}
+  void init(const std::string &UniqName) {
+    UnmangledName = UniqName;
+    size_t Pos = std::string::npos;
+
+    if (UnmangledName.find("async_work_group") == 0) {
+      addUnsignedArg(-1);
+      setArgAttr(1, SPIR::ATTR_CONST);
+    } else if (UnmangledName.find("write_imageui") == 0)
+      addUnsignedArg(2);
+    else if (UnmangledName == "prefetch") {
+      addUnsignedArg(1);
+      setArgAttr(0, SPIR::ATTR_CONST);
+    } else if (UnmangledName == "get_kernel_work_group_size" ||
+               UnmangledName ==
+                   "get_kernel_preferred_work_group_size_multiple") {
+      assert(F && "lack of necessary information");
+      const size_t blockArgIdx = 0;
+      FunctionType *InvokeTy = getBlockInvokeTy(F, blockArgIdx);
+      if (InvokeTy->getNumParams() > 1)
+        setLocalArgBlock(blockArgIdx);
+    } else if (UnmangledName == "enqueue_kernel") {
+      assert(F && "lack of necessary information");
+      setEnumArg(1, SPIR::PRIMITIVE_KERNEL_ENQUEUE_FLAGS_T);
+      addUnsignedArg(3);
+      setArgAttr(4, SPIR::ATTR_CONST);
+      // If there are arguments other then block context then these are pointers
+      // to local memory so this built-in must be mangled accordingly.
+      const size_t blockArgIdx = 6;
+      FunctionType *InvokeTy = getBlockInvokeTy(F, blockArgIdx);
+      if (InvokeTy->getNumParams() > 1) {
+        setLocalArgBlock(blockArgIdx);
+        addUnsignedArg(blockArgIdx + 1);
+        setVarArg(blockArgIdx + 2);
+      }
+    } else if (UnmangledName.find("get_") == 0 || UnmangledName == "nan" ||
+               UnmangledName == "mem_fence" ||
+               UnmangledName.find("shuffle") == 0) {
+      addUnsignedArg(-1);
+      if (UnmangledName.find(kOCLBuiltinName::GetFence) == 0) {
+        setArgAttr(0, SPIR::ATTR_CONST);
+        addVoidPtrArg(0);
+      }
+    } else if (UnmangledName.find("barrier") == 0 ||
+               UnmangledName.find("work_group_barrier") == 0 ||
+               UnmangledName.find("sub_group_barrier") == 0) {
+      addUnsignedArg(0);
+    } else if (UnmangledName.find("atomic_work_item_fence") == 0) {
+      addUnsignedArg(0);
+    } else if (UnmangledName.find("atomic") == 0) {
+      setArgAttr(0, SPIR::ATTR_VOLATILE);
+      if (UnmangledName.find("atomic_umax") == 0 ||
+          UnmangledName.find("atomic_umin") == 0) {
+        addUnsignedArg(0);
+        addUnsignedArg(1);
+        UnmangledName.erase(7, 1);
+      } else if (UnmangledName.find("atomic_fetch_umin") == 0 ||
+                 UnmangledName.find("atomic_fetch_umax") == 0) {
+        addUnsignedArg(0);
+        addUnsignedArg(1);
+        UnmangledName.erase(13, 1);
+      }
+      // Don't set atomic property to the first argument of 1.2 atomic
+      // built-ins.
+      if (UnmangledName.find("atomic_add") != 0 &&
+          UnmangledName.find("atomic_sub") != 0 &&
+          UnmangledName.find("atomic_xchg") != 0 &&
+          UnmangledName.find("atomic_inc") != 0 &&
+          UnmangledName.find("atomic_dec") != 0 &&
+          UnmangledName.find("atomic_cmpxchg") != 0 &&
+          UnmangledName.find("atomic_min") != 0 &&
+          UnmangledName.find("atomic_max") != 0 &&
+          UnmangledName.find("atomic_and") != 0 &&
+          UnmangledName.find("atomic_or") != 0 &&
+          UnmangledName.find("atomic_xor") != 0 &&
+          UnmangledName.find("atom_") != 0) {
+        addAtomicArg(0);
+      }
+
+    } else if (UnmangledName.find("uconvert_") == 0) {
+      addUnsignedArg(0);
+      UnmangledName.erase(0, 1);
+    } else if (UnmangledName.find("s_") == 0) {
+      UnmangledName.erase(0, 2);
+    } else if (UnmangledName.find("u_") == 0) {
+      addUnsignedArg(-1);
+      UnmangledName.erase(0, 2);
+    } else if (UnmangledName == "fclamp") {
+      UnmangledName.erase(0, 1);
+    } else if (UnmangledName == "read_pipe" || UnmangledName == "write_pipe") {
+      assert(F && "lack of necessary information");
+      // handle [read|write]pipe builtins (plus two i32 literal args
+      // required by SPIR 2.0 provisional specification):
+      if (F->getArgumentList().size() == 6) {
+        // with 4 arguments (plus two i32 literals):
+        // int read_pipe (read_only pipe gentype p, reserve_id_t reserve_id,
+        // uint index, gentype *ptr)
+        // int write_pipe (write_only pipe gentype p, reserve_id_t reserve_id,
+        // uint index, const gentype *ptr)
+        addUnsignedArg(2);
+        addVoidPtrArg(3);
+        addUnsignedArg(4);
+        addUnsignedArg(5);
+      } else if (F->getArgumentList().size() == 4) {
+        // with 2 arguments (plus two i32 literals):
+        // int read_pipe (read_only pipe gentype p, gentype *ptr)
+        // int write_pipe (write_only pipe gentype p, const gentype *ptr)
+        addVoidPtrArg(1);
+        addUnsignedArg(2);
+        addUnsignedArg(3);
+      } else {
+        llvm_unreachable(
+            "read/write pipe builtin with unexpected number of arguments");
+      }
+    } else if (UnmangledName.find("reserve_read_pipe") != std::string::npos ||
+               UnmangledName.find("reserve_write_pipe") != std::string::npos) {
+      // process [|work_group|sub_group]reserve[read|write]pipe builtins
+      addUnsignedArg(1);
+      addUnsignedArg(2);
+      addUnsignedArg(3);
+    } else if (UnmangledName.find("commit_read_pipe") != std::string::npos ||
+               UnmangledName.find("commit_write_pipe") != std::string::npos) {
+      // process [|work_group|sub_group]commit[read|write]pipe builtins
+      addUnsignedArg(2);
+      addUnsignedArg(3);
+    } else if (UnmangledName == "capture_event_profiling_info") {
+      addVoidPtrArg(2);
+      setEnumArg(1, SPIR::PRIMITIVE_CLK_PROFILING_INFO);
+    } else if (UnmangledName == "enqueue_marker") {
+      setArgAttr(2, SPIR::ATTR_CONST);
+      addUnsignedArg(1);
+    } else if (UnmangledName.find("vload") == 0) {
+      addUnsignedArg(0);
+      setArgAttr(1, SPIR::ATTR_CONST);
+    } else if (UnmangledName.find("vstore") == 0) {
+      addUnsignedArg(1);
+    } else if (UnmangledName.find("ndrange_") == 0) {
+      addUnsignedArg(-1);
+      if (UnmangledName[8] == '2' || UnmangledName[8] == '3') {
+        setArgAttr(-1, SPIR::ATTR_CONST);
+      }
+    } else if ((Pos = UnmangledName.find("umax")) != std::string::npos ||
+               (Pos = UnmangledName.find("umin")) != std::string::npos) {
+      addUnsignedArg(-1);
+      UnmangledName.erase(Pos, 1);
+    } else if (UnmangledName.find("broadcast") != std::string::npos)
+      addUnsignedArg(-1);
+    else if (UnmangledName.find(kOCLBuiltinName::SampledReadImage) == 0) {
+      UnmangledName.erase(0, strlen(kOCLBuiltinName::Sampled));
+      addSamplerArg(1);
+    }
+  }
+  // Auxiliarry information, it is expected what it is relevant at the moment
+  // the init method is called.
+  Function *F; // SPIRV decorated function
+};
+
+CallInst *mutateCallInstOCL(
+    Module *M, CallInst *CI,
+    std::function<std::string(CallInst *, std::vector<Value *> &)> ArgMutate,
+    AttributeSet *Attrs) {
+  OCLBuiltinFuncMangleInfo BtnInfo(CI->getCalledFunction());
+  return mutateCallInst(M, CI, ArgMutate, &BtnInfo, Attrs);
+}
+
+Instruction *mutateCallInstOCL(
+    Module *M, CallInst *CI,
+    std::function<std::string(CallInst *, std::vector<Value *> &, Type *&RetTy)>
+        ArgMutate,
+    std::function<Instruction *(CallInst *)> RetMutate, AttributeSet *Attrs) {
+  OCLBuiltinFuncMangleInfo BtnInfo(CI->getCalledFunction());
+  return mutateCallInst(M, CI, ArgMutate, RetMutate, &BtnInfo, Attrs);
+}
+
+void mutateFunctionOCL(
+    Function *F,
+    std::function<std::string(CallInst *, std::vector<Value *> &)> ArgMutate,
+    AttributeSet *Attrs) {
+  OCLBuiltinFuncMangleInfo BtnInfo(F);
+  return mutateFunction(F, ArgMutate, &BtnInfo, Attrs, false);
+}
+
+static std::pair<StringRef, StringRef>
+getSrcAndDstElememntTypeName(BitCastInst *BIC) {
+  if (!BIC)
+    return std::pair<StringRef, StringRef>("", "");
+
+  Type *SrcTy = BIC->getSrcTy();
+  Type *DstTy = BIC->getDestTy();
+  if (SrcTy->isPointerTy())
+    SrcTy = SrcTy->getPointerElementType();
+  if (DstTy->isPointerTy())
+    DstTy = DstTy->getPointerElementType();
+  auto SrcST = dyn_cast<StructType>(SrcTy);
+  auto DstST = dyn_cast<StructType>(DstTy);
+  if (!DstST || !DstST->hasName() || !SrcST || !SrcST->hasName())
+    return std::pair<StringRef, StringRef>("", "");
+
+  return std::make_pair(SrcST->getName(), DstST->getName());
+}
+
+bool isSamplerInitializer(Instruction *Inst) {
+  BitCastInst *BIC = dyn_cast<BitCastInst>(Inst);
+  auto Names = getSrcAndDstElememntTypeName(BIC);
+  if (Names.second == getSPIRVTypeName(kSPIRVTypeName::Sampler) &&
+      Names.first == getSPIRVTypeName(kSPIRVTypeName::ConstantSampler))
+    return true;
+
+  return false;
+}
+
+bool isPipeStorageInitializer(Instruction *Inst) {
+  BitCastInst *BIC = dyn_cast<BitCastInst>(Inst);
+  auto Names = getSrcAndDstElememntTypeName(BIC);
+  if (Names.second == getSPIRVTypeName(kSPIRVTypeName::PipeStorage) &&
+      Names.first == getSPIRVTypeName(kSPIRVTypeName::ConstantPipeStorage))
+    return true;
+
+  return false;
+}
+
+bool isSpecialTypeInitializer(Instruction *Inst) {
+  return isSamplerInitializer(Inst) || isPipeStorageInitializer(Inst);
+}
+
+} // namespace OCLUtil
+
+void llvm::MangleOpenCLBuiltin(const std::string &UniqName,
+                               ArrayRef<Type *> ArgTypes,
+                               std::string &MangledName) {
+  OCLUtil::OCLBuiltinFuncMangleInfo BtnInfo(nullptr);
+  MangledName = SPIRV::mangleBuiltin(UniqName, ArgTypes, &BtnInfo);
+}
diff --git a/lib/SPIRV/OCLUtil.h b/lib/SPIRV/OCLUtil.h
new file mode 100644
index 0000000..b876bd1
--- /dev/null
+++ b/lib/SPIRV/OCLUtil.h
@@ -0,0 +1,600 @@
+//===- OCLUtil.h - OCL Utilities declarations -------------------*- C++ -*-===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+//
+// This file declares OCL utility functions.
+//
+//===----------------------------------------------------------------------===//
+#include "SPIRVInternal.h"
+
+#include <utility>
+#include <tuple>
+#include <functional>
+using namespace SPIRV;
+using namespace llvm;
+using namespace spv;
+
+namespace OCLUtil {
+
+///////////////////////////////////////////////////////////////////////////////
+//
+// Enums
+//
+///////////////////////////////////////////////////////////////////////////////
+
+enum OCLMemFenceKind {
+  OCLMF_Local = 1,
+  OCLMF_Global = 2,
+  OCLMF_Image = 4,
+};
+
+enum OCLScopeKind {
+  OCLMS_work_item,
+  OCLMS_work_group,
+  OCLMS_device,
+  OCLMS_all_svm_devices,
+  OCLMS_sub_group,
+};
+
+enum OCLMemOrderKind {
+  OCLMO_relaxed,
+  OCLMO_acquire,
+  OCLMO_release,
+  OCLMO_acq_rel,
+  OCLMO_seq_cst
+};
+
+///////////////////////////////////////////////////////////////////////////////
+//
+// Types
+//
+///////////////////////////////////////////////////////////////////////////////
+
+typedef SPIRVMap<OCLMemFenceKind, MemorySemanticsMask> OCLMemFenceMap;
+
+typedef SPIRVMap<OCLMemOrderKind, unsigned, MemorySemanticsMask> OCLMemOrderMap;
+
+typedef SPIRVMap<OCLScopeKind, Scope> OCLMemScopeMap;
+
+typedef SPIRVMap<std::string, SPIRVGroupOperationKind>
+    SPIRSPIRVGroupOperationMap;
+
+typedef SPIRVMap<std::string, SPIRVFPRoundingModeKind>
+    SPIRSPIRVFPRoundingModeMap;
+
+typedef SPIRVMap<std::string, Op, SPIRVInstruction> OCLSPIRVBuiltinMap;
+
+typedef SPIRVMap<std::string, SPIRVBuiltinVariableKind>
+    SPIRSPIRVBuiltinVariableMap;
+
+/// Tuple of literals for atomic_work_item_fence (flag, order, scope)
+typedef std::tuple<unsigned, OCLMemOrderKind, OCLScopeKind>
+    AtomicWorkItemFenceLiterals;
+
+/// Tuple of literals for work_group_barrier or sub_group_barrier
+///     (flag, mem_scope, exec_scope)
+typedef std::tuple<unsigned, OCLScopeKind, OCLScopeKind> BarrierLiterals;
+
+class OCLOpaqueType;
+typedef SPIRVMap<std::string, Op, OCLOpaqueType> OCLOpaqueTypeOpCodeMap;
+
+/// Information for translating OCL builtin.
+struct OCLBuiltinTransInfo {
+  std::string UniqName;
+  std::string MangledName;
+  std::string Postfix; // Postfix to be added
+  /// Postprocessor of operands
+  std::function<void(std::vector<Value *> &)> PostProc;
+  Type *RetTy;      // Return type of the translated function
+  bool isRetSigned; // When RetTy is int, determines if extensions
+                    // on it should be a sext or zet.
+  OCLBuiltinTransInfo() : RetTy(nullptr), isRetSigned(false) {
+    PostProc = [](std::vector<Value *> &) {};
+  }
+};
+
+///////////////////////////////////////////////////////////////////////////////
+//
+// Constants
+//
+///////////////////////////////////////////////////////////////////////////////
+namespace kOCLBuiltinName {
+const static char All[] = "all";
+const static char Any[] = "any";
+const static char AsyncWorkGroupCopy[] = "async_work_group_copy";
+const static char AsyncWorkGroupStridedCopy[] = "async_work_group_strided_copy";
+const static char AtomPrefix[] = "atom_";
+const static char AtomCmpXchg[] = "atom_cmpxchg";
+const static char AtomicPrefix[] = "atomic_";
+const static char AtomicCmpXchg[] = "atomic_cmpxchg";
+const static char AtomicCmpXchgStrong[] = "atomic_compare_exchange_strong";
+const static char AtomicCmpXchgStrongExplicit[] =
+    "atomic_compare_exchange_strong_explicit";
+const static char AtomicCmpXchgWeak[] = "atomic_compare_exchange_weak";
+const static char AtomicCmpXchgWeakExplicit[] =
+    "atomic_compare_exchange_weak_explicit";
+const static char AtomicInit[] = "atomic_init";
+const static char AtomicWorkItemFence[] = "atomic_work_item_fence";
+const static char Barrier[] = "barrier";
+const static char Clamp[] = "clamp";
+const static char ConvertPrefix[] = "convert_";
+const static char Dot[] = "dot";
+const static char EnqueueKernel[] = "enqueue_kernel";
+const static char FMax[] = "fmax";
+const static char FMin[] = "fmin";
+const static char FMod[] = "fmod";
+const static char GetFence[] = "get_fence";
+const static char GetImageArraySize[] = "get_image_array_size";
+const static char GetImageChannelOrder[] = "get_image_channel_order";
+const static char GetImageChannelDataType[] = "get_image_channel_data_type";
+const static char GetImageDepth[] = "get_image_depth";
+const static char GetImageDim[] = "get_image_dim";
+const static char GetImageHeight[] = "get_image_height";
+const static char GetImageWidth[] = "get_image_width";
+const static char IsFinite[] = "isfinite";
+const static char IsNan[] = "isnan";
+const static char IsNormal[] = "isnormal";
+const static char IsInf[] = "isinf";
+const static char Max[] = "max";
+const static char MemFence[] = "mem_fence";
+const static char Min[] = "min";
+const static char Mix[] = "mix";
+const static char NDRangePrefix[] = "ndrange_";
+const static char Pipe[] = "pipe";
+const static char ReadImage[] = "read_image";
+const static char ReadPipe[] = "read_pipe";
+const static char RoundingPrefix[] = "_r";
+const static char Sampled[] = "sampled_";
+const static char SampledReadImage[] = "sampled_read_image";
+const static char Signbit[] = "signbit";
+const static char SmoothStep[] = "smoothstep";
+const static char Step[] = "step";
+const static char SubGroupPrefix[] = "sub_group_";
+const static char SubGroupBarrier[] = "sub_group_barrier";
+const static char SubPrefix[] = "sub_";
+const static char ToGlobal[] = "to_global";
+const static char ToLocal[] = "to_local";
+const static char ToPrivate[] = "to_private";
+const static char VLoadPrefix[] = "vload";
+const static char VLoadAPrefix[] = "vloada";
+const static char VLoadHalf[] = "vload_half";
+const static char VStorePrefix[] = "vstore";
+const static char VStoreAPrefix[] = "vstorea";
+const static char WaitGroupEvent[] = "wait_group_events";
+const static char WriteImage[] = "write_image";
+const static char WorkGroupBarrier[] = "work_group_barrier";
+const static char WritePipe[] = "write_pipe";
+const static char WorkGroupPrefix[] = "work_group_";
+const static char WorkGroupAll[] = "work_group_all";
+const static char WorkGroupAny[] = "work_group_any";
+const static char SubGroupAll[] = "sub_group_all";
+const static char SubGroupAny[] = "sub_group_any";
+const static char WorkPrefix[] = "work_";
+}
+
+/// Offset for OpenCL image channel order enumeration values.
+const unsigned int OCLImageChannelOrderOffset = 0x10B0;
+
+/// Offset for OpenCL image channel data type enumeration values.
+const unsigned int OCLImageChannelDataTypeOffset = 0x10D0;
+
+/// OCL 1.x atomic memory order when translated to 2.0 atomics.
+const OCLMemOrderKind OCLLegacyAtomicMemOrder = OCLMO_seq_cst;
+
+/// OCL 1.x atomic memory scope when translated to 2.0 atomics.
+const OCLScopeKind OCLLegacyAtomicMemScope = OCLMS_device;
+
+namespace kOCLVer {
+const unsigned CL12 = 102000;
+const unsigned CL20 = 200000;
+const unsigned CL21 = 201000;
+}
+
+namespace OclExt {
+enum Kind {
+#define _SPIRV_OP(x) x,
+  _SPIRV_OP(cl_images) _SPIRV_OP(cl_doubles) _SPIRV_OP(
+      cl_khr_int64_base_atomics) _SPIRV_OP(cl_khr_int64_extended_atomics)
+      _SPIRV_OP(cl_khr_fp16) _SPIRV_OP(cl_khr_gl_sharing) _SPIRV_OP(
+          cl_khr_gl_event) _SPIRV_OP(cl_khr_d3d10_sharing)
+          _SPIRV_OP(cl_khr_media_sharing) _SPIRV_OP(
+              cl_khr_d3d11_sharing) _SPIRV_OP(cl_khr_global_int32_base_atomics)
+              _SPIRV_OP(cl_khr_global_int32_extended_atomics) _SPIRV_OP(
+                  cl_khr_local_int32_base_atomics)
+                  _SPIRV_OP(cl_khr_local_int32_extended_atomics) _SPIRV_OP(
+                      cl_khr_byte_addressable_store)
+                      _SPIRV_OP(cl_khr_3d_image_writes) _SPIRV_OP(
+                          cl_khr_gl_msaa_sharing) _SPIRV_OP(cl_khr_depth_images)
+                          _SPIRV_OP(cl_khr_gl_depth_images) _SPIRV_OP(
+                              cl_khr_subgroups) _SPIRV_OP(cl_khr_mipmap_image)
+                              _SPIRV_OP(cl_khr_mipmap_image_writes)
+                                  _SPIRV_OP(cl_khr_egl_event)
+                                      _SPIRV_OP(cl_khr_srgb_image_writes)
+#undef _SPIRV_OP
+};
+}
+
+///////////////////////////////////////////////////////////////////////////////
+//
+// Functions
+//
+///////////////////////////////////////////////////////////////////////////////
+
+/// Get instruction index for SPIR-V extended instruction for OpenCL.std
+///   or GLSL extended instruction set.
+/// \param MangledName The mangled name of OpenCL/GLSL builtin function.
+/// \param DemangledName The demangled name of OpenCL/GLSL builtin function if
+///   not empty.
+/// \param ext_kind the extended instruction set kind that should be used
+/// \return instruction index of extended instruction if the OpenCL/GLSL builtin
+///   function is translated to an extended instruction, otherwise ~0U.
+unsigned getExtOp(StringRef MangledName, const std::string &DemangledName,
+                  SPIRVExtInstSetKind ext_kind);
+
+/// Get literal arguments of call of atomic_work_item_fence.
+AtomicWorkItemFenceLiterals getAtomicWorkItemFenceLiterals(CallInst *CI);
+
+/// Get literal arguments of call of work_group_barrier or sub_group_barrier.
+BarrierLiterals getBarrierLiterals(CallInst *CI);
+
+/// Get number of memory order arguments for atomic builtin function.
+size_t getAtomicBuiltinNumMemoryOrderArgs(StringRef Name);
+
+/// Get OCL version from metadata opencl.ocl.version.
+/// \param AllowMulti Allows multiple operands if true.
+/// \return OCL version encoded as Major*10^5+Minor*10^3+Rev,
+/// e.g. 201000 for OCL 2.1, 200000 for OCL 2.0, 102000 for OCL 1.2,
+/// 0 if metadata not found.
+/// If there are multiple operands, check they are identical.
+unsigned getOCLVersion(Module *M, bool AllowMulti = false);
+
+/// Encode OpenCL version as Major*10^5+Minor*10^3+Rev.
+unsigned encodeOCLVer(unsigned short Major, unsigned char Minor,
+                      unsigned char Rev);
+
+/// Decode OpenCL version which is encoded as Major*10^5+Minor*10^3+Rev
+std::tuple<unsigned short, unsigned char, unsigned char>
+decodeOCLVer(unsigned Ver);
+
+/// Decode a MDNode assuming it contains three integer constants.
+void decodeMDNode(MDNode *N, unsigned &X, unsigned &Y, unsigned &Z);
+
+/// Decode OpenCL vector type hint MDNode and encode it as SPIR-V execution
+/// mode VecTypeHint.
+unsigned transVecTypeHint(MDNode *Node);
+
+/// Decode SPIR-V encoding of vector type hint execution mode.
+Type *decodeVecTypeHint(LLVMContext &C, unsigned code);
+
+SPIRAddressSpace getOCLOpaqueTypeAddrSpace(Op OpCode);
+SPIR::TypeAttributeEnum getOCLOpaqueTypeAddrSpace(SPIR::TypePrimitiveEnum prim);
+
+inline unsigned mapOCLMemSemanticToSPIRV(unsigned MemFenceFlag,
+                                         OCLMemOrderKind Order) {
+  return OCLMemOrderMap::map(Order) | mapBitMask<OCLMemFenceMap>(MemFenceFlag);
+}
+
+inline unsigned mapOCLMemFenceFlagToSPIRV(unsigned MemFenceFlag) {
+  return mapBitMask<OCLMemFenceMap>(MemFenceFlag);
+}
+
+inline std::pair<unsigned, OCLMemOrderKind>
+mapSPIRVMemSemanticToOCL(unsigned Sema) {
+  return std::make_pair(
+      rmapBitMask<OCLMemFenceMap>(Sema),
+      OCLMemOrderMap::rmap(extractSPIRVMemOrderSemantic(Sema)));
+}
+
+inline OCLMemOrderKind mapSPIRVMemOrderToOCL(unsigned Sema) {
+  return OCLMemOrderMap::rmap(extractSPIRVMemOrderSemantic(Sema));
+}
+
+/// Mutate call instruction to call OpenCL builtin function.
+CallInst *mutateCallInstOCL(
+    Module *M, CallInst *CI,
+    std::function<std::string(CallInst *, std::vector<Value *> &)> ArgMutate,
+    AttributeSet *Attrs = nullptr);
+
+/// Mutate call instruction to call OpenCL builtin function.
+Instruction *mutateCallInstOCL(
+    Module *M, CallInst *CI,
+    std::function<std::string(CallInst *, std::vector<Value *> &, Type *&RetTy)>
+        ArgMutate,
+    std::function<Instruction *(CallInst *)> RetMutate,
+    AttributeSet *Attrs = nullptr);
+
+/// Mutate a function to OpenCL builtin function.
+void mutateFunctionOCL(
+    Function *F,
+    std::function<std::string(CallInst *, std::vector<Value *> &)> ArgMutate,
+    AttributeSet *Attrs = nullptr);
+
+/// Check if instruction is bitcast from spirv.ConstantSampler to spirv.Sampler
+bool isSamplerInitializer(Instruction *Inst);
+
+/// Check if instruction is bitcast from spirv.ConstantPipeStorage
+/// to spirv.PipeStorage
+bool isPipeStorageInitializer(Instruction *Inst);
+
+/// Check (isSamplerInitializer || isPipeStorageInitializer)
+bool isSpecialTypeInitializer(Instruction *Inst);
+
+} // namespace OCLUtil
+
+///////////////////////////////////////////////////////////////////////////////
+//
+// Map definitions
+//
+///////////////////////////////////////////////////////////////////////////////
+
+using namespace OCLUtil;
+namespace SPIRV {
+template <> inline void SPIRVMap<OCLMemFenceKind, MemorySemanticsMask>::init() {
+  add(OCLMF_Local, MemorySemanticsWorkgroupMemoryMask);
+  add(OCLMF_Global, MemorySemanticsCrossWorkgroupMemoryMask);
+  add(OCLMF_Image, MemorySemanticsImageMemoryMask);
+}
+
+template <>
+inline void SPIRVMap<OCLMemOrderKind, unsigned, MemorySemanticsMask>::init() {
+  add(OCLMO_relaxed, MemorySemanticsMaskNone);
+  add(OCLMO_acquire, MemorySemanticsAcquireMask);
+  add(OCLMO_release, MemorySemanticsReleaseMask);
+  add(OCLMO_acq_rel, MemorySemanticsAcquireReleaseMask);
+  add(OCLMO_seq_cst, MemorySemanticsSequentiallyConsistentMask);
+}
+
+template <> inline void SPIRVMap<OCLScopeKind, Scope>::init() {
+  add(OCLMS_work_item, ScopeInvocation);
+  add(OCLMS_work_group, ScopeWorkgroup);
+  add(OCLMS_device, ScopeDevice);
+  add(OCLMS_all_svm_devices, ScopeCrossDevice);
+  add(OCLMS_sub_group, ScopeSubgroup);
+}
+
+template <> inline void SPIRVMap<std::string, SPIRVGroupOperationKind>::init() {
+  add("reduce", GroupOperationReduce);
+  add("scan_inclusive", GroupOperationInclusiveScan);
+  add("scan_exclusive", GroupOperationExclusiveScan);
+}
+
+template <> inline void SPIRVMap<std::string, SPIRVFPRoundingModeKind>::init() {
+  add("rte", FPRoundingModeRTE);
+  add("rtz", FPRoundingModeRTZ);
+  add("rtp", FPRoundingModeRTP);
+  add("rtn", FPRoundingModeRTN);
+}
+
+template <> inline void SPIRVMap<OclExt::Kind, std::string>::init() {
+#define _SPIRV_OP(x) add(OclExt::x, #x);
+  _SPIRV_OP(cl_images)
+  _SPIRV_OP(cl_doubles)
+  _SPIRV_OP(cl_khr_int64_base_atomics)
+  _SPIRV_OP(cl_khr_int64_extended_atomics)
+  _SPIRV_OP(cl_khr_fp16)
+  _SPIRV_OP(cl_khr_gl_sharing)
+  _SPIRV_OP(cl_khr_gl_event)
+  _SPIRV_OP(cl_khr_d3d10_sharing)
+  _SPIRV_OP(cl_khr_media_sharing)
+  _SPIRV_OP(cl_khr_d3d11_sharing)
+  _SPIRV_OP(cl_khr_global_int32_base_atomics)
+  _SPIRV_OP(cl_khr_global_int32_extended_atomics)
+  _SPIRV_OP(cl_khr_local_int32_base_atomics)
+  _SPIRV_OP(cl_khr_local_int32_extended_atomics)
+  _SPIRV_OP(cl_khr_byte_addressable_store)
+  _SPIRV_OP(cl_khr_3d_image_writes)
+  _SPIRV_OP(cl_khr_gl_msaa_sharing)
+  _SPIRV_OP(cl_khr_depth_images)
+  _SPIRV_OP(cl_khr_gl_depth_images)
+  _SPIRV_OP(cl_khr_subgroups)
+  _SPIRV_OP(cl_khr_mipmap_image)
+  _SPIRV_OP(cl_khr_mipmap_image_writes)
+  _SPIRV_OP(cl_khr_egl_event)
+  _SPIRV_OP(cl_khr_srgb_image_writes)
+#undef _SPIRV_OP
+}
+
+template <> inline void SPIRVMap<OclExt::Kind, SPIRVCapabilityKind>::init() {
+  add(OclExt::cl_images, CapabilityImageBasic);
+  add(OclExt::cl_doubles, CapabilityFloat64);
+  add(OclExt::cl_khr_int64_base_atomics, CapabilityInt64Atomics);
+  add(OclExt::cl_khr_int64_extended_atomics, CapabilityInt64Atomics);
+  add(OclExt::cl_khr_fp16, CapabilityFloat16);
+  add(OclExt::cl_khr_subgroups, CapabilityGroups);
+  add(OclExt::cl_khr_mipmap_image, CapabilityImageMipmap);
+  add(OclExt::cl_khr_mipmap_image_writes, CapabilityImageMipmap);
+}
+
+/// Map OpenCL work functions to SPIR-V builtin variables.
+template <>
+inline void SPIRVMap<std::string, SPIRVBuiltinVariableKind>::init() {
+  add("get_work_dim", BuiltInWorkDim);
+  add("get_global_size", BuiltInGlobalSize);
+  add("get_global_id", BuiltInGlobalInvocationId);
+  add("get_global_offset", BuiltInGlobalOffset);
+  add("get_local_size", BuiltInWorkgroupSize);
+  add("get_enqueued_local_size", BuiltInEnqueuedWorkgroupSize);
+  add("get_local_id", BuiltInLocalInvocationId);
+  add("get_num_groups", BuiltInNumWorkgroups);
+  add("get_group_id", BuiltInWorkgroupId);
+  add("get_global_linear_id", BuiltInGlobalLinearId);
+  add("get_local_linear_id", BuiltInLocalInvocationIndex);
+  add("get_sub_group_size", BuiltInSubgroupSize);
+  add("get_max_sub_group_size", BuiltInSubgroupMaxSize);
+  add("get_num_sub_groups", BuiltInNumSubgroups);
+  add("get_enqueued_num_sub_groups", BuiltInNumEnqueuedSubgroups);
+  add("get_sub_group_id", BuiltInSubgroupId);
+  add("get_sub_group_local_id", BuiltInSubgroupLocalInvocationId);
+}
+
+// Maps uniqued OCL builtin function name to SPIR-V op code.
+// A uniqued OCL builtin function name may be different from the real
+// OCL builtin function name. e.g. instead of atomic_min, atomic_umin
+// is used for atomic_min with unsigned integer parameter.
+// work_group_ and sub_group_ functions are unified as group_ functions
+// except work_group_barrier.
+class SPIRVInstruction;
+template <> inline void SPIRVMap<std::string, Op, SPIRVInstruction>::init() {
+#define _SPIRV_OP(x, y) add("atom_" #x, OpAtomic##y);
+  // cl_khr_int64_base_atomics builtins
+  _SPIRV_OP(add, IAdd)
+  _SPIRV_OP(sub, ISub)
+  _SPIRV_OP(xchg, Exchange)
+  _SPIRV_OP(dec, IDecrement)
+  _SPIRV_OP(inc, IIncrement)
+  _SPIRV_OP(cmpxchg, CompareExchange)
+  // cl_khr_int64_extended_atomics builtins
+  _SPIRV_OP(min, SMin)
+  _SPIRV_OP(max, SMax)
+  _SPIRV_OP(and, And)
+  _SPIRV_OP(or, Or)
+  _SPIRV_OP (xor, Xor)
+#undef _SPIRV_OP
+#define _SPIRV_OP(x, y) add("atomic_" #x, Op##y);
+  // CL 2.0 atomic builtins
+  _SPIRV_OP(flag_test_and_set_explicit, AtomicFlagTestAndSet)
+  _SPIRV_OP(flag_clear_explicit, AtomicFlagClear)
+  _SPIRV_OP(load_explicit, AtomicLoad)
+  _SPIRV_OP(store_explicit, AtomicStore)
+  _SPIRV_OP(exchange_explicit, AtomicExchange)
+  _SPIRV_OP(compare_exchange_strong_explicit, AtomicCompareExchange)
+  _SPIRV_OP(compare_exchange_weak_explicit, AtomicCompareExchangeWeak)
+  _SPIRV_OP(inc, AtomicIIncrement)
+  _SPIRV_OP(dec, AtomicIDecrement)
+  _SPIRV_OP(fetch_add_explicit, AtomicIAdd)
+  _SPIRV_OP(fetch_sub_explicit, AtomicISub)
+  _SPIRV_OP(fetch_umin_explicit, AtomicUMin)
+  _SPIRV_OP(fetch_umax_explicit, AtomicUMax)
+  _SPIRV_OP(fetch_min_explicit, AtomicSMin)
+  _SPIRV_OP(fetch_max_explicit, AtomicSMax)
+  _SPIRV_OP(fetch_and_explicit, AtomicAnd)
+  _SPIRV_OP(fetch_or_explicit, AtomicOr)
+  _SPIRV_OP(fetch_xor_explicit, AtomicXor)
+#undef _SPIRV_OP
+#define _SPIRV_OP(x, y) add(#x, Op##y);
+  _SPIRV_OP(dot, Dot)
+  _SPIRV_OP(async_work_group_copy, GroupAsyncCopy)
+  _SPIRV_OP(async_work_group_strided_copy, GroupAsyncCopy)
+  _SPIRV_OP(wait_group_events, GroupWaitEvents)
+  _SPIRV_OP(isequal, FOrdEqual)
+  _SPIRV_OP(isnotequal, FUnordNotEqual)
+  _SPIRV_OP(isgreater, FOrdGreaterThan)
+  _SPIRV_OP(isgreaterequal, FOrdGreaterThanEqual)
+  _SPIRV_OP(isless, FOrdLessThan)
+  _SPIRV_OP(islessequal, FOrdLessThanEqual)
+  _SPIRV_OP(islessgreater, LessOrGreater)
+  _SPIRV_OP(isordered, Ordered)
+  _SPIRV_OP(isunordered, Unordered)
+  _SPIRV_OP(isfinite, IsFinite)
+  _SPIRV_OP(isinf, IsInf)
+  _SPIRV_OP(isnan, IsNan)
+  _SPIRV_OP(isnormal, IsNormal)
+  _SPIRV_OP(signbit, SignBitSet)
+  _SPIRV_OP(any, Any)
+  _SPIRV_OP(all, All)
+  _SPIRV_OP(get_fence, GenericPtrMemSemantics)
+  // CL 2.0 kernel enqueue builtins
+  _SPIRV_OP(enqueue_marker, EnqueueMarker)
+  _SPIRV_OP(enqueue_kernel, EnqueueKernel)
+  _SPIRV_OP(get_kernel_ndrange_subgroup_count, GetKernelNDrangeSubGroupCount)
+  _SPIRV_OP(get_kernel_ndrange_max_subgroup_count,
+            GetKernelNDrangeMaxSubGroupSize)
+  _SPIRV_OP(get_kernel_work_group_size, GetKernelWorkGroupSize)
+  _SPIRV_OP(get_kernel_preferred_work_group_size_multiple,
+            GetKernelPreferredWorkGroupSizeMultiple)
+  _SPIRV_OP(retain_event, RetainEvent)
+  _SPIRV_OP(release_event, ReleaseEvent)
+  _SPIRV_OP(create_user_event, CreateUserEvent)
+  _SPIRV_OP(is_valid_event, IsValidEvent)
+  _SPIRV_OP(set_user_event_status, SetUserEventStatus)
+  _SPIRV_OP(capture_event_profiling_info, CaptureEventProfilingInfo)
+  _SPIRV_OP(get_default_queue, GetDefaultQueue)
+  _SPIRV_OP(ndrange_1D, BuildNDRange)
+  _SPIRV_OP(ndrange_2D, BuildNDRange)
+  _SPIRV_OP(ndrange_3D, BuildNDRange)
+  // Generic Address Space Casts
+  _SPIRV_OP(to_global, GenericCastToPtrExplicit)
+  _SPIRV_OP(to_local, GenericCastToPtrExplicit)
+  _SPIRV_OP(to_private, GenericCastToPtrExplicit)
+  _SPIRV_OP(work_group_barrier, ControlBarrier)
+  // CL 2.0 pipe builtins
+  _SPIRV_OP(read_pipe, ReadPipe)
+  _SPIRV_OP(write_pipe, WritePipe)
+  _SPIRV_OP(reserved_read_pipe, ReservedReadPipe)
+  _SPIRV_OP(reserved_write_pipe, ReservedWritePipe)
+  _SPIRV_OP(reserve_read_pipe, ReserveReadPipePackets)
+  _SPIRV_OP(reserve_write_pipe, ReserveWritePipePackets)
+  _SPIRV_OP(commit_read_pipe, CommitReadPipe)
+  _SPIRV_OP(commit_write_pipe, CommitWritePipe)
+  _SPIRV_OP(is_valid_reserve_id, IsValidReserveId)
+  _SPIRV_OP(group_reserve_read_pipe, GroupReserveReadPipePackets)
+  _SPIRV_OP(group_reserve_write_pipe, GroupReserveWritePipePackets)
+  _SPIRV_OP(group_commit_read_pipe, GroupCommitReadPipe)
+  _SPIRV_OP(group_commit_write_pipe, GroupCommitWritePipe)
+  _SPIRV_OP(get_pipe_num_packets, GetNumPipePackets)
+  _SPIRV_OP(get_pipe_max_packets, GetMaxPipePackets)
+  // CL 2.0 workgroup builtins
+  _SPIRV_OP(group_all, GroupAll)
+  _SPIRV_OP(group_any, GroupAny)
+  _SPIRV_OP(group_broadcast, GroupBroadcast)
+  _SPIRV_OP(group_iadd, GroupIAdd)
+  _SPIRV_OP(group_fadd, GroupFAdd)
+  _SPIRV_OP(group_fmin, GroupFMin)
+  _SPIRV_OP(group_umin, GroupUMin)
+  _SPIRV_OP(group_smin, GroupSMin)
+  _SPIRV_OP(group_fmax, GroupFMax)
+  _SPIRV_OP(group_umax, GroupUMax)
+  _SPIRV_OP(group_smax, GroupSMax)
+  // CL image builtins
+  _SPIRV_OP(SampledImage, SampledImage)
+  _SPIRV_OP(ImageSampleExplicitLod, ImageSampleExplicitLod)
+  _SPIRV_OP(read_image, ImageRead)
+  _SPIRV_OP(write_image, ImageWrite)
+  _SPIRV_OP(get_image_channel_data_type, ImageQueryFormat)
+  _SPIRV_OP(get_image_channel_order, ImageQueryOrder)
+  _SPIRV_OP(get_image_num_mip_levels, ImageQueryLevels)
+  _SPIRV_OP(get_image_num_samples, ImageQuerySamples)
+  // GLSL or standard SPIR-V (TODO: how to ignore these for opencl?)
+  _SPIRV_OP(fmod, FMod)
+#undef _SPIRV_OP
+}
+
+template <> inline void SPIRVMap<std::string, Op, OCLOpaqueType>::init() {
+  add("opencl.event_t", OpTypeEvent);
+  add("opencl.pipe_t", OpTypePipe);
+  add("opencl.clk_event_t", OpTypeDeviceEvent);
+  add("opencl.reserve_id_t", OpTypeReserveId);
+  add("opencl.queue_t", OpTypeQueue);
+}
+
+} // namespace SPIRV
diff --git a/lib/SPIRV/SPIRVInternal.h b/lib/SPIRV/SPIRVInternal.h
new file mode 100644
index 0000000..0d00b25
--- /dev/null
+++ b/lib/SPIRV/SPIRVInternal.h
@@ -0,0 +1,932 @@
+//===- LLVMSPIRVInternal.h -  SPIR-V internal header file -------*- C++ -*-===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+/// \file
+///
+/// This file declares classes and functions shared by SPIR-V reader/writer.
+///
+//===----------------------------------------------------------------------===//
+#ifndef LLVMSPIRVINTERNAL_HPP_
+#define LLVMSPIRVINTERNAL_HPP_
+
+#include "libSPIRV/SPIRVUtil.h"
+#include "libSPIRV/SPIRVEnum.h"
+#include "libSPIRV/SPIRVNameMapEnum.h"
+#include "libSPIRV/SPIRVError.h"
+#include "libSPIRV/SPIRVType.h"
+#include "NameMangleAPI.h"
+
+#include "llvm/IR/Attributes.h"
+#include "llvm/IR/Constants.h"
+#include "llvm/IR/Instructions.h"
+#include "llvm/Support/SPIRV.h"
+
+#include <utility>
+#include <functional>
+
+using namespace SPIRV;
+using namespace llvm;
+
+namespace SPIRV {
+
+/// The LLVM/SPIR-V translator version used to fill the lower 16 bits of the
+/// generator's magic number in the generated SPIR-V module.
+/// This number should be bumped up whenever the generated SPIR-V changes.
+const static unsigned short kTranslatorVer = 14;
+
+#define SPCV_TARGET_LLVM_IMAGE_TYPE_ENCODE_ACCESS_QUAL 0
+// Workaround for SPIR 2 producer bug about kernel function calling convention.
+// This workaround checks metadata to determine if a function is kernel.
+#define SPCV_RELAX_KERNEL_CALLING_CONV 1
+
+class SPIRVOpaqueType;
+typedef SPIRVMap<std::string, Op, SPIRVOpaqueType> SPIRVOpaqueTypeOpCodeMap;
+
+// Ad hoc function used by LLVM/SPIRV converter for type casting
+#define SPCV_CAST "spcv.cast"
+#define LLVM_MEMCPY "llvm.memcpy"
+
+namespace kOCLTypeQualifierName {
+const static char *Const = "const";
+const static char *Volatile = "volatile";
+const static char *Restrict = "restrict";
+const static char *Pipe = "pipe";
+}
+
+template <> inline void SPIRVMap<unsigned, Op>::init() {
+#define _SPIRV_OP(x, y) add(Instruction::x, Op##y);
+  /* Casts */
+  _SPIRV_OP(ZExt, UConvert)
+  _SPIRV_OP(SExt, SConvert)
+  _SPIRV_OP(Trunc, UConvert)
+  _SPIRV_OP(FPToUI, ConvertFToU)
+  _SPIRV_OP(FPToSI, ConvertFToS)
+  _SPIRV_OP(UIToFP, ConvertUToF)
+  _SPIRV_OP(SIToFP, ConvertSToF)
+  _SPIRV_OP(FPTrunc, FConvert)
+  _SPIRV_OP(FPExt, FConvert)
+  _SPIRV_OP(PtrToInt, ConvertPtrToU)
+  _SPIRV_OP(IntToPtr, ConvertUToPtr)
+  _SPIRV_OP(BitCast, Bitcast)
+  _SPIRV_OP(AddrSpaceCast, GenericCastToPtr)
+  _SPIRV_OP(GetElementPtr, AccessChain)
+  /*Binary*/
+  _SPIRV_OP(And, BitwiseAnd)
+  _SPIRV_OP(Or, BitwiseOr)
+  _SPIRV_OP(Xor, BitwiseXor)
+  _SPIRV_OP(Add, IAdd)
+  _SPIRV_OP(FAdd, FAdd)
+  _SPIRV_OP(Sub, ISub)
+  _SPIRV_OP(FSub, FSub)
+  _SPIRV_OP(Mul, IMul)
+  _SPIRV_OP(FMul, FMul)
+  _SPIRV_OP(UDiv, UDiv)
+  _SPIRV_OP(SDiv, SDiv)
+  _SPIRV_OP(FDiv, FDiv)
+  _SPIRV_OP(SRem, SRem)
+  _SPIRV_OP(FRem, FRem)
+  _SPIRV_OP(URem, UMod)
+  _SPIRV_OP(Shl, ShiftLeftLogical)
+  _SPIRV_OP(LShr, ShiftRightLogical)
+  _SPIRV_OP(AShr, ShiftRightArithmetic)
+#undef _SPIRV_OP
+}
+typedef SPIRVMap<unsigned, Op> OpCodeMap;
+
+template <> inline void SPIRVMap<CmpInst::Predicate, Op>::init() {
+#define _SPIRV_OP(x, y) add(CmpInst::x, Op##y);
+  _SPIRV_OP(FCMP_OEQ, FOrdEqual)
+  _SPIRV_OP(FCMP_OGT, FOrdGreaterThan)
+  _SPIRV_OP(FCMP_OGE, FOrdGreaterThanEqual)
+  _SPIRV_OP(FCMP_OLT, FOrdLessThan)
+  _SPIRV_OP(FCMP_OLE, FOrdLessThanEqual)
+  _SPIRV_OP(FCMP_ONE, FOrdNotEqual)
+  _SPIRV_OP(FCMP_ORD, Ordered)
+  _SPIRV_OP(FCMP_UNO, Unordered)
+  _SPIRV_OP(FCMP_UEQ, FUnordEqual)
+  _SPIRV_OP(FCMP_UGT, FUnordGreaterThan)
+  _SPIRV_OP(FCMP_UGE, FUnordGreaterThanEqual)
+  _SPIRV_OP(FCMP_ULT, FUnordLessThan)
+  _SPIRV_OP(FCMP_ULE, FUnordLessThanEqual)
+  _SPIRV_OP(FCMP_UNE, FUnordNotEqual)
+  _SPIRV_OP(ICMP_EQ, IEqual)
+  _SPIRV_OP(ICMP_NE, INotEqual)
+  _SPIRV_OP(ICMP_UGT, UGreaterThan)
+  _SPIRV_OP(ICMP_UGE, UGreaterThanEqual)
+  _SPIRV_OP(ICMP_ULT, ULessThan)
+  _SPIRV_OP(ICMP_ULE, ULessThanEqual)
+  _SPIRV_OP(ICMP_SGT, SGreaterThan)
+  _SPIRV_OP(ICMP_SGE, SGreaterThanEqual)
+  _SPIRV_OP(ICMP_SLT, SLessThan)
+  _SPIRV_OP(ICMP_SLE, SLessThanEqual)
+#undef _SPIRV_OP
+}
+typedef SPIRVMap<CmpInst::Predicate, Op> CmpMap;
+
+class IntBoolOpMapId;
+template <> inline void SPIRVMap<Op, Op, IntBoolOpMapId>::init() {
+  add(OpNot, OpLogicalNot);
+  add(OpBitwiseAnd, OpLogicalAnd);
+  add(OpBitwiseOr, OpLogicalOr);
+  add(OpBitwiseXor, OpLogicalNotEqual);
+  add(OpIEqual, OpLogicalEqual);
+  add(OpINotEqual, OpLogicalNotEqual);
+}
+typedef SPIRVMap<Op, Op, IntBoolOpMapId> IntBoolOpMap;
+
+#define SPIR_TARGETTRIPLE32 "spir-unknown-unknown"
+#define SPIR_TARGETTRIPLE64 "spir64-unknown-unknown"
+#define SPIR_DATALAYOUT32                                                      \
+  "e-p:32:32:32-i1:8:8-i8:8:8-i16:16:16-i32:32:32"                             \
+  "-i64:64:64-f32:32:32-f64:64:64-v16:16:16-v24:32:32"                         \
+  "-v32:32:32-v48:64:64-v64:64:64-v96:128:128"                                 \
+  "-v128:128:128-v192:256:256-v256:256:256"                                    \
+  "-v512:512:512-v1024:1024:1024"
+#define SPIR_DATALAYOUT64                                                      \
+  "e-p:64:64:64-i1:8:8-i8:8:8-i16:16:16-i32:32:32"                             \
+  "-i64:64:64-f32:32:32-f64:64:64-v16:16:16-v24:32:32"                         \
+  "-v32:32:32-v48:64:64-v64:64:64-v96:128:128"                                 \
+  "-v128:128:128-v192:256:256-v256:256:256"                                    \
+  "-v512:512:512-v1024:1024:1024"
+
+// NOTE: modify VulkanFinal pass and clang Targets when this enum or its values
+// changes
+enum SPIRAddressSpace {
+  SPIRAS_Private = 0,
+  SPIRAS_Global = 1,
+  SPIRAS_Constant = 2,
+  SPIRAS_Local = 3,
+  SPIRAS_Generic = 4,
+  // Vulkan/GLSL specific ones
+  SPIRAS_Uniform = 5,
+  SPIRAS_Input = 6,
+  SPIRAS_Output = 7,
+  SPIRAS_VulkanPrivate = 8, // != SPIRAS_Private
+  SPIRAS_PushConstant = 9,
+  SPIRAS_AtomicCounter = 10,
+  SPIRAS_Image = 11,
+  // Workgroup == SPIRAS_Local
+  // CrossWorkgroup == SPIRAS_Global
+  // Function = SPIRAS_Private
+  // UniformConstant = SPIRAS_Constant
+  SPIRAS_Count,
+};
+
+template <> inline void SPIRVMap<SPIRAddressSpace, std::string>::init() {
+  add(SPIRAS_Private, "Private");
+  add(SPIRAS_Global, "Global");
+  add(SPIRAS_Constant, "Constant");
+  add(SPIRAS_Local, "Local");
+  add(SPIRAS_Generic, "Generic");
+  add(SPIRAS_Uniform, "Uniform");
+  add(SPIRAS_Input, "Input");
+  add(SPIRAS_Output, "Output");
+  add(SPIRAS_VulkanPrivate, "Private");
+  add(SPIRAS_PushConstant, "PushConstant");
+  add(SPIRAS_AtomicCounter, "AtomicCounter");
+  add(SPIRAS_Image, "Image");
+}
+typedef SPIRVMap<SPIRAddressSpace, SPIRVStorageClassKind>
+    SPIRAddrSpaceCapitalizedNameMap;
+
+template <>
+inline void SPIRVMap<SPIRAddressSpace, SPIRVStorageClassKind>::init() {
+  add(SPIRAS_Private, StorageClassFunction);
+  add(SPIRAS_Global, StorageClassCrossWorkgroup);
+  add(SPIRAS_Constant, StorageClassUniformConstant);
+  add(SPIRAS_Local, StorageClassWorkgroup);
+  add(SPIRAS_Generic, StorageClassGeneric);
+  add(SPIRAS_Uniform, StorageClassUniform);
+  add(SPIRAS_Input, StorageClassInput);
+  add(SPIRAS_Output, StorageClassOutput);
+  add(SPIRAS_VulkanPrivate, StorageClassPrivate);
+  add(SPIRAS_PushConstant, StorageClassPushConstant);
+  add(SPIRAS_AtomicCounter, StorageClassAtomicCounter);
+  add(SPIRAS_Image, StorageClassImage);
+}
+typedef SPIRVMap<SPIRAddressSpace, SPIRVStorageClassKind> SPIRSPIRVAddrSpaceMap;
+
+// Maps OCL builtin function to SPIRV builtin variable.
+template <>
+inline void SPIRVMap<std::string, SPIRVAccessQualifierKind>::init() {
+  add("read_only", AccessQualifierReadOnly);
+  add("write_only", AccessQualifierWriteOnly);
+  add("read_write", AccessQualifierReadWrite);
+}
+typedef SPIRVMap<std::string, SPIRVAccessQualifierKind>
+    SPIRSPIRVAccessQualifierMap;
+
+template <>
+inline void SPIRVMap<Attribute::AttrKind, SPIRVFuncParamAttrKind>::init() {
+  add(Attribute::ZExt, FunctionParameterAttributeZext);
+  add(Attribute::SExt, FunctionParameterAttributeSext);
+  add(Attribute::ByVal, FunctionParameterAttributeByVal);
+  add(Attribute::StructRet, FunctionParameterAttributeSret);
+  add(Attribute::NoAlias, FunctionParameterAttributeNoAlias);
+  add(Attribute::NoCapture, FunctionParameterAttributeNoCapture);
+}
+typedef SPIRVMap<Attribute::AttrKind, SPIRVFuncParamAttrKind>
+    SPIRSPIRVFuncParamAttrMap;
+
+template <>
+inline void
+SPIRVMap<Attribute::AttrKind, SPIRVFunctionControlMaskKind>::init() {
+  add(Attribute::ReadNone, FunctionControlPureMask);
+  add(Attribute::ReadOnly, FunctionControlConstMask);
+  add(Attribute::AlwaysInline, FunctionControlInlineMask);
+  add(Attribute::NoInline, FunctionControlDontInlineMask);
+}
+typedef SPIRVMap<Attribute::AttrKind, SPIRVFunctionControlMaskKind>
+    SPIRSPIRVFuncCtlMaskMap;
+
+class SPIRVExtSetShortName;
+template <>
+inline void
+SPIRVMap<SPIRVExtInstSetKind, std::string, SPIRVExtSetShortName>::init() {
+  add(SPIRVEIS_OpenCL, "ocl");
+  add(SPIRVEIS_GLSL, "glsl");
+}
+typedef SPIRVMap<SPIRVExtInstSetKind, std::string, SPIRVExtSetShortName>
+    SPIRVExtSetShortNameMap;
+
+#define SPIR_MD_KERNELS "opencl.kernels"
+#define SPIR_MD_COMPILER_OPTIONS "opencl.compiler.options"
+#define SPIR_MD_KERNEL_ARG_ADDR_SPACE "kernel_arg_addr_space"
+#define SPIR_MD_KERNEL_ARG_ACCESS_QUAL "kernel_arg_access_qual"
+#define SPIR_MD_KERNEL_ARG_TYPE "kernel_arg_type"
+#define SPIR_MD_KERNEL_ARG_BASE_TYPE "kernel_arg_base_type"
+#define SPIR_MD_KERNEL_ARG_TYPE_QUAL "kernel_arg_type_qual"
+#define SPIR_MD_KERNEL_ARG_NAME "kernel_arg_name"
+
+#define OCL_TYPE_NAME_SAMPLER_T "sampler_t"
+#define SPIR_TYPE_NAME_EVENT_T "opencl.event_t"
+#define SPIR_TYPE_NAME_CLK_EVENT_T "opencl.clk_event_t"
+#define SPIR_TYPE_NAME_BLOCK_T "opencl.block"
+#define SPIR_INTRINSIC_BLOCK_BIND "spir_block_bind"
+#define SPIR_INTRINSIC_GET_BLOCK_INVOKE "spir_get_block_invoke"
+#define SPIR_INTRINSIC_GET_BLOCK_CONTEXT "spir_get_block_context"
+#define SPIR_TEMP_NAME_PREFIX_BLOCK "block"
+#define SPIR_TEMP_NAME_PREFIX_CALL "call"
+
+namespace kLLVMTypeName {
+const static char StructPrefix[] = "struct.";
+}
+
+namespace kSPIRVImageSampledTypeName {
+const static char Float[] = "float";
+const static char Half[] = "half";
+const static char Int[] = "int";
+const static char UInt[] = "uint";
+const static char Void[] = "void";
+}
+
+namespace kSPIRVTypeName {
+const static char Delimiter = '.';
+const static char DeviceEvent[] = "DeviceEvent";
+const static char Event[] = "Event";
+const static char Image[] = "Image";
+const static char Pipe[] = "Pipe";
+const static char PostfixDelim = '_';
+const static char Prefix[] = "spirv";
+const static char PrefixAndDelim[] = "spirv.";
+const static char Queue[] = "Queue";
+const static char ReserveId[] = "ReserveId";
+const static char SampledImg[] = "SampledImage";
+const static char Sampler[] = "Sampler";
+const static char ConstantSampler[] = "ConstantSampler";
+const static char PipeStorage[] = "PipeStorage";
+const static char ConstantPipeStorage[] = "ConstantPipeStorage";
+}
+
+namespace kSPR2TypeName {
+const static char Delimiter = '.';
+const static char OCLPrefix[] = "opencl.";
+const static char ImagePrefix[] = "opencl.image";
+const static char Pipe[] = "opencl.pipe_t";
+const static char Sampler[] = "opencl.sampler_t";
+const static char Event[] = "opencl.event_t";
+}
+
+namespace kAccessQualName {
+const static char ReadOnly[] = "read_only";
+const static char WriteOnly[] = "write_only";
+const static char ReadWrite[] = "read_write";
+}
+
+namespace kMangledName {
+const static char Sampler[] = "11ocl_sampler";
+const static char AtomicPrefixIncoming[] = "U7_Atomic";
+const static char AtomicPrefixInternal[] = "atomic_";
+}
+
+namespace kSPIRVName {
+const static char GroupPrefix[] = "group_";
+const static char Prefix[] = "__spirv_";
+const static char Postfix[] = "__";
+const static char ImageQuerySize[] = "ImageQuerySize";
+const static char ImageQuerySizeLod[] = "ImageQuerySizeLod";
+const static char ImageSampleExplicitLod[] = "ImageSampleExplicitLod";
+const static char ReservedPrefix[] = "reserved_";
+const static char SampledImage[] = "SampledImage";
+const static char TempSampledImage[] = "TempSampledImage";
+}
+
+namespace kSPIRVPostfix {
+const static char Sat[] = "sat";
+const static char Rtz[] = "rtz";
+const static char Rte[] = "rte";
+const static char Rtp[] = "rtp";
+const static char Rtn[] = "rtn";
+const static char Rt[] = "rt";
+const static char Return[] = "R";
+const static char Divider[] = "_";
+/// Divider between extended instruction name and postfix
+const static char ExtDivider[] = "__";
+}
+
+namespace kSPIRVMD {
+const static char Capability[] = "spirv.Capability";
+const static char EntryPoint[] = "spirv.EntryPoint";
+const static char ExecutionMode[] = "spirv.ExecutionMode";
+const static char Extension[] = "spirv.Extension";
+const static char Generator[] = "spirv.Generator";
+const static char Source[] = "spirv.Source";
+const static char SourceExtension[] = "spirv.SourceExtension";
+const static char MemoryModel[] = "spirv.MemoryModel";
+}
+
+namespace kSPIR2MD {
+const static char Extensions[] = "opencl.used.extensions";
+const static char FPContract[] = "opencl.enable.FP_CONTRACT";
+const static char OCLVer[] = "opencl.ocl.version";
+const static char OptFeatures[] = "opencl.used.optional.core.features";
+const static char SPIRVer[] = "opencl.spir.version";
+const static char VecTyHint[] = "vec_type_hint";
+const static char WGSize[] = "reqd_work_group_size";
+const static char WGSizeHint[] = "work_group_size_hint";
+}
+
+enum Spir2SamplerKind {
+  CLK_ADDRESS_NONE = 0x0000,
+  CLK_ADDRESS_CLAMP = 0x0004,
+  CLK_ADDRESS_CLAMP_TO_EDGE = 0x0002,
+  CLK_ADDRESS_REPEAT = 0x0006,
+  CLK_ADDRESS_MIRRORED_REPEAT = 0x0008,
+  CLK_NORMALIZED_COORDS_FALSE = 0x0000,
+  CLK_NORMALIZED_COORDS_TRUE = 0x0001,
+  CLK_FILTER_NEAREST = 0x0010,
+  CLK_FILTER_LINEAR = 0x0020,
+};
+
+/// Additional information for mangling a function argument type.
+struct BuiltinArgTypeMangleInfo {
+  bool IsSigned;
+  bool IsVoidPtr;
+  bool IsEnum;
+  bool IsSampler;
+  bool IsAtomic;
+  bool IsLocalArgBlock;
+  SPIR::TypePrimitiveEnum Enum;
+  unsigned Attr;
+  BuiltinArgTypeMangleInfo()
+      : IsSigned(true), IsVoidPtr(false), IsEnum(false), IsSampler(false),
+        IsAtomic(false), IsLocalArgBlock(false), Enum(SPIR::PRIMITIVE_NONE),
+        Attr(0) {}
+};
+
+/// Information for mangling builtin function.
+class BuiltinFuncMangleInfo {
+public:
+  /// Translate builtin function name and set
+  /// argument attributes and unsigned args.
+  BuiltinFuncMangleInfo(const std::string &UniqName = "")
+      : LocalArgBlockIdx(-1), VarArgIdx(-1) {
+    if (!UniqName.empty())
+      init(UniqName);
+  }
+  virtual ~BuiltinFuncMangleInfo() {}
+  const std::string &getUnmangledName() const { return UnmangledName; }
+  void addUnsignedArg(int Ndx) { UnsignedArgs.insert(Ndx); }
+  void addVoidPtrArg(int Ndx) { VoidPtrArgs.insert(Ndx); }
+  void addSamplerArg(int Ndx) { SamplerArgs.insert(Ndx); }
+  void addAtomicArg(int Ndx) { AtomicArgs.insert(Ndx); }
+  void setLocalArgBlock(int Ndx) {
+    assert(0 <= Ndx && "it is not allowed to set less than zero index");
+    LocalArgBlockIdx = Ndx;
+  }
+  void setEnumArg(int Ndx, SPIR::TypePrimitiveEnum Enum) {
+    EnumArgs[Ndx] = Enum;
+  }
+  void setArgAttr(int Ndx, unsigned Attr) { Attrs[Ndx] = Attr; }
+  void setVarArg(int Ndx) {
+    assert(0 <= Ndx && "it is not allowed to set less than zero index");
+    VarArgIdx = Ndx;
+  }
+  bool isArgUnsigned(int Ndx) {
+    return UnsignedArgs.count(-1) || UnsignedArgs.count(Ndx);
+  }
+  bool isArgVoidPtr(int Ndx) {
+    return VoidPtrArgs.count(-1) || VoidPtrArgs.count(Ndx);
+  }
+  bool isArgSampler(int Ndx) { return SamplerArgs.count(Ndx); }
+  bool isArgAtomic(int Ndx) { return AtomicArgs.count(Ndx); }
+  bool isLocalArgBlock(int Ndx) { return LocalArgBlockIdx == Ndx; }
+  bool isArgEnum(int Ndx, SPIR::TypePrimitiveEnum *Enum = nullptr) {
+    auto Loc = EnumArgs.find(Ndx);
+    if (Loc == EnumArgs.end())
+      Loc = EnumArgs.find(-1);
+    if (Loc == EnumArgs.end())
+      return false;
+    if (Enum)
+      *Enum = Loc->second;
+    return true;
+  }
+  unsigned getArgAttr(int Ndx) {
+    auto Loc = Attrs.find(Ndx);
+    if (Loc == Attrs.end())
+      Loc = Attrs.find(-1);
+    if (Loc == Attrs.end())
+      return 0;
+    return Loc->second;
+  }
+  // get ellipsis index, single ellipsis at the end of the function is possible
+  // only
+  // return value < 0 if none
+  int getVarArg() const { return VarArgIdx; }
+  BuiltinArgTypeMangleInfo getTypeMangleInfo(int Ndx) {
+    BuiltinArgTypeMangleInfo Info;
+    Info.IsSigned = !isArgUnsigned(Ndx);
+    Info.IsVoidPtr = isArgVoidPtr(Ndx);
+    Info.IsEnum = isArgEnum(Ndx, &Info.Enum);
+    Info.IsSampler = isArgSampler(Ndx);
+    Info.IsAtomic = isArgAtomic(Ndx);
+    Info.IsLocalArgBlock = isLocalArgBlock(Ndx);
+    Info.Attr = getArgAttr(Ndx);
+    return Info;
+  }
+  virtual void init(const std::string &UniqUnmangledName) {
+    UnmangledName = UniqUnmangledName;
+  }
+
+protected:
+  std::string UnmangledName;
+  std::set<int> UnsignedArgs; // unsigned arguments, or -1 if all are unsigned
+  std::set<int> VoidPtrArgs;  // void pointer arguments, or -1 if all are void
+                              // pointer
+  std::set<int> SamplerArgs;  // sampler arguments
+  std::set<int> AtomicArgs;   // atomic arguments
+  std::map<int, SPIR::TypePrimitiveEnum> EnumArgs; // enum arguments
+  std::map<int, unsigned> Attrs;                   // argument attributes
+  int LocalArgBlockIdx; // index of a block with local arguments, idx < 0 if
+                        // none
+  int VarArgIdx;        // index of ellipsis argument, idx < 0 if none
+};
+
+/// \returns a vector of types for a collection of values.
+template <class T> std::vector<Type *> getTypes(T V) {
+  std::vector<Type *> Tys;
+  for (auto &I : V)
+    Tys.push_back(I->getType());
+  return Tys;
+}
+
+/// Move elements of std::vector from [begin, end) to target.
+template <typename T>
+void move(std::vector<T> &V, size_t begin, size_t end, size_t target) {
+  assert(begin < end && end <= V.size() && target <= V.size() &&
+         !(begin < target && target < end));
+  if (begin <= target && target <= end)
+    return;
+  auto B = V.begin() + begin, E = V.begin() + end;
+  if (target > V.size())
+    target = V.size();
+  if (target > end)
+    target -= (end - begin);
+  std::vector<T> Segment(B, E);
+  V.erase(B, E);
+  V.insert(V.begin() + target, Segment.begin(), Segment.end());
+}
+
+/// Find position of first pointer type value in a vector.
+inline size_t findFirstPtr(const std::vector<Value *> &Args) {
+  auto PtArg = std::find_if(Args.begin(), Args.end(), [](Value *V) {
+    return V->getType()->isPointerTy();
+  });
+  return PtArg - Args.begin();
+}
+
+void removeFnAttr(LLVMContext *Context, CallInst *Call,
+                  Attribute::AttrKind Attr);
+void addFnAttr(LLVMContext *Context, CallInst *Call, Attribute::AttrKind Attr);
+void saveLLVMModule(Module *M, const std::string &OutputFile);
+std::string mapSPIRVTypeToOCLType(SPIRVType *Ty, bool Signed);
+std::string mapLLVMTypeToOCLType(const Type *Ty, bool Signed);
+SPIRVDecorate *mapPostfixToDecorate(StringRef Postfix, SPIRVEntry *Target);
+
+/// Add decorations to a SPIR-V entry.
+/// \param Decs Each string is a postfix without _ at the beginning.
+SPIRVValue *addDecorations(SPIRVValue *Target,
+                           const SmallVectorImpl<std::string> &Decs);
+
+PointerType *getOrCreateOpaquePtrType(Module *M, const std::string &Name,
+                                      unsigned AddrSpace = SPIRAS_Global);
+PointerType *getSamplerType(Module *M);
+PointerType *getPipeStorageType(Module *M);
+void getFunctionTypeParameterTypes(llvm::FunctionType *FT,
+                                   std::vector<Type *> &ArgTys);
+Function *getOrCreateFunction(Module *M, Type *RetTy, ArrayRef<Type *> ArgTypes,
+                              StringRef Name,
+                              BuiltinFuncMangleInfo *Mangle = nullptr,
+                              AttributeSet *Attrs = nullptr,
+                              bool takeName = true);
+
+/// Get function call arguments.
+/// \param Start Starting index.
+/// \param End Ending index.
+std::vector<Value *> getArguments(CallInst *CI, unsigned Start = 0,
+                                  unsigned End = 0);
+
+/// Get constant function call argument as an integer.
+/// \param I argument index.
+uint64_t getArgAsInt(CallInst *CI, unsigned I);
+
+/// Get constant function call argument as type \param T.
+/// \param I argument index.
+template <typename T> T getArgAs(CallInst *CI, unsigned I) {
+  return static_cast<T>(getArgAsInt(CI, I));
+}
+
+/// Get constant function call argument as a Scope enum.
+/// \param I argument index.
+Scope getArgAsScope(CallInst *CI, unsigned I);
+
+/// Get constant function call argument as a Decoration enum.
+/// \param I argument index.
+Decoration getArgAsDecoration(CallInst *CI, unsigned I);
+
+bool isPointerToOpaqueStructType(llvm::Type *Ty);
+bool isPointerToOpaqueStructType(llvm::Type *Ty, const std::string &Name);
+
+/// Check if a type is OCL image type.
+/// \return type name without "opencl." prefix.
+bool isOCLImageType(llvm::Type *Ty, StringRef *Name = nullptr);
+
+/// \param BaseTyName is the type name as in spirv.BaseTyName.Postfixes
+/// \param Postfix contains postfixes extracted from the SPIR-V image
+///   type name as spirv.BaseTyName.Postfixes.
+bool isSPIRVType(llvm::Type *Ty, StringRef BaseTyName, StringRef *Postfix = 0);
+
+/// Decorate a function name as __spirv_{Name}_
+std::string decorateSPIRVFunction(const std::string &S);
+
+/// Remove prefix/postfix from __spirv_{Name}_
+std::string undecorateSPIRVFunction(const std::string &S);
+
+/// Check if a function has decorated name as __spirv_{Name}_
+/// and get the original name.
+bool isDecoratedSPIRVFunc(const Function *F, std::string *UndecName = nullptr);
+
+/// Get a canonical function name for a SPIR-V op code.
+std::string getSPIRVFuncName(Op OC, StringRef PostFix = "");
+
+std::string getSPIRVFuncName(Op OC, const Type *pRetTy, bool IsSigned = false);
+
+/// Get a canonical function name for a SPIR-V extended instruction
+std::string getSPIRVExtFuncName(SPIRVExtInstSetKind Set, unsigned ExtOp,
+                                StringRef PostFix = "");
+
+/// Get SPIR-V op code given the canonical function name.
+/// Assume \param Name is either IA64 mangled or unmangled, and the unmangled
+/// name takes the __spirv_{OpName}_{Postfixes} format.
+/// \return op code if the unmangled function name is a valid op code name,
+///   otherwise return OpNop.
+/// \param Dec contains decorations decoded from function name if it is
+///   not nullptr.
+Op getSPIRVFuncOC(const std::string &Name,
+                  SmallVectorImpl<std::string> *Dec = nullptr);
+
+/// Get SPIR-V builtin variable enum given the canonical builtin name
+/// Assume \param Name is in format __spirv_BuiltIn{Name}
+/// \return false if \param Name is not a valid builtin name.
+bool getSPIRVBuiltin(const std::string &Name, spv::BuiltIn &Builtin);
+
+/// \param Name LLVM function name
+/// \param DemangledName demanged name of the OpenCL built-in function
+/// \returns true if Name is the name of the OpenCL built-in function,
+/// false for other functions
+bool oclIsBuiltin(const StringRef &Name, std::string *DemangledName = nullptr,
+                  bool isCPP = false);
+
+/// Check if a function type is void(void).
+bool isVoidFuncTy(FunctionType *FT);
+
+/// \returns true if \p T is a function pointer type.
+bool isFunctionPointerType(Type *T);
+
+/// \returns true if function \p F has function pointer type argument.
+/// \param AI points to the function pointer type argument if returns true.
+bool hasFunctionPointerArg(Function *F, Function::arg_iterator &AI);
+
+/// \returns true if function \p F has array type argument.
+bool hasArrayArg(Function *F);
+
+/// Mutates function call instruction by changing the arguments.
+/// \param ArgMutate mutates the function arguments.
+/// \return mutated call instruction.
+CallInst *mutateCallInst(
+    Module *M, CallInst *CI,
+    std::function<std::string(CallInst *, std::vector<Value *> &)> ArgMutate,
+    BuiltinFuncMangleInfo *Mangle = nullptr, AttributeSet *Attrs = nullptr,
+    bool takeName = false);
+
+/// Mutates function call instruction by changing the arguments and return
+/// value.
+/// \param ArgMutate mutates the function arguments.
+/// \param RetMutate mutates the return value.
+/// \return mutated instruction.
+Instruction *mutateCallInst(
+    Module *M, CallInst *CI,
+    std::function<std::string(CallInst *, std::vector<Value *> &, Type *&RetTy)>
+        ArgMutate,
+    std::function<Instruction *(CallInst *)> RetMutate,
+    BuiltinFuncMangleInfo *Mangle = nullptr, AttributeSet *Attrs = nullptr,
+    bool takeName = false);
+
+/// Mutate call instruction to call SPIR-V builtin function.
+CallInst *mutateCallInstSPIRV(
+    Module *M, CallInst *CI,
+    std::function<std::string(CallInst *, std::vector<Value *> &)> ArgMutate,
+    AttributeSet *Attrs = nullptr);
+
+/// Mutate call instruction to call SPIR-V builtin function.
+Instruction *mutateCallInstSPIRV(
+    Module *M, CallInst *CI,
+    std::function<std::string(CallInst *, std::vector<Value *> &, Type *&RetTy)>
+        ArgMutate,
+    std::function<Instruction *(CallInst *)> RetMutate,
+    AttributeSet *Attrs = nullptr);
+
+/// Mutate function by change the arguments.
+/// \param ArgMutate mutates the function arguments.
+/// \param TakeName Take the original function's name if a new function with
+///   different type needs to be created.
+void mutateFunction(
+    Function *F,
+    std::function<std::string(CallInst *, std::vector<Value *> &)> ArgMutate,
+    BuiltinFuncMangleInfo *Mangle = nullptr, AttributeSet *Attrs = nullptr,
+    bool TakeName = true);
+
+/// Add a call instruction at \p Pos.
+CallInst *addCallInst(Module *M, StringRef FuncName, Type *RetTy,
+                      ArrayRef<Value *> Args, AttributeSet *Attrs,
+                      Instruction *Pos, BuiltinFuncMangleInfo *Mangle = nullptr,
+                      StringRef InstName = SPIR_TEMP_NAME_PREFIX_CALL,
+                      bool TakeFuncName = true);
+
+/// Add a call instruction for SPIR-V builtin function.
+CallInst *addCallInstSPIRV(Module *M, StringRef FuncName, Type *RetTy,
+                           ArrayRef<Value *> Args, AttributeSet *Attrs,
+                           Instruction *Pos, StringRef InstName);
+
+/// Add a call of spir_block_bind function.
+CallInst *addBlockBind(Module *M, Function *InvokeFunc, Value *BlkCtx,
+                       Value *CtxLen, Value *CtxAlign, Instruction *InsPos,
+                       StringRef InstName = SPIR_TEMP_NAME_PREFIX_BLOCK);
+
+typedef std::pair<std::vector<Value *>::iterator,
+                  std::vector<Value *>::iterator>
+    ValueVecRange;
+
+/// Add a vector at \param InsPos.
+Value *addVector(Instruction *InsPos, ValueVecRange Range);
+
+/// Replace scalar values with a vector created at \param InsPos.
+void makeVector(Instruction *InsPos, std::vector<Value *> &Ops,
+                ValueVecRange Range);
+
+/// Expand a vector type value in \param Ops at index \param VecPos.
+/// Generate extract element instructions at \param InsPos and replace
+/// the vector type value with scalar type values.
+/// If the value to be expanded is not vector type, do nothing.
+void expandVector(Instruction *InsPos, std::vector<Value *> &Ops,
+                  size_t VecPos);
+
+/// Get size_t type.
+IntegerType *getSizetType(Module *M);
+
+/// Get void(void) function type.
+Type *getVoidFuncType(Module *M);
+
+/// Get void(void) function pointer type.
+Type *getVoidFuncPtrType(Module *M, unsigned AddrSpace = 0);
+
+/// Get a 64 bit integer constant.
+ConstantInt *getInt64(Module *M, int64_t value);
+
+/// Get a 32 bit integer constant.
+ConstantInt *getInt32(Module *M, int value);
+
+/// Get a 32 bit unsigned integer constant.
+ConstantInt *getUInt32(Module *M, unsigned value);
+
+/// Get a 16 bit unsigned integer constant.
+ConstantInt *getUInt16(Module *M, unsigned short value);
+
+// Get a 32 bit floating point constant.
+Constant *getFloat32(Module *M, float value);
+
+/// Get a 32 bit integer constant vector.
+std::vector<Value *> getInt32(Module *M, const std::vector<int> &value);
+
+/// Get a size_t type constant.
+ConstantInt *getSizet(Module *M, uint64_t value);
+
+/// Get metadata operand as int.
+int getMDOperandAsInt(MDNode *N, unsigned I);
+
+/// Get metadata operand as string.
+std::string getMDOperandAsString(MDNode *N, unsigned I);
+
+/// Get metadata operand as type.
+Type *getMDOperandAsType(MDNode *N, unsigned I);
+
+/// Get a named metadata as a set of string.
+/// Assume the named metadata has one or more operands each of which might
+/// contain set of strings. For instance:
+/// !opencl.used.optional.core.features = !{!0}
+/// !0 = !{!"cl_doubles", !"cl_images"}
+/// or if we linked two modules we may have
+/// !opencl.used.optional.core.features = !{!0, !1}
+/// !0 = !{!"cl_doubles"}
+/// !1 = !{!"cl_images"}
+std::set<std::string> getNamedMDAsStringSet(Module *M,
+                                            const std::string &MDName);
+
+/// Get SPIR-V language by SPIR-V metadata spirv.Source
+std::tuple<unsigned, unsigned, std::string> getSPIRVSource(Module *M);
+
+/// Map an unsigned integer constant by applying a function.
+ConstantInt *mapUInt(Module *M, ConstantInt *I,
+                     std::function<unsigned(unsigned)> F);
+
+/// Map a signed integer constant by applying a function.
+ConstantInt *mapSInt(Module *M, ConstantInt *I, std::function<int(int)> F);
+
+/// Get postfix for given decoration.
+/// The returned postfix does not include "_" at the beginning.
+std::string getPostfix(Decoration Dec, unsigned Value = 0);
+
+/// Get postfix _R{ReturnType} for return type
+/// The returned postfix does not includ "_" at the beginning
+std::string getPostfixForReturnType(CallInst *CI, bool IsSigned = false);
+std::string getPostfixForReturnType(const Type *pRetTy, bool IsSigned = false);
+
+Constant *getScalarOrVectorConstantInt(Type *T, uint64_t V,
+                                       bool isSigned = false);
+
+/// Get a constant int or a constant int array.
+/// \param T is the type of the constant. It should be an integer type or
+//  an integer pointer type.
+/// \param Len is the length of the array.
+/// \param V is the value to fill the array.
+Value *getScalarOrArrayConstantInt(Instruction *P, Type *T, unsigned Len,
+                                   uint64_t V, bool isSigned = false);
+
+/// Get the array from GEP.
+/// \param V is a GEP whose pointer operand is a pointer to an array of size
+/// \param Size.
+Value *getScalarOrArray(Value *V, unsigned Size, Instruction *Pos);
+
+void dumpUsers(Value *V, StringRef Prompt = "");
+
+/// Get SPIR-V type name as spirv.BaseTyName.Postfixes.
+std::string getSPIRVTypeName(StringRef BaseTyName, StringRef Postfixes = "");
+
+/// Checks if given type name is either ConstantSampler or ConsantPipeStorage.
+bool isSPIRVConstantName(StringRef TyName);
+
+/// Get SPIR-V type by changing the type name from spirv.OldName.Postfixes
+/// to spirv.NewName.Postfixes.
+Type *getSPIRVTypeByChangeBaseTypeName(Module *M, Type *T, StringRef OldName,
+                                       StringRef NewName);
+
+/// Get the postfixes of SPIR-V image type name as in spirv.Image.postfixes.
+std::string getSPIRVImageTypePostfixes(StringRef SampledType,
+                                       SPIRVTypeImageDescriptor Desc,
+                                       SPIRVAccessQualifierKind Acc);
+
+/// Get the sampled type name used in postfix of image type in SPIR-V
+/// friendly LLVM IR.
+std::string getSPIRVImageSampledTypeName(SPIRVType *Ty);
+
+/// Translates OpenCL image type names to SPIR-V.
+/// E.g. %opencl.image1d_rw_t -> %spirv.Image._void_0_0_0_0_0_0_2
+Type *getSPIRVImageTypeFromOCL(Module *M, Type *T);
+
+/// Get LLVM type for sampled type of SPIR-V image type by postfix.
+Type *getLLVMTypeForSPIRVImageSampledTypePostfix(StringRef Postfix,
+                                                 LLVMContext &Ctx);
+
+/// Map OpenCL opaque type name to SPIR-V type name.
+std::string mapOCLTypeNameToSPIRV(StringRef Name, StringRef Acc = "");
+
+/// Check if access qualifier is encoded in the type name.
+bool hasAccessQualifiedName(StringRef TyName);
+
+/// Get access qualifier from the type name.
+StringRef getAccessQualifier(StringRef TyName);
+
+bool eraseUselessFunctions(Module *M);
+
+/// Erase a function if it is declaration, has internal linkage and has no use.
+bool eraseIfNoUse(Function *F);
+
+void eraseIfNoUse(Value *V);
+
+// Check if a mangled type name is unsigned
+bool isMangledTypeUnsigned(char Mangled);
+
+// Check if a mangled type name is signed
+bool isMangledTypeSigned(char Mangled);
+
+// Check if a mangled type name is floating point (except half)
+bool isMangledTypeFP(char Mangled);
+
+// Check if a mangled type name is half
+bool isMangledTypeHalf(std::string Mangled);
+
+// Check if \param I is valid vector size: 2, 3, 4, 8, 16.
+bool isValidVectorSize(unsigned I);
+
+enum class ParamType { FLOAT = 0, SIGNED = 1, UNSIGNED = 2, UNKNOWN = 3 };
+
+ParamType LastFuncParamType(const std::string &MangledName);
+
+// Check if the last function parameter is signed
+bool isLastFuncParamSigned(const std::string &MangledName);
+
+// Check if a mangled function name contains unsigned atomic type
+bool containsUnsignedAtomicType(StringRef Name);
+
+/// Mangle builtin function name.
+/// \return \param UniqName if \param BtnInfo is null pointer, otherwise
+///    return IA64 mangled name.
+std::string mangleBuiltin(const std::string &UniqName,
+                          ArrayRef<Type *> ArgTypes,
+                          BuiltinFuncMangleInfo *BtnInfo);
+
+/// Remove cast from a value.
+Value *removeCast(Value *V);
+
+/// Cast a function to a void(void) funtion pointer.
+Constant *castToVoidFuncPtr(Function *F);
+
+/// Get i8* with the same address space.
+PointerType *getInt8PtrTy(PointerType *T);
+
+/// Cast a value to a i8* by inserting a cast instruction.
+Value *castToInt8Ptr(Value *V, Instruction *Pos);
+
+template <> inline void SPIRVMap<std::string, Op, SPIRVOpaqueType>::init() {
+  add(kSPIRVTypeName::DeviceEvent, OpTypeDeviceEvent);
+  add(kSPIRVTypeName::Event, OpTypeEvent);
+  add(kSPIRVTypeName::Image, OpTypeImage);
+  add(kSPIRVTypeName::Pipe, OpTypePipe);
+  add(kSPIRVTypeName::Queue, OpTypeQueue);
+  add(kSPIRVTypeName::ReserveId, OpTypeReserveId);
+  add(kSPIRVTypeName::Sampler, OpTypeSampler);
+  add(kSPIRVTypeName::SampledImg, OpTypeSampledImage);
+}
+}
+
+#endif
diff --git a/lib/SPIRV/SPIRVLowerBool.cpp b/lib/SPIRV/SPIRVLowerBool.cpp
new file mode 100644
index 0000000..255a227
--- /dev/null
+++ b/lib/SPIRV/SPIRVLowerBool.cpp
@@ -0,0 +1,133 @@
+//===- SPIRVLowerBool.cpp  Lower instructions with bool operands ---------===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+//
+// This file implements lowering instructions with bool operands.
+//
+//===----------------------------------------------------------------------===//
+#define DEBUG_TYPE "spvbool"
+
+#include "SPIRVInternal.h"
+#include "llvm/IR/InstVisitor.h"
+#include "llvm/IR/Instructions.h"
+#include "llvm/IR/IRBuilder.h"
+#include "llvm/IR/Verifier.h"
+#include "llvm/Pass.h"
+#include "llvm/PassSupport.h"
+#include "llvm/Support/CommandLine.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/raw_ostream.h"
+
+using namespace llvm;
+using namespace SPIRV;
+
+namespace SPIRV {
+cl::opt<bool> SPIRVLowerBoolValidate(
+    "spvbool-validate",
+    cl::desc("Validate module after lowering boolean instructions for SPIR-V"));
+
+class SPIRVLowerBool : public ModulePass, public InstVisitor<SPIRVLowerBool> {
+public:
+  SPIRVLowerBool() : ModulePass(ID), Context(nullptr) {
+    initializeSPIRVLowerBoolPass(*PassRegistry::getPassRegistry());
+  }
+  void replace(Instruction *I, Instruction *NewI) {
+    NewI->takeName(I);
+    I->replaceAllUsesWith(NewI);
+    I->dropAllReferences();
+    I->eraseFromParent();
+  }
+  bool isBoolType(Type *Ty) {
+    if (Ty->isIntegerTy(1))
+      return true;
+    if (auto VT = dyn_cast<VectorType>(Ty))
+      return isBoolType(VT->getElementType());
+    return false;
+  }
+  virtual void visitTruncInst(TruncInst &I) {
+    if (isBoolType(I.getType())) {
+      auto Op = I.getOperand(0);
+      auto Zero = getScalarOrVectorConstantInt(Op->getType(), 0, false);
+      auto Cmp = new ICmpInst(&I, CmpInst::ICMP_NE, Op, Zero);
+      replace(&I, Cmp);
+    }
+  }
+  virtual void visitZExtInst(ZExtInst &I) {
+    auto Op = I.getOperand(0);
+    if (isBoolType(Op->getType())) {
+      auto Ty = I.getType();
+      auto Zero = getScalarOrVectorConstantInt(Ty, 0, false);
+      auto One = getScalarOrVectorConstantInt(Ty, 1, false);
+      auto Sel = SelectInst::Create(Op, One, Zero, "", &I);
+      replace(&I, Sel);
+    }
+  }
+  virtual void visitSExtInst(SExtInst &I) {
+    auto Op = I.getOperand(0);
+    if (isBoolType(Op->getType())) {
+      auto Ty = I.getType();
+      auto Zero = getScalarOrVectorConstantInt(Ty, 0, false);
+      auto One = getScalarOrVectorConstantInt(Ty, ~0, false);
+      auto Sel = SelectInst::Create(Op, One, Zero, "", &I);
+      replace(&I, Sel);
+    }
+  }
+  virtual bool runOnModule(Module &M) {
+    Context = &M.getContext();
+    visit(M);
+
+    if (SPIRVLowerBoolValidate) {
+      DEBUG(dbgs() << "After SPIRVLowerBool:\n" << M);
+      std::string Err;
+      raw_string_ostream ErrorOS(Err);
+      if (verifyModule(M, &ErrorOS)) {
+        Err = std::string("Fails to verify module: ") + Err;
+        report_fatal_error(Err.c_str(), false);
+      }
+    }
+    return true;
+  }
+
+  static char ID;
+
+private:
+  LLVMContext *Context;
+};
+
+char SPIRVLowerBool::ID = 0;
+}
+
+INITIALIZE_PASS(SPIRVLowerBool, "spvbool",
+                "Lower instructions with bool operands", false, false)
+
+ModulePass *llvm::createSPIRVLowerBool() { return new SPIRVLowerBool(); }
diff --git a/lib/SPIRV/SPIRVLowerConstExpr.cpp b/lib/SPIRV/SPIRVLowerConstExpr.cpp
new file mode 100644
index 0000000..f337b0b
--- /dev/null
+++ b/lib/SPIRV/SPIRVLowerConstExpr.cpp
@@ -0,0 +1,163 @@
+//===- SPIRVLowerConstExpr.cpp - Regularize LLVM for SPIR-V ------- C++ -*-===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+//
+// This file implements regularization of LLVM moduel for SPIR-V.
+//
+//===----------------------------------------------------------------------===//
+#define DEBUG_TYPE "spv-lower-const-expr"
+
+#include "SPIRVInternal.h"
+#include "OCLUtil.h"
+#include "SPIRVMDBuilder.h"
+#include "SPIRVMDWalker.h"
+
+#include "llvm/ADT/StringSwitch.h"
+#include "llvm/ADT/Triple.h"
+#include "llvm/IR/InstVisitor.h"
+#include "llvm/IR/Instructions.h"
+#include "llvm/IR/IRBuilder.h"
+#include "llvm/IR/Verifier.h"
+#include "llvm/Pass.h"
+#include "llvm/PassSupport.h"
+#include "llvm/Support/CommandLine.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/raw_ostream.h"
+
+#include <list>
+#include <set>
+
+using namespace llvm;
+using namespace SPIRV;
+using namespace OCLUtil;
+
+namespace SPIRV {
+
+cl::opt<bool> SPIRVLowerConst(
+    "spirv-lower-const-expr", cl::init(true),
+    cl::desc("LLVM/SPIR-V translation enalbe lowering constant expression"));
+
+class SPIRVLowerConstExpr : public ModulePass {
+public:
+  SPIRVLowerConstExpr() : ModulePass(ID), M(nullptr), Ctx(nullptr) {
+    initializeSPIRVLowerConstExprPass(*PassRegistry::getPassRegistry());
+  }
+
+  virtual bool runOnModule(Module &M);
+  void visit(Module *M);
+
+  static char ID;
+
+private:
+  Module *M;
+  LLVMContext *Ctx;
+};
+
+char SPIRVLowerConstExpr::ID = 0;
+
+bool SPIRVLowerConstExpr::runOnModule(Module &Module) {
+  if (!SPIRVLowerConst)
+    return false;
+
+  M = &Module;
+  Ctx = &M->getContext();
+
+  DEBUG(dbgs() << "Enter SPIRVLowerConstExpr:\n");
+  visit(M);
+
+  DEBUG(dbgs() << "After SPIRVLowerConstExpr:\n" << *M);
+  std::string Err;
+  raw_string_ostream ErrorOS(Err);
+  if (verifyModule(*M, &ErrorOS)) {
+    DEBUG(errs() << "Fails to verify module: " << ErrorOS.str());
+  }
+  return true;
+}
+
+/// Since SPIR-V cannot represent constant expression, constant expressions
+/// in LLVM needs to be lowered to instructions.
+/// For each function, the constant expressions used by instructions of the
+/// function are replaced by instructions placed in the entry block since it
+/// dominates all other BB's. Each constant expression only needs to be lowered
+/// once in each function and all uses of it by instructions in that function
+/// is replaced by one instruction.
+/// ToDo: remove redundant instructions for common subexpression
+
+void SPIRVLowerConstExpr::visit(Module *M) {
+  for (auto &I : *M) {
+    std::map<ConstantExpr *, Instruction *> CMap;
+    std::list<Instruction *> WorkList;
+    auto FBegin = I.begin();
+    for (auto BI = FBegin, BE = I.end(); BI != BE; ++BI) {
+      for (auto II = BI->begin(), IE = BI->end(); II != IE; ++II) {
+        WorkList.push_back(&*II);
+      }
+    }
+    while (!WorkList.empty()) {
+      auto II = WorkList.front();
+      WorkList.pop_front();
+      for (unsigned OI = 0, OE = II->getNumOperands(); OI != OE; ++OI) {
+        auto Op = II->getOperand(OI);
+
+        if (auto CE = dyn_cast<ConstantExpr>(Op)) {
+          SPIRVDBG(dbgs() << "[lowerConstantExpressions] " << *CE;)
+          auto ReplInst = CE->getAsInstruction();
+          ReplInst->insertBefore(&*(I.getEntryBlock().getFirstInsertionPt()));
+          SPIRVDBG(dbgs() << " -> " << *ReplInst << '\n';)
+          WorkList.push_front(ReplInst);
+          std::vector<Instruction *> Users;
+          // Do not replace use during iteration of use. Do it in another loop.
+          for (auto U : CE->users()) {
+            SPIRVDBG(dbgs() << "[lowerConstantExpressions] Use: " << *U
+                            << '\n';)
+            if (auto InstUser = dyn_cast<Instruction>(U)) {
+              if (InstUser->getParent()->getParent() != &I)
+                continue;
+              Users.push_back(InstUser);
+            }
+          }
+          for (auto &User : Users)
+            User->replaceUsesOfWith(CE, ReplInst);
+        }
+      }
+    }
+  }
+}
+}
+
+INITIALIZE_PASS(SPIRVLowerConstExpr, "spv-lower-const-expr",
+                "Regularize LLVM for SPIR-V", false, false)
+
+ModulePass *llvm::createSPIRVLowerConstExpr() {
+  return new SPIRVLowerConstExpr();
+}
diff --git a/lib/SPIRV/SPIRVLowerOCLBlocks.cpp b/lib/SPIRV/SPIRVLowerOCLBlocks.cpp
new file mode 100644
index 0000000..e7025dc
--- /dev/null
+++ b/lib/SPIRV/SPIRVLowerOCLBlocks.cpp
@@ -0,0 +1,590 @@
+//===- SPIRVLowerOCLBlocks.cpp - Lower OpenCL blocks ------------*- C++ -*-===//
+//
+//                     The LLVM/SPIR-V Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+/// \file
+///
+/// This file implements lowering of OpenCL blocks to functions.
+///
+//===----------------------------------------------------------------------===//
+
+#ifndef OCLLOWERBLOCKS_H_
+#define OCLLOWERBLOCKS_H_
+
+#include "SPIRVInternal.h"
+#include "OCLUtil.h"
+
+#include "llvm/ADT/DenseMap.h"
+#include "llvm/ADT/SetVector.h"
+#include "llvm/ADT/StringSwitch.h"
+#include "llvm/ADT/Triple.h"
+#include "llvm/Analysis/AliasAnalysis.h"
+#include "llvm/Analysis/AssumptionCache.h"
+#include "llvm/Analysis/CallGraph.h"
+#include "llvm/Analysis/GlobalsModRef.h"
+#include "llvm/IR/Verifier.h"
+#include "llvm/Bitcode/ReaderWriter.h"
+#include "llvm/IR/Constants.h"
+#include "llvm/IR/DerivedTypes.h"
+#include "llvm/IR/Function.h"
+#include "llvm/IR/InstrTypes.h"
+#include "llvm/IR/Instructions.h"
+#include "llvm/IR/Module.h"
+#include "llvm/IR/Operator.h"
+#include "llvm/Pass.h"
+#include "llvm/PassSupport.h"
+#include "llvm/Support/Casting.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/raw_ostream.h"
+#include "llvm/Support/ToolOutputFile.h"
+#include "llvm/Transforms/Utils/Cloning.h"
+#include "llvm/Transforms/Utils/GlobalStatus.h"
+#include <iostream>
+#include <list>
+#include <memory>
+#include <set>
+#include <sstream>
+#include <vector>
+
+#define DEBUG_TYPE "spvblocks"
+
+using namespace llvm;
+using namespace SPIRV;
+using namespace OCLUtil;
+
+namespace SPIRV {
+
+/// Lower SPIR2 blocks to function calls.
+///
+/// SPIR2 representation of blocks:
+///
+/// block = spir_block_bind(bitcast(block_func), context_len, context_align,
+///   context)
+/// block_func_ptr = bitcast(spir_get_block_invoke(block))
+/// context_ptr = spir_get_block_context(block)
+/// ret = block_func_ptr(context_ptr, args)
+///
+/// Propagates block_func to each spir_get_block_invoke through def-use chain of
+/// spir_block_bind, so that
+/// ret = block_func(context, args)
+class SPIRVLowerOCLBlocks : public ModulePass {
+public:
+  SPIRVLowerOCLBlocks() : ModulePass(ID), M(nullptr) {
+    initializeSPIRVLowerOCLBlocksPass(*PassRegistry::getPassRegistry());
+  }
+
+  virtual void getAnalysisUsage(AnalysisUsage &AU) const {
+    AU.addRequired<CallGraphWrapperPass>();
+    AU.addRequired<AAResultsWrapperPass>();
+    AU.addRequired<AssumptionCacheTracker>();
+    // TODO: not sure about these
+    // AU.addPreserved<GlobalsAAWrapperPass>();
+    // AU.setPreservesCFG();
+  }
+
+  virtual bool runOnModule(Module &Module) {
+    M = &Module;
+    lowerBlockBind();
+    lowerGetBlockInvoke();
+    lowerGetBlockContext();
+    EraseUselessGlobalVars();
+    EliminateDeadArgs();
+    erase(M->getFunction(SPIR_INTRINSIC_GET_BLOCK_INVOKE));
+    erase(M->getFunction(SPIR_INTRINSIC_GET_BLOCK_CONTEXT));
+    erase(M->getFunction(SPIR_INTRINSIC_BLOCK_BIND));
+    DEBUG(dbgs() << "------- After OCLLowerBlocks ------------\n"
+                 << *M << '\n');
+    return true;
+  }
+
+  static char ID;
+
+private:
+  const static int MaxIter = 1000;
+  Module *M;
+
+  bool lowerBlockBind() {
+    auto F = M->getFunction(SPIR_INTRINSIC_BLOCK_BIND);
+    if (!F)
+      return false;
+    int Iter = MaxIter;
+    while (lowerBlockBind(F) && Iter > 0) {
+      Iter--;
+      DEBUG(dbgs() << "-------------- after iteration " << MaxIter - Iter
+                   << " --------------\n"
+                   << *M << '\n');
+    }
+    assert(Iter > 0 && "Too many iterations");
+    return true;
+  }
+
+  bool eraseUselessFunctions() {
+    bool changed = false;
+    for (auto I = M->begin(), E = M->end(); I != E;) {
+      Function *F = &*I;
+      ++I;
+      if (!GlobalValue::isInternalLinkage(F->getLinkage()) &&
+          !F->isDeclaration())
+        continue;
+
+      dumpUsers(F, "[eraseUselessFunctions] ");
+      for (auto UI = F->user_begin(), UE = F->user_end(); UI != UE;) {
+        auto U = *UI++;
+        if (auto CE = dyn_cast<ConstantExpr>(U)) {
+          if (CE->use_empty()) {
+            CE->dropAllReferences();
+            changed = true;
+          }
+        }
+      }
+      if (F->use_empty()) {
+        erase(F);
+        changed = true;
+      }
+    }
+    return changed;
+  }
+
+  void lowerGetBlockInvoke() {
+    if (auto F = M->getFunction(SPIR_INTRINSIC_GET_BLOCK_INVOKE)) {
+      for (auto UI = F->user_begin(), UE = F->user_end(); UI != UE;) {
+        auto CI = dyn_cast<CallInst>(*UI++);
+        assert(CI && "Invalid usage of spir_get_block_invoke");
+        lowerGetBlockInvoke(CI);
+      }
+    }
+  }
+
+  void lowerGetBlockContext() {
+    if (auto F = M->getFunction(SPIR_INTRINSIC_GET_BLOCK_CONTEXT)) {
+      for (auto UI = F->user_begin(), UE = F->user_end(); UI != UE;) {
+        auto CI = dyn_cast<CallInst>(*UI++);
+        assert(CI && "Invalid usage of spir_get_block_context");
+        lowerGetBlockContext(CI);
+      }
+    }
+  }
+  /// Lower calls of spir_block_bind.
+  /// Return true if the Module is changed.
+  bool lowerBlockBind(Function *BlockBindFunc) {
+    bool changed = false;
+    for (auto I = BlockBindFunc->user_begin(), E = BlockBindFunc->user_end();
+         I != E;) {
+      DEBUG(dbgs() << "[lowerBlockBind] " << **I << '\n');
+      // Handle spir_block_bind(bitcast(block_func), context_len,
+      // context_align, context)
+      auto CallBlkBind = cast<CallInst>(*I++);
+      Function *InvF = nullptr;
+      Value *Ctx = nullptr;
+      Value *CtxLen = nullptr;
+      Value *CtxAlign = nullptr;
+      getBlockInvokeFuncAndContext(CallBlkBind, &InvF, &Ctx, &CtxLen,
+                                   &CtxAlign);
+      for (auto II = CallBlkBind->user_begin(), EE = CallBlkBind->user_end();
+           II != EE;) {
+        auto BlkUser = *II++;
+        SPIRVDBG(dbgs() << "  Block user: " << *BlkUser << '\n');
+        if (auto Ret = dyn_cast<ReturnInst>(BlkUser)) {
+          bool Inlined = false;
+          changed |= lowerReturnBlock(Ret, CallBlkBind, Inlined);
+          if (Inlined)
+            return true;
+        } else if (auto CI = dyn_cast<CallInst>(BlkUser)) {
+          auto CallBindF = CI->getCalledFunction();
+          auto Name = CallBindF->getName();
+          std::string DemangledName;
+          if (Name == SPIR_INTRINSIC_GET_BLOCK_INVOKE) {
+            assert(CI->getArgOperand(0) == CallBlkBind);
+            changed |= lowerGetBlockInvoke(CI, cast<Function>(InvF));
+          } else if (Name == SPIR_INTRINSIC_GET_BLOCK_CONTEXT) {
+            assert(CI->getArgOperand(0) == CallBlkBind);
+            // Handle context_ptr = spir_get_block_context(block)
+            lowerGetBlockContext(CI, Ctx);
+            changed = true;
+          } else if (oclIsBuiltin(Name, &DemangledName)) {
+            lowerBlockBuiltin(CI, InvF, Ctx, CtxLen, CtxAlign, DemangledName);
+            changed = true;
+          } else
+            llvm_unreachable("Invalid block user");
+        }
+      }
+      erase(CallBlkBind);
+    }
+    changed |= eraseUselessFunctions();
+    return changed;
+  }
+
+  void lowerGetBlockContext(CallInst *CallGetBlkCtx, Value *Ctx = nullptr) {
+    if (!Ctx)
+      getBlockInvokeFuncAndContext(CallGetBlkCtx->getArgOperand(0), nullptr,
+                                   &Ctx);
+    CallGetBlkCtx->replaceAllUsesWith(Ctx);
+    DEBUG(dbgs() << "  [lowerGetBlockContext] " << *CallGetBlkCtx << " => "
+                 << *Ctx << "\n\n");
+    erase(CallGetBlkCtx);
+  }
+
+  bool lowerGetBlockInvoke(CallInst *CallGetBlkInvoke,
+                           Function *InvokeF = nullptr) {
+    bool changed = false;
+    for (auto UI = CallGetBlkInvoke->user_begin(),
+              UE = CallGetBlkInvoke->user_end();
+         UI != UE;) {
+      // Handle block_func_ptr = bitcast(spir_get_block_invoke(block))
+      auto CallInv = cast<Instruction>(*UI++);
+      auto Cast = dyn_cast<BitCastInst>(CallInv);
+      if (Cast)
+        CallInv = dyn_cast<Instruction>(*CallInv->user_begin());
+      DEBUG(dbgs() << "[lowerGetBlockInvoke]  " << *CallInv);
+      // Handle ret = block_func_ptr(context_ptr, args)
+      auto CI = cast<CallInst>(CallInv);
+      auto F = CI->getCalledValue();
+      if (InvokeF == nullptr) {
+        getBlockInvokeFuncAndContext(CallGetBlkInvoke->getArgOperand(0),
+                                     &InvokeF, nullptr);
+        assert(InvokeF);
+      }
+      assert(F->getType() == InvokeF->getType());
+      CI->replaceUsesOfWith(F, InvokeF);
+      DEBUG(dbgs() << " => " << *CI << "\n\n");
+      erase(Cast);
+      changed = true;
+    }
+    erase(CallGetBlkInvoke);
+    return changed;
+  }
+
+  void lowerBlockBuiltin(CallInst *CI, Function *InvF, Value *Ctx,
+                         Value *CtxLen, Value *CtxAlign,
+                         const std::string &DemangledName) {
+    mutateCallInstSPIRV(M, CI, [=](CallInst *CI, std::vector<Value *> &Args) {
+      size_t I = 0;
+      size_t E = Args.size();
+      for (; I != E; ++I) {
+        if (isPointerToOpaqueStructType(Args[I]->getType(),
+                                        SPIR_TYPE_NAME_BLOCK_T)) {
+          break;
+        }
+      }
+      assert(I < E);
+      Args[I] = castToVoidFuncPtr(InvF);
+      if (I + 1 == E) {
+        Args.push_back(Ctx);
+        Args.push_back(CtxLen);
+        Args.push_back(CtxAlign);
+      } else {
+        Args.insert(Args.begin() + I + 1, CtxAlign);
+        Args.insert(Args.begin() + I + 1, CtxLen);
+        Args.insert(Args.begin() + I + 1, Ctx);
+      }
+      if (DemangledName == kOCLBuiltinName::EnqueueKernel) {
+        // Insert event arguments if there are not.
+        if (!isa<IntegerType>(Args[3]->getType())) {
+          Args.insert(Args.begin() + 3, getInt32(M, 0));
+          Args.insert(Args.begin() + 4, getOCLNullClkEventPtr());
+        }
+        if (!isOCLClkEventPtrType(Args[5]->getType()))
+          Args.insert(Args.begin() + 5, getOCLNullClkEventPtr());
+      }
+      return getSPIRVFuncName(OCLSPIRVBuiltinMap::map(DemangledName));
+    });
+  }
+  /// Transform return of a block.
+  /// The function returning a block is inlined since the context cannot be
+  /// passed to another function.
+  /// Returns true of module is changed.
+  bool lowerReturnBlock(ReturnInst *Ret, Value *CallBlkBind, bool &Inlined) {
+    auto F = Ret->getParent()->getParent();
+    auto changed = false;
+    for (auto UI = F->user_begin(), UE = F->user_end(); UI != UE;) {
+      auto U = *UI++;
+      dumpUsers(U);
+      auto Inst = dyn_cast<Instruction>(U);
+      if (Inst && Inst->use_empty()) {
+        erase(Inst);
+        changed = true;
+        continue;
+      }
+      auto CI = dyn_cast<CallInst>(U);
+      if (!CI || CI->getCalledFunction() != F)
+        continue;
+
+      DEBUG(dbgs() << "[lowerReturnBlock] inline " << F->getName() << '\n');
+      auto CG = &getAnalysis<CallGraphWrapperPass>().getCallGraph();
+      auto ACT = &getAnalysis<AssumptionCacheTracker>();
+      std::function<AssumptionCache &(Function &)> GetAssumptionCache =
+          [&](Function &F) -> AssumptionCache & {
+        return ACT->getAssumptionCache(F);
+      };
+      InlineFunctionInfo IFI(CG, ACT ? &GetAssumptionCache : nullptr);
+      InlineFunction(CI, IFI);
+      Inlined = true;
+    }
+    return changed || Inlined;
+  }
+
+  /// Looking for a global variables initialized by opencl.block*. If found,
+  /// check
+  /// its users. If users are trivially dead, erase them. If the global variable
+  /// has no users left after that, erase it too.
+  void EraseUselessGlobalVars() {
+    std::vector<GlobalVariable *> GlobalVarsToDelete;
+    for (GlobalVariable &G : M->globals()) {
+      if (!G.hasInitializer())
+        continue;
+      Type *T = G.getInitializer()->getType();
+      if (!T->isPointerTy())
+        continue;
+      T = cast<PointerType>(T)->getElementType();
+      if (!T->isStructTy())
+        continue;
+      StringRef STName = cast<StructType>(T)->getName();
+      if (STName != "opencl.block")
+        continue;
+
+      std::vector<User *> UsersToDelete;
+      for (User *U : G.users())
+        if (U->use_empty())
+          UsersToDelete.push_back(U);
+      for (User *U : UsersToDelete)
+        erase(dyn_cast<Instruction>(U));
+
+      if (G.use_empty()) {
+        GlobalVarsToDelete.push_back(&G);
+      }
+    }
+    for (GlobalVariable *G : GlobalVarsToDelete) {
+      if (G->hasInitializer()) {
+        Constant *Init = G->getInitializer();
+        G->setInitializer(nullptr);
+        if (llvm::isSafeToDestroyConstant(Init))
+          Init->destroyConstant();
+      }
+      M->getGlobalList().erase(G);
+    }
+  }
+
+  /// Looking for functions which first argument is i8* %.block_descriptor
+  /// If users of this argument are dead, erase them.
+  /// After that clone the found function, removing its first argument
+  /// Then adjust all users/callers of the function with new arguments
+  /// Implementation of this function is based on
+  /// the dead argument elimination pass.
+  void EliminateDeadArgs() {
+    std::vector<Function *> FunctionsToDelete;
+    for (Function &F : M->functions()) {
+      if (F.arg_size() < 1)
+        continue;
+      auto FirstArg = F.arg_begin();
+      if (FirstArg->getName() != ".block_descriptor")
+        continue;
+
+      std::vector<User *> UsersToDelete;
+      for (User *U : FirstArg->users())
+        if (U->use_empty())
+          UsersToDelete.push_back(U);
+
+      for (User *U : UsersToDelete)
+        erase(dyn_cast<Instruction>(U));
+      UsersToDelete.clear();
+
+      if (!FirstArg->use_empty())
+        continue;
+
+      // Create new function without block descriptor argument.
+      ValueToValueMapTy VMap;
+      // If any of the arguments to the function are in the VMap,
+      // the arguments are deleted from the resultant function.
+      VMap[&*FirstArg] = llvm::UndefValue::get(FirstArg->getType());
+      Function *NF = CloneFunction(&F, VMap);
+      F.getParent()->getFunctionList().push_back(NF);
+      NF->takeName(&F);
+
+      // Redirect all users of the old function to the new one.
+      for (User *U : F.users()) {
+        ConstantExpr *CE = dyn_cast<ConstantExpr>(U);
+        CallSite CS(U);
+        if (CE && CE->getOpcode() == Instruction::BitCast) {
+          Constant *NewCE = ConstantExpr::getBitCast(NF, CE->getType());
+          U->replaceAllUsesWith(NewCE);
+        } else if (CS) {
+          assert(isa<CallInst>(CS.getInstruction()) &&
+                 "Call instruction is expected");
+          CallInst *Call = cast<CallInst>(CS.getInstruction());
+
+          std::vector<Value *> Args;
+          auto I = CS.arg_begin();
+          Args.assign(++I, CS.arg_end()); // Skip first argument.
+          CallInst *New = CallInst::Create(NF, Args, "", Call);
+          assert(New->getType() == Call->getType());
+          New->setCallingConv(CS.getCallingConv());
+          New->setAttributes(NF->getAttributes());
+          if (Call->isTailCall())
+            New->setTailCall();
+          New->setDebugLoc(Call->getDebugLoc());
+          New->takeName(Call);
+          Call->replaceAllUsesWith(New);
+          UsersToDelete.push_back(Call);
+        } else {
+          llvm_unreachable("Unexpected user of function");
+        }
+      }
+      for (User *U : UsersToDelete)
+        erase(cast<Instruction>(U));
+      UsersToDelete.clear();
+      FunctionsToDelete.push_back(&F);
+    } // iteration over module's functions.
+
+    for (Function *F : FunctionsToDelete)
+      erase(F);
+  }
+
+  void getBlockInvokeFuncAndContext(Value *Blk, Function **PInvF, Value **PCtx,
+                                    Value **PCtxLen = nullptr,
+                                    Value **PCtxAlign = nullptr) {
+    Function *InvF = nullptr;
+    Value *Ctx = nullptr;
+    Value *CtxLen = nullptr;
+    Value *CtxAlign = nullptr;
+    if (auto CallBlkBind = dyn_cast<CallInst>(Blk)) {
+      assert(CallBlkBind->getCalledFunction()->getName() ==
+                 SPIR_INTRINSIC_BLOCK_BIND &&
+             "Invalid block");
+      InvF = dyn_cast<Function>(
+          CallBlkBind->getArgOperand(0)->stripPointerCasts());
+      CtxLen = CallBlkBind->getArgOperand(1);
+      CtxAlign = CallBlkBind->getArgOperand(2);
+      Ctx = CallBlkBind->getArgOperand(3);
+    } else if (auto F = dyn_cast<Function>(Blk->stripPointerCasts())) {
+      InvF = F;
+      Ctx = Constant::getNullValue(IntegerType::getInt8PtrTy(M->getContext()));
+    } else if (auto Load = dyn_cast<LoadInst>(Blk)) {
+      auto Op = Load->getPointerOperand();
+      if (auto GV = dyn_cast<GlobalVariable>(Op)) {
+        if (GV->isConstant()) {
+          InvF = cast<Function>(GV->getInitializer()->stripPointerCasts());
+          Ctx = Constant::getNullValue(
+              IntegerType::getInt8PtrTy(M->getContext()));
+        } else {
+          llvm_unreachable("load non-constant block?");
+        }
+      } else {
+        llvm_unreachable("Loading block from non global?");
+      }
+    } else {
+      llvm_unreachable("Invalid block");
+    }
+    DEBUG(dbgs() << "  Block invocation func: " << InvF->getName() << '\n'
+                 << "  Block context: " << *Ctx << '\n');
+    assert(InvF && Ctx && "Invalid block");
+    if (PInvF)
+      *PInvF = InvF;
+    if (PCtx)
+      *PCtx = Ctx;
+    if (PCtxLen)
+      *PCtxLen = CtxLen;
+    if (PCtxAlign)
+      *PCtxAlign = CtxAlign;
+  }
+  void erase(Instruction *I) {
+    if (!I)
+      return;
+    if (I->use_empty()) {
+      I->dropAllReferences();
+      I->eraseFromParent();
+    } else
+      dumpUsers(I);
+  }
+  void erase(ConstantExpr *I) {
+    if (!I)
+      return;
+    if (I->use_empty()) {
+      I->dropAllReferences();
+      I->destroyConstant();
+    } else
+      dumpUsers(I);
+  }
+  void erase(Function *F) {
+    if (!F)
+      return;
+    if (!F->use_empty()) {
+      dumpUsers(F);
+      return;
+    }
+    F->dropAllReferences();
+    auto &CG = getAnalysis<CallGraphWrapperPass>().getCallGraph();
+    CG.removeFunctionFromModule(new CallGraphNode(F));
+  }
+
+  llvm::PointerType *getOCLClkEventType() {
+    return getOrCreateOpaquePtrType(M, SPIR_TYPE_NAME_CLK_EVENT_T,
+                                    SPIRAS_Global);
+  }
+
+  llvm::PointerType *getOCLClkEventPtrType() {
+    return PointerType::get(getOCLClkEventType(), SPIRAS_Generic);
+  }
+
+  bool isOCLClkEventPtrType(Type *T) {
+    if (auto PT = dyn_cast<PointerType>(T))
+      return isPointerToOpaqueStructType(PT->getElementType(),
+                                         SPIR_TYPE_NAME_CLK_EVENT_T);
+    return false;
+  }
+
+  llvm::Constant *getOCLNullClkEventPtr() {
+    return Constant::getNullValue(getOCLClkEventPtrType());
+  }
+
+  void dumpGetBlockInvokeUsers(StringRef Prompt) {
+    DEBUG(dbgs() << Prompt);
+    dumpUsers(M->getFunction(SPIR_INTRINSIC_GET_BLOCK_INVOKE));
+  }
+};
+
+char SPIRVLowerOCLBlocks::ID = 0;
+}
+
+INITIALIZE_PASS_BEGIN(SPIRVLowerOCLBlocks, "spvblocks",
+                      "SPIR-V lower OCL blocks", false, false)
+INITIALIZE_PASS_DEPENDENCY(CallGraphWrapperPass)
+INITIALIZE_PASS_DEPENDENCY(AssumptionCacheTracker)
+INITIALIZE_PASS_DEPENDENCY(AAResultsWrapperPass)
+INITIALIZE_PASS_DEPENDENCY(GlobalsAAWrapperPass)
+INITIALIZE_PASS_END(SPIRVLowerOCLBlocks, "spvblocks", "SPIR-V lower OCL blocks",
+                    false, false)
+
+ModulePass *llvm::createSPIRVLowerOCLBlocks() {
+  return new SPIRVLowerOCLBlocks();
+}
+
+#endif /* OCLLOWERBLOCKS_H_ */
diff --git a/lib/SPIRV/SPIRVMDBuilder.h b/lib/SPIRV/SPIRVMDBuilder.h
new file mode 100644
index 0000000..7497d60
--- /dev/null
+++ b/lib/SPIRV/SPIRVMDBuilder.h
@@ -0,0 +1,131 @@
+//===- SPIRVMDBuilder.h -  SPIR-V metadata builder header file --*- C++ -*-===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+/// \file
+///
+/// This file declares classes for creating SPIR-V metadata.
+///
+//===----------------------------------------------------------------------===//
+
+#ifndef LIB_SPIRV_SPIRVMDBUILDER_H_
+#define LIB_SPIRV_SPIRVMDBUILDER_H_
+
+#include "llvm/IR/Metadata.h"
+#include "SPIRVInternal.h"
+
+#include <functional>
+using namespace llvm;
+
+namespace SPIRV {
+
+class SPIRVMDBuilder {
+public:
+  template <typename ParentT> struct MDWrapper;
+  struct NamedMDWrapper {
+    NamedMDWrapper(NamedMDNode &Named, SPIRVMDBuilder &BB)
+        : NMD(Named), B(BB) {}
+    MDWrapper<NamedMDWrapper> addOp() {
+      return MDWrapper<NamedMDWrapper>(*this, B);
+    }
+    NamedMDWrapper &addOp(MDWrapper<NamedMDWrapper> &MD) {
+      NMD.addOperand(MD.M);
+      return *this;
+    }
+    NamedMDNode &NMD;
+    SPIRVMDBuilder &B;
+  };
+  template <typename ParentT> struct MDWrapper {
+    MDWrapper(ParentT &Parent, SPIRVMDBuilder &Builder)
+        : M(nullptr), P(Parent), B(Builder) {}
+    MDWrapper &add(unsigned I) {
+      V.push_back(ConstantAsMetadata::get(getUInt32(&B.M, I)));
+      return *this;
+    }
+    MDWrapper &addU16(unsigned short I) {
+      V.push_back(ConstantAsMetadata::get(getUInt16(&B.M, I)));
+      return *this;
+    }
+    MDWrapper &add(StringRef S) {
+      V.push_back(MDString::get(B.C, S));
+      return *this;
+    }
+    MDWrapper &add(Function *F) {
+      V.push_back(ConstantAsMetadata::get(F));
+      return *this;
+    }
+    MDWrapper &add(SmallVectorImpl<StringRef> &S) {
+      for (auto &I : S)
+        add(I);
+      return *this;
+    }
+    MDWrapper &addOp(MDNode *Node) {
+      V.push_back(Node);
+      return *this;
+    }
+    MDWrapper<MDWrapper> addOp() { return MDWrapper<MDWrapper>(*this, B); }
+    MDWrapper &addOp(MDWrapper<MDWrapper> &MD) {
+      V.push_back(MD.M);
+      return *this;
+    }
+    /// Generate the scheduled MDNode and return the parent.
+    /// If \param Ptr is not nullptr, save the generated MDNode.
+    ParentT &done(MDNode **Ptr = nullptr) {
+      M = MDNode::get(B.C, V);
+      if (Ptr)
+        *Ptr = M;
+      return P.addOp(*this);
+    }
+    MDNode *M;
+    ParentT &P;
+    SPIRVMDBuilder &B;
+    SmallVector<Metadata *, 10> V;
+  };
+  explicit SPIRVMDBuilder(Module &Mod) : M(Mod), C(Mod.getContext()) {}
+  NamedMDWrapper addNamedMD(StringRef Name) {
+    return NamedMDWrapper(*M.getOrInsertNamedMetadata(Name), *this);
+  }
+  SPIRVMDBuilder &eraseNamedMD(StringRef Name) {
+    if (auto N = M.getNamedMetadata(Name))
+      M.eraseNamedMetadata(N);
+    return *this;
+  }
+  friend struct NamedMDWrapper;
+
+private:
+  Module &M;
+  LLVMContext &C;
+};
+
+} /* namespace SPIRV */
+
+#endif /* LIB_SPIRV_SPIRVMDBUILDER_H_ */
diff --git a/lib/SPIRV/SPIRVMDWalker.h b/lib/SPIRV/SPIRVMDWalker.h
new file mode 100644
index 0000000..6ca20f3
--- /dev/null
+++ b/lib/SPIRV/SPIRVMDWalker.h
@@ -0,0 +1,177 @@
+//===- SPIRVMDWalker.h -  SPIR-V metadata walker header file ----*- C++ -*-===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+/// \file
+///
+/// This file declares classes for walking SPIR-V metadata.
+///
+//===----------------------------------------------------------------------===//
+
+#ifndef LIB_SPIRV_SPIRVMDWALKER_H_
+#define LIB_SPIRV_SPIRVMDWALKER_H_
+
+#include "llvm/IR/Metadata.h"
+#include "SPIRVInternal.h"
+
+#include <functional>
+using namespace llvm;
+
+namespace SPIRV {
+
+class SPIRVMDWalker {
+public:
+  template <typename ParentT> struct MDWrapper;
+
+  struct NamedMDWrapper {
+    NamedMDWrapper(NamedMDNode *Named, SPIRVMDWalker &WW)
+        : NMD(Named), W(WW), I(0), Q(true) {
+      E = Named ? Named->getNumOperands() : 0;
+    }
+
+    operator bool() const { return NMD; }
+
+    bool atEnd() const { return !(NMD && I < E); }
+
+    MDWrapper<NamedMDWrapper> nextOp() {
+      if (!Q)
+        assert(I < E && "out of bound");
+      return MDWrapper<NamedMDWrapper>(
+          (NMD && I < E) ? NMD->getOperand(I++) : nullptr, *this, W);
+    }
+
+    NamedMDWrapper &setQuiet(bool Quiet) {
+      Q = Quiet;
+      return *this;
+    }
+
+    NamedMDNode *NMD;
+    SPIRVMDWalker &W;
+    unsigned I;
+    unsigned E;
+    bool Q; // Quiet
+  };
+
+  template <typename ParentT> struct MDWrapper {
+    MDWrapper(MDNode *Node, ParentT &Parent, SPIRVMDWalker &Walker)
+        : M(Node), P(Parent), W(Walker), I(0), Q(false) {
+      E = Node ? Node->getNumOperands() : 0;
+    }
+
+    operator bool() const { return M; }
+
+    bool atEnd() const { return !(M && I < E); }
+
+    template <typename T> MDWrapper &get(T &V) {
+      if (!Q)
+        assert(I < E && "out of bound");
+      if (atEnd())
+        return *this;
+      V = mdconst::dyn_extract<ConstantInt>(M->getOperand(I++))->getZExtValue();
+      return *this;
+    }
+
+    MDWrapper &get(std::string &S) {
+      if (!Q)
+        assert(I < E && "out of bound");
+      if (atEnd())
+        return *this;
+      Metadata *Op = M->getOperand(I++);
+      if (!Op)
+        S = "";
+      else if (auto Str = dyn_cast<MDString>(Op))
+        S = Str->getString().str();
+      else
+        S = "";
+      return *this;
+    }
+
+    MDWrapper &get(Function *&F) {
+      if (!Q)
+        assert(I < E && "out of bound");
+      if (atEnd())
+        return *this;
+      F = mdconst::dyn_extract<Function>(M->getOperand(I++));
+      return *this;
+    }
+
+    MDWrapper &get(SmallVectorImpl<std::string> &SV) {
+      if (atEnd())
+        return *this;
+      while (I < E) {
+        std::string S;
+        get(S);
+        SV.push_back(S);
+      }
+      return *this;
+    }
+
+    MDWrapper<MDWrapper> nextOp() {
+      if (!Q)
+        assert(I < E && "out of bound");
+      return MDWrapper<MDWrapper>(
+          (M && I < E) ? dyn_cast<MDNode>(M->getOperand(I++)) : nullptr, *this,
+          W);
+    }
+
+    ParentT &done() { return P; }
+
+    MDWrapper &setQuiet(bool Quiet) {
+      Q = Quiet;
+      return *this;
+    }
+
+    MDNode *M;
+    ParentT &P;
+    SPIRVMDWalker &W;
+    SmallVector<Metadata *, 10> V;
+    unsigned I;
+    unsigned E;
+    bool Q; // Quiet
+  };
+
+  explicit SPIRVMDWalker(Module &Mod) : M(Mod), C(Mod.getContext()) {}
+
+  NamedMDWrapper getNamedMD(StringRef Name) {
+    return NamedMDWrapper(M.getNamedMetadata(Name), *this);
+  }
+
+  friend struct NamedMDWrapper;
+
+private:
+  Module &M;
+  LLVMContext &C;
+};
+
+} /* namespace SPIRV */
+
+#endif /* LIB_SPIRV_SPIRVMDBUILDER_H_ */
diff --git a/lib/SPIRV/SPIRVReader.cpp b/lib/SPIRV/SPIRVReader.cpp
new file mode 100644
index 0000000..a6f5558
--- /dev/null
+++ b/lib/SPIRV/SPIRVReader.cpp
@@ -0,0 +1,2731 @@
+//===- SPIRVReader.cpp - Converts SPIR-V to LLVM ----------------*- C++ -*-===//
+//
+//                     The LLVM/SPIR-V Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+/// \file
+///
+/// This file implements conversion of SPIR-V binary to LLVM IR.
+///
+//===----------------------------------------------------------------------===//
+#include "SPIRVUtil.h"
+#include "SPIRVType.h"
+#include "SPIRVValue.h"
+#include "SPIRVModule.h"
+#include "SPIRVFunction.h"
+#include "SPIRVBasicBlock.h"
+#include "SPIRVInstruction.h"
+#include "SPIRVExtInst.h"
+#include "SPIRVInternal.h"
+#include "SPIRVMDBuilder.h"
+#include "OCLUtil.h"
+
+#include "llvm/ADT/DenseMap.h"
+#include "llvm/ADT/StringSwitch.h"
+#include "llvm/IR/Constants.h"
+#include "llvm/IR/DerivedTypes.h"
+#include "llvm/IR/DIBuilder.h"
+#include "llvm/IR/Instructions.h"
+#include "llvm/IR/Metadata.h"
+#include "llvm/IR/Module.h"
+#include "llvm/IR/Operator.h"
+#include "llvm/IR/Type.h"
+#include "llvm/IR/LegacyPassManager.h"
+#include "llvm/Support/Casting.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/Dwarf.h"
+#include "llvm/Support/FileSystem.h"
+#include "llvm/Support/raw_ostream.h"
+#include "llvm/Support/CommandLine.h"
+
+#include <algorithm>
+#include <cstdlib>
+#include <functional>
+#include <fstream>
+#include <iostream>
+#include <iterator>
+#include <map>
+#include <set>
+#include <sstream>
+#include <string>
+
+#define DEBUG_TYPE "spirv"
+
+using namespace std;
+using namespace llvm;
+using namespace SPIRV;
+using namespace OCLUtil;
+
+namespace SPIRV {
+
+cl::opt<bool> SPIRVEnableStepExpansion(
+    "spirv-expand-step", cl::init(true),
+    cl::desc("Enable expansion of OpenCL step and smoothstep function"));
+
+cl::opt<bool> SPIRVGenKernelArgNameMD(
+    "spirv-gen-kernel-arg-name-md", cl::init(false),
+    cl::desc("Enable generating OpenCL kernel argument name "
+             "metadata"));
+
+cl::opt<bool> SPIRVGenImgTypeAccQualPostfix(
+    "spirv-gen-image-type-acc-postfix", cl::init(false),
+    cl::desc("Enable generating access qualifier postfix"
+             " in OpenCL image type names"));
+
+// Prefix for placeholder global variable name.
+const char *kPlaceholderPrefix = "placeholder.";
+
+// Save the translated LLVM before validation for debugging purpose.
+static bool DbgSaveTmpLLVM = true;
+static const char *DbgTmpLLVMFileName = "_tmp_llvmbil.ll";
+
+typedef std::pair<unsigned, AttributeSet> AttributeWithIndex;
+
+static bool isOpenCLKernel(SPIRVFunction *BF) {
+  return BF->getModule()->isEntryPoint(ExecutionModelKernel, BF->getId());
+}
+
+static void dumpLLVM(Module *M, const std::string &FName) {
+  std::error_code EC;
+  raw_fd_ostream FS(FName, EC, sys::fs::F_None);
+  if (EC) {
+    FS << *M;
+    FS.close();
+  }
+}
+
+static MDNode *getMDNodeStringIntVec(LLVMContext *Context,
+                                     const std::string &Str,
+                                     const std::vector<SPIRVWord> &IntVals) {
+  std::vector<Metadata *> ValueVec;
+  ValueVec.push_back(MDString::get(*Context, Str));
+  for (auto &I : IntVals)
+    ValueVec.push_back(ConstantAsMetadata::get(
+        ConstantInt::get(Type::getInt32Ty(*Context), I)));
+  return MDNode::get(*Context, ValueVec);
+}
+
+static MDNode *getMDTwoInt(LLVMContext *Context, unsigned Int1, unsigned Int2) {
+  std::vector<Metadata *> ValueVec;
+  ValueVec.push_back(ConstantAsMetadata::get(
+      ConstantInt::get(Type::getInt32Ty(*Context), Int1)));
+  ValueVec.push_back(ConstantAsMetadata::get(
+      ConstantInt::get(Type::getInt32Ty(*Context), Int2)));
+  return MDNode::get(*Context, ValueVec);
+}
+
+static MDNode *getMDString(LLVMContext *Context, const std::string &Str) {
+  std::vector<Metadata *> ValueVec;
+  if (!Str.empty())
+    ValueVec.push_back(MDString::get(*Context, Str));
+  return MDNode::get(*Context, ValueVec);
+}
+
+static void addOCLVersionMetadata(LLVMContext *Context, Module *M,
+                                  const std::string &MDName, unsigned Major,
+                                  unsigned Minor) {
+  NamedMDNode *NamedMD = M->getOrInsertNamedMetadata(MDName);
+  NamedMD->addOperand(getMDTwoInt(Context, Major, Minor));
+}
+
+static void addNamedMetadataStringSet(LLVMContext *Context, Module *M,
+                                      const std::string &MDName,
+                                      const std::set<std::string> &StrSet) {
+  NamedMDNode *NamedMD = M->getOrInsertNamedMetadata(MDName);
+  std::vector<Metadata *> ValueVec;
+  for (auto &&Str : StrSet) {
+    ValueVec.push_back(MDString::get(*Context, Str));
+  }
+  NamedMD->addOperand(MDNode::get(*Context, ValueVec));
+}
+
+static void addOCLKernelArgumentMetadata(
+    LLVMContext *Context, std::vector<llvm::Metadata *> &KernelMD,
+    const std::string &MDName, SPIRVFunction *BF,
+    std::function<Metadata *(SPIRVFunctionParameter *)> Func) {
+  std::vector<Metadata *> ValueVec;
+  ValueVec.push_back(MDString::get(*Context, MDName));
+  BF->foreachArgument(
+      [&](SPIRVFunctionParameter *Arg) { ValueVec.push_back(Func(Arg)); });
+  KernelMD.push_back(MDNode::get(*Context, ValueVec));
+}
+
+class SPIRVToLLVMDbgTran {
+public:
+  SPIRVToLLVMDbgTran(SPIRVModule *TBM, Module *TM)
+      : BM(TBM), M(TM), SpDbg(BM), Builder(*M) {
+    Enable = BM->hasDebugInfo();
+  }
+
+  void createCompileUnit() {
+    if (!Enable)
+      return;
+    auto File = SpDbg.getEntryPointFileStr(ExecutionModelKernel, 0);
+    std::string BaseName;
+    std::string Path;
+    splitFileName(File, BaseName, Path);
+    Builder.createCompileUnit(dwarf::DW_LANG_C99, BaseName, Path, "spirv",
+                              false, "", 0, "", DICompileUnit::LineTablesOnly);
+  }
+
+  void addDbgInfoVersion() {
+    if (!Enable)
+      return;
+    M->addModuleFlag(Module::Warning, "Dwarf Version", dwarf::DWARF_VERSION);
+    M->addModuleFlag(Module::Warning, "Debug Info Version",
+                     DEBUG_METADATA_VERSION);
+  }
+
+#if 0 // TODO: fix this (horribly broken with llvm 3.8)
+  DIFile* getDIFile(const std::string &FileName){
+    return getOrInsert(FileMap, FileName, [=](){
+      std::string BaseName;
+      std::string Path;
+      splitFileName(FileName, BaseName, Path);
+      if (!BaseName.empty())
+        return Builder.createFile(BaseName, Path);
+      else // TODO: no DIFile() any more, not sure what this should do
+        return Builder.createFile("dummy", Path);
+    });
+  }
+
+  DISubprogram getDISubprogram(SPIRVFunction *SF, Function *F){
+    return getOrInsert(FuncMap, F, [=](){
+      auto DF = getDIFile(SpDbg.getFunctionFileStr(SF));
+      auto FN = F->getName();
+      auto LN = SpDbg.getFunctionLineNo(SF);
+      Metadata *Args[] = { Builder.createNullPtrType() };
+      return Builder.createFunction(DF, FN, FN, DF, LN,
+        Builder.createSubroutineType(DF, Builder.getOrCreateTypeArray(Args)),
+        Function::isInternalLinkage(F->getLinkage()),
+        true, LN, 0, 0, NULL, NULL, NULL);
+    });
+  }
+
+  void transDbgInfo(SPIRVValue *SV, Value *V) {
+    if (!Enable || !SV->hasLine())
+      return;
+    if (auto I = dyn_cast<Instruction>(V)) {
+      assert(SV->isInst() && "Invalid instruction");
+      auto SI = static_cast<SPIRVInstruction *>(SV);
+      assert(SI->getParent() &&
+             SI->getParent()->getParent() &&
+             "Invalid instruction");
+      auto Line = SV->getLine();
+      I->setDebugLoc(DebugLoc::get(Line->getLine(), Line->getColumn(),
+          getDISubprogram(SI->getParent()->getParent(),
+              I->getParent()->getParent())));
+    }
+  }
+#endif
+
+  void finalize() {
+    if (!Enable)
+      return;
+    Builder.finalize();
+  }
+
+private:
+  SPIRVModule *BM;
+  Module *M;
+  SPIRVDbgInfo SpDbg;
+  DIBuilder Builder;
+  bool Enable;
+  std::unordered_map<std::string, DIFile *> FileMap;
+  std::unordered_map<Function *, DISubprogram> FuncMap;
+
+  void splitFileName(const std::string &FileName, std::string &BaseName,
+                     std::string &Path) {
+    auto Loc = FileName.find_last_of("/\\");
+    if (Loc != std::string::npos) {
+      BaseName = FileName.substr(Loc + 1);
+      Path = FileName.substr(0, Loc);
+    } else {
+      BaseName = FileName;
+      Path = ".";
+    }
+  }
+};
+
+class SPIRVToLLVM {
+public:
+  SPIRVToLLVM(Module *LLVMModule, SPIRVModule *TheSPIRVModule)
+      : M(LLVMModule), BM(TheSPIRVModule), DbgTran(BM, M) {
+    assert(M);
+    Context = &M->getContext();
+  }
+
+  std::string getOCLBuiltinName(SPIRVInstruction *BI);
+  std::string getOCLConvertBuiltinName(SPIRVInstruction *BI);
+  std::string getOCLGenericCastToPtrName(SPIRVInstruction *BI);
+
+  Type *transType(SPIRVType *BT, bool IsClassMember = false);
+  std::string transTypeToOCLTypeName(SPIRVType *BT, bool IsSigned = true);
+  std::vector<Type *> transTypeVector(const std::vector<SPIRVType *> &);
+  bool translate();
+  bool transAddressingModel();
+
+  Value *transValue(SPIRVValue *, Function *F, BasicBlock *,
+                    bool CreatePlaceHolder = true);
+  Value *transValueWithoutDecoration(SPIRVValue *, Function *F, BasicBlock *,
+                                     bool CreatePlaceHolder = true);
+  bool transDecoration(SPIRVValue *, Value *);
+  bool transAlign(SPIRVValue *, Value *);
+  Instruction *transOCLBuiltinFromExtInst(SPIRVExtInst *BC, BasicBlock *BB);
+  std::vector<Value *> transValue(const std::vector<SPIRVValue *> &,
+                                  Function *F, BasicBlock *);
+  Function *transFunction(SPIRVFunction *F);
+  bool transFPContractMetadata();
+  bool transKernelMetadata();
+  bool transNonTemporalMetadata(Instruction *I);
+  bool transSourceLanguage();
+  bool transSourceExtension();
+  void transGeneratorMD();
+  Value *transConvertInst(SPIRVValue *BV, Function *F, BasicBlock *BB);
+  Instruction *transBuiltinFromInst(const std::string &FuncName,
+                                    SPIRVInstruction *BI, BasicBlock *BB);
+  Instruction *transOCLBuiltinFromInst(SPIRVInstruction *BI, BasicBlock *BB);
+  Instruction *transSPIRVBuiltinFromInst(SPIRVInstruction *BI, BasicBlock *BB);
+  Instruction *transOCLBarrierFence(SPIRVInstruction *BI, BasicBlock *BB);
+  void transOCLVectorLoadStore(std::string &UnmangledName,
+                               std::vector<SPIRVWord> &BArgs);
+
+  /// Post-process translated LLVM module for OpenCL.
+  bool postProcessOCL();
+
+  /// \brief Post-process OpenCL builtin functions returning struct type.
+  ///
+  /// Some OpenCL builtin functions are translated to SPIR-V instructions with
+  /// struct type result, e.g. NDRange creation functions. Such functions
+  /// need to be post-processed to return the struct through sret argument.
+  bool postProcessOCLBuiltinReturnStruct(Function *F);
+
+  /// \brief Post-process OpenCL builtin functions having block argument.
+  ///
+  /// These functions are translated to functions with function pointer type
+  /// argument first, then post-processed to have block argument.
+  bool postProcessOCLBuiltinWithFuncPointer(Function *F,
+                                            Function::arg_iterator I);
+
+  /// \brief Post-process OpenCL builtin functions having array argument.
+  ///
+  /// These functions are translated to functions with array type argument
+  /// first, then post-processed to have pointer arguments.
+  bool
+  postProcessOCLBuiltinWithArrayArguments(Function *F,
+                                          const std::string &DemangledName);
+
+  /// \brief Post-process OpImageSampleExplicitLod.
+  ///   sampled_image = __spirv_SampledImage__(image, sampler);
+  ///   return __spirv_ImageSampleExplicitLod__(sampled_image, image_operands,
+  ///                                           ...);
+  /// =>
+  ///   read_image(image, sampler, ...)
+  /// \return transformed call instruction.
+  Instruction *postProcessOCLReadImage(SPIRVInstruction *BI, CallInst *CI,
+                                       const std::string &DemangledName);
+
+  /// \brief Post-process OpImageWrite.
+  ///   return write_image(image, coord, color, image_operands, ...);
+  /// =>
+  ///   write_image(image, coord, ..., color)
+  /// \return transformed call instruction.
+  CallInst *postProcessOCLWriteImage(SPIRVInstruction *BI, CallInst *CI,
+                                     const std::string &DemangledName);
+
+  /// \brief Post-process OpBuildNDRange.
+  ///   OpBuildNDRange GlobalWorkSize, LocalWorkSize, GlobalWorkOffset
+  /// =>
+  ///   call ndrange_XD(GlobalWorkOffset, GlobalWorkSize, LocalWorkSize)
+  /// \return transformed call instruction.
+  CallInst *postProcessOCLBuildNDRange(SPIRVInstruction *BI, CallInst *CI,
+                                       const std::string &DemangledName);
+
+  /// \brief Expand OCL builtin functions with scalar argument, e.g.
+  /// step, smoothstep.
+  /// gentype func (fp edge, gentype x)
+  /// =>
+  /// gentype func (gentype edge, gentype x)
+  /// \return transformed call instruction.
+  CallInst *expandOCLBuiltinWithScalarArg(CallInst *CI,
+                                          const std::string &FuncName);
+
+  /// \brief Post-process OpGroupAll and OpGroupAny instructions translation.
+  /// i1 func (<n x i1> arg)
+  /// =>
+  /// i32 func (<n x i32> arg)
+  /// \return transformed call instruction.
+  Instruction *postProcessGroupAllAny(CallInst *CI,
+                                      const std::string &DemangledName);
+
+  typedef DenseMap<SPIRVType *, Type *> SPIRVToLLVMTypeMap;
+  typedef DenseMap<SPIRVValue *, Value *> SPIRVToLLVMValueMap;
+  typedef DenseMap<SPIRVFunction *, Function *> SPIRVToLLVMFunctionMap;
+  typedef DenseMap<GlobalVariable *, SPIRVBuiltinVariableKind> BuiltinVarMap;
+
+  // A SPIRV value may be translated to a load instruction of a placeholder
+  // global variable. This map records load instruction of these placeholders
+  // which are supposed to be replaced by the real values later.
+  typedef std::map<SPIRVValue *, LoadInst *> SPIRVToLLVMPlaceholderMap;
+
+private:
+  Module *M;
+  BuiltinVarMap BuiltinGVMap;
+  LLVMContext *Context;
+  SPIRVModule *BM;
+  SPIRVToLLVMTypeMap TypeMap;
+  SPIRVToLLVMValueMap ValueMap;
+  SPIRVToLLVMFunctionMap FuncMap;
+  SPIRVToLLVMPlaceholderMap PlaceholderMap;
+  SPIRVToLLVMDbgTran DbgTran;
+
+  Type *mapType(SPIRVType *BT, Type *T) {
+    SPIRVDBG(dbgs() << *T << '\n';)
+    TypeMap[BT] = T;
+    return T;
+  }
+
+  // If a value is mapped twice, the existing mapped value is a placeholder,
+  // which must be a load instruction of a global variable whose name starts
+  // with kPlaceholderPrefix.
+  Value *mapValue(SPIRVValue *BV, Value *V) {
+    auto Loc = ValueMap.find(BV);
+    if (Loc != ValueMap.end()) {
+      if (Loc->second == V)
+        return V;
+      auto LD = dyn_cast<LoadInst>(Loc->second);
+      auto Placeholder = dyn_cast<GlobalVariable>(LD->getPointerOperand());
+      assert(LD && Placeholder &&
+             Placeholder->getName().startswith(kPlaceholderPrefix) &&
+             "A value is translated twice");
+      // Replaces placeholders for PHI nodes
+      LD->replaceAllUsesWith(V);
+      LD->dropAllReferences();
+      LD->removeFromParent();
+      Placeholder->dropAllReferences();
+      Placeholder->removeFromParent();
+    }
+    ValueMap[BV] = V;
+    return V;
+  }
+
+  bool isSPIRVBuiltinVariable(GlobalVariable *GV,
+                              SPIRVBuiltinVariableKind *Kind = nullptr) {
+    auto Loc = BuiltinGVMap.find(GV);
+    if (Loc == BuiltinGVMap.end())
+      return false;
+    if (Kind)
+      *Kind = Loc->second;
+    return true;
+  }
+  // OpenCL function always has NoUnwound attribute.
+  // Change this if it is no longer true.
+  bool isFuncNoUnwind() const { return true; }
+  bool isSPIRVCmpInstTransToLLVMInst(SPIRVInstruction *BI) const;
+  bool transOCLBuiltinsFromVariables();
+  bool transOCLBuiltinFromVariable(GlobalVariable *GV,
+                                   SPIRVBuiltinVariableKind Kind);
+  MDString *transOCLKernelArgTypeName(SPIRVFunctionParameter *);
+
+  Value *mapFunction(SPIRVFunction *BF, Function *F) {
+    SPIRVDBG(spvdbgs() << "[mapFunction] " << *BF << " -> ";
+             dbgs() << *F << '\n';)
+    FuncMap[BF] = F;
+    return F;
+  }
+
+  Value *getTranslatedValue(SPIRVValue *BV);
+  Type *getTranslatedType(SPIRVType *BT);
+
+  SPIRVErrorLog &getErrorLog() { return BM->getErrorLog(); }
+
+  void setCallingConv(CallInst *Call) {
+    Function *F = Call->getCalledFunction();
+    assert(F);
+    Call->setCallingConv(F->getCallingConv());
+  }
+
+  void setAttrByCalledFunc(CallInst *Call);
+  Type *transFPType(SPIRVType *T);
+  BinaryOperator *transShiftLogicalBitwiseInst(SPIRVValue *BV, BasicBlock *BB,
+                                               Function *F);
+  void transFlags(llvm::Value *V);
+  Instruction *transCmpInst(SPIRVValue *BV, BasicBlock *BB, Function *F);
+  void transOCLBuiltinFromInstPreproc(SPIRVInstruction *BI, Type *&RetTy,
+                                      std::vector<SPIRVValue *> &Args);
+  Instruction *transOCLBuiltinPostproc(SPIRVInstruction *BI, CallInst *CI,
+                                       BasicBlock *BB,
+                                       const std::string &DemangledName);
+  std::string transOCLImageTypeName(SPIRV::SPIRVTypeImage *ST);
+  std::string transOCLSampledImageTypeName(SPIRV::SPIRVTypeSampledImage *ST);
+  std::string transOCLPipeTypeName(SPIRV::SPIRVTypePipe *ST,
+                                   bool UseSPIRVFriendlyFormat = false,
+                                   int PipeAccess = 0);
+  std::string transOCLPipeStorageTypeName(SPIRV::SPIRVTypePipeStorage *PST);
+  std::string transOCLImageTypeAccessQualifier(SPIRV::SPIRVTypeImage *ST);
+  std::string transOCLPipeTypeAccessQualifier(SPIRV::SPIRVTypePipe *ST);
+
+  Value *oclTransConstantSampler(SPIRV::SPIRVConstantSampler *BCS);
+  Value *oclTransConstantPipeStorage(SPIRV::SPIRVConstantPipeStorage *BCPS);
+  void setName(llvm::Value *V, SPIRVValue *BV);
+  void insertImageNameAccessQualifier(SPIRV::SPIRVTypeImage *ST,
+                                      std::string &Name);
+  template <class Source, class Func> bool foreachFuncCtlMask(Source, Func);
+  llvm::GlobalValue::LinkageTypes transLinkageType(const SPIRVValue *V);
+  Instruction *transOCLAllAny(SPIRVInstruction *BI, BasicBlock *BB);
+  Instruction *transOCLRelational(SPIRVInstruction *BI, BasicBlock *BB);
+
+  CallInst *transOCLBarrier(BasicBlock *BB, SPIRVWord ExecScope,
+                            SPIRVWord MemSema, SPIRVWord MemScope);
+
+  CallInst *transOCLMemFence(BasicBlock *BB, SPIRVWord MemSema,
+                             SPIRVWord MemScope);
+};
+
+Type *SPIRVToLLVM::getTranslatedType(SPIRVType *BV) {
+  auto Loc = TypeMap.find(BV);
+  if (Loc != TypeMap.end())
+    return Loc->second;
+  return nullptr;
+}
+
+Value *SPIRVToLLVM::getTranslatedValue(SPIRVValue *BV) {
+  auto Loc = ValueMap.find(BV);
+  if (Loc != ValueMap.end())
+    return Loc->second;
+  return nullptr;
+}
+
+void SPIRVToLLVM::setAttrByCalledFunc(CallInst *Call) {
+  Function *F = Call->getCalledFunction();
+  assert(F);
+  if (F->isIntrinsic()) {
+    return;
+  }
+  Call->setCallingConv(F->getCallingConv());
+  Call->setAttributes(F->getAttributes());
+}
+
+bool SPIRVToLLVM::transOCLBuiltinsFromVariables() {
+  std::vector<GlobalVariable *> WorkList;
+  for (auto I = M->global_begin(), E = M->global_end(); I != E; ++I) {
+    SPIRVBuiltinVariableKind Kind;
+    if (!isSPIRVBuiltinVariable(&*I, &Kind))
+      continue;
+    if (!transOCLBuiltinFromVariable(&*I, Kind))
+      return false;
+    WorkList.push_back(&*I);
+  }
+  for (auto &I : WorkList) {
+    I->dropAllReferences();
+    I->removeFromParent();
+  }
+  return true;
+}
+
+// For integer types shorter than 32 bit, unsigned/signedness can be inferred
+// from zext/sext attribute.
+MDString *SPIRVToLLVM::transOCLKernelArgTypeName(SPIRVFunctionParameter *Arg) {
+  auto Ty =
+      Arg->isByVal() ? Arg->getType()->getPointerElementType() : Arg->getType();
+  return MDString::get(*Context, transTypeToOCLTypeName(Ty, !Arg->isZext()));
+}
+
+// Variable like GlobalInvolcationId[x] -> get_global_id(x).
+// Variable like WorkDim -> get_work_dim().
+bool SPIRVToLLVM::transOCLBuiltinFromVariable(GlobalVariable *GV,
+                                              SPIRVBuiltinVariableKind Kind) {
+  std::string FuncName = SPIRSPIRVBuiltinVariableMap::rmap(Kind);
+  std::string MangledName;
+  Type *ReturnTy = GV->getType()->getPointerElementType();
+  bool IsVec = ReturnTy->isVectorTy();
+  if (IsVec)
+    ReturnTy = cast<VectorType>(ReturnTy)->getElementType();
+  std::vector<Type *> ArgTy;
+  if (IsVec)
+    ArgTy.push_back(Type::getInt32Ty(*Context));
+  MangleOpenCLBuiltin(FuncName, ArgTy, MangledName);
+  Function *Func = M->getFunction(MangledName);
+  if (!Func) {
+    FunctionType *FT = FunctionType::get(ReturnTy, ArgTy, false);
+    Func = Function::Create(FT, GlobalValue::ExternalLinkage, MangledName, M);
+    Func->setCallingConv(CallingConv::FLOOR_FUNC);
+    Func->addFnAttr(Attribute::NoUnwind);
+    Func->addFnAttr(Attribute::ReadNone);
+  }
+  std::vector<Instruction *> Deletes;
+  std::vector<Instruction *> Uses;
+  for (auto UI = GV->user_begin(), UE = GV->user_end(); UI != UE; ++UI) {
+    assert(isa<LoadInst>(*UI) && "Unsupported use");
+    auto LD = dyn_cast<LoadInst>(*UI);
+    if (!IsVec) {
+      Uses.push_back(LD);
+      Deletes.push_back(LD);
+      continue;
+    }
+    for (auto LDUI = LD->user_begin(), LDUE = LD->user_end(); LDUI != LDUE;
+         ++LDUI) {
+      assert(isa<ExtractElementInst>(*LDUI) && "Unsupported use");
+      auto EEI = dyn_cast<ExtractElementInst>(*LDUI);
+      Uses.push_back(EEI);
+      Deletes.push_back(EEI);
+    }
+    Deletes.push_back(LD);
+  }
+  for (auto &I : Uses) {
+    std::vector<Value *> Arg;
+    if (auto EEI = dyn_cast<ExtractElementInst>(I))
+      Arg.push_back(EEI->getIndexOperand());
+    auto Call = CallInst::Create(Func, Arg, "", I);
+    Call->takeName(I);
+    setAttrByCalledFunc(Call);
+    SPIRVDBG(dbgs() << "[transOCLBuiltinFromVariable] " << *I << " -> " << *Call
+                    << '\n';)
+    I->replaceAllUsesWith(Call);
+  }
+  for (auto &I : Deletes) {
+    I->dropAllReferences();
+    I->removeFromParent();
+  }
+  return true;
+}
+
+Type *SPIRVToLLVM::transFPType(SPIRVType *T) {
+  switch (T->getFloatBitWidth()) {
+  case 16:
+    return Type::getHalfTy(*Context);
+  case 32:
+    return Type::getFloatTy(*Context);
+  case 64:
+    return Type::getDoubleTy(*Context);
+  default:
+    llvm_unreachable("Invalid type");
+    return nullptr;
+  }
+}
+
+std::string SPIRVToLLVM::transOCLImageTypeName(SPIRV::SPIRVTypeImage *ST) {
+  std::string Name = std::string(kSPR2TypeName::OCLPrefix) +
+                     rmap<std::string>(ST->getDescriptor());
+  if (SPIRVGenImgTypeAccQualPostfix)
+    SPIRVToLLVM::insertImageNameAccessQualifier(ST, Name);
+  return Name;
+}
+
+std::string
+SPIRVToLLVM::transOCLSampledImageTypeName(SPIRV::SPIRVTypeSampledImage *ST) {
+  return getSPIRVTypeName(
+      kSPIRVTypeName::SampledImg,
+      getSPIRVImageTypePostfixes(
+          getSPIRVImageSampledTypeName(ST->getImageType()->getSampledType()),
+          ST->getImageType()->getDescriptor(),
+          ST->getImageType()->getAccessQualifier()));
+}
+
+std::string SPIRVToLLVM::transOCLPipeTypeName(SPIRV::SPIRVTypePipe *PT,
+                                              bool UseSPIRVFriendlyFormat,
+                                              int PipeAccess) {
+  if (!UseSPIRVFriendlyFormat)
+    return kSPR2TypeName::Pipe;
+  else
+    return std::string(kSPIRVTypeName::PrefixAndDelim) + kSPIRVTypeName::Pipe +
+           kSPIRVTypeName::Delimiter + kSPIRVTypeName::PostfixDelim +
+           PipeAccess;
+}
+
+std::string
+SPIRVToLLVM::transOCLPipeStorageTypeName(SPIRV::SPIRVTypePipeStorage *PST) {
+  return std::string(kSPIRVTypeName::PrefixAndDelim) +
+         kSPIRVTypeName::PipeStorage;
+}
+
+Type *SPIRVToLLVM::transType(SPIRVType *T, bool IsClassMember) {
+  auto Loc = TypeMap.find(T);
+  if (Loc != TypeMap.end())
+    return Loc->second;
+
+  SPIRVDBG(spvdbgs() << "[transType] " << *T << " -> ";)
+  T->validate();
+  switch (T->getOpCode()) {
+  case OpTypeVoid:
+    return mapType(T, Type::getVoidTy(*Context));
+  case OpTypeBool:
+    return mapType(T, Type::getInt1Ty(*Context));
+  case OpTypeInt:
+    return mapType(T, Type::getIntNTy(*Context, T->getIntegerBitWidth()));
+  case OpTypeFloat:
+    return mapType(T, transFPType(T));
+  case OpTypeArray:
+    return mapType(T, ArrayType::get(transType(T->getArrayElementType()),
+                                     T->getArrayLength()));
+  case OpTypePointer:
+    return mapType(
+        T, PointerType::get(
+               transType(T->getPointerElementType(), IsClassMember),
+               SPIRSPIRVAddrSpaceMap::rmap(T->getPointerStorageClass())));
+  case OpTypeVector:
+    return mapType(T, VectorType::get(transType(T->getVectorComponentType()),
+                                      T->getVectorComponentCount()));
+  case OpTypeOpaque:
+    return mapType(T, StructType::create(*Context, T->getName()));
+  case OpTypeFunction: {
+    auto FT = static_cast<SPIRVTypeFunction *>(T);
+    auto RT = transType(FT->getReturnType());
+    std::vector<Type *> PT;
+    for (size_t I = 0, E = FT->getNumParameters(); I != E; ++I)
+      PT.push_back(transType(FT->getParameterType(I)));
+    return mapType(T, FunctionType::get(RT, PT, false));
+  }
+  case OpTypeImage: {
+    auto ST = static_cast<SPIRVTypeImage *>(T);
+    if (ST->isOCLImage())
+      return mapType(T, getOrCreateOpaquePtrType(M, transOCLImageTypeName(ST)));
+    else
+      llvm_unreachable("Unsupported image type");
+    return nullptr;
+  }
+  case OpTypeSampler:
+    return mapType(T, Type::getInt32Ty(*Context));
+  case OpTypeSampledImage: {
+    auto ST = static_cast<SPIRVTypeSampledImage *>(T);
+    return mapType(
+        T, getOrCreateOpaquePtrType(M, transOCLSampledImageTypeName(ST)));
+  }
+  case OpTypeStruct: {
+    auto ST = static_cast<SPIRVTypeStruct *>(T);
+    auto Name = ST->getName();
+    if (!Name.empty()) {
+      if (auto OldST = M->getTypeByName(Name))
+        OldST->setName("");
+    }
+    auto *StructTy = StructType::create(*Context, Name);
+    mapType(ST, StructTy);
+    SmallVector<Type *, 4> MT;
+    for (size_t I = 0, E = ST->getMemberCount(); I != E; ++I)
+      MT.push_back(transType(ST->getMemberType(I), true));
+    StructTy->setBody(MT, ST->isPacked());
+    return StructTy;
+  }
+  case OpTypePipe: {
+    auto PT = static_cast<SPIRVTypePipe *>(T);
+    return mapType(T, getOrCreateOpaquePtrType(
+                          M, transOCLPipeTypeName(PT, IsClassMember,
+                                                  PT->getAccessQualifier()),
+                          getOCLOpaqueTypeAddrSpace(T->getOpCode())));
+  }
+  case OpTypePipeStorage: {
+    auto PST = static_cast<SPIRVTypePipeStorage *>(T);
+    return mapType(
+        T, getOrCreateOpaquePtrType(M, transOCLPipeStorageTypeName(PST),
+                                    getOCLOpaqueTypeAddrSpace(T->getOpCode())));
+  }
+  default: {
+    auto OC = T->getOpCode();
+    if (isOpaqueGenericTypeOpCode(OC))
+      return mapType(
+          T, getOrCreateOpaquePtrType(M, OCLOpaqueTypeOpCodeMap::rmap(OC),
+                                      getOCLOpaqueTypeAddrSpace(OC)));
+    llvm_unreachable("Not implemented");
+  }
+  }
+  return 0;
+}
+
+std::string SPIRVToLLVM::transTypeToOCLTypeName(SPIRVType *T, bool IsSigned) {
+  switch (T->getOpCode()) {
+  case OpTypeVoid:
+    return "void";
+  case OpTypeBool:
+    return "bool";
+  case OpTypeInt: {
+    std::string Prefix = IsSigned ? "" : "u";
+    switch (T->getIntegerBitWidth()) {
+    case 8:
+      return Prefix + "char";
+    case 16:
+      return Prefix + "short";
+    case 32:
+      return Prefix + "int";
+    case 64:
+      return Prefix + "long";
+    default:
+      llvm_unreachable("invalid integer size");
+      return Prefix + std::string("int") + T->getIntegerBitWidth() + "_t";
+    }
+  } break;
+  case OpTypeFloat:
+    switch (T->getFloatBitWidth()) {
+    case 16:
+      return "half";
+    case 32:
+      return "float";
+    case 64:
+      return "double";
+    default:
+      llvm_unreachable("invalid floating pointer bitwidth");
+      return std::string("float") + T->getFloatBitWidth() + "_t";
+    }
+    break;
+  case OpTypeArray:
+    return "array";
+  case OpTypePointer:
+    return transTypeToOCLTypeName(T->getPointerElementType()) + "*";
+  case OpTypeVector:
+    return transTypeToOCLTypeName(T->getVectorComponentType()) +
+           T->getVectorComponentCount();
+  case OpTypeOpaque:
+    return T->getName();
+  case OpTypeFunction:
+    llvm_unreachable("Unsupported");
+    return "function";
+  case OpTypeStruct: {
+    auto Name = T->getName();
+    if (Name.find("struct.") == 0)
+      Name[6] = ' ';
+    else if (Name.find("union.") == 0)
+      Name[5] = ' ';
+    return Name;
+  }
+  case OpTypePipe:
+    return "pipe";
+  case OpTypeSampler:
+    return "sampler_t";
+  case OpTypeImage: {
+    std::string Name;
+    Name = rmap<std::string>(static_cast<SPIRVTypeImage *>(T)->getDescriptor());
+    if (SPIRVGenImgTypeAccQualPostfix) {
+      auto ST = static_cast<SPIRVTypeImage *>(T);
+      insertImageNameAccessQualifier(ST, Name);
+    }
+    return Name;
+  }
+  default:
+    if (isOpaqueGenericTypeOpCode(T->getOpCode())) {
+      return OCLOpaqueTypeOpCodeMap::rmap(T->getOpCode());
+    }
+    llvm_unreachable("Not implemented");
+    return "unknown";
+  }
+}
+
+std::vector<Type *>
+SPIRVToLLVM::transTypeVector(const std::vector<SPIRVType *> &BT) {
+  std::vector<Type *> T;
+  for (auto I : BT)
+    T.push_back(transType(I));
+  return T;
+}
+
+std::vector<Value *>
+SPIRVToLLVM::transValue(const std::vector<SPIRVValue *> &BV, Function *F,
+                        BasicBlock *BB) {
+  std::vector<Value *> V;
+  for (auto I : BV)
+    V.push_back(transValue(I, F, BB));
+  return V;
+}
+
+bool SPIRVToLLVM::isSPIRVCmpInstTransToLLVMInst(SPIRVInstruction *BI) const {
+  auto OC = BI->getOpCode();
+  return isCmpOpCode(OC) && !(OC >= OpLessOrGreater && OC <= OpUnordered);
+}
+
+void SPIRVToLLVM::transFlags(llvm::Value *V) {
+  if (!isa<Instruction>(V))
+    return;
+  auto OC = cast<Instruction>(V)->getOpcode();
+  if (OC == Instruction::AShr || OC == Instruction::LShr) {
+    cast<BinaryOperator>(V)->setIsExact();
+    return;
+  }
+}
+
+void SPIRVToLLVM::setName(llvm::Value *V, SPIRVValue *BV) {
+  auto Name = BV->getName();
+  if (!Name.empty() && (!V->hasName() || Name != V->getName()))
+    V->setName(Name);
+}
+
+void SPIRVToLLVM::insertImageNameAccessQualifier(SPIRV::SPIRVTypeImage *ST,
+                                                 std::string &Name) {
+  std::string QName = rmap<std::string>(ST->getAccessQualifier());
+  // transform: read_only -> ro, write_only -> wo, read_write -> rw
+  QName = QName.substr(0, 1) + QName.substr(QName.find("_") + 1, 1) + "_";
+  assert(!Name.empty() && "image name should not be empty");
+  Name.insert(Name.size() - 1, QName);
+}
+
+Value *SPIRVToLLVM::transValue(SPIRVValue *BV, Function *F, BasicBlock *BB,
+                               bool CreatePlaceHolder) {
+  SPIRVToLLVMValueMap::iterator Loc = ValueMap.find(BV);
+  if (Loc != ValueMap.end() && (!PlaceholderMap.count(BV) || CreatePlaceHolder))
+    return Loc->second;
+
+  SPIRVDBG(spvdbgs() << "[transValue] " << *BV << " -> ";)
+  BV->validate();
+
+  auto V = transValueWithoutDecoration(BV, F, BB, CreatePlaceHolder);
+  if (!V) {
+    SPIRVDBG(dbgs() << " Warning ! nullptr\n";)
+    return nullptr;
+  }
+  setName(V, BV);
+  if (!transDecoration(BV, V)) {
+    assert(0 && "trans decoration fail");
+    return nullptr;
+  }
+  transFlags(V);
+
+  SPIRVDBG(dbgs() << *V << '\n';)
+
+  return V;
+}
+
+Value *SPIRVToLLVM::transConvertInst(SPIRVValue *BV, Function *F,
+                                     BasicBlock *BB) {
+  SPIRVUnary *BC = static_cast<SPIRVUnary *>(BV);
+  auto Src = transValue(BC->getOperand(0), F, BB, BB ? true : false);
+  auto Dst = transType(BC->getType());
+  CastInst::CastOps CO = Instruction::BitCast;
+  bool IsExt =
+      Dst->getScalarSizeInBits() > Src->getType()->getScalarSizeInBits();
+  switch (BC->getOpCode()) {
+  case OpPtrCastToGeneric:
+  case OpGenericCastToPtr:
+    CO = Instruction::AddrSpaceCast;
+    break;
+  case OpSConvert:
+    CO = IsExt ? Instruction::SExt : Instruction::Trunc;
+    break;
+  case OpUConvert:
+    CO = IsExt ? Instruction::ZExt : Instruction::Trunc;
+    break;
+  case OpFConvert:
+    CO = IsExt ? Instruction::FPExt : Instruction::FPTrunc;
+    break;
+  default:
+    CO = static_cast<CastInst::CastOps>(OpCodeMap::rmap(BC->getOpCode()));
+  }
+  assert(CastInst::isCast(CO) && "Invalid cast op code");
+  SPIRVDBG(if (!CastInst::castIsValid(CO, Src, Dst)) {
+    spvdbgs() << "Invalid cast: " << *BV << " -> ";
+    dbgs() << "Op = " << CO << ", Src = " << *Src << " Dst = " << *Dst << '\n';
+  })
+  if (BB)
+    return CastInst::Create(CO, Src, Dst, BV->getName(), BB);
+  return ConstantExpr::getCast(CO, dyn_cast<Constant>(Src), Dst);
+}
+
+BinaryOperator *SPIRVToLLVM::transShiftLogicalBitwiseInst(SPIRVValue *BV,
+                                                          BasicBlock *BB,
+                                                          Function *F) {
+  SPIRVBinary *BBN = static_cast<SPIRVBinary *>(BV);
+  assert(BB && "Invalid BB");
+  Instruction::BinaryOps BO;
+  auto OP = BBN->getOpCode();
+  if (isLogicalOpCode(OP))
+    OP = IntBoolOpMap::rmap(OP);
+  BO = static_cast<Instruction::BinaryOps>(OpCodeMap::rmap(OP));
+  auto Inst = BinaryOperator::Create(BO, transValue(BBN->getOperand(0), F, BB),
+                                     transValue(BBN->getOperand(1), F, BB),
+                                     BV->getName(), BB);
+  return Inst;
+}
+
+Instruction *SPIRVToLLVM::transCmpInst(SPIRVValue *BV, BasicBlock *BB,
+                                       Function *F) {
+  SPIRVCompare *BC = static_cast<SPIRVCompare *>(BV);
+  assert(BB && "Invalid BB");
+  SPIRVType *BT = BC->getOperand(0)->getType();
+  Instruction *Inst = nullptr;
+  auto OP = BC->getOpCode();
+  if (isLogicalOpCode(OP))
+    OP = IntBoolOpMap::rmap(OP);
+  if (BT->isTypeVectorOrScalarInt() || BT->isTypeVectorOrScalarBool() ||
+      BT->isTypePointer())
+    Inst = new ICmpInst(*BB, CmpMap::rmap(OP),
+                        transValue(BC->getOperand(0), F, BB),
+                        transValue(BC->getOperand(1), F, BB));
+  else if (BT->isTypeVectorOrScalarFloat())
+    Inst = new FCmpInst(*BB, CmpMap::rmap(OP),
+                        transValue(BC->getOperand(0), F, BB),
+                        transValue(BC->getOperand(1), F, BB));
+  assert(Inst && "not implemented");
+  return Inst;
+}
+
+bool SPIRVToLLVM::postProcessOCL() {
+  std::string DemangledName;
+  SPIRVWord SrcLangVer = 0;
+  BM->getSourceLanguage(&SrcLangVer);
+  bool isCPP = SrcLangVer == kOCLVer::CL21;
+  for (auto I = M->begin(), E = M->end(); I != E;) {
+    auto F = I++;
+    if (F->hasName() && F->isDeclaration()) {
+      DEBUG(dbgs() << "[postProcessOCL sret] " << *F << '\n');
+      if (F->getReturnType()->isStructTy() &&
+          oclIsBuiltin(F->getName(), &DemangledName, isCPP)) {
+        if (!postProcessOCLBuiltinReturnStruct(&*F))
+          return false;
+      }
+    }
+  }
+  for (auto I = M->begin(), E = M->end(); I != E;) {
+    auto F = I++;
+    if (F->hasName() && F->isDeclaration()) {
+      DEBUG(dbgs() << "[postProcessOCL func ptr] " << *F << '\n');
+      auto AI = F->arg_begin();
+      if (hasFunctionPointerArg(&*F, AI) && isDecoratedSPIRVFunc(&*F))
+        if (!postProcessOCLBuiltinWithFuncPointer(&*F, AI))
+          return false;
+    }
+  }
+  for (auto I = M->begin(), E = M->end(); I != E;) {
+    auto F = I++;
+    if (F->hasName() && F->isDeclaration()) {
+      DEBUG(dbgs() << "[postProcessOCL array arg] " << *F << '\n');
+      if (hasArrayArg(&*F) && oclIsBuiltin(F->getName(), &DemangledName, isCPP))
+        if (!postProcessOCLBuiltinWithArrayArguments(&*F, DemangledName))
+          return false;
+    }
+  }
+  return true;
+}
+
+bool SPIRVToLLVM::postProcessOCLBuiltinReturnStruct(Function *F) {
+  std::string Name = F->getName();
+  F->setName(Name + ".old");
+  for (auto I = F->user_begin(), E = F->user_end(); I != E;) {
+    if (auto CI = dyn_cast<CallInst>(*I++)) {
+      auto ST = dyn_cast<StoreInst>(*(CI->user_begin()));
+      assert(ST);
+      std::vector<Type *> ArgTys;
+      getFunctionTypeParameterTypes(F->getFunctionType(), ArgTys);
+      ArgTys.insert(ArgTys.begin(),
+                    PointerType::get(F->getReturnType(), SPIRAS_Private));
+      auto newF =
+          getOrCreateFunction(M, Type::getVoidTy(*Context), ArgTys, Name);
+      newF->setCallingConv(F->getCallingConv());
+      auto Args = getArguments(CI);
+      Args.insert(Args.begin(), ST->getPointerOperand());
+      auto NewCI = CallInst::Create(newF, Args, CI->getName(), CI);
+      NewCI->setCallingConv(CI->getCallingConv());
+      ST->dropAllReferences();
+      ST->removeFromParent();
+      CI->dropAllReferences();
+      CI->removeFromParent();
+    }
+  }
+  F->dropAllReferences();
+  F->removeFromParent();
+  return true;
+}
+
+bool SPIRVToLLVM::postProcessOCLBuiltinWithFuncPointer(
+    Function *F, Function::arg_iterator I) {
+  auto Name = undecorateSPIRVFunction(F->getName());
+  std::set<Value *> InvokeFuncPtrs;
+  mutateFunctionOCL(F, [=, &InvokeFuncPtrs](CallInst *CI,
+                                            std::vector<Value *> &Args) {
+    auto ALoc = std::find_if(Args.begin(), Args.end(), [](Value *elem) {
+      return isFunctionPointerType(elem->getType());
+    });
+    assert(ALoc != Args.end() && "Buit-in must accept a pointer to function");
+    assert(isa<Function>(*ALoc) && "Invalid function pointer usage");
+    Value *Ctx = ALoc[1];
+    Value *CtxLen = ALoc[2];
+    Value *CtxAlign = ALoc[3];
+    if (Name == kOCLBuiltinName::EnqueueKernel)
+      assert(Args.end() - ALoc > 3);
+    else
+      assert(Args.end() - ALoc > 0);
+    // Erase arguments what are hanled by "spir_block_bind" according to SPIR
+    // 2.0
+    Args.erase(ALoc + 1, ALoc + 4);
+
+    InvokeFuncPtrs.insert(*ALoc);
+    // There will be as many calls to spir_block_bind as how much device
+    // execution
+    // bult-ins using this block. This doesn't contradict SPIR 2.0
+    // specification.
+    *ALoc = addBlockBind(M, cast<Function>(removeCast(*ALoc)), Ctx, CtxLen,
+                         CtxAlign, CI);
+    return Name;
+  });
+  for (auto &I : InvokeFuncPtrs)
+    eraseIfNoUse(I);
+  return true;
+}
+
+bool SPIRVToLLVM::postProcessOCLBuiltinWithArrayArguments(
+    Function *F, const std::string &DemangledName) {
+  DEBUG(dbgs() << "[postProcessOCLBuiltinWithArrayArguments] " << *F << '\n');
+  auto Attrs = F->getAttributes();
+  auto Name = F->getName();
+  mutateFunction(
+      F,
+      [=](CallInst *CI, std::vector<Value *> &Args) {
+        auto FBegin =
+            CI->getParent()->getParent()->begin()->getFirstInsertionPt();
+        for (auto &I : Args) {
+          auto T = I->getType();
+          if (!T->isArrayTy())
+            continue;
+          auto Alloca = new AllocaInst(T, "", &*FBegin);
+          auto Store = new StoreInst(I, Alloca, false, CI);
+          auto Zero =
+              ConstantInt::getNullValue(Type::getInt32Ty(T->getContext()));
+          Value *Index[] = {Zero, Zero};
+          I = GetElementPtrInst::CreateInBounds(
+              Store, Index, "",
+              CI); // TODO/NOTE: assuming this should be store?
+        }
+        return Name;
+      },
+      nullptr, &Attrs);
+  return true;
+}
+
+// ToDo: Handle unsigned integer return type. May need spec change.
+Instruction *SPIRVToLLVM::postProcessOCLReadImage(SPIRVInstruction *BI,
+                                                  CallInst *CI,
+                                                  const std::string &FuncName) {
+  AttributeSet Attrs = CI->getCalledFunction()->getAttributes();
+  StringRef ImageTypeName;
+  bool isDepthImage = false;
+  if (isOCLImageType(
+          (cast<CallInst>(CI->getOperand(0)))->getArgOperand(0)->getType(),
+          &ImageTypeName))
+    isDepthImage = ImageTypeName.endswith("depth_t");
+  return mutateCallInstOCL(
+      M, CI,
+      [=](CallInst *, std::vector<Value *> &Args, llvm::Type *&RetTy) {
+        CallInst *CallSampledImg = cast<CallInst>(Args[0]);
+        auto Img = CallSampledImg->getArgOperand(0);
+        assert(isOCLImageType(Img->getType()));
+        auto Sampler = CallSampledImg->getArgOperand(1);
+        Args[0] = Img;
+        Args.insert(Args.begin() + 1, Sampler);
+        if (Args.size() > 4) {
+          ConstantInt *ImOp = dyn_cast<ConstantInt>(Args[3]);
+          ConstantFP *LodVal = dyn_cast<ConstantFP>(Args[4]);
+          // Drop "Image Operands" argument.
+          Args.erase(Args.begin() + 3, Args.begin() + 4);
+          // If the image operand is LOD and its value is zero, drop it too.
+          if (ImOp && LodVal && LodVal->isNullValue() &&
+              ImOp->getZExtValue() == ImageOperandsMask::ImageOperandsLodMask)
+            Args.erase(Args.begin() + 3, Args.end());
+        }
+        if (CallSampledImg->hasOneUse()) {
+          CallSampledImg->replaceAllUsesWith(
+              UndefValue::get(CallSampledImg->getType()));
+          CallSampledImg->dropAllReferences();
+          CallSampledImg->eraseFromParent();
+        }
+        Type *T = CI->getType();
+        if (auto VT = dyn_cast<VectorType>(T))
+          T = VT->getElementType();
+        RetTy = isDepthImage ? T : CI->getType();
+        return std::string(kOCLBuiltinName::SampledReadImage) +
+               (T->isFloatingPointTy() ? 'f' : 'i');
+      },
+      [=](CallInst *NewCI) -> Instruction * {
+        if (isDepthImage)
+          return InsertElementInst::Create(
+              UndefValue::get(VectorType::get(NewCI->getType(), 4)), NewCI,
+              getSizet(M, 0), "", NewCI->getParent());
+        return NewCI;
+      },
+      &Attrs);
+}
+
+CallInst *
+SPIRVToLLVM::postProcessOCLWriteImage(SPIRVInstruction *BI, CallInst *CI,
+                                      const std::string &DemangledName) {
+  AttributeSet Attrs = CI->getCalledFunction()->getAttributes();
+  return mutateCallInstOCL(
+      M, CI,
+      [=](CallInst *, std::vector<Value *> &Args) {
+        llvm::Type *T = Args[2]->getType();
+        if (Args.size() > 4) {
+          ConstantInt *ImOp = dyn_cast<ConstantInt>(Args[3]);
+          ConstantFP *LodVal = dyn_cast<ConstantFP>(Args[4]);
+          // Drop "Image Operands" argument.
+          Args.erase(Args.begin() + 3, Args.begin() + 4);
+          // If the image operand is LOD and its value is zero, drop it too.
+          if (ImOp && LodVal && LodVal->isNullValue() &&
+              ImOp->getZExtValue() == ImageOperandsMask::ImageOperandsLodMask)
+            Args.erase(Args.begin() + 3, Args.end());
+          else
+            std::swap(Args[2], Args[3]);
+        }
+        return std::string(kOCLBuiltinName::WriteImage) +
+               (T->isFPOrFPVectorTy() ? 'f' : 'i');
+      },
+      &Attrs);
+}
+
+CallInst *SPIRVToLLVM::postProcessOCLBuildNDRange(SPIRVInstruction *BI,
+                                                  CallInst *CI,
+                                                  const std::string &FuncName) {
+  assert(CI->getNumArgOperands() == 3);
+  auto GWS = CI->getArgOperand(0);
+  auto LWS = CI->getArgOperand(1);
+  auto GWO = CI->getArgOperand(2);
+  CI->setArgOperand(0, GWO);
+  CI->setArgOperand(1, GWS);
+  CI->setArgOperand(2, LWS);
+  return CI;
+}
+
+Instruction *
+SPIRVToLLVM::postProcessGroupAllAny(CallInst *CI,
+                                    const std::string &DemangledName) {
+  AttributeSet Attrs = CI->getCalledFunction()->getAttributes();
+  return mutateCallInstSPIRV(
+      M, CI,
+      [=](CallInst *, std::vector<Value *> &Args, llvm::Type *&RetTy) {
+        Type *Int32Ty = Type::getInt32Ty(*Context);
+        RetTy = Int32Ty;
+        Args[1] = CastInst::CreateZExtOrBitCast(Args[1], Int32Ty, "", CI);
+        return DemangledName;
+      },
+      [=](CallInst *NewCI) -> Instruction * {
+        Type *RetTy = Type::getInt1Ty(*Context);
+        return CastInst::CreateTruncOrBitCast(NewCI, RetTy, "",
+                                              NewCI->getNextNode());
+      },
+      &Attrs);
+}
+
+CallInst *
+SPIRVToLLVM::expandOCLBuiltinWithScalarArg(CallInst *CI,
+                                           const std::string &FuncName) {
+  AttributeSet Attrs = CI->getCalledFunction()->getAttributes();
+  if (!CI->getOperand(0)->getType()->isVectorTy() &&
+      CI->getOperand(1)->getType()->isVectorTy()) {
+    return mutateCallInstOCL(
+        M, CI,
+        [=](CallInst *, std::vector<Value *> &Args) {
+          unsigned vecSize =
+              CI->getOperand(1)->getType()->getVectorNumElements();
+          Value *NewVec = nullptr;
+          if (auto CA = dyn_cast<Constant>(Args[0]))
+            NewVec = ConstantVector::getSplat(vecSize, CA);
+          else {
+            NewVec = ConstantVector::getSplat(
+                vecSize, Constant::getNullValue(Args[0]->getType()));
+            NewVec = InsertElementInst::Create(NewVec, Args[0], getInt32(M, 0),
+                                               "", CI);
+            NewVec = new ShuffleVectorInst(
+                NewVec, NewVec,
+                ConstantVector::getSplat(vecSize, getInt32(M, 0)), "", CI);
+          }
+          NewVec->takeName(Args[0]);
+          Args[0] = NewVec;
+          return FuncName;
+        },
+        &Attrs);
+  }
+  return CI;
+}
+
+std::string
+SPIRVToLLVM::transOCLPipeTypeAccessQualifier(SPIRV::SPIRVTypePipe *ST) {
+  return SPIRSPIRVAccessQualifierMap::rmap(ST->getAccessQualifier());
+}
+
+void SPIRVToLLVM::transGeneratorMD() {
+  SPIRVMDBuilder B(*M);
+  B.addNamedMD(kSPIRVMD::Generator)
+      .addOp()
+      .addU16(BM->getGeneratorId())
+      .addU16(BM->getGeneratorVer())
+      .done();
+}
+
+Value *SPIRVToLLVM::oclTransConstantSampler(SPIRV::SPIRVConstantSampler *BCS) {
+  auto Lit = (BCS->getAddrMode() << 1) | BCS->getNormalized() |
+             ((BCS->getFilterMode() + 1) << 4);
+  auto Ty = IntegerType::getInt32Ty(*Context);
+  return ConstantInt::get(Ty, Lit);
+}
+
+Value *SPIRVToLLVM::oclTransConstantPipeStorage(
+    SPIRV::SPIRVConstantPipeStorage *BCPS) {
+
+  string CPSName = string(kSPIRVTypeName::PrefixAndDelim) +
+                   kSPIRVTypeName::ConstantPipeStorage;
+
+  auto Int32Ty = IntegerType::getInt32Ty(*Context);
+  auto CPSTy = M->getTypeByName(CPSName);
+  if (!CPSTy) {
+    Type *CPSElemsTy[] = {Int32Ty, Int32Ty, Int32Ty};
+    CPSTy = StructType::create(*Context, CPSElemsTy, CPSName);
+  }
+
+  assert(CPSTy != nullptr && "Could not create spirv.ConstantPipeStorage");
+
+  Constant *CPSElems[] = {ConstantInt::get(Int32Ty, BCPS->getPacketSize()),
+                          ConstantInt::get(Int32Ty, BCPS->getPacketAlign()),
+                          ConstantInt::get(Int32Ty, BCPS->getCapacity())};
+
+  return new GlobalVariable(*M, CPSTy, false, GlobalValue::LinkOnceODRLinkage,
+                            ConstantStruct::get(CPSTy, CPSElems),
+                            BCPS->getName(), nullptr,
+                            GlobalValue::NotThreadLocal, SPIRAS_Global);
+}
+
+/// For instructions, this function assumes they are created in order
+/// and appended to the given basic block. An instruction may use a
+/// instruction from another BB which has not been translated. Such
+/// instructions should be translated to place holders at the point
+/// of first use, then replaced by real instructions when they are
+/// created.
+///
+/// When CreatePlaceHolder is true, create a load instruction of a
+/// global variable as placeholder for SPIRV instruction. Otherwise,
+/// create instruction and replace placeholder if there is one.
+Value *SPIRVToLLVM::transValueWithoutDecoration(SPIRVValue *BV, Function *F,
+                                                BasicBlock *BB,
+                                                bool CreatePlaceHolder) {
+
+  auto OC = BV->getOpCode();
+  IntBoolOpMap::rfind(OC, &OC);
+
+  // Translation of non-instruction values
+  switch (OC) {
+  case OpConstant: {
+    SPIRVConstant *BConst = static_cast<SPIRVConstant *>(BV);
+    SPIRVType *BT = BV->getType();
+    Type *LT = transType(BT);
+    switch (BT->getOpCode()) {
+    case OpTypeBool:
+    case OpTypeInt:
+      return mapValue(
+          BV, ConstantInt::get(LT, BConst->getZExtIntValue(),
+                               static_cast<SPIRVTypeInt *>(BT)->isSigned()));
+    case OpTypeFloat: {
+      const llvm::fltSemantics *FS = nullptr;
+      switch (BT->getFloatBitWidth()) {
+      case 16:
+        FS = &APFloat::IEEEhalf;
+        break;
+      case 32:
+        FS = &APFloat::IEEEsingle;
+        break;
+      case 64:
+        FS = &APFloat::IEEEdouble;
+        break;
+      default:
+        llvm_unreachable("invalid float type");
+      }
+      return mapValue(
+          BV, ConstantFP::get(*Context,
+                              APFloat(*FS, APInt(BT->getFloatBitWidth(),
+                                                 BConst->getZExtIntValue()))));
+    }
+    default:
+      llvm_unreachable("Not implemented");
+      return nullptr;
+    }
+  }
+
+  case OpConstantTrue:
+    return mapValue(BV, ConstantInt::getTrue(*Context));
+
+  case OpConstantFalse:
+    return mapValue(BV, ConstantInt::getFalse(*Context));
+
+  case OpConstantNull: {
+    auto LT = transType(BV->getType());
+    return mapValue(BV, Constant::getNullValue(LT));
+  }
+
+  case OpConstantComposite: {
+    auto BCC = static_cast<SPIRVConstantComposite *>(BV);
+    std::vector<Constant *> CV;
+    for (auto &I : BCC->getElements())
+      CV.push_back(dyn_cast<Constant>(transValue(I, F, BB)));
+    switch (BV->getType()->getOpCode()) {
+    case OpTypeVector:
+      return mapValue(BV, ConstantVector::get(CV));
+    case OpTypeArray:
+      return mapValue(
+          BV, ConstantArray::get(dyn_cast<ArrayType>(transType(BCC->getType())),
+                                 CV));
+    case OpTypeStruct: {
+      auto BCCTy = dyn_cast<StructType>(transType(BCC->getType()));
+      auto Members = BCCTy->getNumElements();
+      auto Constants = CV.size();
+      // if we try to initialize constant TypeStruct, add bitcasts
+      // if src and dst types are both pointers but to different types
+      if (Members == Constants) {
+        for (unsigned i = 0; i < Members; ++i) {
+          if (CV[i]->getType() == BCCTy->getElementType(i))
+            continue;
+          if (!CV[i]->getType()->isPointerTy() ||
+              !BCCTy->getElementType(i)->isPointerTy())
+            continue;
+
+          CV[i] = ConstantExpr::getBitCast(CV[i], BCCTy->getElementType(i));
+        }
+      }
+
+      return mapValue(BV,
+                      ConstantStruct::get(
+                          dyn_cast<StructType>(transType(BCC->getType())), CV));
+    }
+    default:
+      llvm_unreachable("not implemented");
+      return nullptr;
+    }
+  }
+
+  case OpConstantSampler: {
+    auto BCS = static_cast<SPIRVConstantSampler *>(BV);
+    return mapValue(BV, oclTransConstantSampler(BCS));
+  }
+
+  case OpConstantPipeStorage: {
+    auto BCPS = static_cast<SPIRVConstantPipeStorage *>(BV);
+    return mapValue(BV, oclTransConstantPipeStorage(BCPS));
+  }
+
+  case OpSpecConstantOp: {
+    auto BI =
+        createInstFromSpecConstantOp(static_cast<SPIRVSpecConstantOp *>(BV));
+    return mapValue(BV, transValue(BI, nullptr, nullptr, false));
+  }
+
+  case OpUndef:
+    return mapValue(BV, UndefValue::get(transType(BV->getType())));
+
+  case OpVariable: {
+    auto BVar = static_cast<SPIRVVariable *>(BV);
+    auto Ty = transType(BVar->getType()->getPointerElementType());
+    bool IsConst = BVar->isConstant();
+    llvm::GlobalValue::LinkageTypes LinkageTy = transLinkageType(BVar);
+    Constant *Initializer = nullptr;
+    SPIRVValue *Init = BVar->getInitializer();
+    if (Init)
+      Initializer = dyn_cast<Constant>(transValue(Init, F, BB, false));
+    else if (LinkageTy == GlobalValue::CommonLinkage)
+      // In LLVM variables with common linkage type must be initilized by 0
+      Initializer = Constant::getNullValue(Ty);
+
+    SPIRVStorageClassKind BS = BVar->getStorageClass();
+    if (BS == StorageClassFunction && !Init) {
+      assert(BB && "Invalid BB");
+      return mapValue(BV, new AllocaInst(Ty, BV->getName(), BB));
+    }
+    auto AddrSpace = SPIRSPIRVAddrSpaceMap::rmap(BS);
+    auto LVar = new GlobalVariable(*M, Ty, IsConst, LinkageTy, Initializer,
+                                   BV->getName(), 0,
+                                   GlobalVariable::NotThreadLocal, AddrSpace);
+    LVar->setUnnamedAddr(IsConst && Ty->isArrayTy() &&
+                                 Ty->getArrayElementType()->isIntegerTy(8)
+                             ? GlobalValue::UnnamedAddr::Global
+                             : GlobalValue::UnnamedAddr::None);
+    SPIRVBuiltinVariableKind BVKind;
+    if (BVar->isBuiltin(&BVKind))
+      BuiltinGVMap[LVar] = BVKind;
+    return mapValue(BV, LVar);
+  }
+
+  case OpFunctionParameter: {
+    auto BA = static_cast<SPIRVFunctionParameter *>(BV);
+    assert(F && "Invalid function");
+    unsigned ArgNo = 0;
+    for (Function::arg_iterator I = F->arg_begin(), E = F->arg_end(); I != E;
+         ++I, ++ArgNo) {
+      if (ArgNo == BA->getArgNo())
+        return mapValue(BV, &*I);
+    }
+    llvm_unreachable("Invalid argument");
+    return nullptr;
+  }
+
+  case OpFunction:
+    return mapValue(BV, transFunction(static_cast<SPIRVFunction *>(BV)));
+
+  case OpLabel:
+    return mapValue(BV, BasicBlock::Create(*Context, BV->getName(), F));
+
+  default:
+    // do nothing
+    break;
+  }
+
+  // During translation of OpSpecConstantOp we create an instruction
+  // corresponding to the Opcode operand and then translate this instruction.
+  // For such instruction BB and F should be nullptr, because it is a constant
+  // expression declared out of scope of any basic block or function.
+  // All other values require valid BB pointer.
+  assert(((isSpecConstantOpAllowedOp(OC) && !F && !BB) || BB) && "Invalid BB");
+
+  // Creation of place holder
+  if (CreatePlaceHolder) {
+    auto GV = new GlobalVariable(
+        *M, transType(BV->getType()), false, GlobalValue::PrivateLinkage,
+        nullptr, std::string(kPlaceholderPrefix) + BV->getName(), 0,
+        GlobalVariable::NotThreadLocal, 0);
+    auto LD = new LoadInst(GV, BV->getName(), BB);
+    PlaceholderMap[BV] = LD;
+    return mapValue(BV, LD);
+  }
+
+  // Translation of instructions
+  switch (BV->getOpCode()) {
+  case OpBranch: {
+    auto BR = static_cast<SPIRVBranch *>(BV);
+    return mapValue(BV, BranchInst::Create(dyn_cast<BasicBlock>(transValue(
+                                               BR->getTargetLabel(), F, BB)),
+                                           BB));
+  }
+
+  case OpBranchConditional: {
+    auto BR = static_cast<SPIRVBranchConditional *>(BV);
+    return mapValue(
+        BV, BranchInst::Create(
+                dyn_cast<BasicBlock>(transValue(BR->getTrueLabel(), F, BB)),
+                dyn_cast<BasicBlock>(transValue(BR->getFalseLabel(), F, BB)),
+                transValue(BR->getCondition(), F, BB), BB));
+  }
+
+  case OpUnreachable: {
+    return mapValue(BV, new UnreachableInst(*Context, BB));
+  }
+
+  case OpPhi: {
+    auto Phi = static_cast<SPIRVPhi *>(BV);
+    auto LPhi = dyn_cast<PHINode>(mapValue(
+        BV, PHINode::Create(transType(Phi->getType()),
+                            Phi->getPairs().size() / 2, Phi->getName(), BB)));
+    Phi->foreachPair([&](SPIRVValue *IncomingV, SPIRVBasicBlock *IncomingBB,
+                         size_t Index) {
+      auto Translated = transValue(IncomingV, F, BB);
+      LPhi->addIncoming(Translated,
+                        dyn_cast<BasicBlock>(transValue(IncomingBB, F, BB)));
+    });
+    return LPhi;
+  }
+
+  case OpReturn:
+    return mapValue(BV, ReturnInst::Create(*Context, BB));
+
+  case OpReturnValue: {
+    auto RV = static_cast<SPIRVReturnValue *>(BV);
+    return mapValue(
+        BV, ReturnInst::Create(*Context,
+                               transValue(RV->getReturnValue(), F, BB), BB));
+  }
+
+  case OpStore: {
+    SPIRVStore *BS = static_cast<SPIRVStore *>(BV);
+    StoreInst *SI = new StoreInst(transValue(BS->getSrc(), F, BB),
+                                  transValue(BS->getDst(), F, BB),
+                                  BS->SPIRVMemoryAccess::isVolatile(),
+                                  BS->SPIRVMemoryAccess::getAlignment(), BB);
+    if (BS->SPIRVMemoryAccess::isNonTemporal())
+      transNonTemporalMetadata(SI);
+    return mapValue(BV, SI);
+  }
+
+  case OpLoad: {
+    SPIRVLoad *BL = static_cast<SPIRVLoad *>(BV);
+    LoadInst *LI = new LoadInst(transValue(BL->getSrc(), F, BB), BV->getName(),
+                                BL->SPIRVMemoryAccess::isVolatile(),
+                                BL->SPIRVMemoryAccess::getAlignment(), BB);
+    if (BL->SPIRVMemoryAccess::isNonTemporal())
+      transNonTemporalMetadata(LI);
+    return mapValue(BV, LI);
+  }
+
+  case OpCopyMemorySized: {
+    SPIRVCopyMemorySized *BC = static_cast<SPIRVCopyMemorySized *>(BV);
+    std::string FuncName = "llvm.memcpy";
+    SPIRVType *BS = BC->getSource()->getType();
+    SPIRVType *BT = BC->getTarget()->getType();
+    Type *Int1Ty = Type::getInt1Ty(*Context);
+    Type *Int32Ty = Type::getInt32Ty(*Context);
+    Type *VoidTy = Type::getVoidTy(*Context);
+    Type *SrcTy = transType(BS);
+    Type *TrgTy = transType(BT);
+    Type *SizeTy = transType(BC->getSize()->getType());
+    Type *ArgTy[] = {TrgTy, SrcTy, SizeTy, Int32Ty, Int1Ty};
+
+    ostringstream TempName;
+    TempName << ".p"
+             << SPIRSPIRVAddrSpaceMap::rmap(BT->getPointerStorageClass())
+             << "i8";
+    TempName << ".p"
+             << SPIRSPIRVAddrSpaceMap::rmap(BS->getPointerStorageClass())
+             << "i8";
+    FuncName += TempName.str();
+    if (BC->getSize()->getType()->getBitWidth() == 32)
+      FuncName += ".i32";
+    else
+      FuncName += ".i64";
+
+    FunctionType *FT = FunctionType::get(VoidTy, ArgTy, false);
+    Function *Func = dyn_cast<Function>(M->getOrInsertFunction(FuncName, FT));
+    assert(Func && Func->getFunctionType() == FT && "Function type mismatch");
+    Func->setLinkage(GlobalValue::ExternalLinkage);
+
+    if (isFuncNoUnwind())
+      Func->addFnAttr(Attribute::NoUnwind);
+
+    Value *Arg[] = {
+        transValue(BC->getTarget(), Func, BB),
+        transValue(BC->getSource(), Func, BB),
+        dyn_cast<llvm::ConstantInt>(transValue(BC->getSize(), Func, BB)),
+        ConstantInt::get(Int32Ty, BC->SPIRVMemoryAccess::getAlignment()),
+        ConstantInt::get(Int1Ty, BC->SPIRVMemoryAccess::isVolatile())};
+    return mapValue(BV, CallInst::Create(Func, Arg, "", BB));
+  }
+
+  case OpSelect: {
+    SPIRVSelect *BS = static_cast<SPIRVSelect *>(BV);
+    return mapValue(BV,
+                    SelectInst::Create(transValue(BS->getCondition(), F, BB),
+                                       transValue(BS->getTrueValue(), F, BB),
+                                       transValue(BS->getFalseValue(), F, BB),
+                                       BV->getName(), BB));
+  }
+
+  case OpSwitch: {
+    auto BS = static_cast<SPIRVSwitch *>(BV);
+    auto Select = transValue(BS->getSelect(), F, BB);
+    auto LS = SwitchInst::Create(
+        Select, dyn_cast<BasicBlock>(transValue(BS->getDefault(), F, BB)),
+        BS->getNumPairs(), BB);
+    BS->foreachPair(
+        [&](SPIRVSwitch::LiteralTy Literals, SPIRVBasicBlock *Label) {
+          assert(!Literals.empty() && "Literals should not be empty");
+          assert(Literals.size() <= 2 &&
+                 "Number of literals should not be more then two");
+          uint64_t Literal = uint64_t(Literals.at(0));
+          if (Literals.size() == 2) {
+            Literal += uint64_t(Literals.at(1)) << 32;
+          }
+          LS->addCase(ConstantInt::get(dyn_cast<IntegerType>(Select->getType()),
+                                       Literal),
+                      dyn_cast<BasicBlock>(transValue(Label, F, BB)));
+        });
+    return mapValue(BV, LS);
+  }
+
+  case OpAccessChain:
+  case OpInBoundsAccessChain:
+  case OpPtrAccessChain:
+  case OpInBoundsPtrAccessChain: {
+    auto AC = static_cast<SPIRVAccessChainBase *>(BV);
+    auto Base = transValue(AC->getBase(), F, BB);
+    auto Index = transValue(AC->getIndices(), F, BB);
+    if (!AC->hasPtrIndex())
+      Index.insert(Index.begin(), getInt32(M, 0));
+    auto IsInbound = AC->isInBounds();
+    Value *V = nullptr;
+    if (BB) {
+      auto GEP =
+          GetElementPtrInst::Create(nullptr, Base, Index, BV->getName(), BB);
+      GEP->setIsInBounds(IsInbound);
+      V = GEP;
+    } else {
+      V = ConstantExpr::getGetElementPtr(nullptr, dyn_cast<Constant>(Base),
+                                         Index, IsInbound);
+    }
+    return mapValue(BV, V);
+  }
+
+  case OpCompositeExtract: {
+    SPIRVCompositeExtract *CE = static_cast<SPIRVCompositeExtract *>(BV);
+    if (CE->getComposite()->getType()->isTypeVector()) {
+      assert(CE->getIndices().size() == 1 && "Invalid index");
+      return mapValue(
+          BV, ExtractElementInst::Create(
+                  transValue(CE->getComposite(), F, BB),
+                  ConstantInt::get(*Context, APInt(32, CE->getIndices()[0])),
+                  BV->getName(), BB));
+    }
+    return mapValue(
+        BV, ExtractValueInst::Create(transValue(CE->getComposite(), F, BB),
+                                     CE->getIndices(), BV->getName(), BB));
+  }
+
+  case OpVectorExtractDynamic: {
+    auto CE = static_cast<SPIRVVectorExtractDynamic *>(BV);
+    return mapValue(
+        BV, ExtractElementInst::Create(transValue(CE->getVector(), F, BB),
+                                       transValue(CE->getIndex(), F, BB),
+                                       BV->getName(), BB));
+  }
+
+  case OpCompositeInsert: {
+    auto CI = static_cast<SPIRVCompositeInsert *>(BV);
+    if (CI->getComposite()->getType()->isTypeVector()) {
+      assert(CI->getIndices().size() == 1 && "Invalid index");
+      return mapValue(
+          BV, InsertElementInst::Create(
+                  transValue(CI->getComposite(), F, BB),
+                  transValue(CI->getObject(), F, BB),
+                  ConstantInt::get(*Context, APInt(32, CI->getIndices()[0])),
+                  BV->getName(), BB));
+    }
+    return mapValue(
+        BV, InsertValueInst::Create(transValue(CI->getComposite(), F, BB),
+                                    transValue(CI->getObject(), F, BB),
+                                    CI->getIndices(), BV->getName(), BB));
+  }
+
+  case OpVectorInsertDynamic: {
+    auto CI = static_cast<SPIRVVectorInsertDynamic *>(BV);
+    return mapValue(
+        BV, InsertElementInst::Create(transValue(CI->getVector(), F, BB),
+                                      transValue(CI->getComponent(), F, BB),
+                                      transValue(CI->getIndex(), F, BB),
+                                      BV->getName(), BB));
+  }
+
+  case OpVectorShuffle: {
+    auto VS = static_cast<SPIRVVectorShuffle *>(BV);
+    std::vector<Constant *> Components;
+    IntegerType *Int32Ty = IntegerType::get(*Context, 32);
+    for (auto I : VS->getComponents()) {
+      if (I == static_cast<SPIRVWord>(-1))
+        Components.push_back(UndefValue::get(Int32Ty));
+      else
+        Components.push_back(ConstantInt::get(Int32Ty, I));
+    }
+    return mapValue(BV,
+                    new ShuffleVectorInst(transValue(VS->getVector1(), F, BB),
+                                          transValue(VS->getVector2(), F, BB),
+                                          ConstantVector::get(Components),
+                                          BV->getName(), BB));
+  }
+
+  case OpFunctionCall: {
+    SPIRVFunctionCall *BC = static_cast<SPIRVFunctionCall *>(BV);
+    auto Call = CallInst::Create(transFunction(BC->getFunction()),
+                                 transValue(BC->getArgumentValues(), F, BB),
+                                 BC->getName(), BB);
+    setCallingConv(Call);
+    setAttrByCalledFunc(Call);
+    return mapValue(BV, Call);
+  }
+
+  case OpExtInst:
+    return mapValue(
+        BV, transOCLBuiltinFromExtInst(static_cast<SPIRVExtInst *>(BV), BB));
+
+  case OpControlBarrier:
+  case OpMemoryBarrier:
+    return mapValue(
+        BV, transOCLBarrierFence(static_cast<SPIRVInstruction *>(BV), BB));
+
+  case OpSNegate: {
+    SPIRVUnary *BC = static_cast<SPIRVUnary *>(BV);
+    return mapValue(
+        BV, BinaryOperator::CreateNSWNeg(transValue(BC->getOperand(0), F, BB),
+                                         BV->getName(), BB));
+  }
+
+  case OpFNegate: {
+    SPIRVUnary *BC = static_cast<SPIRVUnary *>(BV);
+    return mapValue(
+        BV, BinaryOperator::CreateFNeg(transValue(BC->getOperand(0), F, BB),
+                                       BV->getName(), BB));
+  }
+
+  case OpNot: {
+    SPIRVUnary *BC = static_cast<SPIRVUnary *>(BV);
+    return mapValue(
+        BV, BinaryOperator::CreateNot(transValue(BC->getOperand(0), F, BB),
+                                      BV->getName(), BB));
+  }
+
+  case OpAll:
+  case OpAny:
+    return mapValue(BV,
+                    transOCLAllAny(static_cast<SPIRVInstruction *>(BV), BB));
+
+  case OpIsFinite:
+  case OpIsInf:
+  case OpIsNan:
+  case OpIsNormal:
+  case OpSignBitSet:
+    return mapValue(
+        BV, transOCLRelational(static_cast<SPIRVInstruction *>(BV), BB));
+
+  default: {
+    auto OC = BV->getOpCode();
+    if (isSPIRVCmpInstTransToLLVMInst(static_cast<SPIRVInstruction *>(BV))) {
+      return mapValue(BV, transCmpInst(BV, BB, F));
+    } else if (OCLSPIRVBuiltinMap::rfind(OC, nullptr) && !isAtomicOpCode(OC) &&
+               !isGroupOpCode(OC) && !isPipeOpCode(OC)) {
+      return mapValue(
+          BV, transOCLBuiltinFromInst(static_cast<SPIRVInstruction *>(BV), BB));
+    } else if (isBinaryShiftLogicalBitwiseOpCode(OC) || isLogicalOpCode(OC)) {
+      return mapValue(BV, transShiftLogicalBitwiseInst(BV, BB, F));
+    } else if (isCvtOpCode(OC)) {
+      auto BI = static_cast<SPIRVInstruction *>(BV);
+      Value *Inst = nullptr;
+      if (BI->hasFPRoundingMode() || BI->isSaturatedConversion())
+        Inst = transOCLBuiltinFromInst(BI, BB);
+      else
+        Inst = transConvertInst(BV, F, BB);
+      return mapValue(BV, Inst);
+    }
+    return mapValue(
+        BV, transSPIRVBuiltinFromInst(static_cast<SPIRVInstruction *>(BV), BB));
+  }
+
+    SPIRVDBG(spvdbgs() << "Cannot translate " << *BV << '\n';)
+    llvm_unreachable("Translation of SPIRV instruction not implemented");
+    return NULL;
+  }
+}
+
+template <class SourceTy, class FuncTy>
+bool SPIRVToLLVM::foreachFuncCtlMask(SourceTy Source, FuncTy Func) {
+  SPIRVWord FCM = Source->getFuncCtlMask();
+  SPIRSPIRVFuncCtlMaskMap::foreach (
+      [&](Attribute::AttrKind Attr, SPIRVFunctionControlMaskKind Mask) {
+        if (FCM & Mask)
+          Func(Attr);
+      });
+  return true;
+}
+
+Function *SPIRVToLLVM::transFunction(SPIRVFunction *BF) {
+  auto Loc = FuncMap.find(BF);
+  if (Loc != FuncMap.end())
+    return Loc->second;
+
+  auto IsKernel = BM->isEntryPoint(ExecutionModelKernel, BF->getId());
+  auto Linkage = IsKernel ? GlobalValue::ExternalLinkage : transLinkageType(BF);
+  FunctionType *FT = dyn_cast<FunctionType>(transType(BF->getFunctionType()));
+  Function *F = dyn_cast<Function>(
+      mapValue(BF, Function::Create(FT, Linkage, BF->getName(), M)));
+  assert(F);
+  mapFunction(BF, F);
+  if (!F->isIntrinsic()) {
+    F->setCallingConv(IsKernel ? CallingConv::FLOOR_KERNEL
+                               : CallingConv::FLOOR_FUNC);
+    if (isFuncNoUnwind())
+      F->addFnAttr(Attribute::NoUnwind);
+    foreachFuncCtlMask(BF,
+                       [&](Attribute::AttrKind Attr) { F->addFnAttr(Attr); });
+  }
+
+  for (Function::arg_iterator I = F->arg_begin(), E = F->arg_end(); I != E;
+       ++I) {
+    auto BA = BF->getArgument(I->getArgNo());
+    mapValue(BA, &*I);
+    setName(&*I, BA);
+    BA->foreachAttr([&](SPIRVFuncParamAttrKind Kind) {
+      if (Kind == FunctionParameterAttributeNoWrite)
+        return;
+      F->addAttribute(I->getArgNo() + 1, SPIRSPIRVFuncParamAttrMap::rmap(Kind));
+    });
+
+    SPIRVWord MaxOffset = 0;
+    if (BA->hasDecorate(DecorationMaxByteOffset, 0, &MaxOffset)) {
+      AttrBuilder Builder;
+      Builder.addDereferenceableAttr(MaxOffset);
+      I->addAttr(AttributeSet::get(*Context, I->getArgNo() + 1, Builder));
+    }
+  }
+  BF->foreachReturnValueAttr([&](SPIRVFuncParamAttrKind Kind) {
+    if (Kind == FunctionParameterAttributeNoWrite)
+      return;
+    F->addAttribute(AttributeSet::ReturnIndex,
+                    SPIRSPIRVFuncParamAttrMap::rmap(Kind));
+  });
+
+  // Creating all basic blocks before creating instructions.
+  for (size_t I = 0, E = BF->getNumBasicBlock(); I != E; ++I) {
+    transValue(BF->getBasicBlock(I), F, nullptr);
+  }
+
+  for (size_t I = 0, E = BF->getNumBasicBlock(); I != E; ++I) {
+    SPIRVBasicBlock *BBB = BF->getBasicBlock(I);
+    BasicBlock *BB = dyn_cast<BasicBlock>(transValue(BBB, F, nullptr));
+    for (size_t BI = 0, BE = BBB->getNumInst(); BI != BE; ++BI) {
+      SPIRVInstruction *BInst = BBB->getInst(BI);
+      transValue(BInst, F, BB, false);
+    }
+  }
+  return F;
+}
+
+/// LLVM convert builtin functions is translated to two instructions:
+/// y = i32 islessgreater(float x, float z) ->
+///     y = i32 ZExt(bool LessGreater(float x, float z))
+/// When translating back, for simplicity, a trunc instruction is inserted
+/// w = bool LessGreater(float x, float z) ->
+///     w = bool Trunc(i32 islessgreater(float x, float z))
+/// Optimizer should be able to remove the redundant trunc/zext
+void SPIRVToLLVM::transOCLBuiltinFromInstPreproc(
+    SPIRVInstruction *BI, Type *&RetTy, std::vector<SPIRVValue *> &Args) {
+  if (!BI->hasType())
+    return;
+  auto BT = BI->getType();
+  auto OC = BI->getOpCode();
+  if (isCmpOpCode(BI->getOpCode())) {
+    if (BT->isTypeBool())
+      RetTy = IntegerType::getInt32Ty(*Context);
+    else if (BT->isTypeVectorBool())
+      RetTy = VectorType::get(
+          IntegerType::get(
+              *Context,
+              Args[0]->getType()->getVectorComponentType()->isTypeFloat(64)
+                  ? 64
+                  : 32),
+          BT->getVectorComponentCount());
+    else
+      llvm_unreachable("invalid compare instruction");
+  } else if (OC == OpGenericCastToPtrExplicit)
+    Args.pop_back();
+  else if (OC == OpImageRead && Args.size() > 2) {
+    // Drop "Image operands" argument
+    Args.erase(Args.begin() + 2);
+  }
+}
+
+Instruction *
+SPIRVToLLVM::transOCLBuiltinPostproc(SPIRVInstruction *BI, CallInst *CI,
+                                     BasicBlock *BB,
+                                     const std::string &DemangledName) {
+  auto OC = BI->getOpCode();
+  if (isCmpOpCode(OC) && BI->getType()->isTypeVectorOrScalarBool()) {
+    return CastInst::Create(Instruction::Trunc, CI, transType(BI->getType()),
+                            "cvt", BB);
+  }
+  if (OC == OpImageSampleExplicitLod)
+    return postProcessOCLReadImage(BI, CI, DemangledName);
+  if (OC == OpImageWrite) {
+    return postProcessOCLWriteImage(BI, CI, DemangledName);
+  }
+  if (OC == OpGenericPtrMemSemantics)
+    return BinaryOperator::CreateShl(CI, getInt32(M, 8), "", BB);
+  if (OC == OpImageQueryFormat)
+    return BinaryOperator::CreateSub(
+        CI, getInt32(M, OCLImageChannelDataTypeOffset), "", BB);
+  if (OC == OpImageQueryOrder)
+    return BinaryOperator::CreateSub(
+        CI, getInt32(M, OCLImageChannelOrderOffset), "", BB);
+  if (OC == OpBuildNDRange)
+    return postProcessOCLBuildNDRange(BI, CI, DemangledName);
+  if (OC == OpGroupAll || OC == OpGroupAny)
+    return postProcessGroupAllAny(CI, DemangledName);
+  if (SPIRVEnableStepExpansion &&
+      (DemangledName == "smoothstep" || DemangledName == "step"))
+    return expandOCLBuiltinWithScalarArg(CI, DemangledName);
+  return CI;
+}
+
+Instruction *SPIRVToLLVM::transBuiltinFromInst(const std::string &FuncName,
+                                               SPIRVInstruction *BI,
+                                               BasicBlock *BB) {
+  std::string MangledName;
+  auto Ops = BI->getOperands();
+  Type *RetTy =
+      BI->hasType() ? transType(BI->getType()) : Type::getVoidTy(*Context);
+  transOCLBuiltinFromInstPreproc(BI, RetTy, Ops);
+  std::vector<Type *> ArgTys =
+      transTypeVector(SPIRVInstruction::getOperandTypes(Ops));
+  bool HasFuncPtrArg = false;
+  for (auto &I : ArgTys) {
+    if (isa<FunctionType>(I)) {
+      I = PointerType::get(I, SPIRAS_Private);
+      HasFuncPtrArg = true;
+    }
+  }
+  if (!HasFuncPtrArg)
+    MangleOpenCLBuiltin(FuncName, ArgTys, MangledName);
+  else
+    MangledName = decorateSPIRVFunction(FuncName);
+  Function *Func = M->getFunction(MangledName);
+  FunctionType *FT = FunctionType::get(RetTy, ArgTys, false);
+  // ToDo: Some intermediate functions have duplicate names with
+  // different function types. This is OK if the function name
+  // is used internally and finally translated to unique function
+  // names. However it is better to have a way to differentiate
+  // between intermidiate functions and final functions and make
+  // sure final functions have unique names.
+  SPIRVDBG(if (!HasFuncPtrArg && Func && Func->getFunctionType() != FT) {
+    dbgs() << "Warning: Function name conflict:\n"
+           << *Func << '\n'
+           << " => " << *FT << '\n';
+  })
+  if (!Func || Func->getFunctionType() != FT) {
+    DEBUG(for (auto &I : ArgTys) { dbgs() << *I << '\n'; });
+    Func = Function::Create(FT, GlobalValue::ExternalLinkage, MangledName, M);
+    Func->setCallingConv(CallingConv::FLOOR_FUNC);
+    if (isFuncNoUnwind())
+      Func->addFnAttr(Attribute::NoUnwind);
+  }
+  auto Call =
+      CallInst::Create(Func, transValue(Ops, BB->getParent(), BB), "", BB);
+  setName(Call, BI);
+  setAttrByCalledFunc(Call);
+  SPIRVDBG(spvdbgs() << "[transInstToBuiltinCall] " << *BI << " -> ";
+           dbgs() << *Call << '\n';)
+  Instruction *Inst = Call;
+  Inst = transOCLBuiltinPostproc(BI, Call, BB, FuncName);
+  return Inst;
+}
+
+std::string SPIRVToLLVM::getOCLBuiltinName(SPIRVInstruction *BI) {
+  auto OC = BI->getOpCode();
+  if (OC == OpGenericCastToPtrExplicit)
+    return getOCLGenericCastToPtrName(BI);
+  if (isCvtOpCode(OC))
+    return getOCLConvertBuiltinName(BI);
+  if (OC == OpBuildNDRange) {
+    auto NDRangeInst = static_cast<SPIRVBuildNDRange *>(BI);
+    auto EleTy = ((NDRangeInst->getOperands())[0])->getType();
+    int Dim = EleTy->isTypeArray() ? EleTy->getArrayLength() : 1;
+    // cygwin does not have std::to_string
+    ostringstream OS;
+    OS << Dim;
+    assert((EleTy->isTypeInt() && Dim == 1) ||
+           (EleTy->isTypeArray() && Dim >= 2 && Dim <= 3));
+    return std::string(kOCLBuiltinName::NDRangePrefix) + OS.str() + "D";
+  }
+  auto Name = OCLSPIRVBuiltinMap::rmap(OC);
+
+  SPIRVType *T = nullptr;
+  switch (OC) {
+  case OpImageRead:
+    T = BI->getType();
+    break;
+  case OpImageWrite:
+    T = BI->getOperands()[2]->getType();
+    break;
+  default:
+    // do nothing
+    break;
+  }
+  if (T && T->isTypeVector())
+    T = T->getVectorComponentType();
+  if (T)
+    Name += T->isTypeFloat() ? 'f' : 'i';
+
+  return Name;
+}
+
+Instruction *SPIRVToLLVM::transOCLBuiltinFromInst(SPIRVInstruction *BI,
+                                                  BasicBlock *BB) {
+  assert(BB && "Invalid BB");
+  auto FuncName = getOCLBuiltinName(BI);
+  return transBuiltinFromInst(FuncName, BI, BB);
+}
+
+Instruction *SPIRVToLLVM::transSPIRVBuiltinFromInst(SPIRVInstruction *BI,
+                                                    BasicBlock *BB) {
+  assert(BB && "Invalid BB");
+  string Suffix = "";
+  if (BI->getOpCode() == OpCreatePipeFromPipeStorage) {
+    auto CPFPS = static_cast<SPIRVCreatePipeFromPipeStorage *>(BI);
+    assert(CPFPS->getType()->isTypePipe() &&
+           "Invalid type of CreatePipeFromStorage");
+    auto PipeType = static_cast<SPIRVTypePipe *>(CPFPS->getType());
+    switch (PipeType->getAccessQualifier()) {
+    case AccessQualifierReadOnly:
+      Suffix = "_read";
+      break;
+    case AccessQualifierWriteOnly:
+      Suffix = "_write";
+      break;
+    case AccessQualifierReadWrite:
+      Suffix = "_read_write";
+      break;
+    }
+  }
+
+  return transBuiltinFromInst(getSPIRVFuncName(BI->getOpCode(), Suffix), BI,
+                              BB);
+}
+
+bool SPIRVToLLVM::translate() {
+  if (!transAddressingModel())
+    return false;
+
+  DbgTran.createCompileUnit();
+  DbgTran.addDbgInfoVersion();
+
+  for (unsigned I = 0, E = BM->getNumVariables(); I != E; ++I) {
+    auto BV = BM->getVariable(I);
+    if (BV->getStorageClass() != StorageClassFunction)
+      transValue(BV, nullptr, nullptr);
+  }
+
+  for (unsigned I = 0, E = BM->getNumFunctions(); I != E; ++I) {
+    transFunction(BM->getFunction(I));
+  }
+  if (!transKernelMetadata())
+    return false;
+  if (!transFPContractMetadata())
+    return false;
+  if (!transSourceLanguage())
+    return false;
+  if (!transSourceExtension())
+    return false;
+  transGeneratorMD();
+  if (!transOCLBuiltinsFromVariables())
+    return false;
+  if (!postProcessOCL())
+    return false;
+  eraseUselessFunctions(M);
+  DbgTran.finalize();
+  return true;
+}
+
+bool SPIRVToLLVM::transAddressingModel() {
+  switch (BM->getAddressingModel()) {
+  case AddressingModelPhysical64:
+    M->setTargetTriple(SPIR_TARGETTRIPLE64);
+    M->setDataLayout(SPIR_DATALAYOUT64);
+    break;
+  case AddressingModelPhysical32:
+    M->setTargetTriple(SPIR_TARGETTRIPLE32);
+    M->setDataLayout(SPIR_DATALAYOUT32);
+    break;
+  case AddressingModelLogical:
+    // Do not set target triple and data layout
+    break;
+  default:
+    SPIRVCKRT(0, InvalidAddressingModel,
+              "Actual addressing mode is " +
+                  (unsigned)BM->getAddressingModel());
+  }
+  return true;
+}
+
+bool SPIRVToLLVM::transDecoration(SPIRVValue *BV, Value *V) {
+  if (!transAlign(BV, V))
+    return false;
+  // DbgTran.transDbgInfo(BV, V);
+  return true;
+}
+
+bool SPIRVToLLVM::transFPContractMetadata() {
+  bool ContractOff = false;
+  for (unsigned I = 0, E = BM->getNumFunctions(); I != E; ++I) {
+    SPIRVFunction *BF = BM->getFunction(I);
+    if (!isOpenCLKernel(BF))
+      continue;
+    if (BF->getExecutionMode(ExecutionModeContractionOff)) {
+      ContractOff = true;
+      break;
+    }
+  }
+  if (!ContractOff)
+    M->getOrInsertNamedMetadata(kSPIR2MD::FPContract);
+  return true;
+}
+
+std::string
+SPIRVToLLVM::transOCLImageTypeAccessQualifier(SPIRV::SPIRVTypeImage *ST) {
+  return SPIRSPIRVAccessQualifierMap::rmap(ST->getAccessQualifier());
+}
+
+bool SPIRVToLLVM::transNonTemporalMetadata(Instruction *I) {
+  Constant *One = ConstantInt::get(Type::getInt32Ty(*Context), 1);
+  MDNode *Node = MDNode::get(*Context, ConstantAsMetadata::get(One));
+  I->setMetadata(M->getMDKindID("nontemporal"), Node);
+  return true;
+}
+
+bool SPIRVToLLVM::transKernelMetadata() {
+  NamedMDNode *KernelMDs = M->getOrInsertNamedMetadata(SPIR_MD_KERNELS);
+  for (unsigned I = 0, E = BM->getNumFunctions(); I != E; ++I) {
+    SPIRVFunction *BF = BM->getFunction(I);
+    Function *F = static_cast<Function *>(getTranslatedValue(BF));
+    assert(F && "Invalid translated function");
+    if (F->getCallingConv() != CallingConv::FLOOR_KERNEL)
+      continue;
+    std::vector<llvm::Metadata *> KernelMD;
+    KernelMD.push_back(ValueAsMetadata::get(F));
+
+    // Generate metadata for kernel_arg_address_spaces
+    addOCLKernelArgumentMetadata(
+        Context, KernelMD, SPIR_MD_KERNEL_ARG_ADDR_SPACE, BF,
+        [=](SPIRVFunctionParameter *Arg) {
+          SPIRVType *ArgTy = Arg->getType();
+          SPIRAddressSpace AS = SPIRAS_Private;
+          if (ArgTy->isTypePointer())
+            AS = SPIRSPIRVAddrSpaceMap::rmap(ArgTy->getPointerStorageClass());
+          else if (ArgTy->isTypeOCLImage() || ArgTy->isTypePipe())
+            AS = SPIRAS_Global;
+          return ConstantAsMetadata::get(
+              ConstantInt::get(Type::getInt32Ty(*Context), AS));
+        });
+    // Generate metadata for kernel_arg_access_qual
+    addOCLKernelArgumentMetadata(
+        Context, KernelMD, SPIR_MD_KERNEL_ARG_ACCESS_QUAL, BF,
+        [=](SPIRVFunctionParameter *Arg) {
+          std::string Qual;
+          auto T = Arg->getType();
+          if (T->isTypeOCLImage()) {
+            auto ST = static_cast<SPIRVTypeImage *>(T);
+            Qual = transOCLImageTypeAccessQualifier(ST);
+          } else if (T->isTypePipe()) {
+            auto PT = static_cast<SPIRVTypePipe *>(T);
+            Qual = transOCLPipeTypeAccessQualifier(PT);
+          } else
+            Qual = "none";
+          return MDString::get(*Context, Qual);
+        });
+    // Generate metadata for kernel_arg_type
+    addOCLKernelArgumentMetadata(Context, KernelMD, SPIR_MD_KERNEL_ARG_TYPE, BF,
+                                 [=](SPIRVFunctionParameter *Arg) {
+                                   return transOCLKernelArgTypeName(Arg);
+                                 });
+    // Generate metadata for kernel_arg_type_qual
+    addOCLKernelArgumentMetadata(
+        Context, KernelMD, SPIR_MD_KERNEL_ARG_TYPE_QUAL, BF,
+        [=](SPIRVFunctionParameter *Arg) {
+          std::string Qual;
+          if (Arg->hasDecorate(DecorationVolatile))
+            Qual = kOCLTypeQualifierName::Volatile;
+          Arg->foreachAttr([&](SPIRVFuncParamAttrKind Kind) {
+            Qual += Qual.empty() ? "" : " ";
+            switch (Kind) {
+            case FunctionParameterAttributeNoAlias:
+              Qual += kOCLTypeQualifierName::Restrict;
+              break;
+            case FunctionParameterAttributeNoWrite:
+              Qual += kOCLTypeQualifierName::Const;
+              break;
+            default:
+              // do nothing.
+              break;
+            }
+          });
+          if (Arg->getType()->isTypePipe()) {
+            Qual += Qual.empty() ? "" : " ";
+            Qual += kOCLTypeQualifierName::Pipe;
+          }
+          return MDString::get(*Context, Qual);
+        });
+    // Generate metadata for kernel_arg_base_type
+    addOCLKernelArgumentMetadata(Context, KernelMD,
+                                 SPIR_MD_KERNEL_ARG_BASE_TYPE, BF,
+                                 [=](SPIRVFunctionParameter *Arg) {
+                                   return transOCLKernelArgTypeName(Arg);
+                                 });
+    // Generate metadata for kernel_arg_name
+    if (SPIRVGenKernelArgNameMD) {
+      bool ArgHasName = true;
+      BF->foreachArgument([&](SPIRVFunctionParameter *Arg) {
+        ArgHasName &= !Arg->getName().empty();
+      });
+      if (ArgHasName)
+        addOCLKernelArgumentMetadata(Context, KernelMD, SPIR_MD_KERNEL_ARG_NAME,
+                                     BF, [=](SPIRVFunctionParameter *Arg) {
+                                       return MDString::get(*Context,
+                                                            Arg->getName());
+                                     });
+    }
+    // Generate metadata for reqd_work_group_size
+    if (auto EM = BF->getExecutionMode(ExecutionModeLocalSize)) {
+      KernelMD.push_back(
+          getMDNodeStringIntVec(Context, kSPIR2MD::WGSize, EM->getLiterals()));
+    }
+    // Generate metadata for work_group_size_hint
+    if (auto EM = BF->getExecutionMode(ExecutionModeLocalSizeHint)) {
+      KernelMD.push_back(getMDNodeStringIntVec(Context, kSPIR2MD::WGSizeHint,
+                                               EM->getLiterals()));
+    }
+    // Generate metadata for vec_type_hint
+    if (auto EM = BF->getExecutionMode(ExecutionModeVecTypeHint)) {
+      std::vector<Metadata *> MetadataVec;
+      MetadataVec.push_back(MDString::get(*Context, kSPIR2MD::VecTyHint));
+      Type *VecHintTy = decodeVecTypeHint(*Context, EM->getLiterals()[0]);
+      assert(VecHintTy);
+      MetadataVec.push_back(ValueAsMetadata::get(UndefValue::get(VecHintTy)));
+      MetadataVec.push_back(ConstantAsMetadata::get(
+          ConstantInt::get(Type::getInt32Ty(*Context), 1)));
+      KernelMD.push_back(MDNode::get(*Context, MetadataVec));
+    }
+
+    llvm::MDNode *Node = MDNode::get(*Context, KernelMD);
+    KernelMDs->addOperand(Node);
+  }
+  return true;
+}
+
+bool SPIRVToLLVM::transAlign(SPIRVValue *BV, Value *V) {
+  if (auto AL = dyn_cast<AllocaInst>(V)) {
+    SPIRVWord Align = 0;
+    if (BV->hasAlignment(&Align))
+      AL->setAlignment(Align);
+    return true;
+  }
+  if (auto GV = dyn_cast<GlobalVariable>(V)) {
+    SPIRVWord Align = 0;
+    if (BV->hasAlignment(&Align))
+      GV->setAlignment(Align);
+    return true;
+  }
+  return true;
+}
+
+void SPIRVToLLVM::transOCLVectorLoadStore(std::string &UnmangledName,
+                                          std::vector<SPIRVWord> &BArgs) {
+  if (UnmangledName.find("vload") == 0 &&
+      UnmangledName.find("n") != std::string::npos) {
+    if (BArgs.back() != 1) {
+      std::stringstream SS;
+      SS << BArgs.back();
+      UnmangledName.replace(UnmangledName.find("n"), 1, SS.str());
+    } else {
+      UnmangledName.erase(UnmangledName.find("n"), 1);
+    }
+    BArgs.pop_back();
+  } else if (UnmangledName.find("vstore") == 0) {
+    if (UnmangledName.find("n") != std::string::npos) {
+      auto T = BM->getValueType(BArgs[0]);
+      if (T->isTypeVector()) {
+        auto W = T->getVectorComponentCount();
+        std::stringstream SS;
+        SS << W;
+        UnmangledName.replace(UnmangledName.find("n"), 1, SS.str());
+      } else {
+        UnmangledName.erase(UnmangledName.find("n"), 1);
+      }
+    }
+    if (UnmangledName.find("_r") != std::string::npos) {
+      UnmangledName.replace(
+          UnmangledName.find("_r"), 2,
+          std::string("_") +
+              SPIRSPIRVFPRoundingModeMap::rmap(
+                  static_cast<SPIRVFPRoundingModeKind>(BArgs.back())));
+      BArgs.pop_back();
+    }
+  }
+}
+
+// printf is not mangled. The function type should have just one argument.
+// read_image*: the second argument should be mangled as sampler.
+Instruction *SPIRVToLLVM::transOCLBuiltinFromExtInst(SPIRVExtInst *BC,
+                                                     BasicBlock *BB) {
+  assert(BB && "Invalid BB");
+  std::string MangledName;
+  SPIRVWord EntryPoint = BC->getExtOp();
+  SPIRVExtInstSetKind Set = BM->getBuiltinSet(BC->getExtSetId());
+  bool IsVarArg = false;
+  bool IsPrintf = false;
+  std::string UnmangledName;
+  auto BArgs = BC->getArguments();
+
+  assert((Set == SPIRVEIS_OpenCL || Set == SPIRVEIS_GLSL) &&
+         "Not OpenCL or GLSL extended instruction");
+  if (EntryPoint == OpenCLLIB::Printf)
+    IsPrintf = true;
+  else if (Set == SPIRVEIS_OpenCL) {
+    UnmangledName = OCLExtOpMap::map(static_cast<OCLExtOpKind>(EntryPoint));
+  } else if (Set == SPIRVEIS_GLSL) {
+    UnmangledName = GLSLExtOpMap::map(static_cast<GLSLExtOpKind>(EntryPoint));
+  }
+
+  SPIRVDBG(spvdbgs() << "[transOCLBuiltinFromExtInst] OrigUnmangledName: "
+                     << UnmangledName << '\n');
+  transOCLVectorLoadStore(UnmangledName, BArgs);
+
+  std::vector<Type *> ArgTypes = transTypeVector(BC->getValueTypes(BArgs));
+
+  if (IsPrintf) {
+    MangledName = "printf";
+    IsVarArg = true;
+    ArgTypes.resize(1);
+  } else if (UnmangledName.find("read_image") == 0) {
+    auto ModifiedArgTypes = ArgTypes;
+    ModifiedArgTypes[1] = getOrCreateOpaquePtrType(M, "opencl.sampler_t");
+    MangleOpenCLBuiltin(UnmangledName, ModifiedArgTypes, MangledName);
+  } else {
+    MangleOpenCLBuiltin(UnmangledName, ArgTypes, MangledName);
+  }
+  SPIRVDBG(spvdbgs() << "[transOCLBuiltinFromExtInst] ModifiedUnmangledName: "
+                     << UnmangledName << " MangledName: " << MangledName
+                     << '\n');
+
+  FunctionType *FT =
+      FunctionType::get(transType(BC->getType()), ArgTypes, IsVarArg);
+  Function *F = M->getFunction(MangledName);
+  if (!F) {
+    F = Function::Create(FT, GlobalValue::ExternalLinkage, MangledName, M);
+    F->setCallingConv(CallingConv::FLOOR_FUNC);
+    if (isFuncNoUnwind())
+      F->addFnAttr(Attribute::NoUnwind);
+  }
+  auto Args = transValue(BC->getValues(BArgs), F, BB);
+  SPIRVDBG(dbgs() << "[transOCLBuiltinFromExtInst] Function: " << *F
+                  << ", Args: ";
+           for (auto &I
+                : Args) dbgs()
+           << *I << ", ";
+           dbgs() << '\n');
+  CallInst *Call = CallInst::Create(F, Args, BC->getName(), BB);
+  setCallingConv(Call);
+  addFnAttr(Context, Call, Attribute::NoUnwind);
+  return transOCLBuiltinPostproc(BC, Call, BB, UnmangledName);
+}
+
+CallInst *SPIRVToLLVM::transOCLBarrier(BasicBlock *BB, SPIRVWord ExecScope,
+                                       SPIRVWord MemSema, SPIRVWord MemScope) {
+  SPIRVWord Ver = 0;
+  BM->getSourceLanguage(&Ver);
+
+  Type *Int32Ty = Type::getInt32Ty(*Context);
+  Type *VoidTy = Type::getVoidTy(*Context);
+
+  std::string FuncName;
+  SmallVector<Type *, 2> ArgTy;
+  SmallVector<Value *, 2> Arg;
+
+  Constant *MemFenceFlags =
+      ConstantInt::get(Int32Ty, rmapBitMask<OCLMemFenceMap>(MemSema));
+
+  FuncName = (ExecScope == ScopeWorkgroup) ? kOCLBuiltinName::WorkGroupBarrier
+                                           : kOCLBuiltinName::SubGroupBarrier;
+
+  if (ExecScope == ScopeWorkgroup && Ver > 0 && Ver <= kOCLVer::CL12) {
+    FuncName = kOCLBuiltinName::Barrier;
+    ArgTy.push_back(Int32Ty);
+    Arg.push_back(MemFenceFlags);
+  } else {
+    Constant *Scope = ConstantInt::get(
+        Int32Ty, OCLMemScopeMap::rmap(static_cast<spv::Scope>(MemScope)));
+
+    ArgTy.append(2, Int32Ty);
+    Arg.push_back(MemFenceFlags);
+    Arg.push_back(Scope);
+  }
+
+  std::string MangledName;
+
+  MangleOpenCLBuiltin(FuncName, ArgTy, MangledName);
+  Function *Func = M->getFunction(MangledName);
+  if (!Func) {
+    FunctionType *FT = FunctionType::get(VoidTy, ArgTy, false);
+    Func = Function::Create(FT, GlobalValue::ExternalLinkage, MangledName, M);
+    Func->setCallingConv(CallingConv::FLOOR_FUNC);
+    if (isFuncNoUnwind())
+      Func->addFnAttr(Attribute::NoUnwind);
+  }
+
+  return CallInst::Create(Func, Arg, "", BB);
+}
+
+CallInst *SPIRVToLLVM::transOCLMemFence(BasicBlock *BB, SPIRVWord MemSema,
+                                        SPIRVWord MemScope) {
+  SPIRVWord Ver = 0;
+  BM->getSourceLanguage(&Ver);
+
+  Type *Int32Ty = Type::getInt32Ty(*Context);
+  Type *VoidTy = Type::getVoidTy(*Context);
+
+  std::string FuncName;
+  SmallVector<Type *, 3> ArgTy;
+  SmallVector<Value *, 3> Arg;
+
+  Constant *MemFenceFlags =
+      ConstantInt::get(Int32Ty, rmapBitMask<OCLMemFenceMap>(MemSema));
+
+  if (Ver > 0 && Ver <= kOCLVer::CL12) {
+    FuncName = kOCLBuiltinName::MemFence;
+    ArgTy.push_back(Int32Ty);
+    Arg.push_back(MemFenceFlags);
+  } else {
+    Constant *Order = ConstantInt::get(Int32Ty, mapSPIRVMemOrderToOCL(MemSema));
+
+    Constant *Scope = ConstantInt::get(
+        Int32Ty, OCLMemScopeMap::rmap(static_cast<spv::Scope>(MemScope)));
+
+    FuncName = kOCLBuiltinName::AtomicWorkItemFence;
+    ArgTy.append(3, Int32Ty);
+    Arg.push_back(MemFenceFlags);
+    Arg.push_back(Order);
+    Arg.push_back(Scope);
+  }
+
+  std::string MangledName;
+
+  MangleOpenCLBuiltin(FuncName, ArgTy, MangledName);
+  Function *Func = M->getFunction(MangledName);
+  if (!Func) {
+    FunctionType *FT = FunctionType::get(VoidTy, ArgTy, false);
+    Func = Function::Create(FT, GlobalValue::ExternalLinkage, MangledName, M);
+    Func->setCallingConv(CallingConv::FLOOR_FUNC);
+    if (isFuncNoUnwind())
+      Func->addFnAttr(Attribute::NoUnwind);
+  }
+
+  return CallInst::Create(Func, Arg, "", BB);
+}
+
+Instruction *SPIRVToLLVM::transOCLBarrierFence(SPIRVInstruction *MB,
+                                               BasicBlock *BB) {
+  assert(BB && "Invalid BB");
+  std::string FuncName;
+  auto getIntVal = [](SPIRVValue *value) {
+    return static_cast<SPIRVConstant *>(value)->getZExtIntValue();
+  };
+
+  CallInst *Call = nullptr;
+
+  if (MB->getOpCode() == OpMemoryBarrier) {
+    auto MemB = static_cast<SPIRVMemoryBarrier *>(MB);
+
+    SPIRVWord MemScope = getIntVal(MemB->getOpValue(0));
+    SPIRVWord MemSema = getIntVal(MemB->getOpValue(1));
+
+    Call = transOCLMemFence(BB, MemSema, MemScope);
+  } else if (MB->getOpCode() == OpControlBarrier) {
+    auto CtlB = static_cast<SPIRVControlBarrier *>(MB);
+
+    SPIRVWord ExecScope = getIntVal(CtlB->getExecScope());
+    SPIRVWord MemSema = getIntVal(CtlB->getMemSemantic());
+    SPIRVWord MemScope = getIntVal(CtlB->getMemScope());
+
+    Call = transOCLBarrier(BB, ExecScope, MemSema, MemScope);
+  } else {
+    llvm_unreachable("Invalid instruction");
+  }
+
+  setName(Call, MB);
+  setAttrByCalledFunc(Call);
+  SPIRVDBG(spvdbgs() << "[transBarrier] " << *MB << " -> ";
+           dbgs() << *Call << '\n';)
+
+  return Call;
+}
+
+// SPIR-V only contains language version. Use OpenCL language version as
+// SPIR version.
+bool SPIRVToLLVM::transSourceLanguage() {
+  SPIRVWord Ver = 0;
+  SourceLanguage Lang = BM->getSourceLanguage(&Ver);
+  assert((Lang == SourceLanguageOpenCL_C || Lang == SourceLanguageOpenCL_CPP) &&
+         "Unsupported source language");
+  unsigned short Major = 0;
+  unsigned char Minor = 0;
+  unsigned char Rev = 0;
+  std::tie(Major, Minor, Rev) = decodeOCLVer(Ver);
+  SPIRVMDBuilder Builder(*M);
+  Builder.addNamedMD(kSPIRVMD::Source).addOp().add(Lang).add(Ver).done();
+  // ToDo: Phasing out usage of old SPIR metadata
+  if (Ver <= kOCLVer::CL12)
+    addOCLVersionMetadata(Context, M, kSPIR2MD::SPIRVer, 1, 2);
+  else
+    addOCLVersionMetadata(Context, M, kSPIR2MD::SPIRVer, 2, 0);
+
+  addOCLVersionMetadata(Context, M, kSPIR2MD::OCLVer, Major, Minor);
+  return true;
+}
+
+bool SPIRVToLLVM::transSourceExtension() {
+  auto ExtSet = rmap<OclExt::Kind>(BM->getExtension());
+  auto CapSet = rmap<OclExt::Kind>(BM->getCapability());
+  ExtSet.insert(CapSet.begin(), CapSet.end());
+  auto OCLExtensions = map<std::string>(ExtSet);
+  std::set<std::string> OCLOptionalCoreFeatures;
+  static const char *OCLOptCoreFeatureNames[] = {
+      "cl_images", "cl_doubles",
+  };
+  for (auto &I : OCLOptCoreFeatureNames) {
+    auto Loc = OCLExtensions.find(I);
+    if (Loc != OCLExtensions.end()) {
+      OCLExtensions.erase(Loc);
+      OCLOptionalCoreFeatures.insert(I);
+    }
+  }
+  addNamedMetadataStringSet(Context, M, kSPIR2MD::Extensions, OCLExtensions);
+  addNamedMetadataStringSet(Context, M, kSPIR2MD::OptFeatures,
+                            OCLOptionalCoreFeatures);
+  return true;
+}
+
+// If the argument is unsigned return uconvert*, otherwise return convert*.
+std::string SPIRVToLLVM::getOCLConvertBuiltinName(SPIRVInstruction *BI) {
+  auto OC = BI->getOpCode();
+  assert(isCvtOpCode(OC) && "Not convert instruction");
+  auto U = static_cast<SPIRVUnary *>(BI);
+  std::string Name;
+  if (isCvtFromUnsignedOpCode(OC))
+    Name = "u";
+  Name += "convert_";
+  Name += mapSPIRVTypeToOCLType(U->getType(), !isCvtToUnsignedOpCode(OC));
+  SPIRVFPRoundingModeKind Rounding;
+  if (U->isSaturatedConversion())
+    Name += "_sat";
+  if (U->hasFPRoundingMode(&Rounding)) {
+    Name += "_";
+    Name += SPIRSPIRVFPRoundingModeMap::rmap(Rounding);
+  }
+  return Name;
+}
+
+// Check Address Space of the Pointer Type
+std::string SPIRVToLLVM::getOCLGenericCastToPtrName(SPIRVInstruction *BI) {
+  auto GenericCastToPtrInst = BI->getType()->getPointerStorageClass();
+  switch (GenericCastToPtrInst) {
+  case StorageClassCrossWorkgroup:
+    return std::string(kOCLBuiltinName::ToGlobal);
+  case StorageClassWorkgroup:
+    return std::string(kOCLBuiltinName::ToLocal);
+  case StorageClassFunction:
+    return std::string(kOCLBuiltinName::ToPrivate);
+  default:
+    llvm_unreachable("Invalid address space");
+    return "";
+  }
+}
+
+llvm::GlobalValue::LinkageTypes
+SPIRVToLLVM::transLinkageType(const SPIRVValue *V) {
+  if (V->getLinkageType() == LinkageTypeInternal) {
+    return GlobalValue::InternalLinkage;
+  } else if (V->getLinkageType() == LinkageTypeImport) {
+    // Function declaration
+    if (V->getOpCode() == OpFunction) {
+      if (static_cast<const SPIRVFunction *>(V)->getNumBasicBlock() == 0)
+        return GlobalValue::ExternalLinkage;
+    }
+    // Variable declaration
+    if (V->getOpCode() == OpVariable) {
+      if (static_cast<const SPIRVVariable *>(V)->getInitializer() == 0)
+        return GlobalValue::ExternalLinkage;
+    }
+    // Definition
+    return GlobalValue::AvailableExternallyLinkage;
+  } else { // LinkageTypeExport
+    if (V->getOpCode() == OpVariable) {
+      if (static_cast<const SPIRVVariable *>(V)->getInitializer() == 0)
+        // Tentative definition
+        return GlobalValue::CommonLinkage;
+    }
+    return GlobalValue::ExternalLinkage;
+  }
+}
+
+Instruction *SPIRVToLLVM::transOCLAllAny(SPIRVInstruction *I, BasicBlock *BB) {
+  CallInst *CI = cast<CallInst>(transSPIRVBuiltinFromInst(I, BB));
+  AttributeSet Attrs = CI->getCalledFunction()->getAttributes();
+  return cast<Instruction>(mapValue(
+      I, mutateCallInstOCL(
+             M, CI,
+             [=](CallInst *, std::vector<Value *> &Args, llvm::Type *&RetTy) {
+               Type *Int32Ty = Type::getInt32Ty(*Context);
+               auto OldArg = CI->getOperand(0);
+               auto NewArgTy = VectorType::get(
+                   Int32Ty, OldArg->getType()->getVectorNumElements());
+               auto NewArg =
+                   CastInst::CreateSExtOrBitCast(OldArg, NewArgTy, "", CI);
+               Args[0] = NewArg;
+               RetTy = Int32Ty;
+               return CI->getCalledFunction()->getName();
+             },
+             [=](CallInst *NewCI) -> Instruction * {
+               return CastInst::CreateTruncOrBitCast(
+                   NewCI, Type::getInt1Ty(*Context), "", NewCI->getNextNode());
+             },
+             &Attrs)));
+}
+
+Instruction *SPIRVToLLVM::transOCLRelational(SPIRVInstruction *I,
+                                             BasicBlock *BB) {
+  CallInst *CI = cast<CallInst>(transSPIRVBuiltinFromInst(I, BB));
+  AttributeSet Attrs = CI->getCalledFunction()->getAttributes();
+  return cast<Instruction>(mapValue(
+      I, mutateCallInstOCL(
+             M, CI,
+             [=](CallInst *, std::vector<Value *> &Args, llvm::Type *&RetTy) {
+               Type *IntTy = Type::getInt32Ty(*Context);
+               RetTy = IntTy;
+               if (CI->getType()->isVectorTy()) {
+                 if (cast<VectorType>(CI->getOperand(0)->getType())
+                         ->getElementType()
+                         ->isDoubleTy())
+                   IntTy = Type::getInt64Ty(*Context);
+                 if (cast<VectorType>(CI->getOperand(0)->getType())
+                         ->getElementType()
+                         ->isHalfTy())
+                   IntTy = Type::getInt16Ty(*Context);
+                 RetTy = VectorType::get(IntTy,
+                                         CI->getType()->getVectorNumElements());
+               }
+               return CI->getCalledFunction()->getName();
+             },
+             [=](CallInst *NewCI) -> Instruction * {
+               Type *RetTy = Type::getInt1Ty(*Context);
+               if (NewCI->getType()->isVectorTy())
+                 RetTy =
+                     VectorType::get(Type::getInt1Ty(*Context),
+                                     NewCI->getType()->getVectorNumElements());
+               return CastInst::CreateTruncOrBitCast(NewCI, RetTy, "",
+                                                     NewCI->getNextNode());
+             },
+             &Attrs)));
+}
+}
+
+bool llvm::ReadSPIRV(LLVMContext &C, std::istream &IS, Module *&M,
+                     std::string &ErrMsg) {
+  M = new Module("", C);
+  std::unique_ptr<SPIRVModule> BM(SPIRVModule::createSPIRVModule());
+
+  IS >> *BM;
+
+  SPIRVToLLVM BTL(M, BM.get());
+  bool Succeed = true;
+  if (!BTL.translate()) {
+    BM->getError(ErrMsg);
+    Succeed = false;
+  }
+  legacy::PassManager PassMgr;
+  PassMgr.add(createSPIRVToOCL20());
+  PassMgr.add(createOCL20To12());
+  PassMgr.run(*M);
+
+  if (DbgSaveTmpLLVM)
+    dumpLLVM(M, DbgTmpLLVMFileName);
+  if (!Succeed) {
+    delete M;
+    M = nullptr;
+  }
+  return Succeed;
+}
diff --git a/lib/SPIRV/SPIRVRegularizeLLVM.cpp b/lib/SPIRV/SPIRVRegularizeLLVM.cpp
new file mode 100644
index 0000000..ff2e7b9
--- /dev/null
+++ b/lib/SPIRV/SPIRVRegularizeLLVM.cpp
@@ -0,0 +1,214 @@
+//===- SPIRVRegularizeLLVM.cpp - Regularize LLVM for SPIR-V ------- C++ -*-===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+//
+// This file implements regularization of LLVM module for SPIR-V.
+//
+//===----------------------------------------------------------------------===//
+#define DEBUG_TYPE "spvregular"
+
+#include "SPIRVInternal.h"
+#include "OCLUtil.h"
+#include "SPIRVMDBuilder.h"
+#include "SPIRVMDWalker.h"
+
+#include "llvm/ADT/StringSwitch.h"
+#include "llvm/ADT/Triple.h"
+#include "llvm/IR/InstVisitor.h"
+#include "llvm/IR/Instructions.h"
+#include "llvm/IR/IRBuilder.h"
+#include "llvm/IR/Verifier.h"
+#include "llvm/Pass.h"
+#include "llvm/PassSupport.h"
+#include "llvm/Support/CommandLine.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/raw_ostream.h"
+
+#include <set>
+
+using namespace llvm;
+using namespace SPIRV;
+using namespace OCLUtil;
+
+namespace SPIRV {
+
+static bool SPIRVDbgSaveRegularizedModule = false;
+static std::string RegularizedModuleTmpFile = "regularized.bc";
+
+class SPIRVRegularizeLLVM : public ModulePass {
+public:
+  SPIRVRegularizeLLVM() : ModulePass(ID), M(nullptr), Ctx(nullptr) {
+    initializeSPIRVRegularizeLLVMPass(*PassRegistry::getPassRegistry());
+  }
+
+  virtual bool runOnModule(Module &M);
+
+  // Lower functions
+  bool regularize();
+
+  /// Erase cast inst of function and replace with the function.
+  /// Assuming F is a SPIR-V builtin function with op code \param OC.
+  void lowerFuncPtr(Function *F, Op OC);
+  void lowerFuncPtr(Module *M);
+
+  static char ID;
+
+private:
+  Module *M;
+  LLVMContext *Ctx;
+};
+
+char SPIRVRegularizeLLVM::ID = 0;
+
+bool SPIRVRegularizeLLVM::runOnModule(Module &Module) {
+  M = &Module;
+  Ctx = &M->getContext();
+
+  DEBUG(dbgs() << "Enter SPIRVRegularizeLLVM:\n");
+  regularize();
+
+  DEBUG(dbgs() << "After SPIRVRegularizeLLVM:\n" << *M);
+  std::string Err;
+  raw_string_ostream ErrorOS(Err);
+  if (verifyModule(*M, &ErrorOS)) {
+    DEBUG(errs() << "Fails to verify module: " << ErrorOS.str());
+  }
+  return true;
+}
+
+/// Remove entities not representable by SPIR-V
+bool SPIRVRegularizeLLVM::regularize() {
+  LLVMContext *Context = &M->getContext();
+
+  eraseUselessFunctions(M);
+  lowerFuncPtr(M);
+  // lowerConstantExpressions();
+
+  for (auto I = M->begin(), E = M->end(); I != E;) {
+    Function *F = &*I;
+    ++I;
+    if (F->isDeclaration() && F->use_empty()) {
+      F->eraseFromParent();
+      continue;
+    }
+
+    for (auto BI = F->begin(), BE = F->end(); BI != BE; ++BI) {
+      for (auto II = BI->begin(), IE = BI->end(); II != IE; ++II) {
+        if (auto Call = dyn_cast<CallInst>(II)) {
+          Call->setTailCall(false);
+          if (Call->getCalledFunction()->isIntrinsic())
+            removeFnAttr(Context, Call, Attribute::NoUnwind);
+        }
+
+        // Remove optimization info not supported by SPIRV
+        if (auto BO = dyn_cast<BinaryOperator>(II)) {
+          if (isa<OverflowingBinaryOperator>(BO)) {
+            if (BO->hasNoUnsignedWrap())
+              BO->setHasNoUnsignedWrap(false);
+            if (BO->hasNoSignedWrap())
+              BO->setHasNoSignedWrap(false);
+          }
+          if (isa<PossiblyExactOperator>(BO) && BO->isExact())
+            BO->setIsExact(false);
+        }
+        // Remove metadata not supported by SPIRV
+        static const char *MDs[] = {
+            "fpmath", "tbaa", "range",
+        };
+        for (auto &MDName : MDs) {
+          if (II->getMetadata(MDName)) {
+            II->setMetadata(MDName, nullptr);
+          }
+        }
+      }
+    }
+  }
+
+  std::string Err;
+  raw_string_ostream ErrorOS(Err);
+  if (verifyModule(*M, &ErrorOS)) {
+    SPIRVDBG(errs() << "Fails to verify module: " << ErrorOS.str();)
+    return false;
+  }
+
+  if (SPIRVDbgSaveRegularizedModule)
+    saveLLVMModule(M, RegularizedModuleTmpFile);
+  return true;
+}
+
+// Assume F is a SPIR-V builtin function with a function pointer argument which
+// is a bitcast instruction casting a function to a void(void) function pointer.
+void SPIRVRegularizeLLVM::lowerFuncPtr(Function *F, Op OC) {
+  DEBUG(dbgs() << "[lowerFuncPtr] " << *F << '\n');
+  auto Name = decorateSPIRVFunction(getName(OC));
+  std::set<Value *> InvokeFuncPtrs;
+  auto Attrs = F->getAttributes();
+  mutateFunction(
+      F,
+      [=, &InvokeFuncPtrs](CallInst *CI, std::vector<Value *> &Args) {
+        for (auto &I : Args) {
+          if (isFunctionPointerType(I->getType())) {
+            InvokeFuncPtrs.insert(I);
+            I = removeCast(I);
+          }
+        }
+        return Name;
+      },
+      nullptr, &Attrs, false);
+  for (auto &I : InvokeFuncPtrs)
+    eraseIfNoUse(I);
+}
+
+void SPIRVRegularizeLLVM::lowerFuncPtr(Module *M) {
+  std::vector<std::pair<Function *, Op>> Work;
+  for (auto I = M->begin(), E = M->end(); I != E;) {
+    Function *F = &*I;
+    ++I;
+    auto AI = F->arg_begin();
+    if (hasFunctionPointerArg(F, AI)) {
+      auto OC = getSPIRVFuncOC(F->getName());
+      assert(OC != OpNop && "Invalid function pointer usage");
+      Work.push_back(std::make_pair(F, OC));
+    }
+  }
+  for (auto &I : Work)
+    lowerFuncPtr(I.first, I.second);
+}
+}
+
+INITIALIZE_PASS(SPIRVRegularizeLLVM, "spvregular", "Regularize LLVM for SPIR-V",
+                false, false)
+
+ModulePass *llvm::createSPIRVRegularizeLLVM() {
+  return new SPIRVRegularizeLLVM();
+}
diff --git a/lib/SPIRV/SPIRVToOCL20.cpp b/lib/SPIRV/SPIRVToOCL20.cpp
new file mode 100644
index 0000000..fd1ee17
--- /dev/null
+++ b/lib/SPIRV/SPIRVToOCL20.cpp
@@ -0,0 +1,569 @@
+//===- SPIRVToOCL20.cpp - Transform SPIR-V builtins to OCL20 builtins------===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+//
+// This file implements transform SPIR-V builtins to OCL 2.0 builtins.
+//
+//===----------------------------------------------------------------------===//
+#define DEBUG_TYPE "spvtocl20"
+
+#include "SPIRVInternal.h"
+#include "OCLUtil.h"
+#include "llvm/ADT/StringSwitch.h"
+#include "llvm/IR/InstVisitor.h"
+#include "llvm/IR/Instructions.h"
+#include "llvm/IR/IRBuilder.h"
+#include "llvm/IR/Verifier.h"
+#include "llvm/Pass.h"
+#include "llvm/PassSupport.h"
+#include "llvm/Support/CommandLine.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/raw_ostream.h"
+
+#include <cstring>
+
+using namespace llvm;
+using namespace SPIRV;
+using namespace OCLUtil;
+
+namespace SPIRV {
+
+static cl::opt<std::string>
+    MangledAtomicTypeNamePrefix("spirv-atomic-prefix",
+                                cl::desc("Mangled atomic type name prefix"),
+                                cl::init("U7_Atomic"));
+
+class SPIRVToOCL20 : public ModulePass, public InstVisitor<SPIRVToOCL20> {
+public:
+  SPIRVToOCL20() : ModulePass(ID), M(nullptr), Ctx(nullptr) {
+    initializeSPIRVToOCL20Pass(*PassRegistry::getPassRegistry());
+  }
+  virtual bool runOnModule(Module &M);
+
+  void visitCallInst(CallInst &CI);
+
+  // SPIR-V reader should translate vector casts into OCL built-ins because
+  // such conversions are not defined neither by OpenCL C/C++ nor
+  // by SPIR 1.2/2.0 standards. So, it is safer to convert such casts into
+  // appropriate calls to conversion built-ins defined by the standards.
+  void visitCastInst(CastInst &CI);
+
+  /// Transform __spirv_ImageQuerySize[Lod] into vector of the same lenght
+  /// containing {[get_image_width | get_image_dim], get_image_array_size}
+  /// for all images except image1d_t which is always converted into
+  /// get_image_width returning scalar result.
+  void visitCallSPRIVImageQuerySize(CallInst *CI);
+
+  /// Transform __spirv_Atomic* to atomic_*.
+  ///   __spirv_Atomic*(atomic_op, scope, sema, ops, ...) =>
+  ///      atomic_*(atomic_op, ops, ..., order(sema), map(scope))
+  void visitCallSPIRVAtomicBuiltin(CallInst *CI, Op OC);
+
+  /// Transform __spirv_Group* to {work_group|sub_group}_*.
+  ///
+  /// Special handling of work_group_broadcast.
+  ///   __spirv_GroupBroadcast(a, vec3(x, y, z))
+  ///     =>
+  ///   work_group_broadcast(a, x, y, z)
+  ///
+  /// Transform OpenCL group builtin function names from group_
+  /// to workgroup_ and sub_group_.
+  /// Insert group operation part: reduce_/inclusive_scan_/exclusive_scan_
+  /// Transform the operation part:
+  ///    fadd/iadd/sadd => add
+  ///    fmax/smax => max
+  ///    fmin/smin => min
+  /// Keep umax/umin unchanged.
+  void visitCallSPIRVGroupBuiltin(CallInst *CI, Op OC);
+
+  /// Transform __spirv_MemoryBarrier to atomic_work_item_fence.
+  ///   __spirv_MemoryBarrier(scope, sema) =>
+  ///       atomic_work_item_fence(flag(sema), order(sema), map(scope))
+  void visitCallSPIRVMemoryBarrier(CallInst *CI);
+
+  /// Transform __spirv_{PipeOpName} to OCL pipe builtin functions.
+  void visitCallSPIRVPipeBuiltin(CallInst *CI, Op OC);
+
+  /// Transform __spirv_* builtins to OCL 2.0 builtins.
+  /// No change with arguments.
+  void visitCallSPIRVBuiltin(CallInst *CI, Op OC);
+
+  /// Translate mangled atomic type name: "atomic_" =>
+  ///   MangledAtomicTypeNamePrefix
+  void translateMangledAtomicTypeName();
+
+  /// Get prefix work_/sub_ for OCL group builtin functions.
+  /// Assuming the first argument of \param CI is a constant integer for
+  /// workgroup/subgroup scope enums.
+  std::string getGroupBuiltinPrefix(CallInst *CI);
+
+  static char ID;
+
+private:
+  Module *M;
+  LLVMContext *Ctx;
+};
+
+char SPIRVToOCL20::ID = 0;
+
+bool SPIRVToOCL20::runOnModule(Module &Module) {
+  M = &Module;
+  Ctx = &M->getContext();
+  visit(*M);
+
+  translateMangledAtomicTypeName();
+
+  eraseUselessFunctions(&Module);
+
+  DEBUG(dbgs() << "After SPIRVToOCL20:\n" << *M);
+
+  std::string Err;
+  raw_string_ostream ErrorOS(Err);
+  if (verifyModule(*M, &ErrorOS)) {
+    DEBUG(errs() << "Fails to verify module: " << ErrorOS.str());
+  }
+  return true;
+}
+
+void SPIRVToOCL20::visitCallInst(CallInst &CI) {
+  DEBUG(dbgs() << "[visistCallInst] " << CI << '\n');
+  auto F = CI.getCalledFunction();
+  if (!F)
+    return;
+
+  auto MangledName = F->getName();
+  std::string DemangledName;
+  Op OC = OpNop;
+  if (!oclIsBuiltin(MangledName, &DemangledName) ||
+      (OC = getSPIRVFuncOC(DemangledName)) == OpNop)
+    return;
+  DEBUG(dbgs() << "DemangledName = " << DemangledName.c_str() << '\n'
+               << "OpCode = " << OC << '\n');
+
+  if (OC == OpImageQuerySize || OC == OpImageQuerySizeLod) {
+    visitCallSPRIVImageQuerySize(&CI);
+    return;
+  }
+  if (OC == OpMemoryBarrier) {
+    visitCallSPIRVMemoryBarrier(&CI);
+    return;
+  }
+  if (isAtomicOpCode(OC)) {
+    visitCallSPIRVAtomicBuiltin(&CI, OC);
+    return;
+  }
+  if (isGroupOpCode(OC)) {
+    visitCallSPIRVGroupBuiltin(&CI, OC);
+    return;
+  }
+  if (isPipeOpCode(OC)) {
+    visitCallSPIRVPipeBuiltin(&CI, OC);
+    return;
+  }
+  if (OCLSPIRVBuiltinMap::rfind(OC))
+    visitCallSPIRVBuiltin(&CI, OC);
+}
+
+void SPIRVToOCL20::visitCallSPIRVMemoryBarrier(CallInst *CI) {
+  AttributeSet Attrs = CI->getCalledFunction()->getAttributes();
+  mutateCallInstOCL(M, CI,
+                    [=](CallInst *, std::vector<Value *> &Args) {
+                      auto getArg = [=](unsigned I) {
+                        return cast<ConstantInt>(Args[I])->getZExtValue();
+                      };
+                      auto MScope = static_cast<Scope>(getArg(0));
+                      auto Sema = mapSPIRVMemSemanticToOCL(getArg(1));
+                      Args.resize(3);
+                      Args[0] = getInt32(M, Sema.first);
+                      Args[1] = getInt32(M, Sema.second);
+                      Args[2] = getInt32(M, rmap<OCLScopeKind>(MScope));
+                      return kOCLBuiltinName::AtomicWorkItemFence;
+                    },
+                    &Attrs);
+}
+
+void SPIRVToOCL20::visitCallSPRIVImageQuerySize(CallInst *CI) {
+  Function *func = CI->getCalledFunction();
+  // Get image type
+  Type *argTy = func->getFunctionType()->getParamType(0);
+  assert(argTy->isPointerTy() &&
+         "argument must be a pointer to opaque structure");
+  StructType *imgTy = cast<StructType>(argTy->getPointerElementType());
+  assert(imgTy->isOpaque() && "image type must be an opaque structure");
+  StringRef imgTyName = imgTy->getName();
+  assert(imgTyName.startswith("opencl.image") && "not an OCL image type");
+
+  unsigned imgDim = 0;
+  bool imgArray = false;
+
+  if (imgTyName.startswith("opencl.image1d")) {
+    imgDim = 1;
+  } else if (imgTyName.startswith("opencl.image2d")) {
+    imgDim = 2;
+  } else if (imgTyName.startswith("opencl.image3d")) {
+    imgDim = 3;
+  }
+  assert(imgDim != 0 && "unexpected image dimensionality");
+
+  if (imgTyName.count("_array_") != 0) {
+    imgArray = true;
+  }
+
+  AttributeSet attributes = CI->getCalledFunction()->getAttributes();
+  BuiltinFuncMangleInfo mangle;
+  Type *int32Ty = Type::getInt32Ty(*Ctx);
+  Instruction *getImageSize = nullptr;
+
+  if (imgDim == 1) {
+    // OpImageQuerySize from non-arrayed 1d image is always translated
+    // into get_image_width returning scalar argument
+    getImageSize = addCallInst(M, kOCLBuiltinName::GetImageWidth, int32Ty,
+                               CI->getArgOperand(0), &attributes, CI, &mangle,
+                               CI->getName(), false);
+    // The width of integer type returning by OpImageQuerySize[Lod] may
+    // differ from i32
+    if (CI->getType()->getScalarType() != int32Ty) {
+      getImageSize = CastInst::CreateIntegerCast(getImageSize,
+                                                 CI->getType()->getScalarType(),
+                                                 false, CI->getName(), CI);
+    }
+  } else {
+    assert((imgDim == 2 || imgDim == 3) && "invalid image type");
+    assert(CI->getType()->isVectorTy() &&
+           "this code can handle vector result type only");
+    // get_image_dim returns int2 and int4 for 2d and 3d images respecitvely.
+    const unsigned imgDimRetEls = imgDim == 2 ? 2 : 4;
+    VectorType *retTy = VectorType::get(int32Ty, imgDimRetEls);
+    getImageSize = addCallInst(M, kOCLBuiltinName::GetImageDim, retTy,
+                               CI->getArgOperand(0), &attributes, CI, &mangle,
+                               CI->getName(), false);
+    // The width of integer type returning by OpImageQuerySize[Lod] may
+    // differ from i32
+    if (CI->getType()->getScalarType() != int32Ty) {
+      getImageSize = CastInst::CreateIntegerCast(
+          getImageSize,
+          VectorType::get(CI->getType()->getScalarType(),
+                          getImageSize->getType()->getVectorNumElements()),
+          false, CI->getName(), CI);
+    }
+  }
+
+  if (imgArray || imgDim == 3) {
+    assert(
+        CI->getType()->isVectorTy() &&
+        "OpImageQuerySize[Lod] must return vector for arrayed and 3d images");
+    const unsigned imgQuerySizeRetEls = CI->getType()->getVectorNumElements();
+
+    if (imgDim == 1) {
+      // get_image_width returns scalar result while OpImageQuerySize
+      // for image1d_array_t returns <2 x i32> vector.
+      assert(imgQuerySizeRetEls == 2 &&
+             "OpImageQuerySize[Lod] must return <2 x iN> vector type");
+      getImageSize = InsertElementInst::Create(
+          UndefValue::get(CI->getType()), getImageSize,
+          ConstantInt::get(int32Ty, 0), CI->getName(), CI);
+    } else {
+      // get_image_dim and OpImageQuerySize returns different vector
+      // types for arrayed and 3d images.
+      SmallVector<Constant *, 4> maskEls;
+      for (unsigned idx = 0; idx < imgQuerySizeRetEls; ++idx)
+        maskEls.push_back(ConstantInt::get(int32Ty, idx));
+      Constant *mask = ConstantVector::get(maskEls);
+
+      getImageSize = new ShuffleVectorInst(
+          getImageSize, UndefValue::get(getImageSize->getType()), mask,
+          CI->getName(), CI);
+    }
+  }
+
+  if (imgArray) {
+    assert((imgDim == 1 || imgDim == 2) && "invalid image array type");
+    // Insert get_image_array_size to the last position of the resulting vector.
+    Type *sizeTy =
+        Type::getIntNTy(*Ctx, M->getDataLayout().getPointerSizeInBits(0));
+    Instruction *getImageArraySize = addCallInst(
+        M, kOCLBuiltinName::GetImageArraySize, sizeTy, CI->getArgOperand(0),
+        &attributes, CI, &mangle, CI->getName(), false);
+    // The width of integer type returning by OpImageQuerySize[Lod] may
+    // differ from size_t which is returned by get_image_array_size
+    if (getImageArraySize->getType() != CI->getType()->getScalarType()) {
+      getImageArraySize = CastInst::CreateIntegerCast(
+          getImageArraySize, CI->getType()->getScalarType(), false,
+          CI->getName(), CI);
+    }
+    getImageSize = InsertElementInst::Create(
+        getImageSize, getImageArraySize,
+        ConstantInt::get(int32Ty, CI->getType()->getVectorNumElements() - 1),
+        CI->getName(), CI);
+  }
+
+  assert(getImageSize && "must not be null");
+  CI->replaceAllUsesWith(getImageSize);
+  CI->eraseFromParent();
+}
+
+void SPIRVToOCL20::visitCallSPIRVAtomicBuiltin(CallInst *CI, Op OC) {
+  AttributeSet Attrs = CI->getCalledFunction()->getAttributes();
+  Instruction *pInsertBefore = CI;
+
+  mutateCallInstOCL(
+      M, CI,
+      [=](CallInst *, std::vector<Value *> &Args, Type *&RetTy) {
+        auto Ptr = findFirstPtr(Args);
+        auto Name = OCLSPIRVBuiltinMap::rmap(OC);
+        auto NumOrder = getAtomicBuiltinNumMemoryOrderArgs(Name);
+        auto ScopeIdx = Ptr + 1;
+        auto OrderIdx = Ptr + 2;
+        if (OC == OpAtomicIIncrement || OC == OpAtomicIDecrement) {
+          // Since OpenCL 1.2 atomic_inc and atomic_dec builtins don't have,
+          // memory
+          // scope and memory order syntax, and OpenCL 2.0 doesn't have such
+          // builtins, therefore we translate these instructions to
+          // atomic_fetch_add_explicit and atomic_fetch_sub_explicit OpenCL 2.0
+          // builtins with "operand" argument = 1.
+          Name = OCLSPIRVBuiltinMap::rmap(
+              OC == OpAtomicIIncrement ? OpAtomicIAdd : OpAtomicISub);
+          Type *ValueTy =
+              cast<PointerType>(Args[Ptr]->getType())->getElementType();
+          assert(ValueTy->isIntegerTy());
+          Args.push_back(llvm::ConstantInt::get(ValueTy, 1));
+        }
+        Args[ScopeIdx] =
+            mapUInt(M, cast<ConstantInt>(Args[ScopeIdx]), [](unsigned I) {
+              return rmap<OCLScopeKind>(static_cast<Scope>(I));
+            });
+        for (size_t I = 0; I < NumOrder; ++I)
+          Args[OrderIdx + I] =
+              mapUInt(M, cast<ConstantInt>(Args[OrderIdx + I]),
+                      [](unsigned Ord) { return mapSPIRVMemOrderToOCL(Ord); });
+        std::swap(Args[ScopeIdx], Args.back());
+        if (OC == OpAtomicCompareExchange ||
+            OC == OpAtomicCompareExchangeWeak) {
+          // OpAtomicCompareExchange[Weak] semantics is different from
+          // atomic_compare_exchange_[strong|weak] semantics as well as
+          // arguments order.
+          // OCL built-ins returns boolean value and stores a new/original
+          // value by pointer passed as 2nd argument (aka expected) while SPIR-V
+          // instructions returns this new/original value as a resulting value.
+          AllocaInst *pExpected =
+              new AllocaInst(CI->getType(), "expected",
+                             cast<Instruction>(pInsertBefore->getParent()
+                                                   ->getParent()
+                                                   ->getEntryBlock()
+                                                   .getFirstInsertionPt()));
+          pExpected->setAlignment(CI->getType()->getScalarSizeInBits() / 8);
+          new StoreInst(Args[1], pExpected, pInsertBefore);
+          Args[1] = pExpected;
+          std::swap(Args[3], Args[4]);
+          std::swap(Args[2], Args[3]);
+          RetTy = Type::getInt1Ty(*Ctx);
+        }
+        return Name;
+      },
+      [=](CallInst *CI) -> Instruction * {
+        if (OC == OpAtomicCompareExchange ||
+            OC == OpAtomicCompareExchangeWeak) {
+          // OCL built-ins atomic_compare_exchange_[strong|weak] return boolean
+          // value. So,
+          // to obtain the same value as SPIR-V instruction is returning it has
+          // to be loaded
+          // from the memory where 'expected' value is stored. This memory must
+          // contain the
+          // needed value after a call to OCL built-in is completed.
+          LoadInst *pOriginal =
+              new LoadInst(CI->getArgOperand(1), "original", pInsertBefore);
+          return pOriginal;
+        }
+        // For other built-ins the return values match.
+        return CI;
+      },
+      &Attrs);
+}
+
+void SPIRVToOCL20::visitCallSPIRVBuiltin(CallInst *CI, Op OC) {
+  AttributeSet Attrs = CI->getCalledFunction()->getAttributes();
+  mutateCallInstOCL(M, CI,
+                    [=](CallInst *, std::vector<Value *> &Args) {
+                      return OCLSPIRVBuiltinMap::rmap(OC);
+                    },
+                    &Attrs);
+}
+
+void SPIRVToOCL20::visitCallSPIRVGroupBuiltin(CallInst *CI, Op OC) {
+  auto DemangledName = OCLSPIRVBuiltinMap::rmap(OC);
+  assert(DemangledName.find(kSPIRVName::GroupPrefix) == 0);
+
+  std::string Prefix = getGroupBuiltinPrefix(CI);
+
+  bool HasGroupOperation = hasGroupOperation(OC);
+  if (!HasGroupOperation) {
+    DemangledName = Prefix + DemangledName;
+  } else {
+    auto GO = getArgAs<spv::GroupOperation>(CI, 1);
+    StringRef Op = DemangledName;
+    Op = Op.drop_front(strlen(kSPIRVName::GroupPrefix));
+    bool Unsigned = Op.front() == 'u';
+    if (!Unsigned)
+      Op = Op.drop_front(1);
+    DemangledName = Prefix + kSPIRVName::GroupPrefix +
+                    SPIRSPIRVGroupOperationMap::rmap(GO) + '_' + Op.str();
+  }
+  AttributeSet Attrs = CI->getCalledFunction()->getAttributes();
+  mutateCallInstOCL(M, CI,
+                    [=](CallInst *, std::vector<Value *> &Args) {
+                      Args.erase(Args.begin(),
+                                 Args.begin() + (HasGroupOperation ? 2 : 1));
+                      if (OC == OpGroupBroadcast)
+                        expandVector(CI, Args, 1);
+                      return DemangledName;
+                    },
+                    &Attrs);
+}
+
+void SPIRVToOCL20::visitCallSPIRVPipeBuiltin(CallInst *CI, Op OC) {
+  switch (OC) {
+  case OpReservedReadPipe:
+    OC = OpReadPipe;
+    break;
+  case OpReservedWritePipe:
+    OC = OpWritePipe;
+    break;
+  default:
+    // Do nothing.
+    break;
+  }
+  auto DemangledName = OCLSPIRVBuiltinMap::rmap(OC);
+
+  bool HasScope = DemangledName.find(kSPIRVName::GroupPrefix) == 0;
+  if (HasScope)
+    DemangledName = getGroupBuiltinPrefix(CI) + DemangledName;
+
+  AttributeSet Attrs = CI->getCalledFunction()->getAttributes();
+  mutateCallInstOCL(
+      M, CI,
+      [=](CallInst *, std::vector<Value *> &Args) {
+        if (HasScope)
+          Args.erase(Args.begin(), Args.begin() + 1);
+
+        if (!(OC == OpReadPipe || OC == OpWritePipe ||
+              OC == OpReservedReadPipe || OC == OpReservedWritePipe))
+          return DemangledName;
+
+        auto &P = Args[Args.size() - 3];
+        auto T = P->getType();
+        assert(isa<PointerType>(T));
+        auto ET = T->getPointerElementType();
+        if (!ET->isIntegerTy(8) ||
+            T->getPointerAddressSpace() != SPIRAS_Generic) {
+          auto NewTy = PointerType::getInt8PtrTy(*Ctx, SPIRAS_Generic);
+          P = CastInst::CreatePointerBitCastOrAddrSpaceCast(P, NewTy, "", CI);
+        }
+        return DemangledName;
+      },
+      &Attrs);
+}
+
+void SPIRVToOCL20::translateMangledAtomicTypeName() {
+  for (auto &I : M->functions()) {
+    if (!I.hasName())
+      continue;
+    std::string MangledName = I.getName();
+    std::string DemangledName;
+    if (!oclIsBuiltin(MangledName, &DemangledName) ||
+        DemangledName.find(kOCLBuiltinName::AtomPrefix) != 0)
+      continue;
+    auto Loc = MangledName.find(kOCLBuiltinName::AtomPrefix);
+    Loc = MangledName.find(kMangledName::AtomicPrefixInternal, Loc);
+    MangledName.replace(Loc, strlen(kMangledName::AtomicPrefixInternal),
+                        MangledAtomicTypeNamePrefix);
+    I.setName(MangledName);
+  }
+}
+
+std::string SPIRVToOCL20::getGroupBuiltinPrefix(CallInst *CI) {
+  std::string Prefix;
+  auto ES = getArgAsScope(CI, 0);
+  switch (ES) {
+  case ScopeWorkgroup:
+    Prefix = kOCLBuiltinName::WorkPrefix;
+    break;
+  case ScopeSubgroup:
+    Prefix = kOCLBuiltinName::SubPrefix;
+    break;
+  default:
+    llvm_unreachable("Invalid execution scope");
+  }
+  return Prefix;
+}
+
+void SPIRVToOCL20::visitCastInst(CastInst &Cast) {
+  if (!isa<ZExtInst>(Cast) && !isa<SExtInst>(Cast) && !isa<TruncInst>(Cast) &&
+      !isa<FPTruncInst>(Cast) && !isa<FPExtInst>(Cast) &&
+      !isa<FPToUIInst>(Cast) && !isa<FPToSIInst>(Cast) &&
+      !isa<UIToFPInst>(Cast) && !isa<SIToFPInst>(Cast))
+    return;
+
+  Type const *srcTy = Cast.getSrcTy();
+  Type *dstVecTy = Cast.getDestTy();
+  // Leave scalar casts as is. Skip boolean vector casts becase there
+  // are no suitable OCL built-ins.
+  if (!dstVecTy->isVectorTy() || srcTy->getScalarSizeInBits() == 1 ||
+      dstVecTy->getScalarSizeInBits() == 1)
+    return;
+
+  // Assemble built-in name -> convert_gentypeN
+  std::string castBuiltInName(kOCLBuiltinName::ConvertPrefix);
+  // Check if this is 'floating point -> unsigned integer' cast
+  castBuiltInName += mapLLVMTypeToOCLType(dstVecTy, !isa<FPToUIInst>(Cast));
+
+  // Replace LLVM conversion instruction with call to conversion built-in
+  BuiltinFuncMangleInfo mangle;
+  // It does matter if the source is unsigned integer or not. SExt is for
+  // signed source, ZExt and UIToFPInst are for unsigned source.
+  if (isa<ZExtInst>(Cast) || isa<UIToFPInst>(Cast))
+    mangle.addUnsignedArg(0);
+
+  AttributeSet attributes;
+  CallInst *call =
+      addCallInst(M, castBuiltInName, dstVecTy, Cast.getOperand(0), &attributes,
+                  &Cast, &mangle, Cast.getName(), false);
+  Cast.replaceAllUsesWith(call);
+  Cast.eraseFromParent();
+}
+
+} // namespace SPIRV
+
+INITIALIZE_PASS(SPIRVToOCL20, "spvtoocl20",
+                "Translate SPIR-V builtins to OCL 2.0 builtins", false, false)
+
+ModulePass *llvm::createSPIRVToOCL20() { return new SPIRVToOCL20(); }
diff --git a/lib/SPIRV/SPIRVUtil.cpp b/lib/SPIRV/SPIRVUtil.cpp
new file mode 100644
index 0000000..956aff5
--- /dev/null
+++ b/lib/SPIRV/SPIRVUtil.cpp
@@ -0,0 +1,1374 @@
+//===- SPIRVUtil.cpp - SPIR-V Utilities -------------------------*- C++ -*-===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+/// \file
+///
+/// This file defines utility classes and functions shared by SPIR-V
+/// reader/writer.
+///
+//===----------------------------------------------------------------------===//
+
+#include "SPIRVInternal.h"
+#include "libSPIRV/SPIRVDecorate.h"
+#include "libSPIRV/SPIRVValue.h"
+#include "SPIRVMDWalker.h"
+#include "OCLUtil.h"
+
+#include "llvm/ADT/StringSwitch.h"
+#include "llvm/Bitcode/ReaderWriter.h"
+#include "llvm/IR/IRBuilder.h"
+#include "llvm/Support/CommandLine.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/ErrorHandling.h"
+#include "llvm/Support/FileSystem.h"
+#include "llvm/Support/ToolOutputFile.h"
+#include "llvm/Support/raw_ostream.h"
+
+#include <functional>
+#include <sstream>
+
+#define DEBUG_TYPE "spirv"
+
+namespace SPIRV {
+
+#ifdef _SPIRV_SUPPORT_TEXT_FMT
+cl::opt<bool, true>
+    UseTextFormat("spirv-text",
+                  cl::desc("Use text format for SPIR-V for debugging purpose"),
+                  cl::location(SPIRVUseTextFormat));
+#endif
+
+#ifdef _SPIRVDBG
+cl::opt<bool, true> EnableDbgOutput("spirv-debug",
+                                    cl::desc("Enable SPIR-V debug output"),
+                                    cl::location(SPIRVDbgEnable));
+#endif
+
+void addFnAttr(LLVMContext *Context, CallInst *Call, Attribute::AttrKind Attr) {
+  Call->addAttribute(AttributeSet::FunctionIndex, Attr);
+}
+
+void removeFnAttr(LLVMContext *Context, CallInst *Call,
+                  Attribute::AttrKind Attr) {
+  Call->removeAttribute(AttributeSet::FunctionIndex,
+                        Attribute::get(*Context, Attr));
+}
+
+Value *removeCast(Value *V) {
+  auto Cast = dyn_cast<ConstantExpr>(V);
+  if (Cast && Cast->isCast()) {
+    return removeCast(Cast->getOperand(0));
+  }
+  if (auto Cast = dyn_cast<CastInst>(V))
+    return removeCast(Cast->getOperand(0));
+  return V;
+}
+
+void saveLLVMModule(Module *M, const std::string &OutputFile) {
+  std::error_code EC;
+  tool_output_file Out(OutputFile.c_str(), EC, sys::fs::F_None);
+  if (EC) {
+    SPIRVDBG(errs() << "Fails to open output file: " << EC.message();)
+    return;
+  }
+
+  WriteBitcodeToFile(M, Out.os());
+  Out.keep();
+}
+
+std::string mapLLVMTypeToOCLType(const Type *Ty, bool Signed) {
+  if (Ty->isHalfTy())
+    return "half";
+  if (Ty->isFloatTy())
+    return "float";
+  if (Ty->isDoubleTy())
+    return "double";
+  if (auto intTy = dyn_cast<IntegerType>(Ty)) {
+    std::string SignPrefix;
+    std::string Stem;
+    if (!Signed)
+      SignPrefix = "u";
+    switch (intTy->getIntegerBitWidth()) {
+    case 8:
+      Stem = "char";
+      break;
+    case 16:
+      Stem = "short";
+      break;
+    case 32:
+      Stem = "int";
+      break;
+    case 64:
+      Stem = "long";
+      break;
+    default:
+      Stem = "invalid_type";
+      break;
+    }
+    return SignPrefix + Stem;
+  }
+  if (auto vecTy = dyn_cast<VectorType>(Ty)) {
+    Type *eleTy = vecTy->getElementType();
+    unsigned size = vecTy->getVectorNumElements();
+    std::stringstream ss;
+    ss << mapLLVMTypeToOCLType(eleTy, Signed) << size;
+    return ss.str();
+  }
+  return "invalid_type";
+}
+
+std::string mapSPIRVTypeToOCLType(SPIRVType *Ty, bool Signed) {
+  if (Ty->isTypeFloat()) {
+    auto W = Ty->getBitWidth();
+    switch (W) {
+    case 16:
+      return "half";
+    case 32:
+      return "float";
+    case 64:
+      return "double";
+    default:
+      assert(0 && "Invalid floating pointer type");
+      return std::string("float") + W + "_t";
+    }
+  }
+  if (Ty->isTypeInt()) {
+    std::string SignPrefix;
+    std::string Stem;
+    if (!Signed)
+      SignPrefix = "u";
+    auto W = Ty->getBitWidth();
+    switch (W) {
+    case 8:
+      Stem = "char";
+      break;
+    case 16:
+      Stem = "short";
+      break;
+    case 32:
+      Stem = "int";
+      break;
+    case 64:
+      Stem = "long";
+      break;
+    default:
+      llvm_unreachable("Invalid integer type");
+      Stem = std::string("int") + W + "_t";
+      break;
+    }
+    return SignPrefix + Stem;
+  }
+  if (Ty->isTypeVector()) {
+    auto eleTy = Ty->getVectorComponentType();
+    auto size = Ty->getVectorComponentCount();
+    std::stringstream ss;
+    ss << mapSPIRVTypeToOCLType(eleTy, Signed) << size;
+    return ss.str();
+  }
+  llvm_unreachable("Invalid type");
+  return "unknown_type";
+}
+
+PointerType *getOrCreateOpaquePtrType(Module *M, const std::string &Name,
+                                      unsigned AddrSpace) {
+  auto OpaqueType = M->getTypeByName(Name);
+  if (!OpaqueType)
+    OpaqueType = StructType::create(M->getContext(), Name);
+  return PointerType::get(OpaqueType, AddrSpace);
+}
+
+PointerType *getSamplerType(Module *M) {
+  return getOrCreateOpaquePtrType(M, getSPIRVTypeName(kSPIRVTypeName::Sampler),
+                                  SPIRAS_Constant);
+}
+
+PointerType *getPipeStorageType(Module *M) {
+  return getOrCreateOpaquePtrType(
+      M, getSPIRVTypeName(kSPIRVTypeName::PipeStorage), SPIRAS_Constant);
+}
+
+void getFunctionTypeParameterTypes(llvm::FunctionType *FT,
+                                   std::vector<Type *> &ArgTys) {
+  for (auto I = FT->param_begin(), E = FT->param_end(); I != E; ++I) {
+    ArgTys.push_back(*I);
+  }
+}
+
+bool isVoidFuncTy(FunctionType *FT) {
+  return FT->getReturnType()->isVoidTy() && FT->getNumParams() == 0;
+}
+
+bool isPointerToOpaqueStructType(llvm::Type *Ty) {
+  if (auto PT = dyn_cast<PointerType>(Ty))
+    if (auto ST = dyn_cast<StructType>(PT->getElementType()))
+      if (ST->isOpaque())
+        return true;
+  return false;
+}
+
+bool isPointerToOpaqueStructType(llvm::Type *Ty, const std::string &Name) {
+  if (auto PT = dyn_cast<PointerType>(Ty))
+    if (auto ST = dyn_cast<StructType>(PT->getElementType()))
+      if (ST->isOpaque() && ST->getName() == Name)
+        return true;
+  return false;
+}
+
+bool isOCLImageType(llvm::Type *Ty, StringRef *Name) {
+  if (auto PT = dyn_cast<PointerType>(Ty))
+    if (auto ST = dyn_cast<StructType>(PT->getElementType()))
+      if (ST->isOpaque()) {
+        auto FullName = ST->getName();
+        if (FullName.find(kSPR2TypeName::ImagePrefix) == 0) {
+          if (Name)
+            *Name = FullName.drop_front(strlen(kSPR2TypeName::OCLPrefix));
+          return true;
+        }
+      }
+  return false;
+}
+
+/// \param BaseTyName is the type name as in spirv.BaseTyName.Postfixes
+/// \param Postfix contains postfixes extracted from the SPIR-V image
+///   type name as spirv.BaseTyName.Postfixes.
+bool isSPIRVType(llvm::Type *Ty, StringRef BaseTyName, StringRef *Postfix) {
+  if (auto PT = dyn_cast<PointerType>(Ty))
+    if (auto ST = dyn_cast<StructType>(PT->getElementType()))
+      if (ST->isOpaque()) {
+        auto FullName = ST->getName();
+        std::string N =
+            std::string(kSPIRVTypeName::PrefixAndDelim) + BaseTyName.str();
+        if (FullName != N)
+          N = N + kSPIRVTypeName::Delimiter;
+        if (FullName.startswith(N)) {
+          if (Postfix)
+            *Postfix = FullName.drop_front(N.size());
+          return true;
+        }
+      }
+  return false;
+}
+
+Function *getOrCreateFunction(Module *M, Type *RetTy, ArrayRef<Type *> ArgTypes,
+                              StringRef Name, BuiltinFuncMangleInfo *Mangle,
+                              AttributeSet *Attrs, bool takeName) {
+  std::string MangledName = Name;
+  bool isVarArg = false;
+  if (Mangle) {
+    MangledName = mangleBuiltin(Name, ArgTypes, Mangle);
+    isVarArg = 0 <= Mangle->getVarArg();
+    if (isVarArg)
+      ArgTypes = ArgTypes.slice(0, Mangle->getVarArg());
+  }
+  FunctionType *FT = FunctionType::get(RetTy, ArgTypes, isVarArg);
+  Function *F = M->getFunction(MangledName);
+  if (!takeName && F && F->getFunctionType() != FT && Mangle != nullptr) {
+    std::string S;
+    raw_string_ostream SS(S);
+    SS << "Error: Attempt to redefine function: " << *F << " => " << *FT
+       << '\n';
+    report_fatal_error(SS.str(), false);
+  }
+  if (!F || F->getFunctionType() != FT) {
+    auto NewF =
+        Function::Create(FT, GlobalValue::ExternalLinkage, MangledName, M);
+    if (F && takeName) {
+      NewF->takeName(F);
+      DEBUG(dbgs() << "[getOrCreateFunction] Warning: taking function name\n");
+    }
+    if (NewF->getName() != MangledName) {
+      DEBUG(dbgs() << "[getOrCreateFunction] Warning: function name changed\n");
+    }
+    DEBUG(dbgs() << "[getOrCreateFunction] "; if (F) dbgs() << *F << " => ";
+          dbgs() << *NewF << '\n';);
+    F = NewF;
+    F->setCallingConv(CallingConv::FLOOR_FUNC);
+    if (Attrs)
+      F->setAttributes(*Attrs);
+  }
+  return F;
+}
+
+std::vector<Value *> getArguments(CallInst *CI, unsigned Start, unsigned End) {
+  std::vector<Value *> Args;
+  if (End == 0)
+    End = CI->getNumArgOperands();
+  for (; Start != End; ++Start) {
+    Args.push_back(CI->getArgOperand(Start));
+  }
+  return Args;
+}
+
+uint64_t getArgAsInt(CallInst *CI, unsigned I) {
+  return cast<ConstantInt>(CI->getArgOperand(I))->getZExtValue();
+}
+
+Scope getArgAsScope(CallInst *CI, unsigned I) {
+  return static_cast<Scope>(getArgAsInt(CI, I));
+}
+
+Decoration getArgAsDecoration(CallInst *CI, unsigned I) {
+  return static_cast<Decoration>(getArgAsInt(CI, I));
+}
+
+std::string decorateSPIRVFunction(const std::string &S) {
+  return std::string(kSPIRVName::Prefix) + S + kSPIRVName::Postfix;
+}
+
+std::string undecorateSPIRVFunction(const std::string &S) {
+  assert(S.find(kSPIRVName::Prefix) == 0);
+  const size_t Start = strlen(kSPIRVName::Prefix);
+  auto End = S.rfind(kSPIRVName::Postfix);
+  return S.substr(Start, End - Start);
+}
+
+std::string prefixSPIRVName(const std::string &S) {
+  return std::string(kSPIRVName::Prefix) + S;
+}
+
+StringRef dePrefixSPIRVName(StringRef R, SmallVectorImpl<StringRef> &Postfix) {
+  const size_t Start = strlen(kSPIRVName::Prefix);
+  if (!R.startswith(kSPIRVName::Prefix))
+    return R;
+  R = R.drop_front(Start);
+  R.split(Postfix, "_", -1, false);
+  auto Name = Postfix.front();
+  Postfix.erase(Postfix.begin());
+  return Name;
+}
+
+std::string getSPIRVFuncName(Op OC, StringRef PostFix) {
+  return prefixSPIRVName(getName(OC) + PostFix.str());
+}
+
+std::string getSPIRVFuncName(Op OC, const Type *pRetTy, bool IsSigned) {
+  return prefixSPIRVName(getName(OC) + kSPIRVPostfix::Divider +
+                         getPostfixForReturnType(pRetTy, false));
+}
+
+std::string getSPIRVExtFuncName(SPIRVExtInstSetKind Set, unsigned ExtOp,
+                                StringRef PostFix) {
+  std::string ExtOpName;
+  switch (Set) {
+  default:
+    llvm_unreachable("invalid extended instruction set");
+    ExtOpName = "unknown";
+    break;
+  case SPIRVEIS_OpenCL:
+    ExtOpName = getName(static_cast<OCLExtOpKind>(ExtOp));
+    break;
+  case SPIRVEIS_GLSL:
+    ExtOpName = getName(static_cast<GLSLExtOpKind>(ExtOp));
+    break;
+  }
+  return prefixSPIRVName(SPIRVExtSetShortNameMap::map(Set) + '_' + ExtOpName +
+                         PostFix.str());
+}
+
+SPIRVDecorate *mapPostfixToDecorate(StringRef Postfix, SPIRVEntry *Target) {
+  if (Postfix == kSPIRVPostfix::Sat)
+    return new SPIRVDecorate(spv::DecorationSaturatedConversion, Target);
+
+  if (Postfix.startswith(kSPIRVPostfix::Rt))
+    return new SPIRVDecorate(spv::DecorationFPRoundingMode, Target,
+                             map<SPIRVFPRoundingModeKind>(Postfix.str()));
+
+  return nullptr;
+}
+
+SPIRVValue *addDecorations(SPIRVValue *Target,
+                           const SmallVectorImpl<std::string> &Decs) {
+  for (auto &I : Decs)
+    if (auto Dec = mapPostfixToDecorate(I, Target))
+      Target->addDecorate(Dec);
+  return Target;
+}
+
+std::string getPostfix(Decoration Dec, unsigned Value) {
+  switch (Dec) {
+  default:
+    llvm_unreachable("not implemented");
+    return "unknown";
+  case spv::DecorationSaturatedConversion:
+    return kSPIRVPostfix::Sat;
+  case spv::DecorationFPRoundingMode:
+    return rmap<std::string>(static_cast<SPIRVFPRoundingModeKind>(Value));
+  }
+}
+
+std::string getPostfixForReturnType(CallInst *CI, bool IsSigned) {
+  return getPostfixForReturnType(CI->getType(), IsSigned);
+}
+
+std::string getPostfixForReturnType(const Type *pRetTy, bool IsSigned) {
+  return std::string(kSPIRVPostfix::Return) +
+         mapLLVMTypeToOCLType(pRetTy, IsSigned);
+}
+
+Op getSPIRVFuncOC(const std::string &S, SmallVectorImpl<std::string> *Dec) {
+  Op OC;
+  SmallVector<StringRef, 2> Postfix;
+  std::string Name;
+  if (!oclIsBuiltin(S, &Name))
+    Name = S;
+  StringRef R(Name);
+  R = dePrefixSPIRVName(R, Postfix);
+  if (!getByName(R.str(), OC))
+    return OpNop;
+  if (Dec)
+    for (auto &I : Postfix)
+      Dec->push_back(I.str());
+  return OC;
+}
+
+bool getSPIRVBuiltin(const std::string &OrigName, spv::BuiltIn &B) {
+  SmallVector<StringRef, 2> Postfix;
+  StringRef R(OrigName);
+  R = dePrefixSPIRVName(R, Postfix);
+  assert(Postfix.empty() && "Invalid SPIR-V builtin name");
+  return getByName(R.str(), B);
+}
+
+bool oclIsBuiltin(const StringRef &Name, std::string *DemangledName,
+                  bool isCPP) {
+  if (Name == "printf") {
+    if (DemangledName)
+      *DemangledName = Name;
+    return true;
+  }
+  if (!Name.startswith("_Z"))
+    return false;
+  if (!DemangledName)
+    return true;
+  // OpenCL C++ built-ins are declared in cl namespace.
+  // TODO: consider using 'St' abbriviation for cl namespace mangling.
+  // Similar to ::std:: in C++.
+  if (isCPP) {
+    if (!Name.startswith("_ZN"))
+      return false;
+    // Skip CV and ref qualifiers.
+    size_t NameSpaceStart = Name.find_first_not_of("rVKRO", 3);
+    // All built-ins are in the ::cl:: namespace.
+    if (Name.substr(NameSpaceStart, 11) != "2cl7__spirv")
+      return false;
+    size_t DemangledNameLenStart = NameSpaceStart + 11;
+    size_t Start = Name.find_first_not_of("0123456789", DemangledNameLenStart);
+    size_t Len = 0;
+    Name.substr(DemangledNameLenStart, Start - DemangledNameLenStart)
+        .getAsInteger(10, Len);
+    *DemangledName = Name.substr(Start, Len);
+  } else {
+    size_t Start = Name.find_first_not_of("0123456789", 2);
+    size_t Len = 0;
+    Name.substr(2, Start - 2).getAsInteger(10, Len);
+    *DemangledName = Name.substr(Start, Len);
+  }
+  return true;
+}
+
+// Check if a mangled type name is unsigned
+bool isMangledTypeUnsigned(char Mangled) {
+  return Mangled == 'h'    /* uchar */
+         || Mangled == 't' /* ushort */
+         || Mangled == 'j' /* uint */
+         || Mangled == 'm' /* ulong */;
+}
+
+// Check if a mangled type name is signed
+bool isMangledTypeSigned(char Mangled) {
+  return Mangled == 'c'    /* char */
+         || Mangled == 'a' /* signed char */
+         || Mangled == 's' /* short */
+         || Mangled == 'i' /* int */
+         || Mangled == 'l' /* long */;
+}
+
+// Check if a mangled type name is floating point (excludes half)
+bool isMangledTypeFP(char Mangled) {
+  return Mangled == 'f'     /* float */
+         || Mangled == 'd'; /* double */
+}
+
+// Check if a mangled type name is half
+bool isMangledTypeHalf(std::string Mangled) {
+  return Mangled == "Dh"; /* half */
+}
+
+void eraseSubstitutionFromMangledName(std::string &MangledName) {
+  auto Len = MangledName.length();
+  while (Len >= 2 && MangledName.substr(Len - 2, 2) == "S_") {
+    Len -= 2;
+    MangledName.erase(Len, 2);
+  }
+}
+
+ParamType LastFuncParamType(const std::string &MangledName) {
+  auto Copy = MangledName;
+  eraseSubstitutionFromMangledName(Copy);
+  char Mangled = Copy.back();
+  std::string Mangled2 = Copy.substr(Copy.size() - 2);
+
+  if (isMangledTypeFP(Mangled) || isMangledTypeHalf(Mangled2)) {
+    return ParamType::FLOAT;
+  } else if (isMangledTypeUnsigned(Mangled)) {
+    return ParamType::UNSIGNED;
+  } else if (isMangledTypeSigned(Mangled)) {
+    return ParamType::SIGNED;
+  }
+
+  return ParamType::UNKNOWN;
+}
+
+// Check if the last argument is signed
+bool isLastFuncParamSigned(const std::string &MangledName) {
+  return LastFuncParamType(MangledName) == ParamType::SIGNED;
+}
+
+// Check if a mangled function name contains unsigned atomic type
+bool containsUnsignedAtomicType(StringRef Name) {
+  auto Loc = Name.find(kMangledName::AtomicPrefixIncoming);
+  if (Loc == StringRef::npos)
+    return false;
+  return isMangledTypeUnsigned(
+      Name[Loc + strlen(kMangledName::AtomicPrefixIncoming)]);
+}
+
+bool isFunctionPointerType(Type *T) {
+  if (isa<PointerType>(T) && isa<FunctionType>(T->getPointerElementType())) {
+    return true;
+  }
+  return false;
+}
+
+bool hasFunctionPointerArg(Function *F, Function::arg_iterator &AI) {
+  AI = F->arg_begin();
+  for (auto AE = F->arg_end(); AI != AE; ++AI) {
+    DEBUG(dbgs() << "[hasFuncPointerArg] " << *AI << '\n');
+    if (isFunctionPointerType(AI->getType())) {
+      return true;
+    }
+  }
+  return false;
+}
+
+Constant *castToVoidFuncPtr(Function *F) {
+  auto T = getVoidFuncPtrType(F->getParent());
+  return ConstantExpr::getBitCast(F, T);
+}
+
+bool hasArrayArg(Function *F) {
+  for (auto I = F->arg_begin(), E = F->arg_end(); I != E; ++I) {
+    DEBUG(dbgs() << "[hasArrayArg] " << *I << '\n');
+    if (I->getType()->isArrayTy()) {
+      return true;
+    }
+  }
+  return false;
+}
+
+CallInst *mutateCallInst(
+    Module *M, CallInst *CI,
+    std::function<std::string(CallInst *, std::vector<Value *> &)> ArgMutate,
+    BuiltinFuncMangleInfo *Mangle, AttributeSet *Attrs, bool TakeFuncName) {
+  DEBUG(dbgs() << "[mutateCallInst] " << *CI);
+
+  auto Args = getArguments(CI);
+  auto NewName = ArgMutate(CI, Args);
+  std::string InstName;
+  if (!CI->getType()->isVoidTy() && CI->hasName()) {
+    InstName = CI->getName();
+    CI->setName(InstName + ".old");
+  }
+  auto NewCI = addCallInst(M, NewName, CI->getType(), Args, Attrs, CI, Mangle,
+                           InstName, TakeFuncName);
+  DEBUG(dbgs() << " => " << *NewCI << '\n');
+  CI->replaceAllUsesWith(NewCI);
+  CI->dropAllReferences();
+  CI->removeFromParent();
+  return NewCI;
+}
+
+Instruction *mutateCallInst(
+    Module *M, CallInst *CI,
+    std::function<std::string(CallInst *, std::vector<Value *> &, Type *&RetTy)>
+        ArgMutate,
+    std::function<Instruction *(CallInst *)> RetMutate,
+    BuiltinFuncMangleInfo *Mangle, AttributeSet *Attrs, bool TakeFuncName) {
+  DEBUG(dbgs() << "[mutateCallInst] " << *CI);
+
+  auto Args = getArguments(CI);
+  Type *RetTy = CI->getType();
+  auto NewName = ArgMutate(CI, Args, RetTy);
+  std::string InstName;
+  if (CI->hasName()) {
+    InstName = CI->getName();
+    CI->setName(InstName + ".old");
+  }
+  auto NewCI = addCallInst(M, NewName, RetTy, Args, Attrs, CI, Mangle,
+                           InstName + ".tmp", TakeFuncName);
+  auto NewI = RetMutate(NewCI);
+  NewI->takeName(CI);
+  DEBUG(dbgs() << " => " << *NewI << '\n');
+  CI->replaceAllUsesWith(NewI);
+  CI->dropAllReferences();
+  CI->removeFromParent();
+  return NewI;
+}
+
+void mutateFunction(
+    Function *F,
+    std::function<std::string(CallInst *, std::vector<Value *> &)> ArgMutate,
+    BuiltinFuncMangleInfo *Mangle, AttributeSet *Attrs, bool TakeFuncName) {
+  auto M = F->getParent();
+  for (auto I = F->user_begin(), E = F->user_end(); I != E;) {
+    if (auto CI = dyn_cast<CallInst>(*I++))
+      mutateCallInst(M, CI, ArgMutate, Mangle, Attrs, TakeFuncName);
+  }
+  if (F->use_empty())
+    F->eraseFromParent();
+}
+
+CallInst *mutateCallInstSPIRV(
+    Module *M, CallInst *CI,
+    std::function<std::string(CallInst *, std::vector<Value *> &)> ArgMutate,
+    AttributeSet *Attrs) {
+  BuiltinFuncMangleInfo BtnInfo;
+  return mutateCallInst(M, CI, ArgMutate, &BtnInfo, Attrs);
+}
+
+Instruction *mutateCallInstSPIRV(
+    Module *M, CallInst *CI,
+    std::function<std::string(CallInst *, std::vector<Value *> &, Type *&RetTy)>
+        ArgMutate,
+    std::function<Instruction *(CallInst *)> RetMutate, AttributeSet *Attrs) {
+  BuiltinFuncMangleInfo BtnInfo;
+  return mutateCallInst(M, CI, ArgMutate, RetMutate, &BtnInfo, Attrs);
+}
+
+CallInst *addCallInst(Module *M, StringRef FuncName, Type *RetTy,
+                      ArrayRef<Value *> Args, AttributeSet *Attrs,
+                      Instruction *Pos, BuiltinFuncMangleInfo *Mangle,
+                      StringRef InstName, bool TakeFuncName) {
+
+  auto F = getOrCreateFunction(M, RetTy, getTypes(Args), FuncName, Mangle,
+                               Attrs, TakeFuncName);
+  // Cannot assign a name to void typed values
+  auto CI = CallInst::Create(F, Args, RetTy->isVoidTy() ? "" : InstName, Pos);
+  CI->setCallingConv(F->getCallingConv());
+  return CI;
+}
+
+CallInst *addCallInstSPIRV(Module *M, StringRef FuncName, Type *RetTy,
+                           ArrayRef<Value *> Args, AttributeSet *Attrs,
+                           Instruction *Pos, StringRef InstName) {
+  BuiltinFuncMangleInfo BtnInfo;
+  return addCallInst(M, FuncName, RetTy, Args, Attrs, Pos, &BtnInfo, InstName);
+}
+
+bool isValidVectorSize(unsigned I) {
+  return I == 2 || I == 3 || I == 4 || I == 8 || I == 16;
+}
+
+Value *addVector(Instruction *InsPos, ValueVecRange Range) {
+  size_t VecSize = Range.second - Range.first;
+  if (VecSize == 1)
+    return *Range.first;
+  assert(isValidVectorSize(VecSize) && "Invalid vector size");
+  IRBuilder<> Builder(InsPos);
+  auto Vec = Builder.CreateVectorSplat(VecSize, *Range.first);
+  unsigned Index = 1;
+  for (++Range.first; Range.first != Range.second; ++Range.first, ++Index)
+    Vec = Builder.CreateInsertElement(
+        Vec, *Range.first,
+        ConstantInt::get(Type::getInt32Ty(InsPos->getContext()), Index, false));
+  return Vec;
+}
+
+void makeVector(Instruction *InsPos, std::vector<Value *> &Ops,
+                ValueVecRange Range) {
+  auto Vec = addVector(InsPos, Range);
+  Ops.erase(Range.first, Range.second);
+  Ops.push_back(Vec);
+}
+
+void expandVector(Instruction *InsPos, std::vector<Value *> &Ops,
+                  size_t VecPos) {
+  auto Vec = Ops[VecPos];
+  auto VT = Vec->getType();
+  if (!VT->isVectorTy())
+    return;
+  size_t N = VT->getVectorNumElements();
+  IRBuilder<> Builder(InsPos);
+  for (size_t I = 0; I != N; ++I)
+    Ops.insert(Ops.begin() + VecPos + I,
+               Builder.CreateExtractElement(
+                   Vec, ConstantInt::get(Type::getInt32Ty(InsPos->getContext()),
+                                         I, false)));
+  Ops.erase(Ops.begin() + VecPos + N);
+}
+
+Constant *castToInt8Ptr(Constant *V, unsigned Addr = 0) {
+  return ConstantExpr::getBitCast(V, Type::getInt8PtrTy(V->getContext(), Addr));
+}
+
+PointerType *getInt8PtrTy(PointerType *T) {
+  return Type::getInt8PtrTy(T->getContext(), T->getAddressSpace());
+}
+
+Value *castToInt8Ptr(Value *V, Instruction *Pos) {
+  return CastInst::CreatePointerCast(
+      V, getInt8PtrTy(cast<PointerType>(V->getType())), "", Pos);
+}
+
+CallInst *addBlockBind(Module *M, Function *InvokeFunc, Value *BlkCtx,
+                       Value *CtxLen, Value *CtxAlign, Instruction *InsPos,
+                       StringRef InstName) {
+  auto BlkTy =
+      getOrCreateOpaquePtrType(M, SPIR_TYPE_NAME_BLOCK_T, SPIRAS_Private);
+  auto &Ctx = M->getContext();
+  Value *BlkArgs[] = {
+      castToInt8Ptr(InvokeFunc),
+      CtxLen ? CtxLen : UndefValue::get(Type::getInt32Ty(Ctx)),
+      CtxAlign ? CtxAlign : UndefValue::get(Type::getInt32Ty(Ctx)),
+      BlkCtx ? BlkCtx : UndefValue::get(Type::getInt8PtrTy(Ctx))};
+  return addCallInst(M, SPIR_INTRINSIC_BLOCK_BIND, BlkTy, BlkArgs, nullptr,
+                     InsPos, nullptr, InstName);
+}
+
+IntegerType *getSizetType(Module *M) {
+  return IntegerType::getIntNTy(M->getContext(),
+                                M->getDataLayout().getPointerSizeInBits(0));
+}
+
+Type *getVoidFuncType(Module *M) {
+  return FunctionType::get(Type::getVoidTy(M->getContext()), false);
+}
+
+Type *getVoidFuncPtrType(Module *M, unsigned AddrSpace) {
+  return PointerType::get(getVoidFuncType(M), AddrSpace);
+}
+
+ConstantInt *getInt64(Module *M, int64_t value) {
+  return ConstantInt::get(Type::getInt64Ty(M->getContext()), value, true);
+}
+
+Constant *getFloat32(Module *M, float value) {
+  return ConstantFP::get(Type::getFloatTy(M->getContext()), value);
+}
+
+ConstantInt *getInt32(Module *M, int value) {
+  return ConstantInt::get(Type::getInt32Ty(M->getContext()), value, true);
+}
+
+ConstantInt *getUInt32(Module *M, unsigned value) {
+  return ConstantInt::get(Type::getInt32Ty(M->getContext()), value, false);
+}
+
+ConstantInt *getUInt16(Module *M, unsigned short value) {
+  return ConstantInt::get(Type::getInt16Ty(M->getContext()), value, false);
+}
+
+std::vector<Value *> getInt32(Module *M, const std::vector<int> &value) {
+  std::vector<Value *> V;
+  for (auto &I : value)
+    V.push_back(getInt32(M, I));
+  return V;
+}
+
+ConstantInt *getSizet(Module *M, uint64_t value) {
+  return ConstantInt::get(getSizetType(M), value, false);
+}
+
+///////////////////////////////////////////////////////////////////////////////
+//
+// Functions for getting metadata
+//
+///////////////////////////////////////////////////////////////////////////////
+int getMDOperandAsInt(MDNode *N, unsigned I) {
+  return mdconst::dyn_extract<ConstantInt>(N->getOperand(I))->getZExtValue();
+}
+
+std::string getMDOperandAsString(MDNode *N, unsigned I) {
+  if (!N)
+    return "";
+
+  Metadata *Op = N->getOperand(I);
+  if (!Op)
+    return "";
+
+  if (MDString *Str = dyn_cast<MDString>(Op)) {
+    return Str->getString().str();
+  }
+  return "";
+}
+
+Type *getMDOperandAsType(MDNode *N, unsigned I) {
+  return cast<ValueAsMetadata>(N->getOperand(I))->getType();
+}
+
+std::set<std::string> getNamedMDAsStringSet(Module *M,
+                                            const std::string &MDName) {
+  NamedMDNode *NamedMD = M->getNamedMetadata(MDName);
+  std::set<std::string> StrSet;
+  if (!NamedMD)
+    return StrSet;
+
+  assert(NamedMD->getNumOperands() > 0 && "Invalid SPIR");
+
+  for (unsigned I = 0, E = NamedMD->getNumOperands(); I != E; ++I) {
+    MDNode *MD = NamedMD->getOperand(I);
+    if (!MD || MD->getNumOperands() == 0)
+      continue;
+    for (unsigned J = 0, N = MD->getNumOperands(); J != N; ++J)
+      StrSet.insert(getMDOperandAsString(MD, J));
+  }
+
+  return StrSet;
+}
+
+std::tuple<unsigned, unsigned, std::string> getSPIRVSource(Module *M) {
+  std::tuple<unsigned, unsigned, std::string> Tup;
+  if (auto N = SPIRVMDWalker(*M).getNamedMD(kSPIRVMD::Source).nextOp())
+    N.get(std::get<0>(Tup))
+        .get(std::get<1>(Tup))
+        .setQuiet(true)
+        .get(std::get<2>(Tup));
+  return Tup;
+}
+
+ConstantInt *mapUInt(Module *M, ConstantInt *I,
+                     std::function<unsigned(unsigned)> F) {
+  return ConstantInt::get(I->getType(), F(I->getZExtValue()), false);
+}
+
+ConstantInt *mapSInt(Module *M, ConstantInt *I, std::function<int(int)> F) {
+  return ConstantInt::get(I->getType(), F(I->getSExtValue()), true);
+}
+
+bool isDecoratedSPIRVFunc(const Function *F, std::string *UndecoratedName) {
+  if (!F->hasName() || !F->getName().startswith(kSPIRVName::Prefix))
+    return false;
+  if (UndecoratedName)
+    *UndecoratedName = undecorateSPIRVFunction(F->getName());
+  return true;
+}
+
+/// Get TypePrimitiveEnum for special OpenCL type except opencl.block.
+SPIR::TypePrimitiveEnum getOCLTypePrimitiveEnum(StringRef TyName) {
+  return StringSwitch<SPIR::TypePrimitiveEnum>(TyName)
+      .Case("opencl.image1d_t", SPIR::PRIMITIVE_IMAGE_1D_T)
+      .Case("opencl.image1d_array_t", SPIR::PRIMITIVE_IMAGE_1D_ARRAY_T)
+      .Case("opencl.image1d_buffer_t", SPIR::PRIMITIVE_IMAGE_1D_BUFFER_T)
+      .Case("opencl.image2d_t", SPIR::PRIMITIVE_IMAGE_2D_T)
+      .Case("opencl.image2d_array_t", SPIR::PRIMITIVE_IMAGE_2D_ARRAY_T)
+      .Case("opencl.image3d_t", SPIR::PRIMITIVE_IMAGE_3D_T)
+      .Case("opencl.image2d_msaa_t", SPIR::PRIMITIVE_IMAGE_2D_MSAA_T)
+      .Case("opencl.image2d_array_msaa_t",
+            SPIR::PRIMITIVE_IMAGE_2D_ARRAY_MSAA_T)
+      .Case("opencl.image2d_msaa_depth_t",
+            SPIR::PRIMITIVE_IMAGE_2D_MSAA_DEPTH_T)
+      .Case("opencl.image2d_array_msaa_depth_t",
+            SPIR::PRIMITIVE_IMAGE_2D_ARRAY_MSAA_DEPTH_T)
+      .Case("opencl.image2d_depth_t", SPIR::PRIMITIVE_IMAGE_2D_DEPTH_T)
+      .Case("opencl.image2d_array_depth_t",
+            SPIR::PRIMITIVE_IMAGE_2D_ARRAY_DEPTH_T)
+      .Case("opencl.imagecube_t", SPIR::PRIMITIVE_IMAGE_CUBE_T)
+      .Case("opencl.imagecube_array_t", SPIR::PRIMITIVE_IMAGE_CUBE_ARRAY_T)
+      .Case("opencl.imagecube_depth_t", SPIR::PRIMITIVE_IMAGE_CUBE_DEPTH_T)
+      .Case("opencl.imagecube_array_depth_t",
+            SPIR::PRIMITIVE_IMAGE_CUBE_ARRAY_DEPTH_T)
+      .Case("opencl.event_t", SPIR::PRIMITIVE_EVENT_T)
+      .Case("opencl.pipe_t", SPIR::PRIMITIVE_PIPE_T)
+      .Case("opencl.reserve_id_t", SPIR::PRIMITIVE_RESERVE_ID_T)
+      .Case("opencl.queue_t", SPIR::PRIMITIVE_QUEUE_T)
+      .Case("opencl.clk_event_t", SPIR::PRIMITIVE_CLK_EVENT_T)
+      .Case("opencl.sampler_t", SPIR::PRIMITIVE_SAMPLER_T)
+      .Case("struct.ndrange_t", SPIR::PRIMITIVE_NDRANGE_T)
+      .Default(SPIR::PRIMITIVE_NONE);
+}
+/// Translates LLVM type to descriptor for mangler.
+/// \param Signed indicates integer type should be translated as signed.
+/// \param VoidPtr indicates i8* should be translated as void*.
+static SPIR::RefParamType transTypeDesc(Type *Ty,
+                                        const BuiltinArgTypeMangleInfo &Info) {
+  bool Signed = Info.IsSigned;
+  unsigned Attr = Info.Attr;
+  bool VoidPtr = Info.IsVoidPtr;
+  if (Info.IsEnum)
+    return SPIR::RefParamType(new SPIR::PrimitiveType(Info.Enum));
+  if (Info.IsSampler)
+    return SPIR::RefParamType(
+        new SPIR::PrimitiveType(SPIR::PRIMITIVE_SAMPLER_T));
+  if (Info.IsAtomic && !Ty->isPointerTy()) {
+    BuiltinArgTypeMangleInfo DTInfo = Info;
+    DTInfo.IsAtomic = false;
+    return SPIR::RefParamType(new SPIR::AtomicType(transTypeDesc(Ty, DTInfo)));
+  }
+  if (auto *IntTy = dyn_cast<IntegerType>(Ty)) {
+    switch (IntTy->getBitWidth()) {
+    case 1:
+      return SPIR::RefParamType(new SPIR::PrimitiveType(SPIR::PRIMITIVE_BOOL));
+    case 8:
+      return SPIR::RefParamType(new SPIR::PrimitiveType(
+          Signed ? SPIR::PRIMITIVE_CHAR : SPIR::PRIMITIVE_UCHAR));
+    case 16:
+      return SPIR::RefParamType(new SPIR::PrimitiveType(
+          Signed ? SPIR::PRIMITIVE_SHORT : SPIR::PRIMITIVE_USHORT));
+    case 32:
+      return SPIR::RefParamType(new SPIR::PrimitiveType(
+          Signed ? SPIR::PRIMITIVE_INT : SPIR::PRIMITIVE_UINT));
+    case 64:
+      return SPIR::RefParamType(new SPIR::PrimitiveType(
+          Signed ? SPIR::PRIMITIVE_LONG : SPIR::PRIMITIVE_ULONG));
+    default:
+      llvm_unreachable("invliad int size");
+    }
+  }
+  if (Ty->isVoidTy())
+    return SPIR::RefParamType(new SPIR::PrimitiveType(SPIR::PRIMITIVE_VOID));
+  if (Ty->isHalfTy())
+    return SPIR::RefParamType(new SPIR::PrimitiveType(SPIR::PRIMITIVE_HALF));
+  if (Ty->isFloatTy())
+    return SPIR::RefParamType(new SPIR::PrimitiveType(SPIR::PRIMITIVE_FLOAT));
+  if (Ty->isDoubleTy())
+    return SPIR::RefParamType(new SPIR::PrimitiveType(SPIR::PRIMITIVE_DOUBLE));
+  if (Ty->isVectorTy()) {
+    return SPIR::RefParamType(
+        new SPIR::VectorType(transTypeDesc(Ty->getVectorElementType(), Info),
+                             Ty->getVectorNumElements()));
+  }
+  if (Ty->isArrayTy()) {
+    return transTypeDesc(PointerType::get(Ty->getArrayElementType(), 0), Info);
+  }
+  if (Ty->isStructTy()) {
+    auto Name = Ty->getStructName();
+    std::string Tmp;
+
+    if (Name.startswith(kLLVMTypeName::StructPrefix))
+      Name = Name.drop_front(strlen(kLLVMTypeName::StructPrefix));
+    if (Name.startswith(kSPIRVTypeName::PrefixAndDelim)) {
+      Name = Name.substr(sizeof(kSPIRVTypeName::PrefixAndDelim) - 1);
+      Tmp = Name.str();
+      auto pos = Tmp.find(kSPIRVTypeName::Delimiter); // first dot
+      while (pos != std::string::npos) {
+        Tmp[pos] = '_';
+        pos = Tmp.find(kSPIRVTypeName::Delimiter, pos);
+      }
+      Name = Tmp = kSPIRVName::Prefix + Tmp;
+    }
+    // ToDo: Create a better unique name for struct without name
+    if (Name.empty()) {
+      std::ostringstream OS;
+      OS << reinterpret_cast<size_t>(Ty);
+      Name = Tmp = std::string("struct_") + OS.str();
+    }
+    return SPIR::RefParamType(new SPIR::UserDefinedType(Name));
+  }
+
+  if (Ty->isPointerTy()) {
+    auto ET = Ty->getPointerElementType();
+    SPIR::ParamType *EPT = nullptr;
+    if (auto FT = dyn_cast<FunctionType>(ET)) {
+      assert(isVoidFuncTy(FT) && "Not supported");
+      EPT = new SPIR::BlockType;
+    } else if (auto StructTy = dyn_cast<StructType>(ET)) {
+      DEBUG(dbgs() << "ptr to struct: " << *Ty << '\n');
+      auto TyName = StructTy->getStructName();
+      if (TyName.startswith(kSPR2TypeName::ImagePrefix) ||
+          TyName.startswith(kSPR2TypeName::Pipe)) {
+        auto DelimPos = TyName.find_first_of(kSPR2TypeName::Delimiter,
+                                             strlen(kSPR2TypeName::OCLPrefix));
+        if (DelimPos != StringRef::npos)
+          TyName = TyName.substr(0, DelimPos);
+      }
+      DEBUG(dbgs() << "  type name: " << TyName << '\n');
+
+      auto Prim = getOCLTypePrimitiveEnum(TyName);
+      if (StructTy->isOpaque()) {
+        if (TyName == "opencl.block") {
+          auto BlockTy = new SPIR::BlockType;
+          // Handle block with local memory arguments according to OpenCL 2.0
+          // spec.
+          if (Info.IsLocalArgBlock) {
+            SPIR::RefParamType VoidTyRef(
+                new SPIR::PrimitiveType(SPIR::PRIMITIVE_VOID));
+            auto VoidPtrTy = new SPIR::PointerType(VoidTyRef);
+            VoidPtrTy->setAddressSpace(SPIR::ATTR_LOCAL);
+            // "__local void *"
+            BlockTy->setParam(0, SPIR::RefParamType(VoidPtrTy));
+            // "..."
+            BlockTy->setParam(1, SPIR::RefParamType(new SPIR::PrimitiveType(
+                                     SPIR::PRIMITIVE_VAR_ARG)));
+          }
+          EPT = BlockTy;
+        } else if (Prim != SPIR::PRIMITIVE_NONE) {
+          if (Prim == SPIR::PRIMITIVE_PIPE_T) {
+            SPIR::RefParamType OpaqueTyRef(new SPIR::PrimitiveType(Prim));
+            auto OpaquePtrTy = new SPIR::PointerType(OpaqueTyRef);
+            OpaquePtrTy->setAddressSpace(getOCLOpaqueTypeAddrSpace(Prim));
+            EPT = OpaquePtrTy;
+          } else {
+            EPT = new SPIR::PrimitiveType(Prim);
+          }
+        }
+      } else if (Prim == SPIR::PRIMITIVE_NDRANGE_T)
+        // ndrange_t is not opaque type
+        EPT = new SPIR::PrimitiveType(SPIR::PRIMITIVE_NDRANGE_T);
+    }
+    if (EPT)
+      return SPIR::RefParamType(EPT);
+
+    if (VoidPtr && ET->isIntegerTy(8))
+      ET = Type::getVoidTy(ET->getContext());
+    auto PT = new SPIR::PointerType(transTypeDesc(ET, Info));
+    PT->setAddressSpace(static_cast<SPIR::TypeAttributeEnum>(
+        Ty->getPointerAddressSpace() + (unsigned)SPIR::ATTR_ADDR_SPACE_FIRST));
+    for (unsigned I = SPIR::ATTR_QUALIFIER_FIRST, E = SPIR::ATTR_QUALIFIER_LAST;
+         I <= E; ++I)
+      PT->setQualifier(static_cast<SPIR::TypeAttributeEnum>(I), I & Attr);
+    return SPIR::RefParamType(PT);
+  }
+  DEBUG(dbgs() << "[transTypeDesc] " << *Ty << '\n');
+  assert(0 && "not implemented");
+  return SPIR::RefParamType(new SPIR::PrimitiveType(SPIR::PRIMITIVE_INT));
+}
+
+Value *getScalarOrArray(Value *V, unsigned Size, Instruction *Pos) {
+  if (!V->getType()->isPointerTy())
+    return V;
+  assert((isa<ConstantExpr>(V) || isa<GetElementPtrInst>(V)) &&
+         "unexpected value type");
+  auto GEP = cast<User>(V);
+  assert(GEP->getNumOperands() == 3 && "must be a GEP from an array");
+  auto P = GEP->getOperand(0);
+  assert(P->getType()->getPointerElementType()->getArrayNumElements() == Size);
+  auto Index0 = GEP->getOperand(1);
+  assert(dyn_cast<ConstantInt>(Index0)->getZExtValue() == 0);
+  auto Index1 = GEP->getOperand(2);
+  assert(dyn_cast<ConstantInt>(Index1)->getZExtValue() == 0);
+  return new LoadInst(P, "", Pos);
+}
+
+Constant *getScalarOrVectorConstantInt(Type *T, uint64_t V, bool isSigned) {
+  if (auto IT = dyn_cast<IntegerType>(T))
+    return ConstantInt::get(IT, V);
+  if (auto VT = dyn_cast<VectorType>(T)) {
+    std::vector<Constant *> EV(
+        VT->getVectorNumElements(),
+        getScalarOrVectorConstantInt(VT->getVectorElementType(), V, isSigned));
+    return ConstantVector::get(EV);
+  }
+  llvm_unreachable("Invalid type");
+  return nullptr;
+}
+
+Value *getScalarOrArrayConstantInt(Instruction *Pos, Type *T, unsigned Len,
+                                   uint64_t V, bool isSigned) {
+  if (auto IT = dyn_cast<IntegerType>(T)) {
+    assert(Len == 1 && "Invalid length");
+    return ConstantInt::get(IT, V, isSigned);
+  }
+  if (auto PT = dyn_cast<PointerType>(T)) {
+    auto ET = PT->getPointerElementType();
+    auto AT = ArrayType::get(ET, Len);
+    std::vector<Constant *> EV(Len, ConstantInt::get(ET, V, isSigned));
+    auto CA = ConstantArray::get(AT, EV);
+    auto Alloca = new AllocaInst(AT, "", Pos);
+    new StoreInst(CA, Alloca, Pos);
+    auto Zero = ConstantInt::getNullValue(Type::getInt32Ty(T->getContext()));
+    Value *Index[] = {Zero, Zero};
+    auto Ret = GetElementPtrInst::CreateInBounds(Alloca, Index, "", Pos);
+    DEBUG(dbgs() << "[getScalarOrArrayConstantInt] Alloca: " << *Alloca
+                 << ", Return: " << *Ret << '\n');
+    return Ret;
+  }
+  if (auto AT = dyn_cast<ArrayType>(T)) {
+    auto ET = AT->getArrayElementType();
+    assert(AT->getArrayNumElements() == Len);
+    std::vector<Constant *> EV(Len, ConstantInt::get(ET, V, isSigned));
+    auto Ret = ConstantArray::get(AT, EV);
+    DEBUG(dbgs() << "[getScalarOrArrayConstantInt] Array type: " << *AT
+                 << ", Return: " << *Ret << '\n');
+    return Ret;
+  }
+  llvm_unreachable("Invalid type");
+  return nullptr;
+}
+
+void dumpUsers(Value *V, StringRef Prompt) {
+  if (!V)
+    return;
+  DEBUG(dbgs() << Prompt << " Users of " << *V << " :\n");
+  for (auto UI = V->user_begin(), UE = V->user_end(); UI != UE; ++UI)
+    DEBUG(dbgs() << "  " << **UI << '\n');
+}
+
+std::string getSPIRVTypeName(StringRef BaseName, StringRef Postfixes) {
+  assert(!BaseName.empty() && "Invalid SPIR-V type name");
+  auto TN = std::string(kSPIRVTypeName::PrefixAndDelim) + BaseName.str();
+  if (Postfixes.empty())
+    return TN;
+  return TN + kSPIRVTypeName::Delimiter + Postfixes.str();
+}
+
+bool isSPIRVConstantName(StringRef TyName) {
+  if (TyName == getSPIRVTypeName(kSPIRVTypeName::ConstantSampler) ||
+      TyName == getSPIRVTypeName(kSPIRVTypeName::ConstantPipeStorage))
+    return true;
+
+  return false;
+}
+
+Type *getSPIRVTypeByChangeBaseTypeName(Module *M, Type *T, StringRef OldName,
+                                       StringRef NewName) {
+  StringRef Postfixes;
+  if (isSPIRVType(T, OldName, &Postfixes))
+    return getOrCreateOpaquePtrType(M, getSPIRVTypeName(NewName, Postfixes));
+  DEBUG(dbgs() << " Invalid SPIR-V type " << *T << '\n');
+  llvm_unreachable("Invalid SPIRV-V type");
+  return nullptr;
+}
+
+std::string getSPIRVImageTypePostfixes(StringRef SampledType,
+                                       SPIRVTypeImageDescriptor Desc,
+                                       SPIRVAccessQualifierKind Acc) {
+  std::string S;
+  raw_string_ostream OS(S);
+  OS << SampledType << kSPIRVTypeName::PostfixDelim << Desc.Dim
+     << kSPIRVTypeName::PostfixDelim << Desc.Depth
+     << kSPIRVTypeName::PostfixDelim << Desc.Arrayed
+     << kSPIRVTypeName::PostfixDelim << Desc.MS << kSPIRVTypeName::PostfixDelim
+     << Desc.Sampled << kSPIRVTypeName::PostfixDelim << Desc.Format
+     << kSPIRVTypeName::PostfixDelim << Acc;
+  return OS.str();
+}
+
+std::string getSPIRVImageSampledTypeName(SPIRVType *Ty) {
+  switch (Ty->getOpCode()) {
+  case OpTypeVoid:
+    return kSPIRVImageSampledTypeName::Void;
+  case OpTypeInt:
+    if (Ty->getIntegerBitWidth() == 32) {
+      if (static_cast<SPIRVTypeInt *>(Ty)->isSigned()) {
+        return kSPIRVImageSampledTypeName::Int;
+      } else {
+        return kSPIRVImageSampledTypeName::UInt;
+      }
+    }
+    break;
+  case OpTypeFloat:
+    switch (Ty->getFloatBitWidth()) {
+    case 16:
+      return kSPIRVImageSampledTypeName::Half;
+    case 32:
+      return kSPIRVImageSampledTypeName::Float;
+    default:
+      break;
+    }
+    break;
+  default:
+    break;
+  }
+  llvm_unreachable("Invalid sampled type for image");
+}
+
+// ToDo: Find a way to represent uint sampled type in LLVM, maybe an
+//      opaque type.
+Type *getLLVMTypeForSPIRVImageSampledTypePostfix(StringRef Postfix,
+                                                 LLVMContext &Ctx) {
+  if (Postfix == kSPIRVImageSampledTypeName::Void)
+    return Type::getVoidTy(Ctx);
+  if (Postfix == kSPIRVImageSampledTypeName::Float)
+    return Type::getFloatTy(Ctx);
+  if (Postfix == kSPIRVImageSampledTypeName::Half)
+    return Type::getHalfTy(Ctx);
+  if (Postfix == kSPIRVImageSampledTypeName::Int ||
+      Postfix == kSPIRVImageSampledTypeName::UInt)
+    return Type::getInt32Ty(Ctx);
+  llvm_unreachable("Invalid sampled type postfix");
+}
+
+std::string mapOCLTypeNameToSPIRV(StringRef Name, StringRef Acc) {
+  std::string BaseTy;
+  std::string Postfixes;
+  raw_string_ostream OS(Postfixes);
+  if (!Acc.empty())
+    OS << kSPIRVTypeName::PostfixDelim;
+  if (Name.startswith(kSPR2TypeName::Pipe)) {
+    BaseTy = kSPIRVTypeName::Pipe;
+    OS << SPIRSPIRVAccessQualifierMap::map(Acc);
+  } else if (Name.startswith(kSPR2TypeName::ImagePrefix)) {
+    SmallVector<StringRef, 4> SubStrs;
+    const char Delims[] = {kSPR2TypeName::Delimiter, 0};
+    Name.split(SubStrs, Delims);
+    std::string ImageTyName = SubStrs[1].str();
+    if (hasAccessQualifiedName(Name))
+      ImageTyName.erase(ImageTyName.size() - 5, 3);
+    auto Desc = map<SPIRVTypeImageDescriptor>(ImageTyName);
+    DEBUG(dbgs() << "[trans image type] " << SubStrs[1] << " => "
+                 << "(" << (unsigned)Desc.Dim << ", " << Desc.Depth << ", "
+                 << Desc.Arrayed << ", " << Desc.MS << ", " << Desc.Sampled
+                 << ", " << Desc.Format << ")\n");
+
+    BaseTy = kSPIRVTypeName::Image;
+    OS << getSPIRVImageTypePostfixes(kSPIRVImageSampledTypeName::Void, Desc,
+                                     SPIRSPIRVAccessQualifierMap::map(Acc));
+  } else {
+    DEBUG(dbgs() << "Mapping of " << Name << " is not implemented\n");
+    llvm_unreachable("Not implemented");
+  }
+  return getSPIRVTypeName(BaseTy, OS.str());
+}
+
+bool eraseIfNoUse(Function *F) {
+  bool changed = false;
+  if (!F)
+    return changed;
+  if (!GlobalValue::isInternalLinkage(F->getLinkage()) && !F->isDeclaration())
+    return changed;
+
+  dumpUsers(F, "[eraseIfNoUse] ");
+  for (auto UI = F->user_begin(), UE = F->user_end(); UI != UE;) {
+    auto U = *UI++;
+    if (auto CE = dyn_cast<ConstantExpr>(U)) {
+      if (CE->use_empty()) {
+        CE->dropAllReferences();
+        changed = true;
+      }
+    }
+  }
+  if (F->use_empty()) {
+    DEBUG(dbgs() << "Erase "; F->printAsOperand(dbgs()); dbgs() << '\n');
+    F->eraseFromParent();
+    changed = true;
+  }
+  return changed;
+}
+
+void eraseIfNoUse(Value *V) {
+  if (!V->use_empty())
+    return;
+  if (Constant *C = dyn_cast<Constant>(V)) {
+    C->destroyConstant();
+    return;
+  }
+  if (Instruction *I = dyn_cast<Instruction>(V)) {
+    if (!I->mayHaveSideEffects())
+      I->eraseFromParent();
+  }
+  eraseIfNoUse(dyn_cast<Function>(V));
+}
+
+bool eraseUselessFunctions(Module *M) {
+  bool changed = false;
+  for (auto I = M->begin(), E = M->end(); I != E;) {
+    // iterator will be invalidated if the function is erased
+    // -> need to increment before calling eraseIfNoUse
+    Function *func_ptr = &*I;
+    ++I;
+    changed |= eraseIfNoUse(func_ptr);
+  }
+  return changed;
+}
+
+std::string mangleBuiltin(const std::string &UniqName,
+                          ArrayRef<Type *> ArgTypes,
+                          BuiltinFuncMangleInfo *BtnInfo) {
+  if (!BtnInfo)
+    return UniqName;
+  BtnInfo->init(UniqName);
+  std::string MangledName;
+  DEBUG(dbgs() << "[mangle] " << UniqName << " => ");
+  SPIR::NameMangler Mangler(SPIR::SPIR20);
+  SPIR::FunctionDescriptor FD;
+  FD.name = BtnInfo->getUnmangledName();
+  bool BIVarArgNegative = BtnInfo->getVarArg() < 0;
+
+  if (ArgTypes.empty()) {
+    // Function signature cannot be ()(void, ...) so if there is an ellipsis
+    // it must be ()(...)
+    if (BIVarArgNegative) {
+      FD.parameters.emplace_back(
+          SPIR::RefParamType(new SPIR::PrimitiveType(SPIR::PRIMITIVE_VOID)));
+    }
+  } else {
+    for (unsigned I = 0, E = BIVarArgNegative ? ArgTypes.size()
+                                              : (unsigned)BtnInfo->getVarArg();
+         I != E; ++I) {
+      auto T = ArgTypes[I];
+      FD.parameters.emplace_back(
+          transTypeDesc(T, BtnInfo->getTypeMangleInfo(I)));
+    }
+  }
+  // Ellipsis must be the last argument of any function
+  if (!BIVarArgNegative) {
+    assert((unsigned)BtnInfo->getVarArg() <= ArgTypes.size() &&
+           "invalid index of an ellipsis");
+    FD.parameters.emplace_back(
+        SPIR::RefParamType(new SPIR::PrimitiveType(SPIR::PRIMITIVE_VAR_ARG)));
+  }
+  Mangler.mangle(FD, MangledName);
+  DEBUG(dbgs() << MangledName << '\n');
+  return MangledName;
+}
+
+/// Check if access qualifier is encoded in the type name.
+bool hasAccessQualifiedName(StringRef TyName) {
+  if (TyName.endswith("_ro_t") || TyName.endswith("_wo_t") ||
+      TyName.endswith("_rw_t"))
+    return true;
+  return false;
+}
+
+/// Get access qualifier from the type name.
+StringRef getAccessQualifier(StringRef TyName) {
+  assert(hasAccessQualifiedName(TyName) &&
+         "Type is not qualified with access.");
+  auto Acc = TyName.substr(TyName.size() - 4, 2);
+  return llvm::StringSwitch<StringRef>(Acc)
+      .Case("ro", "read_only")
+      .Case("wo", "write_only")
+      .Case("rw", "read_write")
+      .Default("");
+}
+
+/// Translates OpenCL image type names to SPIR-V.
+Type *getSPIRVImageTypeFromOCL(Module *M, Type *ImageTy) {
+  assert(isOCLImageType(ImageTy) && "Unsupported type");
+  auto ImageTypeName = ImageTy->getPointerElementType()->getStructName();
+  std::string Acc = kAccessQualName::ReadOnly;
+  if (hasAccessQualifiedName(ImageTypeName))
+    Acc = getAccessQualifier(ImageTypeName);
+  return getOrCreateOpaquePtrType(M, mapOCLTypeNameToSPIRV(ImageTypeName, Acc));
+}
+}
diff --git a/lib/SPIRV/SPIRVWriter.cpp b/lib/SPIRV/SPIRVWriter.cpp
new file mode 100644
index 0000000..791b84c
--- /dev/null
+++ b/lib/SPIRV/SPIRVWriter.cpp
@@ -0,0 +1,2708 @@
+//===- SPIRVWriter.cpp - Converts LLVM to SPIR-V ----------------*- C++ -*-===//
+//
+//                     The LLVM/SPIR-V Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+// Copyright (c) 2016 Florian Ziesche Vulkan/SPIR-V support
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+/// \file
+///
+/// This file implements conversion of LLVM intermediate language to SPIR-V
+/// binary.
+///
+//===----------------------------------------------------------------------===//
+
+#include "SPIRVModule.h"
+#include "SPIRVEnum.h"
+#include "SPIRVEntry.h"
+#include "SPIRVType.h"
+#include "SPIRVValue.h"
+#include "SPIRVFunction.h"
+#include "SPIRVBasicBlock.h"
+#include "SPIRVInstruction.h"
+#include "SPIRVExtInst.h"
+#include "SPIRVUtil.h"
+#include "SPIRVInternal.h"
+#include "SPIRVMDWalker.h"
+#include "OCLTypeToSPIRV.h"
+#include "OCLUtil.h"
+
+#include "llvm/ADT/DenseMap.h"
+#include "llvm/ADT/SetVector.h"
+#include "llvm/ADT/StringSwitch.h"
+#include "llvm/ADT/Triple.h"
+#include "llvm/Bitcode/ReaderWriter.h"
+#include "llvm/IR/Constants.h"
+#include "llvm/IR/DerivedTypes.h"
+#include "llvm/IR/DebugInfo.h"
+#include "llvm/IR/Function.h"
+#include "llvm/IR/InstrTypes.h"
+#include "llvm/IR/Instructions.h"
+#include "llvm/IR/Module.h"
+#include "llvm/IR/Operator.h"
+#include "llvm/IR/Verifier.h"
+#include "llvm/Pass.h"
+#include "llvm/PassSupport.h"
+#include "llvm/IR/LegacyPassManager.h"
+#include "llvm/Support/Casting.h"
+#include "llvm/Support/CommandLine.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/raw_ostream.h"
+#include "llvm/Support/ToolOutputFile.h"
+#include "llvm/Transforms/IPO.h"
+
+#include <iostream>
+#include <list>
+#include <memory>
+#include <set>
+#include <sstream>
+#include <vector>
+#include <functional>
+#include <cstdlib>
+
+#define DEBUG_TYPE "spirv"
+
+using namespace llvm;
+using namespace SPIRV;
+using namespace OCLUtil;
+
+namespace llvm {
+FunctionPass *createPromoteMemoryToRegisterPass();
+}
+
+namespace SPIRV {
+
+cl::opt<bool> SPIRVMemToReg("spirv-mem2reg", cl::init(true),
+                            cl::desc("LLVM/SPIR-V translation enable mem2reg"));
+
+static void foreachKernelArgMD(
+    MDNode *MD, SPIRVFunction *BF,
+    std::function<void(const std::string &Str, SPIRVFunctionParameter *BA)>
+        Func) {
+  for (unsigned I = 1, E = MD->getNumOperands(); I != E; ++I) {
+    SPIRVFunctionParameter *BA = BF->getArgument(I - 1);
+    Func(getMDOperandAsString(MD, I), BA);
+  }
+}
+
+/// Information for translating OCL builtin.
+struct OCLBuiltinSPIRVTransInfo {
+  std::string UniqName;
+  /// Postprocessor of operands
+  std::function<void(std::vector<SPIRVWord> &)> PostProc;
+  OCLBuiltinSPIRVTransInfo() {
+    PostProc = [](std::vector<SPIRVWord> &) {};
+  }
+};
+
+class LLVMToSPIRVDbgTran {
+public:
+  LLVMToSPIRVDbgTran(Module *TM = nullptr, SPIRVModule *TBM = nullptr)
+      : BM(TBM), M(TM) {}
+
+  void setModule(Module *Mod) { M = Mod; }
+  void setSPIRVModule(SPIRVModule *SMod) { BM = SMod; }
+
+  void transDbgInfo(Value *V, SPIRVValue *BV) {
+    if (auto I = dyn_cast<Instruction>(V)) {
+      auto DL = I->getDebugLoc();
+      if (DL) {
+        DILocation *DIL = DL.get();
+        auto File = BM->getString(DIL->getFilename().str());
+        // TODO: SPIR-V rev.31 cannot add debug info for instructions without
+        // ids.
+        // This limitation needs to be addressed.
+        if (!BV->hasId())
+          return;
+        BM->addLine(BV, File, DIL->getLine(), DIL->getColumn());
+      }
+    }
+#if 0 // TODO: subprogram <-> cu changes
+	else if (auto F = dyn_cast<Function>(V)) {
+      if (auto DIS = getDISubprogram(F)) {
+        auto File = BM->getString(DIS->getFilename().str());
+        BM->addLine(BV, File, DIS->getLine(), 0);
+      }
+	}
+#endif
+  }
+
+private:
+  SPIRVModule *BM;
+  Module *M;
+};
+
+class LLVMToSPIRV : public ModulePass {
+public:
+  LLVMToSPIRV(SPIRVModule *SMod = nullptr)
+      : ModulePass(ID), M(nullptr), Ctx(nullptr), BM(SMod),
+        ExtSetId(SPIRVID_INVALID), SrcLang(0), SrcLangVer(0),
+        DbgTran(nullptr, SMod) {}
+
+  bool runOnModule(Module &Mod) override {
+    M = &Mod;
+    Ctx = &M->getContext();
+    DbgTran.setModule(M);
+    assert(BM && "SPIR-V module not initialized");
+    translate();
+    return true;
+  }
+
+  void getAnalysisUsage(AnalysisUsage &AU) const override {
+    AU.addRequired<OCLTypeToSPIRV>();
+  }
+
+  static char ID;
+
+  SPIRVType *transType(Type *T);
+  SPIRVType *transSPIRVOpaqueType(Type *T);
+
+  SPIRVValue *getTranslatedValue(Value *);
+
+  // Translation functions
+  bool transAddressingMode();
+  bool transAlign(Value *V, SPIRVValue *BV);
+  std::vector<SPIRVValue *> transArguments(CallInst *, SPIRVBasicBlock *);
+  std::vector<SPIRVWord> transArguments(CallInst *, SPIRVBasicBlock *,
+                                        SPIRVEntry *);
+  bool transSourceLanguage();
+  bool transExtension();
+  bool transBuiltinSet();
+  SPIRVValue *transCallInst(CallInst *Call, SPIRVBasicBlock *BB);
+  bool transDecoration(Value *V, SPIRVValue *BV);
+  SPIRVWord transFunctionControlMask(CallInst *);
+  SPIRVWord transFunctionControlMask(Function *);
+  SPIRVFunction *transFunctionDecl(Function *F);
+  bool transGlobalVariables();
+
+  Op transBoolOpCode(SPIRVValue *Opn, Op OC);
+  // Translate LLVM module to SPIR-V module.
+  // Returns true if succeeds.
+  bool translate();
+  bool transExecutionMode();
+  SPIRVValue *transConstant(Value *V);
+  SPIRVValue *transValue(Value *V, SPIRVBasicBlock *BB,
+                         bool CreateForward = true);
+  SPIRVValue *transValueWithoutDecoration(Value *V, SPIRVBasicBlock *BB,
+                                          bool CreateForward = true);
+
+  typedef DenseMap<Type *, SPIRVType *> LLVMToSPIRVTypeMap;
+  typedef DenseMap<Value *, SPIRVValue *> LLVMToSPIRVValueMap;
+
+private:
+  Module *M;
+  LLVMContext *Ctx;
+  SPIRVModule *BM;
+  LLVMToSPIRVTypeMap TypeMap;
+  LLVMToSPIRVValueMap ValueMap;
+  // TODO: support multiple builtin sets. Currently assume one builtin set.
+  SPIRVId ExtSetId;
+  SPIRVWord SrcLang;
+  SPIRVWord SrcLangVer;
+  LLVMToSPIRVDbgTran DbgTran;
+
+  SPIRVType *mapType(Type *T, SPIRVType *BT) {
+    TypeMap[T] = BT;
+    SPIRVDBG(dbgs() << "[mapType] " << *T << " => "; spvdbgs() << *BT << '\n');
+    return BT;
+  }
+
+  SPIRVValue *mapValue(Value *V, SPIRVValue *BV) {
+    auto Loc = ValueMap.find(V);
+    if (Loc != ValueMap.end()) {
+      if (Loc->second == BV)
+        return BV;
+      assert(Loc->second->isForward() &&
+             "LLVM Value is mapped to different SPIRV Values");
+      auto Forward = static_cast<SPIRVForward *>(Loc->second);
+      BV->setId(Forward->getId());
+      BM->replaceForward(Forward, BV);
+    }
+    ValueMap[V] = BV;
+    SPIRVDBG(dbgs() << "[mapValue] " << *V << " => "; spvdbgs() << *BV << "\n");
+    return BV;
+  }
+
+  SPIRVType *getSPIRVType(Type *T) { return TypeMap[T]; }
+
+  SPIRVValue *getSPIRVValue(Value *V) { return ValueMap[V]; }
+
+  SPIRVErrorLog &getErrorLog() { return BM->getErrorLog(); }
+
+  llvm::IntegerType *getSizetType();
+  std::vector<SPIRVValue *> transValue(const std::vector<Value *> &Values,
+                                       SPIRVBasicBlock *BB);
+  std::vector<SPIRVWord> transValue(const std::vector<Value *> &Values,
+                                    SPIRVBasicBlock *BB, SPIRVEntry *Entry);
+
+  SPIRVInstruction *transBinaryInst(BinaryOperator *B, SPIRVBasicBlock *BB);
+  SPIRVInstruction *transCmpInst(CmpInst *Cmp, SPIRVBasicBlock *BB);
+
+  void dumpUsers(Value *V);
+
+  template <class ExtInstKind>
+  bool oclGetExtInstIndex(const std::string &MangledName,
+                          const std::string &DemangledName,
+                          SPIRVWord *EntryPoint);
+  void
+  oclGetMutatedArgumentTypesByBuiltin(llvm::FunctionType *FT,
+                                      std::map<unsigned, Type *> &ChangedType,
+                                      Function *F);
+
+  bool isBuiltinTransToInst(Function *F);
+  bool isBuiltinTransToExtInst(Function *F,
+                               SPIRVExtInstSetKind *BuiltinSet = nullptr,
+                               SPIRVWord *EntryPoint = nullptr,
+                               SmallVectorImpl<std::string> *Dec = nullptr);
+  bool oclIsEntryPoint(Function *F);
+  spv::ExecutionModel oclGetEntryPointType(Function *F, unsigned int SrcLang);
+
+  bool transOCLKernelMetadata();
+
+  SPIRVInstruction *transBuiltinToInst(const std::string &DemangledName,
+                                       const std::string &MangledName,
+                                       CallInst *CI, SPIRVBasicBlock *BB);
+  SPIRVInstruction *transBuiltinToInstWithoutDecoration(Op OC, CallInst *CI,
+                                                        SPIRVBasicBlock *BB);
+  void mutateFuncArgType(const std::map<unsigned, Type *> &ChangedType,
+                         Function *F);
+
+  SPIRVValue *transSpcvCast(CallInst *CI, SPIRVBasicBlock *BB);
+  SPIRVValue *oclTransSpvcCastSampler(CallInst *CI, SPIRVBasicBlock *BB);
+
+  SPIRV::SPIRVInstruction *transUnaryInst(UnaryInstruction *U,
+                                          SPIRVBasicBlock *BB);
+
+  void transFunction(Function *I);
+  SPIRV::SPIRVLinkageTypeKind transLinkageType(const GlobalValue *GV);
+
+  void decorateComposite(llvm::Type *llvm_type, SPIRVType *spirv_type);
+
+  bool ignore_next_unreachable{false};
+
+  //
+  struct spirv_global_io_type {
+    bool is_constant{false};
+    bool is_uniform{false};
+    bool is_input{false};
+    bool is_builtin{false};
+    bool is_read_only{false};
+    bool is_write_only{false};
+  };
+
+  GlobalVariable *
+  emitShaderGlobal(const Function &F, SPIRVFunction *spirv_func,
+                   const std::string &var_name, llvm::Type *llvm_type,
+                   uint32_t address_space,
+                   const spirv_global_io_type global_type,
+                   SPIRVVariable **created_spirv_var = nullptr,
+                   spv::BuiltIn builtin = spv::BuiltIn::BuiltInPosition);
+
+  SPIRVVariable *
+  emitShaderSPIRVGlobal(SPIRVFunction *spirv_func, const GlobalVariable &GV,
+                        const std::string &var_name, uint32_t address_space,
+                        const spirv_global_io_type global_type,
+                        spv::BuiltIn builtin = spv::BuiltIn::BuiltInPosition);
+};
+
+SPIRVValue *LLVMToSPIRV::getTranslatedValue(Value *V) {
+  LLVMToSPIRVValueMap::iterator Loc = ValueMap.find(V);
+  if (Loc != ValueMap.end())
+    return Loc->second;
+  return nullptr;
+}
+
+bool LLVMToSPIRV::oclIsEntryPoint(Function *F) {
+  if (F->getCallingConv() == CallingConv::FLOOR_KERNEL ||
+      F->getCallingConv() == CallingConv::FLOOR_VERTEX ||
+      F->getCallingConv() == CallingConv::FLOOR_FRAGMENT)
+    return true;
+  return false;
+}
+
+spv::ExecutionModel LLVMToSPIRV::oclGetEntryPointType(Function *F,
+                                                      unsigned int SrcLang) {
+  switch (F->getCallingConv()) {
+  case CallingConv::FLOOR_KERNEL:
+    return (SrcLang == spv::SourceLanguageGLSL
+                ? spv::ExecutionModel::ExecutionModelGLCompute
+                : spv::ExecutionModel::ExecutionModelKernel);
+  case CallingConv::FLOOR_VERTEX:
+    return spv::ExecutionModel::ExecutionModelVertex;
+  case CallingConv::FLOOR_FRAGMENT:
+    return spv::ExecutionModel::ExecutionModelFragment;
+  default:
+    return spv::ExecutionModel::ExecutionModelInvalid;
+  }
+}
+
+bool LLVMToSPIRV::isBuiltinTransToInst(Function *F) {
+  std::string DemangledName;
+  if (!oclIsBuiltin(F->getName(), &DemangledName) &&
+      !isDecoratedSPIRVFunc(F, &DemangledName))
+    return false;
+  SPIRVDBG(spvdbgs() << "CallInst: demangled name: " << DemangledName << '\n');
+  return getSPIRVFuncOC(DemangledName) != OpNop;
+}
+
+bool LLVMToSPIRV::isBuiltinTransToExtInst(Function *F,
+                                          SPIRVExtInstSetKind *ExtSet,
+                                          SPIRVWord *ExtOp,
+                                          SmallVectorImpl<std::string> *Dec) {
+  std::string OrigName = F->getName();
+  std::string DemangledName;
+  if (!oclIsBuiltin(OrigName, &DemangledName))
+    return false;
+  DEBUG(dbgs() << "[oclIsBuiltinTransToExtInst] CallInst: demangled name: "
+               << DemangledName << '\n');
+  StringRef S = DemangledName;
+  if (!S.startswith(kSPIRVName::Prefix))
+    return false;
+  S = S.drop_front(strlen(kSPIRVName::Prefix));
+  auto Loc = S.find(kSPIRVPostfix::Divider);
+  auto ExtSetName = S.substr(0, Loc);
+  SPIRVExtInstSetKind Set = SPIRVEIS_Count;
+  if (!SPIRVExtSetShortNameMap::rfind(ExtSetName, &Set))
+    return false;
+  assert(Set == BM->getBuiltinSet(ExtSetId) &&
+         "Invalid extended instruction set");
+  assert((Set == SPIRVEIS_OpenCL || Set == SPIRVEIS_GLSL) &&
+         "Unsupported extended instruction set");
+
+  auto ExtOpName = S.substr(Loc + 1);
+  auto Splited = ExtOpName.split(kSPIRVPostfix::ExtDivider);
+  if (Set == SPIRVEIS_OpenCL) {
+    OCLExtOpKind EOC;
+    if (!OCLExtOpMap::rfind(Splited.first, &EOC))
+      return false;
+
+    if (ExtSet)
+      *ExtSet = Set;
+    if (ExtOp)
+      *ExtOp = EOC;
+  } else if (Set == SPIRVEIS_GLSL) {
+    GLSLExtOpKind EGLSL;
+    if (!GLSLExtOpMap::rfind(Splited.first, &EGLSL))
+      return false;
+
+    if (ExtSet)
+      *ExtSet = Set;
+    if (ExtOp)
+      *ExtOp = EGLSL;
+  }
+
+  if (Dec) {
+    SmallVector<StringRef, 2> P;
+    Splited.second.split(P, kSPIRVPostfix::Divider);
+    for (auto &I : P)
+      Dec->push_back(I.str());
+  }
+  return true;
+}
+
+/// Decode SPIR-V type name in the format spirv.{TypeName}._{Postfixes}
+/// where Postfixes are strings separated by underscores.
+/// \return TypeName.
+/// \param Ops contains the integers decoded from postfixes.
+static std::string decodeSPIRVTypeName(StringRef Name,
+                                       SmallVectorImpl<std::string> &Strs) {
+  SmallVector<StringRef, 4> SubStrs;
+  const char Delim[] = {kSPIRVTypeName::Delimiter, 0};
+  Name.split(SubStrs, Delim, -1, true);
+  assert(SubStrs.size() >= 2 && "Invalid SPIRV type name");
+  assert(SubStrs[0] == kSPIRVTypeName::Prefix && "Invalid prefix");
+  assert((SubStrs.size() == 2 || !SubStrs[2].empty()) && "Invalid postfix");
+
+  if (SubStrs.size() > 2) {
+    const char PostDelim[] = {kSPIRVTypeName::PostfixDelim, 0};
+    SmallVector<StringRef, 4> Postfixes;
+    SubStrs[2].split(Postfixes, PostDelim, -1, true);
+    assert(Postfixes.size() > 1 && Postfixes[0].empty() && "Invalid postfix");
+    for (unsigned I = 1, E = Postfixes.size(); I != E; ++I)
+      Strs.push_back(std::string(Postfixes[I]).c_str());
+  }
+  return SubStrs[1].str();
+}
+
+static bool recursiveType(const StructType *ST, const Type *Ty) {
+  SmallPtrSet<const StructType *, 4> Seen;
+
+  std::function<bool(const Type *Ty)> Run = [&](const Type *Ty) {
+    if (!isa<CompositeType>(Ty))
+      return false;
+
+    if (auto *StructTy = dyn_cast<StructType>(Ty)) {
+      if (StructTy == ST)
+        return true;
+
+      if (Seen.count(StructTy))
+        return false;
+
+      Seen.insert(StructTy);
+
+      return find_if(StructTy->subtype_begin(), StructTy->subtype_end(), Run) !=
+             StructTy->subtype_end();
+    }
+
+    if (auto *PtrTy = dyn_cast<PointerType>(Ty))
+      return Run(PtrTy->getPointerElementType());
+
+    if (auto *ArrayTy = dyn_cast<ArrayType>(Ty))
+      return Run(ArrayTy->getArrayElementType());
+
+    return false;
+  };
+
+  return Run(Ty);
+}
+
+SPIRVType *LLVMToSPIRV::transType(Type *T) {
+  LLVMToSPIRVTypeMap::iterator Loc = TypeMap.find(T);
+  if (Loc != TypeMap.end())
+    return Loc->second;
+
+  SPIRVDBG(dbgs() << "[transType] " << *T << '\n');
+  if (T->isVoidTy())
+    return mapType(T, BM->addVoidType());
+
+  if (T->isIntegerTy(1))
+    return mapType(T, BM->addBoolType());
+
+  if (T->isIntegerTy())
+    return mapType(T, BM->addIntegerType(T->getIntegerBitWidth(),
+                                         SrcLang == spv::SourceLanguageGLSL));
+
+  if (T->isFloatingPointTy())
+    return mapType(T, BM->addFloatType(T->getPrimitiveSizeInBits()));
+
+  // A pointer to image or pipe type in LLVM is translated to a SPIRV
+  // sampler or pipe type.
+  if (T->isPointerTy()) {
+    auto ET = T->getPointerElementType();
+    assert(!ET->isFunctionTy() && "Function pointer type is not allowed");
+    auto ST = dyn_cast<StructType>(ET);
+    auto AddrSpc = T->getPointerAddressSpace();
+    if (ST && !ST->isSized()) {
+      Op OpCode;
+      StringRef STName = ST->getName();
+      // Workaround for non-conformant SPIR binary
+      if (STName == "struct._event_t") {
+        STName = kSPR2TypeName::Event;
+        ST->setName(STName);
+      }
+      assert(!STName.startswith(kSPR2TypeName::Pipe) &&
+             "OpenCL type names should be translated to SPIR-V type names");
+      // TODO: For SPIR1.2/2.0 there may still be load/store or bitcast
+      // instructions using opencl.* type names. We need to handle these
+      // type names until they are all mapped or FE generates SPIR-V type
+      // names.
+      if (STName.find(kSPR2TypeName::Pipe) == 0) {
+        assert(AddrSpc == SPIRAS_Global);
+        SmallVector<StringRef, 4> SubStrs;
+        const char Delims[] = {kSPR2TypeName::Delimiter, 0};
+        STName.split(SubStrs, Delims);
+        std::string Acc = kAccessQualName::ReadOnly;
+        if (SubStrs.size() > 2) {
+          Acc = SubStrs[2];
+        }
+        auto PipeT = BM->addPipeType();
+        PipeT->setPipeAcessQualifier(SPIRSPIRVAccessQualifierMap::map(Acc));
+        return mapType(T, PipeT);
+      } else if (STName.find(kSPR2TypeName::ImagePrefix) == 0) {
+        assert(AddrSpc == SPIRAS_Global);
+        auto SPIRVImageTy = getSPIRVImageTypeFromOCL(M, T);
+        return mapType(T, transSPIRVOpaqueType(SPIRVImageTy));
+      } else if (STName.startswith(kSPIRVTypeName::PrefixAndDelim))
+        return transSPIRVOpaqueType(T);
+      else if (OCLOpaqueTypeOpCodeMap::find(STName, &OpCode)) {
+        switch (OpCode) {
+        default:
+          return mapType(T, BM->addOpaqueGenericType(OpCode));
+        case OpTypePipe:
+          return mapType(T, BM->addPipeType());
+        case OpTypeDeviceEvent:
+          return mapType(T, BM->addDeviceEventType());
+        case OpTypeQueue:
+          return mapType(T, BM->addQueueType());
+        }
+      } else if (isPointerToOpaqueStructType(T)) {
+        return mapType(
+            T, BM->addPointerType(SPIRSPIRVAddrSpaceMap::map(
+                                      static_cast<SPIRAddressSpace>(AddrSpc)),
+                                  transType(ET)));
+      }
+    } else {
+      return mapType(
+          T, BM->addPointerType(SPIRSPIRVAddrSpaceMap::map(
+                                    static_cast<SPIRAddressSpace>(AddrSpc)),
+                                transType(ET)));
+    }
+  }
+
+  if (T->isVectorTy())
+    return mapType(T, BM->addVectorType(transType(T->getVectorElementType()),
+                                        T->getVectorNumElements()));
+
+  if (T->isArrayTy())
+    return mapType(T, BM->addArrayType(
+                          transType(T->getArrayElementType()),
+                          static_cast<SPIRVConstant *>(transValue(
+                              ConstantInt::get(getSizetType(),
+                                               T->getArrayNumElements(), false),
+                              nullptr))));
+
+  if (T->isStructTy() && !T->isSized()) {
+    auto ST = dyn_cast<StructType>(T);
+    assert(!ST->getName().startswith(kSPR2TypeName::Pipe));
+    assert(!ST->getName().startswith(kSPR2TypeName::ImagePrefix));
+    return mapType(T, BM->addOpaqueType(T->getStructName()));
+  }
+
+  if (auto ST = dyn_cast<StructType>(T)) {
+    assert(ST->isSized());
+
+    std::string Name;
+    if (ST->hasName())
+      Name = ST->getName();
+
+    if (Name == getSPIRVTypeName(kSPIRVTypeName::ConstantSampler))
+      return transType(getSamplerType(M));
+    if (Name == getSPIRVTypeName(kSPIRVTypeName::ConstantPipeStorage))
+      return transType(getPipeStorageType(M));
+
+    auto *Struct = BM->openStructType(T->getStructNumElements(), Name);
+    mapType(T, Struct);
+
+    SmallVector<unsigned, 4> ForwardRefs;
+
+    for (unsigned I = 0, E = T->getStructNumElements(); I != E; ++I) {
+      auto *ElemTy = ST->getElementType(I);
+      if (isa<CompositeType>(ElemTy) && recursiveType(ST, ElemTy))
+        ForwardRefs.push_back(I);
+      else
+        Struct->setMemberType(I, transType(ST->getElementType(I)));
+    }
+
+    BM->closeStructType(Struct, ST->isPacked());
+
+    for (auto I : ForwardRefs)
+      Struct->setMemberType(I, transType(ST->getElementType(I)));
+
+    return Struct;
+  }
+
+  if (FunctionType *FT = dyn_cast<FunctionType>(T)) {
+    SPIRVType *RT = transType(FT->getReturnType());
+    std::vector<SPIRVType *> PT;
+    for (FunctionType::param_iterator I = FT->param_begin(),
+                                      E = FT->param_end();
+         I != E; ++I)
+      PT.push_back(transType(*I));
+    return mapType(T, BM->addFunctionType(RT, PT));
+  }
+
+  if (T->isLabelTy()) {
+    assert("labels can't be mapped as types - handle this earlier!");
+    return nullptr;
+  }
+
+  llvm_unreachable("Not implemented!");
+  return 0;
+}
+
+SPIRVType *LLVMToSPIRV::transSPIRVOpaqueType(Type *T) {
+  auto ET = T->getPointerElementType();
+  auto ST = cast<StructType>(ET);
+  auto AddrSpc = T->getPointerAddressSpace();
+  auto STName = ST->getStructName();
+  assert(STName.startswith(kSPIRVTypeName::PrefixAndDelim) &&
+         "Invalid SPIR-V opaque type name");
+  SmallVector<std::string, 8> Postfixes;
+  auto TN = decodeSPIRVTypeName(STName, Postfixes);
+  if (TN == kSPIRVTypeName::Pipe) {
+    assert(AddrSpc == SPIRAS_Global);
+    assert(Postfixes.size() == 1 && "Invalid pipe type ops");
+    auto PipeT = BM->addPipeType();
+    PipeT->setPipeAcessQualifier(
+        static_cast<spv::AccessQualifier>(atoi(Postfixes[0].c_str())));
+    return mapType(T, PipeT);
+  } else if (TN == kSPIRVTypeName::Image) {
+    assert(AddrSpc == SPIRAS_Global);
+    // The sampled type needs to be translated through LLVM type to guarantee
+    // uniqueness.
+    auto SampledT = transType(
+        getLLVMTypeForSPIRVImageSampledTypePostfix(Postfixes[0], *Ctx));
+    SmallVector<int, 7> Ops;
+    for (unsigned I = 1; I < 8; ++I)
+      Ops.push_back(atoi(Postfixes[I].c_str()));
+    SPIRVTypeImageDescriptor Desc(static_cast<SPIRVImageDimKind>(Ops[0]),
+                                  Ops[1], Ops[2], Ops[3], Ops[4], Ops[5]);
+    return mapType(T,
+                   BM->addImageType(SampledT, Desc,
+                                    static_cast<spv::AccessQualifier>(Ops[6])));
+  } else if (TN == kSPIRVTypeName::SampledImg) {
+    return mapType(
+        T, BM->addSampledImageType(static_cast<SPIRVTypeImage *>(
+               transType(getSPIRVTypeByChangeBaseTypeName(
+                   M, T, kSPIRVTypeName::SampledImg, kSPIRVTypeName::Image)))));
+  } else if (TN == kSPIRVTypeName::Sampler)
+    return mapType(T, BM->addSamplerType());
+  else if (TN == kSPIRVTypeName::DeviceEvent)
+    return mapType(T, BM->addDeviceEventType());
+  else if (TN == kSPIRVTypeName::Queue)
+    return mapType(T, BM->addQueueType());
+  else if (TN == kSPIRVTypeName::PipeStorage)
+    return mapType(T, BM->addPipeStorageType());
+  else
+    return mapType(T,
+                   BM->addOpaqueGenericType(SPIRVOpaqueTypeOpCodeMap::map(TN)));
+}
+
+SPIRVFunction *LLVMToSPIRV::transFunctionDecl(Function *F) {
+  // skip any floor.* functions, these shouldn't be here
+  if (F->getName().startswith("floor."))
+    return nullptr;
+
+  // return already translated value
+  if (auto BF = getTranslatedValue(F))
+    return static_cast<SPIRVFunction *>(BF);
+
+  // all shader/glsl entry points need special handling compared to normal and
+  // kernel functions
+  const auto entry_point_type = oclGetEntryPointType(F, SrcLang);
+  if (entry_point_type == spv::ExecutionModel::ExecutionModelKernel ||
+      entry_point_type == spv::ExecutionModel::ExecutionModelInvalid) {
+    SPIRVTypeFunction *BFT = static_cast<SPIRVTypeFunction *>(
+        transType(getAnalysis<OCLTypeToSPIRV>().getAdaptedType(F)));
+    SPIRVFunction *BF =
+        static_cast<SPIRVFunction *>(mapValue(F, BM->addFunction(BFT)));
+    BF->setFunctionControlMask(transFunctionControlMask(F));
+    if (F->hasName())
+      BM->setName(BF, F->getName());
+    if (entry_point_type != spv::ExecutionModel::ExecutionModelInvalid) {
+      BM->addEntryPoint(entry_point_type, BF->getId());
+    } else if (F->getLinkage() != GlobalValue::InternalLinkage)
+      BF->setLinkageType(transLinkageType(F));
+    auto Attrs = F->getAttributes();
+    for (Function::arg_iterator I = F->arg_begin(), E = F->arg_end(); I != E;
+         ++I) {
+      auto ArgNo = I->getArgNo();
+      SPIRVFunctionParameter *BA = BF->getArgument(ArgNo);
+      if (I->hasName())
+        BM->setName(BA, I->getName());
+      if (I->hasByValAttr())
+        BA->addAttr(FunctionParameterAttributeByVal);
+      if (I->hasNoAliasAttr())
+        BA->addAttr(FunctionParameterAttributeNoAlias);
+      if (I->hasNoCaptureAttr())
+        BA->addAttr(FunctionParameterAttributeNoCapture);
+      if (I->hasStructRetAttr())
+        BA->addAttr(FunctionParameterAttributeSret);
+      if (Attrs.hasAttribute(ArgNo + 1, Attribute::ZExt))
+        BA->addAttr(FunctionParameterAttributeZext);
+      if (Attrs.hasAttribute(ArgNo + 1, Attribute::SExt))
+        BA->addAttr(FunctionParameterAttributeSext);
+      if (Attrs.hasAttribute(ArgNo + 1, Attribute::Dereferenceable))
+        BA->addDecorate(
+            DecorationMaxByteOffset,
+            Attrs.getAttribute(ArgNo + 1, Attribute::Dereferenceable)
+                .getDereferenceableBytes());
+    }
+    if (Attrs.hasAttribute(AttributeSet::ReturnIndex, Attribute::ZExt))
+      BF->addDecorate(DecorationFuncParamAttr, FunctionParameterAttributeZext);
+    if (Attrs.hasAttribute(AttributeSet::ReturnIndex, Attribute::SExt))
+      BF->addDecorate(DecorationFuncParamAttr, FunctionParameterAttributeSext);
+    DbgTran.transDbgInfo(F, BF);
+    SPIRVDBG(dbgs() << "[transFunction (kernel)] " << *F << " => ";
+             spvdbgs() << *BF << '\n';)
+    return BF;
+  } else {
+    // shader function is always "void func_name()"
+    const auto shader_func_type =
+        llvm::FunctionType::get(llvm::Type::getVoidTy(*Ctx), false);
+    SPIRVTypeFunction *BFT =
+        static_cast<SPIRVTypeFunction *>(transType(shader_func_type));
+    SPIRVFunction *BF =
+        static_cast<SPIRVFunction *>(mapValue(F, BM->addFunction(BFT)));
+    assert(F->hasName() && "entry point function must have a name");
+    BM->setName(BF, F->getName());
+    BM->addEntryPoint(entry_point_type, BF->getId());
+    // NOTE: not handling/adding function parameters here
+    DbgTran.transDbgInfo(F, BF);
+    SPIRVDBG(dbgs() << "[transFunction (shader)] " << *F << " => ";
+             spvdbgs() << *BF << '\n';)
+    return BF;
+  }
+}
+
+SPIRVValue *LLVMToSPIRV::transConstant(Value *V) {
+  if (auto CPNull = dyn_cast<ConstantPointerNull>(V))
+    return BM->addNullConstant(
+        bcast<SPIRVTypePointer>(transType(CPNull->getType())));
+
+  if (auto CAZero = dyn_cast<ConstantAggregateZero>(V)) {
+    Type *AggType = CAZero->getType();
+    if (const StructType *ST = dyn_cast<StructType>(AggType))
+      if (ST->getName() == getSPIRVTypeName(kSPIRVTypeName::ConstantSampler))
+        return BM->addSamplerConstant(transType(AggType), 0, 0, 0);
+
+    return BM->addNullConstant(transType(AggType));
+  }
+
+  if (auto ConstI = dyn_cast<ConstantInt>(V))
+    return BM->addConstant(transType(V->getType()), ConstI->getZExtValue());
+
+  if (auto ConstFP = dyn_cast<ConstantFP>(V)) {
+    auto BT = static_cast<SPIRVType *>(transType(V->getType()));
+    return BM->addConstant(
+        BT, ConstFP->getValueAPF().bitcastToAPInt().getZExtValue());
+  }
+
+  if (auto ConstDA = dyn_cast<ConstantDataArray>(V)) {
+    std::vector<SPIRVValue *> BV;
+    for (unsigned I = 0, E = ConstDA->getNumElements(); I != E; ++I)
+      BV.push_back(transValue(ConstDA->getElementAsConstant(I), nullptr));
+    return BM->addCompositeConstant(transType(V->getType()), BV);
+  }
+
+  if (auto ConstA = dyn_cast<ConstantArray>(V)) {
+    std::vector<SPIRVValue *> BV;
+    for (auto I = ConstA->op_begin(), E = ConstA->op_end(); I != E; ++I)
+      BV.push_back(transValue(*I, nullptr));
+    return BM->addCompositeConstant(transType(V->getType()), BV);
+  }
+
+  if (auto ConstDV = dyn_cast<ConstantDataVector>(V)) {
+    std::vector<SPIRVValue *> BV;
+    for (unsigned I = 0, E = ConstDV->getNumElements(); I != E; ++I)
+      BV.push_back(transValue(ConstDV->getElementAsConstant(I), nullptr));
+    return BM->addCompositeConstant(transType(V->getType()), BV);
+  }
+
+  if (auto ConstV = dyn_cast<ConstantVector>(V)) {
+    std::vector<SPIRVValue *> BV;
+    for (auto I = ConstV->op_begin(), E = ConstV->op_end(); I != E; ++I)
+      BV.push_back(transValue(*I, nullptr));
+    return BM->addCompositeConstant(transType(V->getType()), BV);
+  }
+
+  if (auto ConstV = dyn_cast<ConstantStruct>(V)) {
+    if (ConstV->getType()->getName() ==
+        getSPIRVTypeName(kSPIRVTypeName::ConstantSampler)) {
+      assert(ConstV->getNumOperands() == 3);
+      SPIRVWord AddrMode =
+                    ConstV->getOperand(0)->getUniqueInteger().getZExtValue(),
+                Normalized =
+                    ConstV->getOperand(1)->getUniqueInteger().getZExtValue(),
+                FilterMode =
+                    ConstV->getOperand(2)->getUniqueInteger().getZExtValue();
+      assert(AddrMode < 5 && "Invalid addressing mode");
+      assert(Normalized < 2 && "Invalid value of normalized coords");
+      assert(FilterMode < 2 && "Invalid filter mode");
+      SPIRVType *SamplerTy = transType(ConstV->getType());
+      return BM->addSamplerConstant(SamplerTy, AddrMode, Normalized,
+                                    FilterMode);
+    }
+    if (ConstV->getType()->getName() ==
+        getSPIRVTypeName(kSPIRVTypeName::ConstantPipeStorage)) {
+      assert(ConstV->getNumOperands() == 3);
+      SPIRVWord PacketSize =
+                    ConstV->getOperand(0)->getUniqueInteger().getZExtValue(),
+                PacketAlign =
+                    ConstV->getOperand(1)->getUniqueInteger().getZExtValue(),
+                Capacity =
+                    ConstV->getOperand(2)->getUniqueInteger().getZExtValue();
+      assert(PacketAlign >= 1 && "Invalid packet alignment");
+      assert(PacketSize >= PacketAlign && PacketSize % PacketAlign == 0 &&
+             "Invalid packet size and/or alignment.");
+      SPIRVType *PipeStorageTy = transType(ConstV->getType());
+      return BM->addPipeStorageConstant(PipeStorageTy, PacketSize, PacketAlign,
+                                        Capacity);
+    }
+    std::vector<SPIRVValue *> BV;
+    for (auto I = ConstV->op_begin(), E = ConstV->op_end(); I != E; ++I)
+      BV.push_back(transValue(*I, nullptr));
+    return BM->addCompositeConstant(transType(V->getType()), BV);
+  }
+
+  if (auto ConstUE = dyn_cast<ConstantExpr>(V)) {
+    auto Inst = ConstUE->getAsInstruction();
+    SPIRVDBG(dbgs() << "ConstantExpr: " << *ConstUE << '\n';
+             dbgs() << "Instruction: " << *Inst << '\n';)
+    auto BI = transValue(Inst, nullptr, false);
+    Inst->dropAllReferences();
+    return BI;
+  }
+
+  if (isa<UndefValue>(V)) {
+    // TODO/NOTE: don't allow global undef constants in vulkan/glsl until
+    // drivers (amd) catch up
+    if (SrcLang == spv::SourceLanguageGLSL) {
+      return nullptr;
+    } else {
+      return BM->addUndef(transType(V->getType()));
+    }
+  }
+
+  return nullptr;
+}
+
+SPIRVValue *LLVMToSPIRV::transValue(Value *V, SPIRVBasicBlock *BB,
+                                    bool CreateForward) {
+  LLVMToSPIRVValueMap::iterator Loc = ValueMap.find(V);
+  if (Loc != ValueMap.end() && (!Loc->second->isForward() || CreateForward))
+    return Loc->second;
+
+  SPIRVDBG(dbgs() << "[transValue] " << *V << '\n');
+  assert((!isa<Instruction>(V) || isa<GetElementPtrInst>(V) ||
+          isa<CastInst>(V) || BB) &&
+         "Invalid SPIRV BB");
+
+  auto BV = transValueWithoutDecoration(V, BB, CreateForward);
+  std::string name = V->getName();
+  if (!name.empty()) // Don't erase the name, which BM might already have
+    BM->setName(BV, name);
+  if (!transDecoration(V, BV))
+    return nullptr;
+  return BV;
+}
+
+SPIRVInstruction *LLVMToSPIRV::transBinaryInst(BinaryOperator *B,
+                                               SPIRVBasicBlock *BB) {
+  unsigned LLVMOC = B->getOpcode();
+  auto Op0 = transValue(B->getOperand(0), BB);
+  SPIRVInstruction *BI = BM->addBinaryInst(
+      transBoolOpCode(Op0, OpCodeMap::map(LLVMOC)), transType(B->getType()),
+      Op0, transValue(B->getOperand(1), BB), BB);
+  return BI;
+}
+
+SPIRVInstruction *LLVMToSPIRV::transCmpInst(CmpInst *Cmp, SPIRVBasicBlock *BB) {
+  auto Op0 = transValue(Cmp->getOperand(0), BB);
+  SPIRVInstruction *BI = BM->addCmpInst(
+      transBoolOpCode(Op0, CmpMap::map(Cmp->getPredicate())),
+      transType(Cmp->getType()), Op0, transValue(Cmp->getOperand(1), BB), BB);
+  return BI;
+}
+
+SPIRV::SPIRVInstruction *LLVMToSPIRV::transUnaryInst(UnaryInstruction *U,
+                                                     SPIRVBasicBlock *BB) {
+  Op BOC = OpNop;
+  if (auto Cast = dyn_cast<AddrSpaceCastInst>(U)) {
+    if (Cast->getDestTy()->getPointerAddressSpace() == SPIRAS_Generic) {
+      assert(Cast->getSrcTy()->getPointerAddressSpace() != SPIRAS_Constant &&
+             "Casts from constant address space to generic are illegal");
+      BOC = OpPtrCastToGeneric;
+    } else {
+      assert(Cast->getDestTy()->getPointerAddressSpace() != SPIRAS_Constant &&
+             "Casts from generic address space to constant are illegal");
+      assert(Cast->getSrcTy()->getPointerAddressSpace() == SPIRAS_Generic);
+      BOC = OpGenericCastToPtr;
+    }
+  } else {
+    auto OpCode = U->getOpcode();
+    BOC = OpCodeMap::map(OpCode);
+  }
+
+  auto Op = transValue(U->getOperand(0), BB);
+  return BM->addUnaryInst(transBoolOpCode(Op, BOC), transType(U->getType()), Op,
+                          BB);
+}
+
+/// An instruction may use an instruction from another BB which has not been
+/// translated. SPIRVForward should be created as place holder for these
+/// instructions and replaced later by the real instructions.
+/// Use CreateForward = true to indicate such situation.
+SPIRVValue *LLVMToSPIRV::transValueWithoutDecoration(Value *V,
+                                                     SPIRVBasicBlock *BB,
+                                                     bool CreateForward) {
+  if (auto LBB = dyn_cast<BasicBlock>(V)) {
+    auto BF =
+        static_cast<SPIRVFunction *>(getTranslatedValue(LBB->getParent()));
+    assert(BF && "Function not translated");
+    BB = static_cast<SPIRVBasicBlock *>(mapValue(V, BM->addBasicBlock(BF)));
+    BM->setName(BB, LBB->getName());
+    return BB;
+  }
+
+  if (auto F = dyn_cast<Function>(V))
+    return transFunctionDecl(F);
+
+  if (auto GV = dyn_cast<GlobalVariable>(V)) {
+    llvm::PointerType *Ty = GV->getType();
+
+    if (GV->hasName() && GV->getName().find(".vulkan") != std::string::npos) {
+      // special global variables are handled/added in transFunction
+      // (note: should only be output vars here)
+      return nullptr;
+    }
+
+    // Though variables with common linkage type are initialized by 0,
+    // they can be represented in SPIR-V as uninitialized variables with
+    // 'Export' linkage type, just as tentative definitions look in C
+    llvm::Value *Init = GV->hasInitializer() && !GV->hasCommonLinkage()
+                            ? GV->getInitializer()
+                            : nullptr;
+    StructType *ST = Init ? dyn_cast<StructType>(Init->getType()) : nullptr;
+    if (ST && ST->hasName() && isSPIRVConstantName(ST->getName())) {
+      auto BV = transConstant(Init);
+      assert(BV);
+      return mapValue(V, BV);
+    } else if (ConstantExpr *ConstUE = dyn_cast_or_null<ConstantExpr>(Init)) {
+      Instruction *Inst = ConstUE->getAsInstruction();
+      if (isSpecialTypeInitializer(Inst)) {
+        Init = Inst->getOperand(0);
+        Ty = static_cast<PointerType *>(Init->getType());
+      }
+      Inst->dropAllReferences();
+    }
+
+    // Vulkan/GLSL doesn't do linkage
+    auto linkage =
+        (SrcLang != spv::SourceLanguageGLSL ? transLinkageType(GV)
+                                            : spv::LinkageTypeInternal);
+
+    // remove invalid initializers (zero or undef needs to be present in LLVM,
+    // but not in SPIR-V)
+    auto storage_class = SPIRSPIRVAddrSpaceMap::map(
+        static_cast<SPIRAddressSpace>(Ty->getAddressSpace()));
+    assert(((storage_class == spv::StorageClassFunction && BB != nullptr) ||
+            storage_class != spv::StorageClassFunction) &&
+           "invalid GV/BB");
+    auto initializer =
+        (storage_class == StorageClassWorkgroup || Init == nullptr
+             ? nullptr
+             : transValue(Init, nullptr));
+
+    auto BVar = static_cast<SPIRVVariable *>(BM->addVariable(
+        transType(Ty), GV->isConstant(), linkage, initializer, GV->getName(),
+        storage_class,
+        (storage_class == spv::StorageClassFunction ? BB : nullptr)));
+    mapValue(V, BVar);
+    if (Ty->isPointerTy()) {
+      auto elem_type = Ty->getPointerElementType();
+      auto spirv_elem_type = transType(elem_type);
+      decorateComposite(elem_type, spirv_elem_type);
+    }
+    spv::BuiltIn Builtin = spv::BuiltInPosition;
+    if (!GV->hasName() || !getSPIRVBuiltin(GV->getName().str(), Builtin))
+      return BVar;
+    BVar->setBuiltin(Builtin);
+    return BVar;
+  }
+
+  // always create a new undef variable for vulkan/glsl to workaround driver
+  // issues
+  if (isa<UndefValue>(V) && SrcLang == spv::SourceLanguageGLSL) {
+    return BM->addUndefInst(transType(V->getType()), BB);
+  }
+
+  if (isa<Constant>(V)) {
+    auto BV = transConstant(V);
+    assert(BV);
+    return mapValue(V, BV);
+  }
+
+  if (auto Arg = dyn_cast<Argument>(V)) {
+    unsigned ArgNo = Arg->getArgNo();
+    SPIRVFunction *BF = BB->getParent();
+    // assert(BF->existArgument(ArgNo));
+    return mapValue(V, BF->getArgument(ArgNo));
+  }
+
+  if (CreateForward)
+    return mapValue(V, BM->addForward(transType(V->getType())));
+
+  if (StoreInst *ST = dyn_cast<StoreInst>(V)) {
+    std::vector<SPIRVWord> MemoryAccess(1, 0);
+    if (ST->isVolatile())
+      MemoryAccess[0] |= MemoryAccessVolatileMask;
+    if (ST->getAlignment()) {
+      MemoryAccess[0] |= MemoryAccessAlignedMask;
+      MemoryAccess.push_back(ST->getAlignment());
+    }
+    if (ST->getMetadata(LLVMContext::MD_nontemporal))
+      MemoryAccess[0] |= MemoryAccessNontemporalMask;
+    if (MemoryAccess.front() == 0)
+      MemoryAccess.clear();
+    return mapValue(V, BM->addStoreInst(transValue(ST->getPointerOperand(), BB),
+                                        transValue(ST->getValueOperand(), BB),
+                                        MemoryAccess, BB));
+  }
+
+  if (LoadInst *LD = dyn_cast<LoadInst>(V)) {
+    std::vector<SPIRVWord> MemoryAccess(1, 0);
+    if (LD->isVolatile())
+      MemoryAccess[0] |= MemoryAccessVolatileMask;
+    if (LD->getAlignment()) {
+      MemoryAccess[0] |= MemoryAccessAlignedMask;
+      MemoryAccess.push_back(LD->getAlignment());
+    }
+    if (LD->getMetadata(LLVMContext::MD_nontemporal))
+      MemoryAccess[0] |= MemoryAccessNontemporalMask;
+    if (MemoryAccess.front() == 0)
+      MemoryAccess.clear();
+    return mapValue(V, BM->addLoadInst(transValue(LD->getPointerOperand(), BB),
+                                       MemoryAccess, BB));
+  }
+
+  if (BinaryOperator *B = dyn_cast<BinaryOperator>(V)) {
+    SPIRVInstruction *BI = transBinaryInst(B, BB);
+    return mapValue(V, BI);
+  }
+
+  if (auto RI = dyn_cast<ReturnInst>(V)) {
+    if (auto RV = RI->getReturnValue())
+      return mapValue(V, BM->addReturnValueInst(transValue(RV, BB), BB));
+    return mapValue(V, BM->addReturnInst(BB));
+  }
+
+  if (CmpInst *Cmp = dyn_cast<CmpInst>(V)) {
+    SPIRVInstruction *BI = transCmpInst(Cmp, BB);
+    return mapValue(V, BI);
+  }
+
+  if (SelectInst *Sel = dyn_cast<SelectInst>(V))
+    return mapValue(V, BM->addSelectInst(transValue(Sel->getCondition(), BB),
+                                         transValue(Sel->getTrueValue(), BB),
+                                         transValue(Sel->getFalseValue(), BB),
+                                         BB));
+
+  if (AllocaInst *Alc = dyn_cast<AllocaInst>(V))
+    return mapValue(
+        V, BM->addVariable(transType(Alc->getType()), false,
+                           SPIRVLinkageTypeKind::LinkageTypeInternal, nullptr,
+                           Alc->getName(), StorageClassFunction, BB));
+
+  if (auto *Switch = dyn_cast<SwitchInst>(V)) {
+    std::vector<SPIRVSwitch::PairTy> Pairs;
+    auto Select = transValue(Switch->getCondition(), BB);
+
+    for (auto I = Switch->case_begin(), E = Switch->case_end(); I != E; ++I) {
+      SPIRVSwitch::LiteralTy Lit;
+      uint64_t CaseValue = I.getCaseValue()->getZExtValue();
+
+      Lit.push_back(CaseValue);
+      assert(Select->getType()->getBitWidth() <= 64 &&
+             "unexpected selector bitwidth");
+      if (Select->getType()->getBitWidth() == 64)
+        Lit.push_back(CaseValue >> 32);
+
+      Pairs.push_back(
+          std::make_pair(Lit, static_cast<SPIRVBasicBlock *>(
+                                  transValue(I.getCaseSuccessor(), nullptr))));
+    }
+
+    return mapValue(
+        V, BM->addSwitchInst(Select, static_cast<SPIRVBasicBlock *>(transValue(
+                                         Switch->getDefaultDest(), nullptr)),
+                             Pairs, BB));
+  }
+
+  if (auto Branch = dyn_cast<BranchInst>(V)) {
+    if (Branch->isUnconditional())
+      return mapValue(V, BM->addBranchInst(static_cast<SPIRVLabel *>(transValue(
+                                               Branch->getSuccessor(0), BB)),
+                                           BB));
+    return mapValue(
+        V,
+        BM->addBranchConditionalInst(
+            transValue(Branch->getCondition(), BB),
+            static_cast<SPIRVLabel *>(transValue(Branch->getSuccessor(0), BB)),
+            static_cast<SPIRVLabel *>(transValue(Branch->getSuccessor(1), BB)),
+            BB));
+  }
+
+  if (auto Phi = dyn_cast<PHINode>(V)) {
+    std::vector<SPIRVValue *> IncomingPairs;
+    for (size_t I = 0, E = Phi->getNumIncomingValues(); I != E; ++I) {
+      IncomingPairs.push_back(transValue(Phi->getIncomingValue(I), BB));
+      IncomingPairs.push_back(transValue(Phi->getIncomingBlock(I), nullptr));
+    }
+    return mapValue(
+        V, BM->addPhiInst(transType(Phi->getType()), IncomingPairs, BB));
+  }
+
+  if (auto Ext = dyn_cast<ExtractValueInst>(V)) {
+    return mapValue(V, BM->addCompositeExtractInst(
+                           transType(Ext->getType()),
+                           transValue(Ext->getAggregateOperand(), BB),
+                           Ext->getIndices(), BB));
+  }
+
+  if (auto Ins = dyn_cast<InsertValueInst>(V)) {
+    return mapValue(V, BM->addCompositeInsertInst(
+                           transValue(Ins->getInsertedValueOperand(), BB),
+                           transValue(Ins->getAggregateOperand(), BB),
+                           Ins->getIndices(), BB));
+  }
+
+  if (auto Ext = dyn_cast<ExtractValueInst>(V)) {
+    return mapValue(V, BM->addCompositeExtractInst(
+                           transType(Ext->getType()),
+                           transValue(Ext->getAggregateOperand(), BB),
+                           Ext->getIndices(), BB));
+  }
+
+  if (auto Ins = dyn_cast<InsertValueInst>(V)) {
+    return mapValue(V, BM->addCompositeInsertInst(
+                           transValue(Ins->getInsertedValueOperand(), BB),
+                           transValue(Ins->getAggregateOperand(), BB),
+                           Ins->getIndices(), BB));
+  }
+
+  if (UnaryInstruction *U = dyn_cast<UnaryInstruction>(V)) {
+    if (isSpecialTypeInitializer(U))
+      return mapValue(V, transValue(U->getOperand(0), BB));
+    return mapValue(V, transUnaryInst(U, BB));
+  }
+
+  if (GetElementPtrInst *GEP = dyn_cast<GetElementPtrInst>(V)) {
+    std::vector<SPIRVValue *> Indices;
+    for (unsigned i = 0, e = GEP->getNumIndices(); i != e; ++i)
+      Indices.push_back(transValue(GEP->getOperand(i + 1), BB));
+    if (SrcLang != spv::SourceLanguageGLSL) {
+      return mapValue(
+          V, BM->addPtrAccessChainInst(transType(GEP->getType()),
+                                       transValue(GEP->getPointerOperand(), BB),
+                                       Indices, BB, GEP->isInBounds()));
+    } else {
+      return mapValue(
+          V, BM->addAccessChainInst(transType(GEP->getType()),
+                                    transValue(GEP->getPointerOperand(), BB),
+                                    Indices, BB, GEP->isInBounds()));
+    }
+  }
+
+  if (auto Ext = dyn_cast<ExtractElementInst>(V)) {
+    auto Index = Ext->getIndexOperand();
+    if (auto Const = dyn_cast<ConstantInt>(Index))
+      return mapValue(V, BM->addCompositeExtractInst(
+                             transType(Ext->getType()),
+                             transValue(Ext->getVectorOperand(), BB),
+                             std::vector<SPIRVWord>(1, Const->getZExtValue()),
+                             BB));
+    else
+      return mapValue(V, BM->addVectorExtractDynamicInst(
+                             transValue(Ext->getVectorOperand(), BB),
+                             transValue(Index, BB), BB));
+  }
+
+  if (auto Ins = dyn_cast<InsertElementInst>(V)) {
+    auto Index = Ins->getOperand(2);
+    if (auto Const = dyn_cast<ConstantInt>(Index))
+      return mapValue(V, BM->addCompositeInsertInst(
+                             transValue(Ins->getOperand(1), BB),
+                             transValue(Ins->getOperand(0), BB),
+                             std::vector<SPIRVWord>(1, Const->getZExtValue()),
+                             BB));
+    else
+      return mapValue(
+          V, BM->addVectorInsertDynamicInst(transValue(Ins->getOperand(0), BB),
+                                            transValue(Ins->getOperand(1), BB),
+                                            transValue(Index, BB), BB));
+  }
+
+  if (auto SF = dyn_cast<ShuffleVectorInst>(V)) {
+    std::vector<SPIRVWord> Comp;
+    for (auto &I : SF->getShuffleMask())
+      Comp.push_back(I);
+    return mapValue(V, BM->addVectorShuffleInst(
+                           transType(SF->getType()),
+                           transValue(SF->getOperand(0), BB),
+                           transValue(SF->getOperand(1), BB), Comp, BB));
+  }
+
+  if (CallInst *CI = dyn_cast<CallInst>(V))
+    return mapValue(V, transCallInst(CI, BB));
+
+  if (isa<UnreachableInst>(V)) {
+    // TODO: fix this be either creating a llvm OpKill instruction or metadata
+    if (ignore_next_unreachable) {
+      ignore_next_unreachable = false;
+      return nullptr;
+    }
+    return mapValue(V, BM->addUnreachableInst(BB));
+  }
+
+  errs() << "not implemented: " << *V << "\n";
+  llvm_unreachable("Not implemented");
+  return nullptr;
+}
+
+bool LLVMToSPIRV::transDecoration(Value *V, SPIRVValue *BV) {
+  if (!transAlign(V, BV))
+    return false;
+  if ((isa<AtomicCmpXchgInst>(V) && cast<AtomicCmpXchgInst>(V)->isVolatile()) ||
+      (isa<AtomicRMWInst>(V) && cast<AtomicRMWInst>(V)->isVolatile()))
+    BV->setVolatile(true);
+  DbgTran.transDbgInfo(V, BV);
+  return true;
+}
+
+bool LLVMToSPIRV::transAlign(Value *V, SPIRVValue *BV) {
+  // shader doesn't have the alignment decoration -> just return
+  if (SrcLang == spv::SourceLanguageGLSL) {
+    return true;
+  }
+
+  if (auto AL = dyn_cast<AllocaInst>(V)) {
+    BM->setAlignment(BV, AL->getAlignment());
+    return true;
+  }
+  if (auto GV = dyn_cast<GlobalVariable>(V)) {
+    BM->setAlignment(BV, GV->getAlignment());
+    return true;
+  }
+  return true;
+}
+
+/// Do this after source language is set.
+bool LLVMToSPIRV::transBuiltinSet() {
+  SPIRVWord Ver = 0;
+  SourceLanguage Kind = BM->getSourceLanguage(&Ver);
+  assert((Kind == SourceLanguageOpenCL_C || Kind == SourceLanguageOpenCL_CPP ||
+          Kind == SourceLanguageGLSL) &&
+         "not supported");
+  std::stringstream SS;
+  if (Kind != SourceLanguageGLSL)
+    SS << "OpenCL.std";
+  else
+    SS << "GLSL.std.450";
+  return BM->importBuiltinSet(SS.str(), &ExtSetId);
+}
+
+/// Transform sampler* spcv.cast(i32 arg)
+/// Only two cases are possible:
+///   arg = ConstantInt x -> SPIRVConstantSampler
+///   arg = i32 argument -> transValue(arg)
+///   arg = load from sampler -> look through load
+SPIRVValue *LLVMToSPIRV::oclTransSpvcCastSampler(CallInst *CI,
+                                                 SPIRVBasicBlock *BB) {
+  llvm::Function *F = CI->getCalledFunction();
+  auto FT = F->getFunctionType();
+  auto RT = FT->getReturnType();
+  assert(FT->getNumParams() == 1);
+  assert(isSPIRVType(RT, kSPIRVTypeName::Sampler) &&
+         FT->getParamType(0)->isIntegerTy() && "Invalid sampler type");
+  auto Arg = CI->getArgOperand(0);
+
+  auto GetSamplerConstant = [&](uint64_t SamplerValue) {
+    auto AddrMode = (SamplerValue & 0xE) >> 1;
+    auto Param = SamplerValue & 0x1;
+    auto Filter = ((SamplerValue & 0x30) >> 4) - 1;
+    auto BV = BM->addSamplerConstant(transType(RT), AddrMode, Param, Filter);
+    return BV;
+  };
+
+  if (auto Const = dyn_cast<ConstantInt>(Arg)) {
+    // Sampler is declared as a kernel scope constant
+    return GetSamplerConstant(Const->getZExtValue());
+  } else if (auto Load = dyn_cast<LoadInst>(Arg)) {
+    // If value of the sampler is loaded from a global constant, use its
+    // initializer for initialization of the sampler.
+    auto Op = Load->getPointerOperand();
+    assert(isa<GlobalVariable>(Op) && "Unknown sampler pattern!");
+    auto GV = cast<GlobalVariable>(Op);
+    assert(GV->isConstant() ||
+           GV->getType()->getPointerAddressSpace() == SPIRAS_Constant);
+    auto Initializer = GV->getInitializer();
+    assert(isa<ConstantInt>(Initializer) && "sampler not constant int?");
+    return GetSamplerConstant(cast<ConstantInt>(Initializer)->getZExtValue());
+  }
+  // Sampler is a function argument
+  auto BV = transValue(Arg, BB);
+  assert(BV && BV->getType() == transType(RT));
+  return BV;
+}
+
+SPIRVValue *LLVMToSPIRV::transSpcvCast(CallInst *CI, SPIRVBasicBlock *BB) {
+  return oclTransSpvcCastSampler(CI, BB);
+}
+
+SPIRVValue *LLVMToSPIRV::transCallInst(CallInst *CI, SPIRVBasicBlock *BB) {
+  SPIRVExtInstSetKind ExtSetKind = SPIRVEIS_Count;
+  SPIRVWord ExtOp = SPIRVWORD_MAX;
+  llvm::Function *F = CI->getCalledFunction();
+  auto MangledName = F->getName();
+  std::string DemangledName;
+
+  if (MangledName.startswith(SPCV_CAST))
+    return transSpcvCast(CI, BB);
+
+  if (MangledName.startswith("llvm.memcpy")) {
+    std::vector<SPIRVWord> MemoryAccess;
+
+    if (isa<ConstantInt>(CI->getOperand(4)) &&
+        dyn_cast<ConstantInt>(CI->getOperand(4))->getZExtValue() == 1)
+      MemoryAccess.push_back(MemoryAccessVolatileMask);
+    if (isa<ConstantInt>(CI->getOperand(3))) {
+      MemoryAccess.push_back(MemoryAccessAlignedMask);
+      MemoryAccess.push_back(
+          dyn_cast<ConstantInt>(CI->getOperand(3))->getZExtValue());
+    }
+
+    return BM->addCopyMemorySizedInst(
+        transValue(CI->getOperand(0), BB), transValue(CI->getOperand(1), BB),
+        transValue(CI->getOperand(2), BB), MemoryAccess, BB);
+  }
+
+  if (oclIsBuiltin(MangledName, &DemangledName) ||
+      isDecoratedSPIRVFunc(F, &DemangledName)) {
+    if (auto BV = transBuiltinToInst(DemangledName, MangledName, CI, BB)) {
+      return BV;
+    }
+  }
+
+  SmallVector<std::string, 2> Dec;
+  if (isBuiltinTransToExtInst(CI->getCalledFunction(), &ExtSetKind, &ExtOp,
+                              &Dec)) {
+    return addDecorations(
+        BM->addExtInst(
+            transType(CI->getType()), ExtSetId, ExtOp,
+            transArguments(CI, BB,
+                           SPIRVEntry::create_unique(ExtSetKind, ExtOp).get()),
+            BB),
+        Dec);
+  }
+
+  // TODO: put this into an extra function + use lut
+  if (MangledName.startswith("floor.")) {
+    if (MangledName == "floor.discard_fragment") {
+      // since "discard" can't be modelled as a single noreturn +
+      // unreachable-after-call instruction right now, but must add an
+      // "additional" unreachable instead, we need to get rid of (ignore) the
+      // next unreachable (this isn't particularly nice, but we can't do this on
+      // the llvm side, b/c it would badly break things)
+      ignore_next_unreachable = true;
+      return BM->addKillInst(BB);
+    } else if (MangledName == "floor.loop_merge") {
+      return BM->addLoopMergeInst(
+          (SPIRVBasicBlock *)transValue(CI->getArgOperand(0), nullptr),
+          (SPIRVBasicBlock *)transValue(CI->getArgOperand(1), nullptr), BB);
+    } else if (MangledName == "floor.selection_merge") {
+      return BM->addSelectionMergeInst(
+          (SPIRVBasicBlock *)transValue(CI->getArgOperand(0), nullptr), BB);
+    }
+    errs() << "unhandled floor func: " << MangledName << "\n";
+  }
+
+  return BM->addCallInst(
+      transFunctionDecl(CI->getCalledFunction()),
+      transArguments(CI, BB, SPIRVEntry::create_unique(OpFunctionCall).get()),
+      BB);
+}
+
+bool LLVMToSPIRV::transAddressingMode() {
+  Triple TargetTriple(M->getTargetTriple());
+  Triple::ArchType Arch = TargetTriple.getArch();
+
+  SPIRVCKRT(Arch == Triple::spir || Arch == Triple::spir64, InvalidTargetTriple,
+            "Actual target triple is " + M->getTargetTriple());
+
+  if (TargetTriple.getEnvironment() != llvm::Triple::EnvironmentType::Vulkan) {
+    if (Arch == Triple::spir)
+      BM->setAddressingModel(AddressingModelPhysical32);
+    else
+      BM->setAddressingModel(AddressingModelPhysical64);
+    // Physical addressing model requires Addresses capability
+    BM->addCapability(CapabilityAddresses);
+    // OpenCL memory model requires Kernel capability
+    BM->setMemoryModel(MemoryModelOpenCL);
+  } else {
+    BM->setAddressingModel(AddressingModelLogical);
+    BM->addCapability(CapabilityShader);
+    BM->addCapability(
+        CapabilityUniformBufferArrayDynamicIndexing); // always add this for now
+    BM->addCapability(
+        CapabilityStorageBufferArrayDynamicIndexing); // always add this for now
+    BM->setMemoryModel(MemoryModelGLSL450);
+  }
+  return true;
+}
+std::vector<SPIRVValue *>
+LLVMToSPIRV::transValue(const std::vector<Value *> &Args, SPIRVBasicBlock *BB) {
+  std::vector<SPIRVValue *> BArgs;
+  for (auto &I : Args)
+    BArgs.push_back(transValue(I, BB));
+  return BArgs;
+}
+
+std::vector<SPIRVValue *> LLVMToSPIRV::transArguments(CallInst *CI,
+                                                      SPIRVBasicBlock *BB) {
+  return transValue(getArguments(CI), BB);
+}
+
+std::vector<SPIRVWord> LLVMToSPIRV::transValue(const std::vector<Value *> &Args,
+                                               SPIRVBasicBlock *BB,
+                                               SPIRVEntry *Entry) {
+  std::vector<SPIRVWord> Operands;
+  for (size_t I = 0, E = Args.size(); I != E; ++I) {
+    Operands.push_back(Entry->isOperandLiteral(I)
+                           ? cast<ConstantInt>(Args[I])->getZExtValue()
+                           : transValue(Args[I], BB)->getId());
+  }
+  return Operands;
+}
+
+std::vector<SPIRVWord> LLVMToSPIRV::transArguments(CallInst *CI,
+                                                   SPIRVBasicBlock *BB,
+                                                   SPIRVEntry *Entry) {
+  return transValue(getArguments(CI), BB, Entry);
+}
+
+SPIRVWord LLVMToSPIRV::transFunctionControlMask(CallInst *CI) {
+  SPIRVWord FCM = 0;
+  SPIRSPIRVFuncCtlMaskMap::foreach (
+      [&](Attribute::AttrKind Attr, SPIRVFunctionControlMaskKind Mask) {
+        if (CI->hasFnAttr(Attr))
+          FCM |= Mask;
+      });
+  return FCM;
+}
+
+SPIRVWord LLVMToSPIRV::transFunctionControlMask(Function *F) {
+  SPIRVWord FCM = 0;
+  SPIRSPIRVFuncCtlMaskMap::foreach (
+      [&](Attribute::AttrKind Attr, SPIRVFunctionControlMaskKind Mask) {
+        if (F->hasFnAttribute(Attr))
+          FCM |= Mask;
+      });
+  return FCM;
+}
+
+bool LLVMToSPIRV::transGlobalVariables() {
+  for (auto I = M->global_begin(), E = M->global_end(); I != E; ++I) {
+    // ignore any special vulkan globals used by functions (these will be
+    // handled when translating the functions)
+    if (I->hasName() && I->getName().find(".vulkan") != std::string::npos)
+      continue;
+    // ignore any globals that need to be put into functions (map to function
+    // storage class), these are handled later
+    if (SPIRSPIRVAddrSpaceMap::map(static_cast<SPIRAddressSpace>(
+            I->getType()->getAddressSpace())) == spv::StorageClassFunction)
+      continue;
+    if (!transValue(&*I, nullptr))
+      return false;
+  }
+  return true;
+}
+
+void LLVMToSPIRV::mutateFuncArgType(
+    const std::map<unsigned, Type *> &ChangedType, Function *F) {
+  for (auto &I : ChangedType) {
+    for (auto UI = F->user_begin(), UE = F->user_end(); UI != UE; ++UI) {
+      auto Call = dyn_cast<CallInst>(*UI);
+      if (!Call)
+        continue;
+      auto Arg = Call->getArgOperand(I.first);
+      auto OrigTy = Arg->getType();
+      if (OrigTy == I.second)
+        continue;
+      SPIRVDBG(dbgs() << "[mutate arg type] " << *Call << ", " << *Arg << '\n');
+      auto CastF = M->getOrInsertFunction(SPCV_CAST, I.second, OrigTy, nullptr);
+      std::vector<Value *> Args;
+      Args.push_back(Arg);
+      auto Cast = CallInst::Create(CastF, Args, "", Call);
+      Call->replaceUsesOfWith(Arg, Cast);
+      SPIRVDBG(dbgs() << "[mutate arg type] -> " << *Cast << '\n');
+    }
+  }
+}
+
+// TODO: move this to a proper place
+enum class VULKAN_STAGE : uint32_t {
+  NONE = 0u,
+  VERTEX = (1u << 0u),
+  TESSELLATION_CONTROL = (1u << 1u),
+  TESSELLATION_EVALUATION = (1u << 2u),
+  GEOMETRY = (1u << 3u),
+  FRAGMENT = (1u << 4u),
+  KERNEL = (1u << 5u),
+};
+static const char *vulkan_stage_to_string(const VULKAN_STAGE &stage) {
+  switch (stage) {
+  case VULKAN_STAGE::VERTEX:
+    return "vertex";
+  case VULKAN_STAGE::TESSELLATION_CONTROL:
+    return "tessellation-control";
+  case VULKAN_STAGE::TESSELLATION_EVALUATION:
+    return "tesselation-evaluation";
+  case VULKAN_STAGE::GEOMETRY:
+    return "geometry";
+  case VULKAN_STAGE::FRAGMENT:
+    return "fragment";
+  case VULKAN_STAGE::KERNEL:
+    return "kernel";
+  default:
+    break;
+  }
+  return "";
+}
+constexpr VULKAN_STAGE operator|(const VULKAN_STAGE &e0,
+                                 const VULKAN_STAGE &e1) {
+  return (VULKAN_STAGE)((typename std::underlying_type<VULKAN_STAGE>::type)e0 |
+                        (typename std::underlying_type<VULKAN_STAGE>::type)e1);
+}
+constexpr VULKAN_STAGE &operator|=(VULKAN_STAGE &e0, const VULKAN_STAGE &e1) {
+  e0 = e0 | e1;
+  return e0;
+}
+constexpr VULKAN_STAGE operator&(const VULKAN_STAGE &e0,
+                                 const VULKAN_STAGE &e1) {
+  return (VULKAN_STAGE)((typename std::underlying_type<VULKAN_STAGE>::type)e0 &
+                        (typename std::underlying_type<VULKAN_STAGE>::type)e1);
+}
+constexpr VULKAN_STAGE &operator&=(VULKAN_STAGE &e0, const VULKAN_STAGE &e1) {
+  e0 = e0 & e1;
+  return e0;
+}
+
+void LLVMToSPIRV::decorateComposite(llvm::Type *llvm_type,
+                                    SPIRVType *spirv_type) {
+  if (SrcLang != SourceLanguageGLSL)
+    return;
+  // TODO: this doesn't respect padding/alignment yet, fix it (might already
+  // need to dump this info on the clang/llvm side)
+  const auto &DL = M->getDataLayout();
+  if (auto struct_type = dyn_cast<llvm::StructType>(llvm_type)) {
+    uint32_t member_idx = 0, offset = 0;
+    for (const auto &elem_type : struct_type->elements()) {
+      auto spirv_elem_type =
+          ((SPIRVTypeStruct *)spirv_type)->getMemberType(member_idx);
+
+      const auto this_member_idx = member_idx++;
+      const auto &member_decs = spirv_type->getMemberDecorates();
+      const auto iter =
+          member_decs.find({this_member_idx, spv::DecorationOffset});
+      if (iter == member_decs.end()) {
+        spirv_type->addMemberDecorate(this_member_idx, spv::DecorationOffset,
+                                      offset);
+      } else {
+        // shouldn't occur as far as I can tell, but better check it to be
+        // certain
+        assert(iter->second->getMemberNumber() == this_member_idx &&
+               iter->second->getLiteral(0) == offset &&
+               "existing member decoration differs from this one");
+      }
+      offset += DL.getTypeStoreSize(elem_type);
+
+      // recurse
+      decorateComposite(elem_type, spirv_elem_type);
+    }
+  } else if (auto array_type = dyn_cast<llvm::ArrayType>(llvm_type)) {
+    spirv_type->addDecorate(spv::DecorationArrayStride,
+                            DL.getTypeStoreSize(array_type->getElementType()));
+    auto spirv_elem_type =
+        (spirv_type->isTypeRuntimeArray()
+             ? ((SPIRVTypeRuntimeArray *)spirv_type)->getElementType()
+             : ((SPIRVTypeArray *)spirv_type)->getElementType());
+
+    // recurse
+    decorateComposite(array_type->getElementType(), spirv_elem_type);
+  }
+}
+
+SPIRVVariable *LLVMToSPIRV::emitShaderSPIRVGlobal(
+    SPIRVFunction *spirv_func, const GlobalVariable &GV,
+    const std::string &var_name, uint32_t address_space,
+    const spirv_global_io_type global_type, spv::BuiltIn builtin) {
+  spv::StorageClass storage_class = spv::StorageClassUniform;
+  if (global_type.is_builtin) {
+    storage_class = (global_type.is_input ? spv::StorageClassInput
+                                          : spv::StorageClassOutput);
+  } else if (global_type.is_input) {
+    storage_class = spv::StorageClassInput;
+  } else if (global_type.is_uniform) {
+    storage_class = spv::StorageClassUniform;
+  } else {
+    storage_class = spv::StorageClassOutput;
+  }
+
+  SPIRVType *mapped_type = nullptr;
+  if (global_type.is_uniform) {
+    assert(GV.getType()->isPointerTy() && "uniform must be a pointer type");
+    auto elem_type = GV.getType()->getPointerElementType();
+    auto spirv_elem_type = transType(elem_type);
+    if (!global_type.is_constant) {
+      // this is a SSBO with an unknown size, switch out the top pointer
+      // type with a runtime array type
+      auto rtarr_type = BM->addRuntimeArrayType(spirv_elem_type);
+      std::string enclosing_type_name = "enclose.";
+      if (elem_type->isStructTy()) {
+        enclosing_type_name += elem_type->getStructName().str();
+      } else {
+        std::string type_str = "";
+        llvm::raw_string_ostream type_stream(type_str);
+        elem_type->print(type_stream, false, true);
+        enclosing_type_name += type_stream.str();
+      }
+      auto enclosing_type = BM->openStructType(1, enclosing_type_name);
+      enclosing_type->setMemberType(0, rtarr_type);
+      BM->closeStructType(enclosing_type, false);
+      mapped_type =
+          BM->addPointerType(spv::StorageClassUniform, enclosing_type);
+
+      // add required deco
+      enclosing_type->addDecorate(
+          new SPIRVDecorate(DecorationBufferBlock, enclosing_type));
+      enclosing_type->addMemberDecorate(0, spv::DecorationOffset, 0);
+      rtarr_type->addDecorate(spv::DecorationArrayStride,
+                              M->getDataLayout().getTypeStoreSize(elem_type));
+    } else {
+      assert(elem_type->isStructTy() && "uniform type must be a struct");
+
+      mapped_type = transType(GV.getType());
+
+      // deco
+      spirv_elem_type->addDecorate(
+          new SPIRVDecorate(DecorationBlock, spirv_elem_type));
+    }
+    decorateComposite(elem_type, spirv_elem_type);
+  } else {
+    mapped_type = transType(GV.getType());
+  }
+
+  auto BVar = static_cast<SPIRVVariable *>(
+      BM->addVariable(mapped_type, false, spv::LinkageTypeInternal, nullptr,
+                      GV.getName(), storage_class, nullptr));
+  BM->setName(BVar, GV.getName().str());
+  mapValue((Value *)&GV, BVar);
+
+  if (global_type.is_builtin) {
+    BVar->setBuiltin(builtin);
+  }
+
+  if (!global_type.is_uniform) {
+    BM->addEntryPointIO(spirv_func->getId(), BVar);
+  }
+
+  // set non-readable/-writable deco on SSBOs
+  if (global_type.is_uniform && !global_type.is_constant) {
+    if (global_type.is_read_only) {
+      BVar->addDecorate(new SPIRVDecorate(DecorationNonWritable, BVar));
+    } else if (global_type.is_write_only) {
+      BVar->addDecorate(new SPIRVDecorate(DecorationNonReadable, BVar));
+    }
+  }
+
+  return BVar;
+}
+
+GlobalVariable *LLVMToSPIRV::emitShaderGlobal(
+    const Function &F, SPIRVFunction *spirv_func, const std::string &var_name,
+    llvm::Type *llvm_type, uint32_t address_space,
+    const spirv_global_io_type global_type, SPIRVVariable **created_spirv_var,
+    spv::BuiltIn builtin) {
+  std::string name_type = ".";
+  if (global_type.is_builtin) {
+    name_type = (global_type.is_input ? ".vulkan_builtin_input."
+                                      : ".vulkan_builtin_output.");
+  } else if (global_type.is_input) {
+    name_type = ".vulkan_input.";
+  } else if (global_type.is_uniform) {
+    name_type = ".vulkan_uniform.";
+  }
+
+  auto GV =
+      new GlobalVariable(*M, llvm_type, false, GlobalVariable::InternalLinkage,
+                         nullptr, F.getName().str() + name_type + var_name,
+                         nullptr, GlobalValue::NotThreadLocal, address_space);
+
+  // also add the SPIR-V global
+  auto spirv_var = emitShaderSPIRVGlobal(spirv_func, *GV, var_name,
+                                         address_space, global_type, builtin);
+  if (created_spirv_var != nullptr) {
+    *created_spirv_var = spirv_var;
+  }
+
+  return GV;
+}
+
+// helper function to figure out if a SSBO argument is only being written to
+// TODO/NOTE: since WriteOnly is a fairly new attribute, the FunctionAttrs pass
+// can't handle it yet (like it does for readonly/readnone) -> once it can infer
+// the WriteOnly attribute, use that instead
+static bool is_write_only_arg(Function &F, Argument &arg) {
+  // since Vulkan/SPIR-V is very restrictive on pointer usage, that makes this
+  // rather simple. however, we still bail out if we find something that we
+  // can't handle.
+  const std::function<bool(Value *)> user_recurse =
+      [&user_recurse](Value *val) {
+        for (User *user : val->users()) {
+          // is read from -> bail
+          if (isa<LoadInst>(user)) {
+            return false;
+          }
+          // is written to -> continue
+          else if (isa<StoreInst>(user)) {
+            continue;
+          }
+          // recurse for GEPs
+          else if (isa<GetElementPtrInst>(user)) {
+            // bail if GEP is used for loads
+            if (!user_recurse(user)) {
+              return false;
+            }
+          }
+          // calls are somewhat tricky
+          else if (CallInst *CI = dyn_cast<CallInst>(user)) {
+            // does read -> bail
+            if (!CI->doesNotReadMemory()) {
+              return false;
+            }
+            // we don't know what the call is doing exactly, but if it does
+            // return a pointer, assume it's us
+            if (CI->getType()->isPointerTy()) {
+              if (!user_recurse(user)) {
+                return false;
+              }
+            }
+          }
+          // NOTE: Vulkan/SPIR-V doesn't allow pointer usage in
+          // select/phi/bitcast, so we're good here
+          // unknown usage -> assume it's being read
+          else {
+            return false;
+          }
+        }
+        // didn't find any loads -> write-only
+        return true;
+      };
+  return user_recurse(&arg);
+}
+
+void LLVMToSPIRV::transFunction(Function *F) {
+  // again, ignore any floor.* functions
+  if (F->getName().startswith("floor."))
+    return;
+
+  auto spirv_func = transFunctionDecl(F);
+
+  // we're only interested in shader entry points here
+  // TODO: cleanup + move to functions
+  if (SrcLang == SourceLanguageGLSL &&
+      (F->getCallingConv() == llvm::CallingConv::FLOOR_KERNEL ||
+       F->getCallingConv() == llvm::CallingConv::FLOOR_VERTEX ||
+       F->getCallingConv() == llvm::CallingConv::FLOOR_FRAGMENT)) {
+    VULKAN_STAGE stage;
+    switch (F->getCallingConv()) {
+    case llvm::CallingConv::FLOOR_VERTEX:
+      stage = VULKAN_STAGE::VERTEX;
+      break;
+    case llvm::CallingConv::FLOOR_FRAGMENT:
+      stage = VULKAN_STAGE::FRAGMENT;
+      break;
+    case llvm::CallingConv::FLOOR_KERNEL:
+      stage = VULKAN_STAGE::KERNEL;
+      break;
+    default:
+      return;
+    }
+
+    const std::string func_name = F->getName().str();
+    std::vector<std::string> md_data_input, md_data_output;
+    auto vulkan_io_md = M->getNamedMetadata("vulkan.stage_io");
+    assert(vulkan_io_md != nullptr && "vulkan.io metadata doesn't exist");
+    for (const auto &op : vulkan_io_md->operands()) {
+      assert(op->getNumOperands() > 0 &&
+             "invalid op count in vulkan.io metadata");
+      if (auto md_func_name = dyn_cast<llvm::MDString>(op->getOperand(0))) {
+        if (md_func_name->getString() == func_name) {
+          // found our function, dump metadata strings to an easier to use
+          // vector<string>
+          bool at_input = false, at_output = false;
+          for (uint32_t i = 1; i < op->getNumOperands(); ++i) {
+            const auto md_op_str =
+                dyn_cast<llvm::MDString>(op->getOperand(i))->getString();
+
+            if (md_op_str == "stage_input") {
+              at_input = true;
+              at_output = false;
+              continue;
+            } else if (md_op_str == "stage_output") {
+              at_input = false;
+              at_output = true;
+              continue;
+            }
+
+            if (at_input)
+              md_data_input.emplace_back(md_op_str.str());
+            else if (at_output)
+              md_data_output.emplace_back(md_op_str.str());
+          }
+          break;
+        }
+      }
+    }
+
+    const auto get_builtin =
+        [](const std::string &str) -> std::pair<spv::BuiltIn, bool> {
+      static const std::unordered_map<std::string, spv::BuiltIn> builtin_lut{
+          {"position", spv::BuiltInPosition},
+          {"point_size", spv::BuiltInPointSize},
+          {"clip_distance", spv::BuiltInClipDistance},
+          {"cull_distance", spv::BuiltInCullDistance},
+          //{ "vertex_id", spv::BuiltInVertexId }, // unsupported in vulkan
+          //{ "instance_id", spv::BuiltInInstanceId }, // unsupported in vulkan
+          {"primitive_id", spv::BuiltInPrimitiveId},
+          {"invocation_id", spv::BuiltInInvocationId},
+          {"layer", spv::BuiltInLayer},
+          {"viewport_index", spv::BuiltInViewportIndex},
+          {"tess_level_outer", spv::BuiltInTessLevelOuter},
+          {"tess_level_inner", spv::BuiltInTessLevelInner},
+          {"tess_coord", spv::BuiltInTessCoord},
+          {"patch_vertices", spv::BuiltInPatchVertices},
+          {"frag_coord", spv::BuiltInFragCoord},
+          {"point_coord", spv::BuiltInPointCoord},
+          {"front_facing", spv::BuiltInFrontFacing},
+          {"sample_id", spv::BuiltInSampleId},
+          {"sample_position", spv::BuiltInSamplePosition},
+          {"sample_mask", spv::BuiltInSampleMask},
+          {"frag_depth", spv::BuiltInFragDepth},
+          {"helper_invocation", spv::BuiltInHelperInvocation},
+          {"num_workgroups", spv::BuiltInNumWorkgroups},
+          //{ "workgroup_size", spv::BuiltInWorkgroupSize }, // NOTE: must be a
+          // constant or spec constant
+          {"workgroup_id", spv::BuiltInWorkgroupId},
+          {"local_invocation_id", spv::BuiltInLocalInvocationId},
+          {"global_invocation_id", spv::BuiltInGlobalInvocationId},
+          // OpenCL-only:
+          //{ "local_invocation_index", spv::BuiltInLocalInvocationIndex },
+          //{ "work_dim", spv::BuiltInWorkDim },
+          //{ "global_size", spv::BuiltInGlobalSize },
+          //{ "enqueued_workgroup_size", spv::BuiltInEnqueuedWorkgroupSize },
+          //{ "global_offset", spv::BuiltInGlobalOffset },
+          //{ "global_linear_id", spv::BuiltInGlobalLinearId },
+          //{ "subgroup_size", spv::BuiltInSubgroupSize },
+          //{ "subgroup_max_size", spv::BuiltInSubgroupMaxSize },
+          //{ "num_subgroups", spv::BuiltInNumSubgroups },
+          //{ "num_enqueued_subgroups", spv::BuiltInNumEnqueuedSubgroups },
+          //{ "subgroup_id", spv::BuiltInSubgroupId },
+          //{ "subgroup_local_invocation_id",
+          // spv::BuiltInSubgroupLocalInvocationId },
+          {"vertex_index", spv::BuiltInVertexIndex},
+          {"instance_index", spv::BuiltInInstanceIndex},
+      };
+      const auto iter = builtin_lut.find(str);
+      if (iter == builtin_lut.end()) {
+        return {spv::BuiltInPosition, false};
+      }
+      return {iter->second, true};
+    };
+    const auto is_builtin_valid_in_stage = [](const spv::BuiltIn &builtin,
+                                              const VULKAN_STAGE &stage,
+                                              const bool is_input) {
+      // NOTE: the non-listed/commented ones are unsupported in vulkan
+      static const std::unordered_map<spv::BuiltIn, VULKAN_STAGE>
+          builtin_validity_input_lut{
+              {spv::BuiltInPosition, (VULKAN_STAGE::TESSELLATION_CONTROL |
+                                      VULKAN_STAGE::TESSELLATION_EVALUATION |
+                                      VULKAN_STAGE::GEOMETRY)},
+              {spv::BuiltInPointSize, (VULKAN_STAGE::TESSELLATION_CONTROL |
+                                       VULKAN_STAGE::TESSELLATION_EVALUATION |
+                                       VULKAN_STAGE::GEOMETRY)},
+              {spv::BuiltInClipDistance,
+               (VULKAN_STAGE::FRAGMENT | VULKAN_STAGE::TESSELLATION_CONTROL |
+                VULKAN_STAGE::TESSELLATION_EVALUATION |
+                VULKAN_STAGE::GEOMETRY)},
+              {spv::BuiltInCullDistance,
+               (VULKAN_STAGE::FRAGMENT | VULKAN_STAGE::TESSELLATION_CONTROL |
+                VULKAN_STAGE::TESSELLATION_EVALUATION |
+                VULKAN_STAGE::GEOMETRY)},
+              //{ spv::BuiltInVertexId, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInInstanceId, VULKAN_STAGE::NONE },
+              {spv::BuiltInPrimitiveId, VULKAN_STAGE::GEOMETRY},
+              {spv::BuiltInInvocationId,
+               (VULKAN_STAGE::TESSELLATION_CONTROL | VULKAN_STAGE::GEOMETRY)},
+              {spv::BuiltInLayer, VULKAN_STAGE::FRAGMENT},
+              {spv::BuiltInViewportIndex, VULKAN_STAGE::FRAGMENT},
+              {spv::BuiltInTessLevelOuter,
+               VULKAN_STAGE::TESSELLATION_EVALUATION},
+              {spv::BuiltInTessLevelInner,
+               VULKAN_STAGE::TESSELLATION_EVALUATION},
+              {spv::BuiltInTessCoord, VULKAN_STAGE::TESSELLATION_EVALUATION},
+              {spv::BuiltInPatchVertices,
+               (VULKAN_STAGE::TESSELLATION_CONTROL |
+                VULKAN_STAGE::TESSELLATION_EVALUATION)},
+              {spv::BuiltInFragCoord, VULKAN_STAGE::FRAGMENT},
+              {spv::BuiltInPointCoord, VULKAN_STAGE::FRAGMENT},
+              {spv::BuiltInFrontFacing, VULKAN_STAGE::FRAGMENT},
+              {spv::BuiltInSampleId, VULKAN_STAGE::FRAGMENT},
+              {spv::BuiltInSamplePosition, VULKAN_STAGE::FRAGMENT},
+              {spv::BuiltInSampleMask, VULKAN_STAGE::FRAGMENT},
+              {spv::BuiltInFragDepth, VULKAN_STAGE::NONE},
+              {spv::BuiltInHelperInvocation, VULKAN_STAGE::FRAGMENT},
+              {spv::BuiltInNumWorkgroups, VULKAN_STAGE::KERNEL},
+              {spv::BuiltInWorkgroupSize,
+               VULKAN_STAGE::NONE}, // NOTE: must be a constant or spec constant
+              {spv::BuiltInWorkgroupId, VULKAN_STAGE::KERNEL},
+              {spv::BuiltInLocalInvocationId, VULKAN_STAGE::KERNEL},
+              {spv::BuiltInGlobalInvocationId, VULKAN_STAGE::KERNEL},
+              //{ spv::BuiltInLocalInvocationIndex, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInWorkDim, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInGlobalSize, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInEnqueuedWorkgroupSize, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInGlobalOffset, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInGlobalLinearId, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInSubgroupSize, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInSubgroupMaxSize, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInNumSubgroups, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInNumEnqueuedSubgroups, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInSubgroupId, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInSubgroupLocalInvocationId, VULKAN_STAGE::NONE },
+              {spv::BuiltInVertexIndex, VULKAN_STAGE::VERTEX},
+              {spv::BuiltInInstanceIndex, VULKAN_STAGE::VERTEX},
+          };
+      static const std::unordered_map<spv::BuiltIn, VULKAN_STAGE>
+          builtin_validity_output_lut{
+              {spv::BuiltInPosition,
+               (VULKAN_STAGE::VERTEX | VULKAN_STAGE::TESSELLATION_CONTROL |
+                VULKAN_STAGE::TESSELLATION_EVALUATION |
+                VULKAN_STAGE::GEOMETRY)},
+              {spv::BuiltInPointSize,
+               (VULKAN_STAGE::VERTEX | VULKAN_STAGE::TESSELLATION_CONTROL |
+                VULKAN_STAGE::TESSELLATION_EVALUATION |
+                VULKAN_STAGE::GEOMETRY)},
+              {spv::BuiltInClipDistance,
+               (VULKAN_STAGE::VERTEX | VULKAN_STAGE::TESSELLATION_CONTROL |
+                VULKAN_STAGE::TESSELLATION_EVALUATION |
+                VULKAN_STAGE::GEOMETRY)},
+              {spv::BuiltInCullDistance,
+               (VULKAN_STAGE::VERTEX | VULKAN_STAGE::TESSELLATION_CONTROL |
+                VULKAN_STAGE::TESSELLATION_EVALUATION |
+                VULKAN_STAGE::GEOMETRY)},
+              //{ spv::BuiltInVertexId, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInInstanceId, VULKAN_STAGE::NONE },
+              {spv::BuiltInPrimitiveId,
+               (VULKAN_STAGE::FRAGMENT | VULKAN_STAGE::TESSELLATION_CONTROL |
+                VULKAN_STAGE::TESSELLATION_EVALUATION |
+                VULKAN_STAGE::GEOMETRY)},
+              {spv::BuiltInInvocationId, VULKAN_STAGE::NONE},
+              {spv::BuiltInLayer, VULKAN_STAGE::GEOMETRY},
+              {spv::BuiltInViewportIndex, VULKAN_STAGE::GEOMETRY},
+              {spv::BuiltInTessLevelOuter, VULKAN_STAGE::TESSELLATION_CONTROL},
+              {spv::BuiltInTessLevelInner, VULKAN_STAGE::TESSELLATION_CONTROL},
+              {spv::BuiltInTessCoord, VULKAN_STAGE::NONE},
+              {spv::BuiltInPatchVertices, VULKAN_STAGE::NONE},
+              {spv::BuiltInFragCoord, VULKAN_STAGE::NONE},
+              {spv::BuiltInPointCoord, VULKAN_STAGE::NONE},
+              {spv::BuiltInFrontFacing, VULKAN_STAGE::NONE},
+              {spv::BuiltInSampleId, VULKAN_STAGE::NONE},
+              {spv::BuiltInSamplePosition, VULKAN_STAGE::NONE},
+              {spv::BuiltInSampleMask, VULKAN_STAGE::FRAGMENT},
+              {spv::BuiltInFragDepth, VULKAN_STAGE::FRAGMENT},
+              {spv::BuiltInHelperInvocation, VULKAN_STAGE::NONE},
+              {spv::BuiltInNumWorkgroups, VULKAN_STAGE::NONE},
+              {spv::BuiltInWorkgroupSize, VULKAN_STAGE::NONE},
+              {spv::BuiltInWorkgroupId, VULKAN_STAGE::NONE},
+              {spv::BuiltInLocalInvocationId, VULKAN_STAGE::NONE},
+              {spv::BuiltInGlobalInvocationId, VULKAN_STAGE::NONE},
+              //{ spv::BuiltInLocalInvocationIndex, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInWorkDim, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInGlobalSize, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInEnqueuedWorkgroupSize, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInGlobalOffset, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInGlobalLinearId, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInSubgroupSize, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInSubgroupMaxSize, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInNumSubgroups, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInNumEnqueuedSubgroups, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInSubgroupId, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInSubgroupLocalInvocationId, VULKAN_STAGE::NONE },
+              {spv::BuiltInVertexIndex, VULKAN_STAGE::NONE},
+              {spv::BuiltInInstanceIndex, VULKAN_STAGE::NONE},
+          };
+
+      if (is_input) {
+        const auto iter = builtin_validity_input_lut.find(builtin);
+        if (iter == builtin_validity_input_lut.end()) {
+          return false;
+        }
+        return (iter->second & stage) != VULKAN_STAGE::NONE;
+      } else {
+        const auto iter = builtin_validity_output_lut.find(builtin);
+        if (iter == builtin_validity_output_lut.end()) {
+          return false;
+        }
+        return (iter->second & stage) != VULKAN_STAGE::NONE;
+      }
+    };
+
+    // handle parameters (input or globals)
+    uint32_t input_arg_idx = 0, uniform_arg_idx = 0;
+    uint32_t desc_set = 0;
+    switch (stage) { // put each stage into a different set
+    case VULKAN_STAGE::KERNEL:
+    case VULKAN_STAGE::VERTEX:
+      desc_set = 0;
+      break;
+    case VULKAN_STAGE::FRAGMENT:
+      desc_set = 1;
+      break;
+    case VULKAN_STAGE::GEOMETRY:
+      desc_set = 2;
+      break;
+    case VULKAN_STAGE::TESSELLATION_CONTROL:
+      desc_set = 3;
+      break;
+    case VULKAN_STAGE::TESSELLATION_EVALUATION:
+      desc_set = 4;
+      break;
+    default:
+      llvm_unreachable("invalid stage");
+    }
+    for (Argument &arg : F->args()) {
+      llvm::Type *arg_type = arg.getType();
+      const auto arg_name = arg.getName();
+
+      if (arg_type->isPointerTy() &&
+          arg_type->getPointerAddressSpace() != SPIRAS_Input) {
+        llvm::Type *elem_type = arg_type->getPointerElementType();
+
+        // -> globals
+        SPIRVVariable *uniform_var = nullptr;
+        if (arg.onlyReadsMemory() &&
+            (arg.hasAttribute(Attribute::Dereferenceable) ||
+             arg.hasAttribute(Attribute::DereferenceableOrNull))) {
+          // -> Block uniform (TODO: could also make this a push constant later
+          // on)
+          spirv_global_io_type global_type;
+          global_type.is_constant = true;
+          global_type.is_uniform = true;
+          global_type.is_read_only = true;
+          auto GV = emitShaderGlobal(*F, spirv_func, arg_name.str(), elem_type,
+                                     SPIRAS_Uniform, global_type, &uniform_var);
+          arg.replaceAllUsesWith(GV);
+        } else if (arg_type->getPointerAddressSpace() == SPIRAS_Uniform) {
+          // all image types are opaque/unsized
+          if (!elem_type->isSized()) {
+            // -> TODO: image
+            errs() << "images are not handled yet\n";
+          } else {
+            // -> BufferBlock uniform (SSBO)
+            spirv_global_io_type global_type;
+            global_type.is_uniform = true;
+            global_type.is_read_only = arg.onlyReadsMemory();
+            global_type.is_write_only =
+                (!global_type.is_read_only ? is_write_only_arg(*F, arg)
+                                           : false);
+            auto GV =
+                emitShaderGlobal(*F, spirv_func, arg_name.str(), elem_type,
+                                 SPIRAS_Uniform, global_type, &uniform_var);
+            arg.replaceAllUsesWith(GV);
+          }
+        } else if (arg_type->getPointerAddressSpace() == SPIRAS_Local) {
+          // -> local memory (TODO: implement this)
+          llvm_unreachable("local memory parameters are not yet implemented");
+        } else if (arg_type->getPointerAddressSpace() == SPIRAS_Generic) {
+          // -> unknown generic
+          llvm_unreachable("generic parameters are not supported");
+        } else
+          llvm_unreachable("unknown parameter address space");
+
+        //
+        uniform_var->addDecorate(
+            new SPIRVDecorate(DecorationDescriptorSet, uniform_var, desc_set));
+        uniform_var->addDecorate(
+            new SPIRVDecorate(DecorationBinding, uniform_var, uniform_arg_idx));
+        ++uniform_arg_idx;
+      } else {
+        if (md_data_input[input_arg_idx] != "none") {
+          // -> special input variable
+          // transform function parameter to in-function alloca + input
+          // annotation
+          const auto builtin = get_builtin(md_data_input[input_arg_idx]);
+          if (!builtin.second) {
+            errs() << "unknown builtin: " << md_data_input[input_arg_idx]
+                   << "\n";
+          }
+
+          const auto is_valid =
+              is_builtin_valid_in_stage(builtin.first, stage, true /* input */);
+          if (is_valid) {
+            llvm::Type *elem_type = arg_type->getPointerElementType();
+            spirv_global_io_type global_type;
+            global_type.is_input = true;
+            global_type.is_builtin = true;
+            auto repl_var = emitShaderGlobal(
+                *F, spirv_func, arg_name, elem_type, SPIRAS_Input, global_type,
+                nullptr, builtin.first);
+            arg.replaceAllUsesWith(repl_var);
+          } else {
+            // TODO: should catch this earlier
+            if (arg.getNumUses() > 0) {
+              errs() << "input builtin \"" << md_data_input[input_arg_idx]
+                     << "\" can not be used in stage \""
+                     << vulkan_stage_to_string(stage) << "\"\n";
+            }
+          }
+        } else {
+          // -> stage input
+          spirv_global_io_type global_type;
+          global_type.is_input = true;
+          global_type.is_read_only = true;
+          auto repl_var = emitShaderGlobal(*F, spirv_func, arg_name, arg_type,
+                                           SPIRAS_Input, global_type);
+          // only emit load if there actually is a user
+          if (arg.getNumUses() > 0) {
+            LoadInst *load_repl_var = new LoadInst(repl_var, arg_name, false,
+                                                   &*next(F->front().begin()));
+            arg.replaceAllUsesWith(load_repl_var);
+          }
+        }
+        ++input_arg_idx;
+      }
+    }
+
+    // handle return value / output
+    // TODO: more metadata + handling
+    // NOTE: inputs, builtins and uniforms are handled on the SPIRVLib side
+    // above, outputs are however already handled on the LLVM side (VulkanFinal
+    // pass) and thus have no SPIRVVariable mapping yet and have not been added
+    // to the entry point i/o set yet
+    // -> create SPIRVVariable for outputs + add them to the entry point i/o set
+    // in here
+    const std::string output_var_name_stub = func_name + ".vulkan_output.";
+    uint32_t output_arg_idx = 0;
+    for (const auto &GV : M->globals()) {
+      if (GV.hasName() &&
+          GV.getName().find(output_var_name_stub) != std::string::npos) {
+        auto output_name = GV.getName().split(".vulkan_output.").second;
+        const auto is_fbo_output = (md_data_output[output_arg_idx].find(
+                                        "fbo_output:") != std::string::npos);
+        if (!is_fbo_output && md_data_output[output_arg_idx] != "none") {
+          const auto builtin = get_builtin(md_data_output[output_arg_idx]);
+          if (!builtin.second) {
+            errs() << "unknown builtin: " << md_data_output[output_arg_idx]
+                   << "\n";
+          }
+
+          const auto is_valid = is_builtin_valid_in_stage(builtin.first, stage,
+                                                          false /* output */);
+          if (is_valid) {
+            spirv_global_io_type global_type;
+            global_type.is_builtin = true;
+            global_type.is_write_only = true;
+            emitShaderSPIRVGlobal(spirv_func, GV, output_name, SPIRAS_Output,
+                                  global_type, builtin.first);
+          } else {
+            // TODO: should catch this earlier
+            errs() << "output builtin \"" << md_data_output[output_arg_idx]
+                   << "\" can not be used in stage \""
+                   << vulkan_stage_to_string(stage) << "\"\n";
+          }
+        } else if (is_fbo_output) {
+          spirv_global_io_type global_type;
+          global_type.is_write_only = true;
+          auto fbo_output_var = emitShaderSPIRVGlobal(
+              spirv_func, GV, output_name, SPIRAS_Output, global_type);
+
+          // extract location idx + add the resp. decoration
+          const auto location_str = md_data_output[output_arg_idx].substr(
+              md_data_output[output_arg_idx].rfind(':'));
+          const auto location = (uint32_t)strtoull(
+              md_data_output[output_arg_idx].c_str(), nullptr, 10);
+          fbo_output_var->addDecorate(
+              new SPIRVDecorate(DecorationLocation, fbo_output_var, location));
+        } else {
+          spirv_global_io_type global_type;
+          global_type.is_write_only = true;
+          emitShaderSPIRVGlobal(spirv_func, GV, output_name, SPIRAS_Output,
+                                global_type);
+        }
+        ++output_arg_idx;
+      }
+    }
+
+    // set compute shader constant work-group size
+    if (F->getCallingConv() == llvm::CallingConv::FLOOR_KERNEL) {
+      const auto global_name = func_name + ".vulkan_constant.workgroup_size";
+      auto gv_wg_size = M->getNamedGlobal(global_name);
+      const auto llvm_wg_size_init =
+          ((llvm::ConstantVector *)gv_wg_size->getInitializer());
+      const uint32_t llvm_wg_size_vals[3]{
+          (uint32_t)(
+              (llvm::ConstantInt *)llvm_wg_size_init->getAggregateElement(0u))
+              ->getZExtValue(),
+          (uint32_t)(
+              (llvm::ConstantInt *)llvm_wg_size_init->getAggregateElement(1u))
+              ->getZExtValue(),
+          (uint32_t)(
+              (llvm::ConstantInt *)llvm_wg_size_init->getAggregateElement(2u))
+              ->getZExtValue(),
+      };
+      auto uint_type = BM->addIntegerType(32, false);
+      auto uint3_type = BM->addVectorType(uint_type, 3);
+      std::vector<SPIRVValue *> wg_size_vals{
+          BM->addIntegerConstant(uint_type, llvm_wg_size_vals[0]),
+          BM->addIntegerConstant(uint_type, llvm_wg_size_vals[1]),
+          BM->addIntegerConstant(uint_type, llvm_wg_size_vals[2]),
+      };
+      auto wg_size = BM->addCompositeConstant(uint3_type, wg_size_vals);
+      wg_size->addDecorate(spv::DecorationBuiltIn, spv::BuiltInWorkgroupSize);
+      BM->setName(wg_size, global_name);
+      spirv_func->addExecutionMode(new SPIRVExecutionMode(
+          spirv_func, spv::ExecutionModeLocalSize, llvm_wg_size_vals[0],
+          llvm_wg_size_vals[1], llvm_wg_size_vals[2]));
+    }
+  }
+
+  // Create all basic blocks before creating any instruction.
+  for (Function::iterator FI = F->begin(), FE = F->end(); FI != FE; ++FI) {
+    transValue(&*FI, nullptr);
+  }
+
+  // handle global constant variables, these need to be lowered to
+  // function-scope (duplicate per function)
+  // NOTE: needs to be done after basic blocks have been created (to add
+  // OpVariables), but before being used when adding the instructions
+  std::unordered_set<GlobalVariable *> added_globals;
+  for (auto &GV : M->globals()) {
+    // don't want to handle the globals that we added in here
+    if (added_globals.count(&GV) > 0)
+      continue;
+
+    if (SPIRSPIRVAddrSpaceMap::map(static_cast<SPIRAddressSpace>(
+            GV.getType()->getAddressSpace())) == spv::StorageClassFunction) {
+      bool is_used_in_function = false;
+      for (const auto &user : GV.users()) {
+        if (const auto instr = cast<Instruction>(user)) {
+          if (instr->getParent()->getParent() == F) {
+            is_used_in_function = true;
+            break;
+          }
+        }
+      }
+      if (!is_used_in_function)
+        continue;
+
+      // duplicate the global + replace all uses of it in this function with the
+      // duplicate
+      auto dup = new GlobalVariable(
+          *M, GV.getType()->getPointerElementType(), GV.isConstant(),
+          GlobalVariable::InternalLinkage,
+          (GV.hasInitializer() ? GV.getInitializer() : nullptr),
+          GV.getName() + "." + F->getName(), nullptr,
+          GlobalValue::NotThreadLocal, GV.getType()->getAddressSpace());
+      added_globals.emplace(dup);
+
+      // need to copy all uses beforehand due iter invalidation
+      std::vector<Use *> uses;
+      uses.reserve(GV.getNumUses());
+      for (auto &use : GV.uses()) {
+        uses.emplace_back(&use);
+      }
+
+      for (auto &use : uses) {
+        if (const auto instr = dyn_cast<Instruction>(use->getUser())) {
+          if (instr->getParent()->getParent() == F) {
+            use->set(dup);
+          }
+        }
+      }
+
+      // translate value/duplicate at the beginnging of the entry BB of this
+      // function
+      auto BB = (SPIRVBasicBlock *)transValue(&F->getEntryBlock(), nullptr);
+      transValue(dup, BB);
+    }
+  }
+
+  // create all instructions
+  for (Function::iterator FI = F->begin(), FE = F->end(); FI != FE; ++FI) {
+    SPIRVBasicBlock *BB =
+        static_cast<SPIRVBasicBlock *>(transValue(&*FI, nullptr));
+    for (BasicBlock::iterator BI = FI->begin(), BE = FI->end(); BI != BE;
+         ++BI) {
+      transValue(&*BI, BB, false);
+    }
+  }
+}
+
+bool LLVMToSPIRV::translate() {
+  BM->setGeneratorVer(kTranslatorVer);
+
+  if (!transSourceLanguage())
+    return false;
+  if (!transExtension())
+    return false;
+  if (!transBuiltinSet())
+    return false;
+  if (!transAddressingMode())
+    return false;
+  if (!transGlobalVariables())
+    return false;
+
+  for (Module::iterator I = M->begin(), E = M->end(); I != E; ++I) {
+    Function *F = &*I;
+    auto FT = F->getFunctionType();
+    std::map<unsigned, Type *> ChangedType;
+    oclGetMutatedArgumentTypesByBuiltin(FT, ChangedType, F);
+    mutateFuncArgType(ChangedType, F);
+  }
+
+  // SPIR-V logical layout requires all function declarations go before
+  // function definitions.
+  std::vector<Function *> Decls, Defs;
+  for (Module::iterator I = M->begin(), E = M->end(); I != E; ++I) {
+    if (isBuiltinTransToInst(&*I) || isBuiltinTransToExtInst(&*I) ||
+        I->getName().startswith(SPCV_CAST) ||
+        I->getName().startswith(LLVM_MEMCPY))
+      continue;
+    if (I->isDeclaration())
+      Decls.push_back(&*I);
+    else
+      Defs.push_back(&*I);
+  }
+  for (auto I : Decls)
+    transFunctionDecl(I);
+  for (auto I : Defs)
+    transFunction(I);
+
+  if (!transOCLKernelMetadata())
+    return false;
+  if (!transExecutionMode())
+    return false;
+
+  // TODO/NOTE: disabled for now due to external issues
+  // BM->optimizeDecorates();
+  BM->resolveUnknownStructFields();
+  BM->createForwardPointers();
+  return true;
+}
+
+llvm::IntegerType *LLVMToSPIRV::getSizetType() {
+  return IntegerType::getIntNTy(M->getContext(),
+                                M->getDataLayout().getPointerSizeInBits());
+}
+
+void LLVMToSPIRV::oclGetMutatedArgumentTypesByBuiltin(
+    llvm::FunctionType *FT, std::map<unsigned, Type *> &ChangedType,
+    Function *F) {
+  auto Name = F->getName();
+  std::string Demangled;
+  if (!oclIsBuiltin(Name, &Demangled))
+    return;
+  if (Demangled.find(kSPIRVName::SampledImage) == std::string::npos)
+    return;
+  if (FT->getParamType(1)->isIntegerTy())
+    ChangedType[1] = getSamplerType(F->getParent());
+}
+
+SPIRVInstruction *
+LLVMToSPIRV::transBuiltinToInst(const std::string &DemangledName,
+                                const std::string &MangledName, CallInst *CI,
+                                SPIRVBasicBlock *BB) {
+  SmallVector<std::string, 2> Dec;
+  auto OC = getSPIRVFuncOC(DemangledName, &Dec);
+
+  if (OC == OpNop)
+    return nullptr;
+
+  auto Inst = transBuiltinToInstWithoutDecoration(OC, CI, BB);
+  addDecorations(Inst, Dec);
+  return Inst;
+}
+
+bool LLVMToSPIRV::transExecutionMode() {
+  if (auto NMD = SPIRVMDWalker(*M).getNamedMD(kSPIRVMD::ExecutionMode)) {
+    while (!NMD.atEnd()) {
+      unsigned EMode = ~0U;
+      Function *F = nullptr;
+      auto N = NMD.nextOp(); /* execution mode MDNode */
+      N.get(F).get(EMode);
+
+      SPIRVFunction *BF = static_cast<SPIRVFunction *>(getTranslatedValue(F));
+      assert(BF && "Invalid kernel function");
+      if (!BF)
+        return false;
+
+      switch (EMode) {
+      case spv::ExecutionModeContractionOff:
+      case spv::ExecutionModeInitializer:
+      case spv::ExecutionModeFinalizer:
+        BF->addExecutionMode(
+            new SPIRVExecutionMode(BF, static_cast<ExecutionMode>(EMode)));
+        break;
+      case spv::ExecutionModeLocalSize:
+      case spv::ExecutionModeLocalSizeHint: {
+        unsigned X, Y, Z;
+        N.get(X).get(Y).get(Z);
+        BF->addExecutionMode(new SPIRVExecutionMode(
+            BF, static_cast<ExecutionMode>(EMode), X, Y, Z));
+      } break;
+      case spv::ExecutionModeVecTypeHint:
+      case spv::ExecutionModeSubgroupSize:
+      case spv::ExecutionModeSubgroupsPerWorkgroup: {
+        unsigned X;
+        N.get(X);
+        BF->addExecutionMode(
+            new SPIRVExecutionMode(BF, static_cast<ExecutionMode>(EMode), X));
+      } break;
+      default:
+        llvm_unreachable("invalid execution mode");
+      }
+    }
+  }
+  return true;
+}
+
+bool LLVMToSPIRV::transOCLKernelMetadata() {
+  NamedMDNode *KernelMDs = M->getNamedMetadata(SPIR_MD_KERNELS);
+  std::vector<std::string> argAccessQual;
+  // TODO: do shaders need to be handled in here?
+  if (!KernelMDs || SrcLang == spv::SourceLanguageGLSL)
+    return true;
+
+  for (unsigned I = 0, E = KernelMDs->getNumOperands(); I < E; ++I) {
+    MDNode *KernelMD = KernelMDs->getOperand(I);
+    if (KernelMD->getNumOperands() == 0)
+      continue;
+    Function *Kernel = mdconst::dyn_extract<Function>(KernelMD->getOperand(0));
+
+    SPIRVFunction *BF =
+        static_cast<SPIRVFunction *>(getTranslatedValue(Kernel));
+    assert(BF && "Kernel function should be translated first");
+    assert(Kernel && oclIsEntryPoint(Kernel) &&
+           "Invalid entry point calling convention or metadata");
+    for (unsigned MI = 1, ME = KernelMD->getNumOperands(); MI < ME; ++MI) {
+      MDNode *MD = dyn_cast<MDNode>(KernelMD->getOperand(MI));
+      if (!MD)
+        continue;
+      MDString *NameMD = dyn_cast<MDString>(MD->getOperand(0));
+      if (!NameMD)
+        continue;
+      StringRef Name = NameMD->getString();
+      if (Name == SPIR_MD_KERNEL_ARG_TYPE_QUAL) {
+        foreachKernelArgMD(
+            MD, BF, [](const std::string &Str, SPIRVFunctionParameter *BA) {
+              if (Str.find("volatile") != std::string::npos)
+                BA->addDecorate(new SPIRVDecorate(DecorationVolatile, BA));
+              if (Str.find("restrict") != std::string::npos)
+                BA->addDecorate(
+                    new SPIRVDecorate(DecorationFuncParamAttr, BA,
+                                      FunctionParameterAttributeNoAlias));
+              if (Str.find("const") != std::string::npos)
+                BA->addDecorate(
+                    new SPIRVDecorate(DecorationFuncParamAttr, BA,
+                                      FunctionParameterAttributeNoWrite));
+            });
+      } else if (Name == SPIR_MD_KERNEL_ARG_NAME) {
+        foreachKernelArgMD(
+            MD, BF, [=](const std::string &Str, SPIRVFunctionParameter *BA) {
+              BM->setName(BA, Str);
+            });
+      }
+    }
+  }
+  return true;
+}
+
+bool LLVMToSPIRV::transSourceLanguage() {
+  auto Src = getSPIRVSource(M);
+  SrcLang = std::get<0>(Src);
+  SrcLangVer = std::get<1>(Src);
+  if (SrcLang == SourceLanguageGLSL) {
+    // "GLSL" is compiled as OpenCL 2.0 -> switch out the version number
+    SrcLangVer = 450;
+  }
+  BM->setSourceLanguage(static_cast<SourceLanguage>(SrcLang), SrcLangVer);
+  return true;
+}
+
+bool LLVMToSPIRV::transExtension() {
+  if (auto N = SPIRVMDWalker(*M).getNamedMD(kSPIRVMD::Extension)) {
+    while (!N.atEnd()) {
+      std::string S;
+      N.nextOp().get(S);
+      assert(!S.empty() && "Invalid extension");
+      BM->getExtension().insert(S);
+    }
+  }
+  if (auto N = SPIRVMDWalker(*M).getNamedMD(kSPIRVMD::SourceExtension)) {
+    while (!N.atEnd()) {
+      std::string S;
+      N.nextOp().get(S);
+      assert(!S.empty() && "Invalid extension");
+      BM->getSourceExtension().insert(S);
+    }
+  }
+  for (auto &I :
+       map<SPIRVCapabilityKind>(rmap<OclExt::Kind>(BM->getExtension())))
+    BM->addCapability(I);
+
+  return true;
+}
+
+void LLVMToSPIRV::dumpUsers(Value *V) {
+  SPIRVDBG(dbgs() << "Users of " << *V << " :\n");
+  for (auto UI = V->user_begin(), UE = V->user_end(); UI != UE; ++UI)
+    SPIRVDBG(dbgs() << "  " << **UI << '\n');
+}
+
+Op LLVMToSPIRV::transBoolOpCode(SPIRVValue *Opn, Op OC) {
+  if (!Opn->getType()->isTypeVectorOrScalarBool())
+    return OC;
+  IntBoolOpMap::find(OC, &OC);
+  return OC;
+}
+
+SPIRVInstruction *
+LLVMToSPIRV::transBuiltinToInstWithoutDecoration(Op OC, CallInst *CI,
+                                                 SPIRVBasicBlock *BB) {
+  if (isGroupOpCode(OC))
+    BM->addCapability(CapabilityGroups);
+  switch (OC) {
+  case OpControlBarrier: {
+    auto BArgs = transValue(getArguments(CI), BB);
+    return BM->addControlBarrierInst(BArgs[0], BArgs[1], BArgs[2], BB);
+  } break;
+  case OpGroupAsyncCopy: {
+    auto BArgs = transValue(getArguments(CI), BB);
+    return BM->addAsyncGroupCopy(BArgs[0], BArgs[1], BArgs[2], BArgs[3],
+                                 BArgs[4], BArgs[5], BB);
+  } break;
+  default: {
+    if (isCvtOpCode(OC) && OC != OpGenericCastToPtrExplicit) {
+      return BM->addUnaryInst(OC, transType(CI->getType()),
+                              transValue(CI->getArgOperand(0), BB), BB);
+    } else if (isCmpOpCode(OC)) {
+      assert(CI && CI->getNumArgOperands() == 2 && "Invalid call inst");
+      auto ResultTy = CI->getType();
+      Type *BoolTy = IntegerType::getInt1Ty(M->getContext());
+      auto IsVector = ResultTy->isVectorTy();
+      if (IsVector)
+        BoolTy = VectorType::get(BoolTy, ResultTy->getVectorNumElements());
+      auto BBT = transType(BoolTy);
+      auto Cmp = BM->addCmpInst(OC, BBT, transValue(CI->getArgOperand(0), BB),
+                                transValue(CI->getArgOperand(1), BB), BB);
+      auto Zero = transValue(Constant::getNullValue(ResultTy), BB);
+      auto One = transValue(
+          IsVector ? Constant::getAllOnesValue(ResultTy) : getInt32(M, 1), BB);
+      return BM->addSelectInst(Cmp, One, Zero, BB);
+    } else if (isBinaryOpCode(OC)) {
+      assert(CI && CI->getNumArgOperands() == 2 && "Invalid call inst");
+      return BM->addBinaryInst(OC, transType(CI->getType()),
+                               transValue(CI->getArgOperand(0), BB),
+                               transValue(CI->getArgOperand(1), BB), BB);
+    } else if (CI->getNumArgOperands() == 1 && !CI->getType()->isVoidTy() &&
+               !hasExecScope(OC) && !isAtomicOpCode(OC)) {
+      return BM->addUnaryInst(OC, transType(CI->getType()),
+                              transValue(CI->getArgOperand(0), BB), BB);
+    } else {
+      auto Args = getArguments(CI);
+      SPIRVType *SPRetTy = nullptr;
+      Type *RetTy = CI->getType();
+      auto F = CI->getCalledFunction();
+      if (!RetTy->isVoidTy()) {
+        SPRetTy = transType(RetTy);
+      } else if (Args.size() > 0 && F->arg_begin()->hasStructRetAttr()) {
+        SPRetTy = transType(F->arg_begin()->getType()->getPointerElementType());
+        Args.erase(Args.begin());
+      }
+      auto SPI = BM->addInstTemplate(OC, BB, SPRetTy);
+      std::vector<SPIRVWord> SPArgs;
+      for (size_t I = 0, E = Args.size(); I != E; ++I) {
+        assert((!isFunctionPointerType(Args[I]->getType()) ||
+                isa<Function>(Args[I])) &&
+               "Invalid function pointer argument");
+        SPArgs.push_back(SPI->isOperandLiteral(I)
+                             ? cast<ConstantInt>(Args[I])->getZExtValue()
+                             : transValue(Args[I], BB)->getId());
+      }
+      SPI->setOpWordsAndValidate(SPArgs);
+      if (!SPRetTy || !SPRetTy->isTypeStruct())
+        return SPI;
+      std::vector<SPIRVWord> Mem;
+      SPIRVDBG(spvdbgs() << *SPI << '\n');
+      return BM->addStoreInst(transValue(CI->getArgOperand(0), BB), SPI, Mem,
+                              BB);
+    }
+  }
+  }
+  return nullptr;
+}
+
+SPIRV::SPIRVLinkageTypeKind
+LLVMToSPIRV::transLinkageType(const GlobalValue *GV) {
+  if (GV->isDeclarationForLinker())
+    return SPIRVLinkageTypeKind::LinkageTypeImport;
+  if (GV->hasInternalLinkage() || GV->hasPrivateLinkage())
+    return SPIRVLinkageTypeKind::LinkageTypeInternal;
+  return SPIRVLinkageTypeKind::LinkageTypeExport;
+}
+} // end of SPIRV namespace
+
+char LLVMToSPIRV::ID = 0;
+
+INITIALIZE_PASS_BEGIN(LLVMToSPIRV, "llvmtospv", "Translate LLVM to SPIR-V",
+                      false, false)
+INITIALIZE_PASS_DEPENDENCY(OCLTypeToSPIRV)
+INITIALIZE_PASS_END(LLVMToSPIRV, "llvmtospv", "Translate LLVM to SPIR-V", false,
+                    false)
+
+ModulePass *llvm::createLLVMToSPIRV(SPIRVModule *SMod) {
+  return new LLVMToSPIRV(SMod);
+}
+
+void addPassesForSPIRV(legacy::PassManager &PassMgr) {
+  if (SPIRVMemToReg)
+    PassMgr.add(createPromoteMemoryToRegisterPass());
+  PassMgr.add(createTransOCLMD());
+  PassMgr.add(createOCL21ToSPIRV());
+  PassMgr.add(createSPIRVLowerOCLBlocks());
+  PassMgr.add(createOCLTypeToSPIRV());
+  PassMgr.add(createOCL20ToSPIRV());
+  PassMgr.add(createSPIRVRegularizeLLVM());
+  PassMgr.add(createSPIRVLowerConstExpr());
+  PassMgr.add(createSPIRVLowerBool());
+}
+
+bool llvm::WriteSPIRV(Module *M, llvm::raw_ostream &OS, std::string &ErrMsg) {
+  std::unique_ptr<SPIRVModule> BM(SPIRVModule::createSPIRVModule());
+  legacy::PassManager PassMgr;
+  addPassesForSPIRV(PassMgr);
+  PassMgr.add(createLLVMToSPIRV(BM.get()));
+  PassMgr.run(*M);
+
+  if (BM->getError(ErrMsg) != SPIRVEC_Success)
+    return false;
+  OS << *BM;
+  return true;
+}
+
+bool llvm::RegularizeLLVMForSPIRV(Module *M, std::string &ErrMsg) {
+  std::unique_ptr<SPIRVModule> BM(SPIRVModule::createSPIRVModule());
+  legacy::PassManager PassMgr;
+  addPassesForSPIRV(PassMgr);
+  PassMgr.run(*M);
+  return true;
+}
diff --git a/lib/SPIRV/SPIRVWriterPass.cpp b/lib/SPIRV/SPIRVWriterPass.cpp
new file mode 100644
index 0000000..8d9db7e
--- /dev/null
+++ b/lib/SPIRV/SPIRVWriterPass.cpp
@@ -0,0 +1,50 @@
+//===- SPIRVWriterPass.cpp - SPIRV writing pass -----------------------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+// SPIRVWriterPass implementation.
+//
+//===----------------------------------------------------------------------===//
+
+#include "SPIRVWriterPass.h"
+#include "llvm/IR/Module.h"
+#include "llvm/IR/PassManager.h"
+#include "llvm/Pass.h"
+#include "llvm/Support/SPIRV.h"
+using namespace llvm;
+
+PreservedAnalyses SPIRVWriterPass::run(Module &M) {
+  // FIXME: at the moment LLVM/SPIR-V translation errors are ignored.
+  std::string err;
+  WriteSPIRV(&M, OS, err);
+  return PreservedAnalyses::all();
+}
+
+namespace {
+class WriteSPIRVPass : public ModulePass {
+  raw_ostream &OS; // raw_ostream to print on
+public:
+  static char ID; // Pass identification, replacement for typeid
+  explicit WriteSPIRVPass(raw_ostream &o) : ModulePass(ID), OS(o) {}
+
+  const char *getPassName() const override { return "SPIRV Writer"; }
+
+  bool runOnModule(Module &M) override {
+    // FIXME: at the moment LLVM/SPIR-V translation errors are ignored.
+    std::string err;
+    WriteSPIRV(&M, OS, err);
+    return false;
+  }
+};
+}
+
+char WriteSPIRVPass::ID = 0;
+
+ModulePass *llvm::createSPIRVWriterPass(raw_ostream &Str) {
+  return new WriteSPIRVPass(Str);
+}
diff --git a/lib/SPIRV/SPIRVWriterPass.h b/lib/SPIRV/SPIRVWriterPass.h
new file mode 100644
index 0000000..b7fe021
--- /dev/null
+++ b/lib/SPIRV/SPIRVWriterPass.h
@@ -0,0 +1,50 @@
+//===------ SPIRVWriterPass.h - SPIRV writing pass --------------*- C++ -*-===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+/// \file
+///
+/// This file provides a SPIRV writing pass.
+///
+//===----------------------------------------------------------------------===//
+
+#ifndef LLVM_SPIRVWRITERPASS_H
+#define LLVM_SPIRVWRITERPASS_H
+
+#include "llvm/ADT/StringRef.h"
+
+namespace llvm {
+class Module;
+class ModulePass;
+class raw_ostream;
+class PreservedAnalyses;
+
+/// \brief Create and return a pass that writes the module to the specified
+/// ostream. Note that this pass is designed for use with the legacy pass
+/// manager.
+ModulePass *createSPIRVWriterPass(raw_ostream &Str);
+
+/// \brief Pass for writing a module of IR out to a SPIRV file.
+///
+/// Note that this is intended for use with the new pass manager. To construct
+/// a pass for the legacy pass manager, use the function above.
+class SPIRVWriterPass {
+  raw_ostream &OS;
+
+public:
+  /// \brief Construct a SPIRV writer pass around a particular output stream.
+  explicit SPIRVWriterPass(raw_ostream &OS) : OS(OS) {}
+
+  /// \brief Run the SPIRV writer pass, and output the module to the selected
+  /// output stream.
+  PreservedAnalyses run(Module &M);
+
+  static StringRef name() { return "SPIRVWriterPass"; }
+};
+}
+
+#endif
diff --git a/lib/SPIRV/TransOCLMD.cpp b/lib/SPIRV/TransOCLMD.cpp
new file mode 100644
index 0000000..f5fe175
--- /dev/null
+++ b/lib/SPIRV/TransOCLMD.cpp
@@ -0,0 +1,252 @@
+//===- TransOCLMD.cpp - Transform OCL metadata to SPIR-V metadata - C++ -*-===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+//
+// This file implements translation of OCL metadata to SPIR-V metadata.
+//
+//===----------------------------------------------------------------------===//
+#define DEBUG_TYPE "clmdtospv"
+
+#include "SPIRVInternal.h"
+#include "OCLUtil.h"
+#include "SPIRVMDBuilder.h"
+#include "SPIRVMDWalker.h"
+
+#include "llvm/ADT/StringSwitch.h"
+#include "llvm/ADT/Triple.h"
+#include "llvm/IR/InstVisitor.h"
+#include "llvm/IR/Instructions.h"
+#include "llvm/IR/IRBuilder.h"
+#include "llvm/IR/Verifier.h"
+#include "llvm/Pass.h"
+#include "llvm/PassSupport.h"
+#include "llvm/Support/CommandLine.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/raw_ostream.h"
+
+#include <set>
+
+using namespace llvm;
+using namespace SPIRV;
+using namespace OCLUtil;
+
+namespace SPIRV {
+
+cl::opt<bool> EraseOCLMD("spirv-erase-cl-md", cl::init(true),
+                         cl::desc("Erase OpenCL metadata"));
+
+class TransOCLMD : public ModulePass {
+public:
+  TransOCLMD() : ModulePass(ID), M(nullptr), Ctx(nullptr), CLVer(0) {
+    initializeTransOCLMDPass(*PassRegistry::getPassRegistry());
+  }
+
+  virtual bool runOnModule(Module &M);
+  void visit(Module *M);
+
+  static char ID;
+
+private:
+  Module *M;
+  LLVMContext *Ctx;
+  unsigned CLVer; /// OpenCL version as major*10+minor
+};
+
+char TransOCLMD::ID = 0;
+
+bool TransOCLMD::runOnModule(Module &Module) {
+  M = &Module;
+  Ctx = &M->getContext();
+  CLVer = getOCLVersion(M, true);
+  if (CLVer == 0)
+    return false;
+
+  DEBUG(dbgs() << "Enter TransOCLMD:\n");
+  visit(M);
+
+  DEBUG(dbgs() << "After TransOCLMD:\n" << *M);
+  std::string Err;
+  raw_string_ostream ErrorOS(Err);
+  if (verifyModule(*M, &ErrorOS)) {
+    DEBUG(errs() << "Fails to verify module: " << ErrorOS.str());
+  }
+  return true;
+}
+
+void TransOCLMD::visit(Module *M) {
+  SPIRVMDBuilder B(*M);
+  SPIRVMDWalker W(*M);
+
+  Triple TT(M->getTargetTriple());
+  auto Arch = TT.getArch();
+  assert((Arch == Triple::spir || Arch == Triple::spir64) && "Invalid triple");
+  const bool is_vulkan =
+      (TT.getEnvironment() == llvm::Triple::EnvironmentType::Vulkan);
+  if (is_vulkan)
+    EraseOCLMD = true;
+
+  B.addNamedMD(kSPIRVMD::Source)
+      .addOp()
+      .add(!is_vulkan ? (CLVer < kOCLVer::CL21 ? spv::SourceLanguageOpenCL_C
+                                               : spv::SourceLanguageOpenCL_CPP)
+                      : spv::SourceLanguageGLSL)
+      .add(CLVer)
+      .done();
+  if (EraseOCLMD)
+    B.eraseNamedMD(kSPIR2MD::OCLVer).eraseNamedMD(kSPIR2MD::SPIRVer);
+
+  if (!is_vulkan) {
+    B.addNamedMD(kSPIRVMD::MemoryModel)
+        .addOp()
+        .add(Arch == Triple::spir ? spv::AddressingModelPhysical32
+                                  : AddressingModelPhysical64)
+        .add(spv::MemoryModelOpenCL)
+        .done();
+  } else {
+    B.addNamedMD(kSPIRVMD::MemoryModel)
+        .addOp()
+        .add(spv::AddressingModelLogical)
+        .add(spv::MemoryModelGLSL450)
+        .done();
+  }
+
+  // Add extensions
+  auto Exts = getNamedMDAsStringSet(M, kSPIR2MD::Extensions);
+  if (!Exts.empty()) {
+    auto N = B.addNamedMD(kSPIRVMD::Extension);
+    for (auto &I : Exts) {
+      // skip cl_* extensions for vulkan
+      if (is_vulkan && I.find("cl_") == 0)
+        continue;
+      N.addOp().add(I).done();
+    }
+  }
+  if (EraseOCLMD)
+    B.eraseNamedMD(kSPIR2MD::Extensions).eraseNamedMD(kSPIR2MD::OptFeatures);
+
+  bool HasFPContract = W.getNamedMD(kSPIR2MD::FPContract) && !is_vulkan;
+  if (EraseOCLMD)
+    B.eraseNamedMD(kSPIR2MD::FPContract);
+
+  // Add entry points
+  auto EP = B.addNamedMD(kSPIRVMD::EntryPoint);
+  auto EM = B.addNamedMD(kSPIRVMD::ExecutionMode);
+
+  // Add execution mode
+  NamedMDNode *FuncMDs = M->getNamedMetadata(SPIR_MD_KERNELS);
+  if (!FuncMDs)
+    return;
+
+  for (unsigned I = 0, E = FuncMDs->getNumOperands(); I < E; ++I) {
+    MDNode *FuncMD = FuncMDs->getOperand(I);
+    if (FuncMD->getNumOperands() == 0)
+      continue;
+    Function *Func = mdconst::dyn_extract<Function>(FuncMD->getOperand(0));
+
+// Workaround for OCL 2.0 producer not using FLOOR_KERNEL calling convention
+#if SPCV_RELAX_KERNEL_CALLING_CONV
+    if (Func->getCallingConv() == llvm::CallingConv::C) {
+      Func->setCallingConv(CallingConv::FLOOR_KERNEL);
+    }
+#endif
+
+    ExecutionModel exec_model =
+        (!is_vulkan ? spv::ExecutionModelKernel : spv::ExecutionModelGLCompute);
+    switch (Func->getCallingConv()) {
+    default:
+    case CallingConv::FLOOR_KERNEL:
+      break;
+    case CallingConv::FLOOR_VERTEX:
+      exec_model = spv::ExecutionModelVertex;
+      break;
+    case CallingConv::FLOOR_FRAGMENT:
+      exec_model = spv::ExecutionModelFragment;
+      break;
+    }
+
+    MDNode *EPNode;
+    EP.addOp().add(exec_model).add(Func).add(Func->getName()).done(&EPNode);
+
+    if (!HasFPContract && !is_vulkan)
+      EM.addOp().add(Func).add(spv::ExecutionModeContractionOff).done();
+
+    for (unsigned MI = 1, ME = FuncMD->getNumOperands(); MI < ME; ++MI) {
+      MDNode *MD = dyn_cast<MDNode>(FuncMD->getOperand(MI));
+      if (!MD)
+        continue;
+      MDString *NameMD = dyn_cast<MDString>(MD->getOperand(0));
+      if (!NameMD)
+        continue;
+      StringRef Name = NameMD->getString();
+      if (!is_vulkan) {
+        if (Name == kSPIR2MD::WGSizeHint) {
+          unsigned X, Y, Z;
+          decodeMDNode(MD, X, Y, Z);
+          EM.addOp()
+              .add(Func)
+              .add(spv::ExecutionModeLocalSizeHint)
+              .add(X)
+              .add(Y)
+              .add(Z)
+              .done();
+        } else if (Name == kSPIR2MD::WGSize) {
+          unsigned X, Y, Z;
+          decodeMDNode(MD, X, Y, Z);
+          EM.addOp()
+              .add(Func)
+              .add(spv::ExecutionModeLocalSize)
+              .add(X)
+              .add(Y)
+              .add(Z)
+              .done();
+        } else if (Name == kSPIR2MD::VecTyHint) {
+          EM.addOp()
+              .add(Func)
+              .add(spv::ExecutionModeVecTypeHint)
+              .add(transVecTypeHint(MD))
+              .done();
+        }
+      } else {
+        // TODO: vulkan?
+        // NOTE: don't want work-group size metadata here, this is already
+        // handled elsewhere
+      }
+    }
+  }
+}
+}
+
+INITIALIZE_PASS(TransOCLMD, "clmdtospv", "Transform OCL metadata to SPIR-V",
+                false, false)
+
+ModulePass *llvm::createTransOCLMD() { return new TransOCLMD(); }
diff --git a/lib/SPIRV/libSPIRV/GLSL.std.450.h b/lib/SPIRV/libSPIRV/GLSL.std.450.h
new file mode 100644
index 0000000..7cb1542
--- /dev/null
+++ b/lib/SPIRV/libSPIRV/GLSL.std.450.h
@@ -0,0 +1,135 @@
+/*
+** Copyright (c) 2014-2016 The Khronos Group Inc.
+**
+** Permission is hereby granted, free of charge, to any person obtaining a copy
+** of this software and/or associated documentation files (the "Materials"),
+** to deal in the Materials without restriction, including without limitation
+** the rights to use, copy, modify, merge, publish, distribute, sublicense,
+** and/or sell copies of the Materials, and to permit persons to whom the
+** Materials are furnished to do so, subject to the following conditions:
+**
+** The above copyright notice and this permission notice shall be included in
+** all copies or substantial portions of the Materials.
+**
+** MODIFICATIONS TO THIS FILE MAY MEAN IT NO LONGER ACCURATELY REFLECTS KHRONOS
+** STANDARDS. THE UNMODIFIED, NORMATIVE VERSIONS OF KHRONOS SPECIFICATIONS AND
+** HEADER INFORMATION ARE LOCATED AT https://www.khronos.org/registry/ 
+**
+** THE MATERIALS ARE PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
+** OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+** FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
+** THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+** LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+** FROM,OUT OF OR IN CONNECTION WITH THE MATERIALS OR THE USE OR OTHER DEALINGS
+** IN THE MATERIALS.
+*/
+
+#ifndef GLSLstd450_H
+#define GLSLstd450_H
+
+namespace GLSLLIB {
+
+static const int GLSLstd450Version = 100;
+static const int GLSLstd450Revision = 3;
+
+enum GLSLstd450 {
+    Bad = 0,              // Don't use
+
+    Round = 1,
+    RoundEven = 2,
+    Trunc = 3,
+    FAbs = 4,
+    SAbs = 5,
+    FSign = 6,
+    SSign = 7,
+    Floor = 8,
+    Ceil = 9,
+    Fract = 10,
+
+    Radians = 11,
+    Degrees = 12,
+    Sin = 13,
+    Cos = 14,
+    Tan = 15,
+    Asin = 16,
+    Acos = 17,
+    Atan = 18,
+    Sinh = 19,
+    Cosh = 20,
+    Tanh = 21,
+    Asinh = 22,
+    Acosh = 23,
+    Atanh = 24,
+    Atan2 = 25,
+
+    Pow = 26,
+    Exp = 27,
+    Log = 28,
+    Exp2 = 29,
+    Log2 = 30,
+    Sqrt = 31,
+    InverseSqrt = 32,
+
+    Determinant = 33,
+    MatrixInverse = 34,
+
+    Modf = 35,            // second operand needs an OpVariable to write to
+    ModfStruct = 36,      // no OpVariable operand
+    FMin = 37,
+    UMin = 38,
+    SMin = 39,
+    FMax = 40,
+    UMax = 41,
+    SMax = 42,
+    FClamp = 43,
+    UClamp = 44,
+    SClamp = 45,
+    FMix = 46,
+    IMix = 47,            // Reserved
+    Step = 48,
+    SmoothStep = 49,
+
+    Fma = 50,
+    Frexp = 51,            // second operand needs an OpVariable to write to
+    FrexpStruct = 52,      // no OpVariable operand
+    Ldexp = 53,
+
+    PackSnorm4x8 = 54,
+    PackUnorm4x8 = 55,
+    PackSnorm2x16 = 56,
+    PackUnorm2x16 = 57,
+    PackHalf2x16 = 58,
+    PackDouble2x32 = 59,
+    UnpackSnorm2x16 = 60,
+    UnpackUnorm2x16 = 61,
+    UnpackHalf2x16 = 62,
+    UnpackSnorm4x8 = 63,
+    UnpackUnorm4x8 = 64,
+    UnpackDouble2x32 = 65,
+
+    Length = 66,
+    Distance = 67,
+    Cross = 68,
+    Normalize = 69,
+    FaceForward = 70,
+    Reflect = 71,
+    Refract = 72,
+
+    FindILsb = 73,
+    FindSMsb = 74,
+    FindUMsb = 75,
+
+    InterpolateAtCentroid = 76,
+    InterpolateAtSample = 77,
+    InterpolateAtOffset = 78,
+
+    NMin = 79,
+    NMax = 80,
+    NClamp = 81,
+
+    Count
+};
+
+}
+
+#endif  // #ifndef GLSLstd450_H
diff --git a/lib/SPIRV/libSPIRV/OpenCL.std.h b/lib/SPIRV/libSPIRV/OpenCL.std.h
new file mode 100644
index 0000000..620debfc
--- /dev/null
+++ b/lib/SPIRV/libSPIRV/OpenCL.std.h
@@ -0,0 +1,269 @@
+/*
+** Copyright (c) 2015 The Khronos Group Inc.
+**
+** Permission is hereby granted, free of charge, to any person obtaining a copy
+** of this software and/or associated documentation files (the "Materials"),
+** to deal in the Materials without restriction, including without limitation
+** the rights to use, copy, modify, merge, publish, distribute, sublicense,
+** and/or sell copies of the Materials, and to permit persons to whom the
+** Materials are furnished to do so, subject to the following conditions:
+**
+** The above copyright notice and this permission notice shall be included in
+** all copies or substantial portions of the Materials.
+**
+** MODIFICATIONS TO THIS FILE MAY MEAN IT NO LONGER ACCURATELY REFLECTS KHRONOS
+** STANDARDS. THE UNMODIFIED, NORMATIVE VERSIONS OF KHRONOS SPECIFICATIONS AND
+** HEADER INFORMATION ARE LOCATED AT https://www.khronos.org/registry/ 
+**
+** THE MATERIALS ARE PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
+** OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+** FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
+** THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+** LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+** FROM,OUT OF OR IN CONNECTION WITH THE MATERIALS OR THE USE OR OTHER DEALINGS
+** IN THE MATERIALS.
+*/
+
+//
+// Author: Boaz Ouriel, Intel
+//
+
+namespace OpenCLLIB {
+
+enum Entrypoints {
+
+    // math functions
+    Acos = 0,
+    Acosh = 1,
+    Acospi = 2,
+    Asin = 3,
+    Asinh = 4,
+    Asinpi = 5,
+    Atan = 6,
+    Atan2 = 7,
+    Atanh = 8,
+    Atanpi = 9,
+    Atan2pi = 10,
+    Cbrt = 11,
+    Ceil = 12,
+    Copysign = 13,
+    Cos = 14,
+    Cosh = 15,
+    Cospi = 16,
+    Erfc = 17,
+    Erf = 18,
+    Exp = 19,
+    Exp2 = 20,
+    Exp10 = 21,
+    Expm1 = 22,
+    Fabs = 23,
+    Fdim = 24,
+    Floor = 25,
+    Fma = 26,
+    Fmax = 27,
+    Fmin = 28,
+    Fmod = 29,
+    Fract = 30, 
+    Frexp = 31,
+    Hypot = 32,
+    Ilogb = 33,
+    Ldexp = 34,
+    Lgamma = 35,
+    Lgamma_r = 36,
+    Log = 37,
+    Log2 = 38,
+    Log10 = 39,
+    Log1p = 40,
+    Logb = 41,
+    Mad = 42,
+    Maxmag = 43,
+    Minmag = 44,
+    Modf = 45,
+    Nan = 46,
+    Nextafter = 47,
+    Pow = 48,
+    Pown = 49,
+    Powr = 50,
+    Remainder = 51,
+    Remquo = 52,
+    Rint = 53,
+    Rootn = 54,
+    Round = 55,
+    Rsqrt = 56,
+    Sin = 57,
+    Sincos = 58,
+    Sinh = 59,
+    Sinpi = 60,
+    Sqrt = 61,
+    Tan = 62,
+    Tanh = 63,
+    Tanpi = 64,
+    Tgamma = 65,
+    Trunc = 66,
+    Half_cos = 67,
+    Half_divide = 68,
+    Half_exp = 69,
+    Half_exp2 = 70,
+    Half_exp10 = 71,
+    Half_log = 72,
+    Half_log2 = 73,
+    Half_log10 = 74,
+    Half_powr = 75,
+    Half_recip = 76,
+    Half_rsqrt = 77,
+    Half_sin = 78,
+    Half_sqrt = 79,
+    Half_tan = 80,
+    Native_cos = 81,
+    Native_divide = 82,
+    Native_exp = 83,
+    Native_exp2 = 84,
+    Native_exp10 = 85,
+    Native_log = 86,
+    Native_log2 = 87,
+    Native_log10 = 88,
+    Native_powr = 89,
+    Native_recip = 90,
+    Native_rsqrt = 91,
+    Native_sin = 92,
+    Native_sqrt = 93,
+    Native_tan = 94,
+    
+    // Common
+    FClamp = 95,
+    Degrees = 96,
+    FMax_common = 97,
+    FMin_common = 98, 
+    Mix = 99,
+    Radians = 100,
+    Step = 101,
+    Smoothstep = 102,
+    Sign = 103,
+    
+    // Geometrics
+    Cross = 104,
+    Distance = 105, 
+    Length = 106,
+    Normalize = 107,
+    Fast_distance = 108,
+    Fast_length = 109,
+    Fast_normalize = 110,
+
+    // Images - Deprecated 
+    Read_imagef = 111,
+    Read_imagei = 112,
+    Read_imageui = 113,
+    Read_imageh = 114,
+
+    Read_imagef_samplerless = 115,
+    Read_imagei_samplerless = 116,
+    Read_imageui_samplerless = 117,
+    Read_imageh_samplerless = 118,
+
+    Write_imagef = 119,
+    Write_imagei = 120,
+    Write_imageui = 121,
+    Write_imageh = 122,
+    Read_imagef_mipmap_lod = 123,
+    Read_imagei_mipmap_lod = 124,
+    Read_imageui_mipmap_lod = 125,
+    Read_imagef_mipmap_grad = 126,
+    Read_imagei_mipmap_grad = 127,
+    Read_imageui_mipmap_grad = 128,
+
+    // Image write with LOD
+    Write_imagef_mipmap_lod = 129,
+    Write_imagei_mipmap_lod = 130,
+    Write_imageui_mipmap_lod = 131,
+
+    // Images - Deprecated
+    Get_image_width = 132,
+    Get_image_height = 133,
+    Get_image_depth = 134,
+    Get_image_channel_data_type = 135,
+    Get_image_channel_order = 136,
+    Get_image_dim = 137,
+    Get_image_array_size = 138,
+    Get_image_num_samples = 139,
+    Get_image_num_mip_levels = 140,
+    
+    // Integers
+    SAbs = 141,
+    SAbs_diff = 142,
+    SAdd_sat = 143,
+    UAdd_sat = 144,
+    SHadd = 145,
+    UHadd = 146,
+    SRhadd = 147,
+    URhadd = 148,
+    SClamp = 149,
+    UClamp = 150, 
+    Clz = 151,
+    Ctz = 152,    
+    SMad_hi = 153,
+    UMad_sat = 154,
+    SMad_sat = 155,
+    SMax = 156,
+    UMax = 157,
+    SMin = 158,
+    UMin = 159,
+    SMul_hi = 160,
+    Rotate = 161,
+    SSub_sat = 162,
+    USub_sat = 163,
+    U_Upsample = 164,
+    S_Upsample = 165,
+    Popcount = 166,
+    SMad24 = 167,
+    UMad24 = 168,
+    SMul24 = 169,
+    UMul24 = 170,
+
+    // Vector Loads/Stores
+    Vloadn = 171,
+    Vstoren = 172,
+    Vload_half = 173,
+    Vload_halfn = 174,
+    Vstore_half = 175,
+    Vstore_half_r = 176,
+    Vstore_halfn = 177,
+    Vstore_halfn_r = 178,
+    Vloada_halfn = 179,
+    Vstorea_halfn = 180,
+    Vstorea_halfn_r = 181,
+
+    // Vector Misc 
+    Shuffle = 182,
+    Shuffle2 = 183,
+
+    // 
+    Printf = 184,
+    Prefetch = 185,
+    
+    // Relationals
+    Bitselect = 186,
+    Select = 187,
+        
+    // pipes
+    Read_pipe = 188,
+    Write_pipe = 189,
+    Reserve_read_pipe = 190,
+    Reserve_write_pipe = 191,
+    Commit_read_pipe = 192,
+    Commit_write_pipe = 193,
+    Is_valid_reserve_id = 194,
+    Work_group_reserve_read_pipe = 195,
+    Work_group_reserve_write_pipe = 196,
+    Work_group_commit_read_pipe = 197,
+    Work_group_commit_write_pipe = 198,
+    Get_pipe_num_packets = 199,
+    Get_pipe_max_packets = 200,
+    
+    // more integers
+    UAbs = 201,
+    UAbs_diff = 202,
+    UMul_hi = 203,
+    UMad_hi = 204,
+};
+
+} // end namespace OpenCL20
diff --git a/lib/SPIRV/libSPIRV/SPIRVBasicBlock.cpp b/lib/SPIRV/libSPIRV/SPIRVBasicBlock.cpp
new file mode 100644
index 0000000..67f0f46
--- /dev/null
+++ b/lib/SPIRV/libSPIRV/SPIRVBasicBlock.cpp
@@ -0,0 +1,81 @@
+//===- SPIRVBasicBlock.cpp - SPIR-V Basic Block -----------------*- C++ -*-===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+/// \file
+///
+/// This file implements SPIRV basic block.
+///
+//===----------------------------------------------------------------------===//
+
+#include "SPIRVEntry.h"
+#include "SPIRVValue.h"
+#include "SPIRVBasicBlock.h"
+#include "SPIRVInstruction.h"
+#include "SPIRVFunction.h"
+#include "SPIRVStream.h"
+
+#include <iostream>
+
+using namespace SPIRV;
+
+SPIRVBasicBlock::SPIRVBasicBlock(SPIRVId TheId, SPIRVFunction *Func)
+    : SPIRVValue(Func->getModule(), 2, OpLabel, TheId), ParentF(Func) {
+  setAttr();
+  validate();
+}
+
+SPIRVDecoder SPIRVBasicBlock::getDecoder(std::istream &IS) {
+  return SPIRVDecoder(IS, *this);
+}
+
+/// Assume I contains valid Id.
+SPIRVInstruction *SPIRVBasicBlock::addInstruction(SPIRVInstruction *I) {
+  assert(I && "Invalid instruction");
+  Module->add(I);
+  I->setParent(this);
+  InstVec.push_back(I);
+  return I;
+}
+
+void SPIRVBasicBlock::encodeChildren(spv_ostream &O) const {
+  O << SPIRVNL();
+  for (size_t i = 0, e = InstVec.size(); i != e; ++i)
+    O << *InstVec[i];
+}
+
+_SPIRV_IMP_ENCDEC1(SPIRVBasicBlock, Id)
+
+void SPIRVBasicBlock::setScope(SPIRVEntry *Scope) {
+  assert(Scope && Scope->getOpCode() == OpFunction && "Invalid scope");
+  setParent(static_cast<SPIRVFunction *>(Scope));
+}
diff --git a/lib/SPIRV/libSPIRV/SPIRVBasicBlock.h b/lib/SPIRV/libSPIRV/SPIRVBasicBlock.h
new file mode 100644
index 0000000..dce0a34
--- /dev/null
+++ b/lib/SPIRV/libSPIRV/SPIRVBasicBlock.h
@@ -0,0 +1,103 @@
+//===- SPIRVBasicBlock.h  SPIR-V Basic Block -------------------*- C++ -*-===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+/// \file
+///
+/// This file defines Basic Block class for SPIR-V.
+///
+//===----------------------------------------------------------------------===//
+
+#ifndef SPIRVBASICBLOCK_HPP_
+#define SPIRVBASICBLOCK_HPP_
+
+#include "SPIRVValue.h"
+#include <algorithm>
+
+namespace SPIRV {
+class SPIRVFunction;
+class SPIRVInstruction;
+class SPIRVDecoder;
+class SPIRVBasicBlock : public SPIRVValue {
+
+public:
+  SPIRVBasicBlock(SPIRVId TheId, SPIRVFunction *Func);
+
+  SPIRVBasicBlock() : SPIRVValue(OpLabel), ParentF(NULL) { setAttr(); }
+
+  SPIRVDecoder getDecoder(std::istream &IS);
+  SPIRVFunction *getParent() const { return ParentF; }
+  size_t getNumInst() const { return InstVec.size(); }
+  SPIRVInstruction *getInst(size_t I) const { return InstVec[I]; }
+  SPIRVInstruction *getPrevious(const SPIRVInstruction *I) const {
+    auto Loc = find(I);
+    if (Loc == InstVec.end() || Loc == InstVec.begin())
+      return nullptr;
+    return *(--Loc);
+  }
+  SPIRVInstruction *getNext(const SPIRVInstruction *I) const {
+    auto Loc = find(I);
+    if (Loc == InstVec.end())
+      return nullptr;
+    ++Loc;
+    if (Loc == InstVec.end())
+      return nullptr;
+    return *Loc;
+  }
+
+  void setScope(SPIRVEntry *Scope);
+  void setParent(SPIRVFunction *F) { ParentF = F; }
+  SPIRVInstruction *addInstruction(SPIRVInstruction *I);
+
+  void setAttr() { setHasNoType(); }
+  _SPIRV_DCL_ENCDEC
+  void encodeChildren(spv_ostream &) const;
+  void validate() const {
+    SPIRVValue::validate();
+    assert(ParentF && "Invalid parent function");
+  }
+
+private:
+  SPIRVFunction *ParentF;
+  typedef std::vector<SPIRVInstruction *> SPIRVInstructionVector;
+  SPIRVInstructionVector InstVec;
+
+  SPIRVInstructionVector::const_iterator
+  find(const SPIRVInstruction *Inst) const {
+    return std::find(InstVec.begin(), InstVec.end(), Inst);
+  }
+};
+
+typedef SPIRVBasicBlock SPIRVLabel;
+}
+
+#endif
diff --git a/lib/SPIRV/libSPIRV/SPIRVDebug.cpp b/lib/SPIRV/libSPIRV/SPIRVDebug.cpp
new file mode 100644
index 0000000..acace61
--- /dev/null
+++ b/lib/SPIRV/libSPIRV/SPIRVDebug.cpp
@@ -0,0 +1,46 @@
+//===- SPIRVDebug.cpp - SPIR-V Debug Utility --------------------*- C++ -*-===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+/// \file
+///
+/// This file defines variables for enabling/disabling SPIR-V debug macro.
+///
+//===----------------------------------------------------------------------===//
+
+#include "SPIRVDebug.h"
+
+using namespace SPIRV;
+
+bool SPIRV::SPIRVDbgEnable = false;
+bool SPIRV::SPIRVDbgAssertOnError = true;
+bool SPIRV::SPIRVDbgErrorMsgIncludesSourceInfo = true;
diff --git a/lib/SPIRV/libSPIRV/SPIRVDebug.h b/lib/SPIRV/libSPIRV/SPIRVDebug.h
new file mode 100644
index 0000000..cf24bb9
--- /dev/null
+++ b/lib/SPIRV/libSPIRV/SPIRVDebug.h
@@ -0,0 +1,83 @@
+//===- SPIRVDebug.h - SPIR-V Debug Utility ----------------------*- C++ -*-===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+/// \file
+///
+/// This file defines Macros and variables for debugging SPIRV.
+///
+//===----------------------------------------------------------------------===//
+
+#ifndef SPIRVDEBUG_HPP_
+#define SPIRVDEBUG_HPP_
+
+#include "SPIRVUtil.h"
+#ifdef _SPIRV_LLVM_API
+#include "llvm/Support/Debug.h"
+#endif
+#include <iostream>
+
+namespace SPIRV {
+
+#define _SPIRVDBG
+#ifdef _SPIRVDBG
+
+#define SPIRVDBG(x)                                                            \
+  if (SPIRVDbgEnable) {                                                        \
+    x;                                                                         \
+  }
+
+// Enable debug output.
+extern bool SPIRVDbgEnable;
+
+// Include source file and line number in error message.
+extern bool SPIRVDbgErrorMsgIncludesSourceInfo;
+
+// Enable assert on error
+extern bool SPIRVDbgAssertOnError;
+
+// Output stream for SPIRV debug information.
+inline spv_ostream &spvdbgs() {
+#ifdef _SPIRV_LLVM_API
+  return llvm::dbgs();
+#else
+  return std::cerr;
+#endif
+}
+
+#else
+
+#define SPIRVDBG(x)
+
+#endif
+}
+#endif /* SPIRVDEBUG_HPP_ */
diff --git a/lib/SPIRV/libSPIRV/SPIRVDecorate.cpp b/lib/SPIRV/libSPIRV/SPIRVDecorate.cpp
new file mode 100644
index 0000000..b82d5ac
--- /dev/null
+++ b/lib/SPIRV/libSPIRV/SPIRVDecorate.cpp
@@ -0,0 +1,212 @@
+//===- SPIRVDecorate.cpp -SPIR-V Decorations --------------------*- C++ -*-===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+/// \file
+///
+/// This file implements SPIR-V decorations.
+///
+//===----------------------------------------------------------------------===//
+
+#include "SPIRVDecorate.h"
+#include "SPIRVStream.h"
+#include "SPIRVValue.h"
+#include "SPIRVModule.h"
+
+namespace SPIRV {
+template <class T, class B>
+spv_ostream &operator<<(spv_ostream &O, const std::multiset<T *, B> &V) {
+  for (auto &I : V)
+    O << *I;
+  return O;
+}
+
+SPIRVDecorateGeneric::SPIRVDecorateGeneric(Op OC, SPIRVWord WC,
+                                           Decoration TheDec,
+                                           SPIRVEntry *TheTarget)
+    : SPIRVAnnotationGeneric(TheTarget->getModule(), WC, OC,
+                             TheTarget->getId()),
+      Dec(TheDec), Owner(nullptr) {
+  validate();
+  updateModuleVersion();
+}
+
+SPIRVDecorateGeneric::SPIRVDecorateGeneric(Op OC, SPIRVWord WC,
+                                           Decoration TheDec,
+                                           SPIRVEntry *TheTarget, SPIRVWord V)
+    : SPIRVAnnotationGeneric(TheTarget->getModule(), WC, OC,
+                             TheTarget->getId()),
+      Dec(TheDec), Owner(nullptr) {
+  Literals.push_back(V);
+  validate();
+  updateModuleVersion();
+}
+
+SPIRVDecorateGeneric::SPIRVDecorateGeneric(Op OC)
+    : SPIRVAnnotationGeneric(OC), Dec(DecorationRelaxedPrecision),
+      Owner(nullptr) {}
+
+Decoration SPIRVDecorateGeneric::getDecorateKind() const { return Dec; }
+
+SPIRVWord SPIRVDecorateGeneric::getLiteral(size_t i) const {
+  assert(0 <= i && i <= Literals.size() && "Out of bounds");
+  return Literals[i];
+}
+
+size_t SPIRVDecorateGeneric::getLiteralCount() const { return Literals.size(); }
+
+void SPIRVDecorate::encode(spv_ostream &O) const {
+  SPIRVEncoder Encoder = getEncoder(O);
+  Encoder << Target << Dec;
+  if (Dec == DecorationLinkageAttributes)
+    SPIRVDecorateLinkageAttr::encodeLiterals(Encoder, Literals);
+  else
+    Encoder << Literals;
+}
+
+void SPIRVDecorate::setWordCount(SPIRVWord Count) {
+  WordCount = Count;
+  Literals.resize(WordCount - FixedWC);
+}
+
+void SPIRVDecorate::decode(std::istream &I) {
+  SPIRVDecoder Decoder = getDecoder(I);
+  Decoder >> Target >> Dec;
+  if (Dec == DecorationLinkageAttributes)
+    SPIRVDecorateLinkageAttr::decodeLiterals(Decoder, Literals);
+  else
+    Decoder >> Literals;
+  getOrCreateTarget()->addDecorate(this);
+}
+
+void SPIRVMemberDecorate::encode(spv_ostream &O) const {
+  getEncoder(O) << Target << MemberNumber << Dec << Literals;
+}
+
+void SPIRVMemberDecorate::setWordCount(SPIRVWord Count) {
+  WordCount = Count;
+  Literals.resize(WordCount - FixedWC);
+}
+
+void SPIRVMemberDecorate::decode(std::istream &I) {
+  getDecoder(I) >> Target >> MemberNumber >> Dec >> Literals;
+  getOrCreateTarget()->addMemberDecorate(this);
+}
+
+void SPIRVDecorationGroup::encode(spv_ostream &O) const { getEncoder(O) << Id; }
+
+void SPIRVDecorationGroup::decode(std::istream &I) {
+  getDecoder(I) >> Id;
+  Module->addDecorationGroup(this);
+}
+
+void SPIRVDecorationGroup::encodeAll(spv_ostream &O) const {
+  O << Decorations;
+  SPIRVEntry::encodeAll(O);
+}
+
+void SPIRVGroupDecorateGeneric::encode(spv_ostream &O) const {
+  getEncoder(O) << DecorationGroup << Targets;
+}
+
+void SPIRVGroupDecorateGeneric::decode(std::istream &I) {
+  getDecoder(I) >> DecorationGroup >> Targets;
+  Module->addGroupDecorateGeneric(this);
+}
+
+void SPIRVGroupDecorate::decorateTargets() {
+  for (auto &I : Targets) {
+    auto Target = getOrCreate(I);
+    for (auto &Dec : DecorationGroup->getDecorations()) {
+      assert(Dec->isDecorate());
+      Target->addDecorate(static_cast<const SPIRVDecorate *const>(Dec));
+    }
+  }
+}
+
+void SPIRVGroupMemberDecorate::decorateTargets() {
+  for (auto &I : Targets) {
+    auto Target = getOrCreate(I);
+    for (auto &Dec : DecorationGroup->getDecorations()) {
+      assert(Dec->isMemberDecorate());
+      Target->addMemberDecorate(static_cast<const SPIRVMemberDecorate *>(Dec));
+    }
+  }
+}
+
+bool SPIRVDecorateGeneric::Comparator::
+operator()(const SPIRVDecorateGeneric *A, const SPIRVDecorateGeneric *B) const {
+  auto Action = [=]() {
+    if (A->getOpCode() < B->getOpCode())
+      return true;
+    if (A->getOpCode() > B->getOpCode())
+      return false;
+    if (A->getDecorateKind() < B->getDecorateKind())
+      return true;
+    if (A->getDecorateKind() > B->getDecorateKind())
+      return false;
+    if (A->getLiteralCount() < B->getLiteralCount())
+      return true;
+    if (A->getLiteralCount() > B->getLiteralCount())
+      return false;
+    for (size_t I = 0, E = A->getLiteralCount(); I != E; ++I) {
+      auto EA = A->getLiteral(I);
+      auto EB = B->getLiteral(I);
+      if (EA < EB)
+        return true;
+      if (EA > EB)
+        return false;
+    }
+    return false;
+  };
+  auto Res = Action();
+  return Res;
+}
+
+bool operator==(const SPIRVDecorateGeneric &A, const SPIRVDecorateGeneric &B) {
+  if (A.getTargetId() != B.getTargetId())
+    return false;
+  if (A.getOpCode() != B.getOpCode())
+    return false;
+  if (A.getDecorateKind() != B.getDecorateKind())
+    return false;
+  if (A.getLiteralCount() != B.getLiteralCount())
+    return false;
+  for (size_t I = 0, E = A.getLiteralCount(); I != E; ++I) {
+    auto EA = A.getLiteral(I);
+    auto EB = B.getLiteral(I);
+    if (EA != EB)
+      return false;
+  }
+  return true;
+}
+}
diff --git a/lib/SPIRV/libSPIRV/SPIRVDecorate.h b/lib/SPIRV/libSPIRV/SPIRVDecorate.h
new file mode 100644
index 0000000..151779f
--- /dev/null
+++ b/lib/SPIRV/libSPIRV/SPIRVDecorate.h
@@ -0,0 +1,312 @@
+//===- SPIRVDecorate.h - SPIR-V Decorations ---------------------*- C++ -*-===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+/// \file
+///
+/// This file defines SPIR-V decorations.
+///
+//===----------------------------------------------------------------------===//
+
+#ifndef SPIRVDECORATE_HPP_
+#define SPIRVDECORATE_HPP_
+
+#include "SPIRVEntry.h"
+#include "SPIRVUtil.h"
+#include "SPIRVStream.h"
+#include <string>
+#include <vector>
+#include <utility>
+
+namespace SPIRV {
+class SPIRVDecorationGroup;
+class SPIRVDecorateGeneric : public SPIRVAnnotationGeneric {
+public:
+  // Complete constructor for decorations without literals
+  SPIRVDecorateGeneric(Op OC, SPIRVWord WC, Decoration TheDec,
+                       SPIRVEntry *TheTarget);
+  // Complete constructor for decorations with one word literal
+  SPIRVDecorateGeneric(Op OC, SPIRVWord WC, Decoration TheDec,
+                       SPIRVEntry *TheTarget, SPIRVWord V);
+  // Incomplete constructor
+  SPIRVDecorateGeneric(Op OC);
+
+  SPIRVWord getLiteral(size_t) const;
+  Decoration getDecorateKind() const;
+  size_t getLiteralCount() const;
+  /// Compare for kind and literal only.
+  struct Comparator {
+    bool operator()(const SPIRVDecorateGeneric *A,
+                    const SPIRVDecorateGeneric *B) const;
+  };
+  /// Compare kind, literals and target.
+  friend bool operator==(const SPIRVDecorateGeneric &A,
+                         const SPIRVDecorateGeneric &B);
+
+  SPIRVDecorationGroup *getOwner() const { return Owner; }
+
+  void setOwner(SPIRVDecorationGroup *owner) { Owner = owner; }
+
+  SPIRVCapVec getRequiredCapability() const { return getCapability(Dec); }
+
+  SPIRVWord getRequiredSPIRVVersion() const override {
+    switch (Dec) {
+    case DecorationSpecId:
+      if (getModule()->hasCapability(CapabilityKernel))
+        return SPIRV_1_1;
+      else
+        return SPIRV_1_0;
+
+    case DecorationMaxByteOffset:
+      return SPIRV_1_1;
+
+    default:
+      return SPIRV_1_0;
+    }
+  }
+
+protected:
+  Decoration Dec;
+  std::vector<SPIRVWord> Literals;
+  SPIRVDecorationGroup *Owner; // Owning decorate group
+};
+
+class SPIRVDecorateSet
+    : public std::multiset<const SPIRVDecorateGeneric *,
+                           SPIRVDecorateGeneric::Comparator> {
+public:
+  typedef std::multiset<const SPIRVDecorateGeneric *,
+                        SPIRVDecorateGeneric::Comparator>
+      BaseType;
+  iterator insert(const value_type &Dec) {
+    auto ER = BaseType::equal_range(Dec);
+    for (auto I = ER.first, E = ER.second; I != E; ++I) {
+      SPIRVDBG(spvdbgs() << "[compare decorate] " << *Dec << " vs " << **I
+                         << " : ");
+      if (**I == *Dec)
+        return I;
+      SPIRVDBG(spvdbgs() << " diff\n");
+    }
+    SPIRVDBG(spvdbgs() << "[add decorate] " << *Dec << '\n');
+    return BaseType::insert(Dec);
+  }
+};
+
+class SPIRVDecorate : public SPIRVDecorateGeneric {
+public:
+  static const Op OC = OpDecorate;
+  static const SPIRVWord FixedWC = 3;
+  // Complete constructor for decorations without literals
+  SPIRVDecorate(Decoration TheDec, SPIRVEntry *TheTarget)
+      : SPIRVDecorateGeneric(OC, 3, TheDec, TheTarget) {}
+  // Complete constructor for decorations with one word literal
+  SPIRVDecorate(Decoration TheDec, SPIRVEntry *TheTarget, SPIRVWord V)
+      : SPIRVDecorateGeneric(OC, 4, TheDec, TheTarget, V) {}
+  // Incomplete constructor
+  SPIRVDecorate() : SPIRVDecorateGeneric(OC) {}
+
+  _SPIRV_DCL_ENCDEC
+  void setWordCount(SPIRVWord);
+  void validate() const {
+    SPIRVDecorateGeneric::validate();
+    assert(WordCount == Literals.size() + FixedWC);
+  }
+};
+
+class SPIRVDecorateLinkageAttr : public SPIRVDecorate {
+public:
+  // Complete constructor for LinkageAttributes decorations
+  SPIRVDecorateLinkageAttr(SPIRVEntry *TheTarget, const std::string &Name,
+                           SPIRVLinkageTypeKind Kind)
+      : SPIRVDecorate(DecorationLinkageAttributes, TheTarget) {
+    for (auto &I : getVec(Name))
+      Literals.push_back(I);
+    Literals.push_back(Kind);
+    WordCount += Literals.size();
+  }
+  // Incomplete constructor
+  SPIRVDecorateLinkageAttr() : SPIRVDecorate() {}
+
+  std::string getLinkageName() const {
+    return getString(Literals.cbegin(), Literals.cend() - 1);
+  }
+  SPIRVLinkageTypeKind getLinkageType() const {
+    return (SPIRVLinkageTypeKind)Literals.back();
+  }
+
+  static void encodeLiterals(SPIRVEncoder &Encoder,
+                             const std::vector<SPIRVWord> &Literals) {
+#ifdef _SPIRV_SUPPORT_TEXT_FMT
+    if (SPIRVUseTextFormat) {
+      Encoder << getString(Literals.cbegin(), Literals.cend() - 1);
+      Encoder.OS << " ";
+      Encoder << (SPIRVLinkageTypeKind)Literals.back();
+    } else
+#endif
+      Encoder << Literals;
+  }
+
+  static void decodeLiterals(SPIRVDecoder &Decoder,
+                             std::vector<SPIRVWord> &Literals) {
+#ifdef _SPIRV_SUPPORT_TEXT_FMT
+    if (SPIRVUseTextFormat) {
+      std::string Name;
+      Decoder >> Name;
+      SPIRVLinkageTypeKind Kind;
+      Decoder >> Kind;
+      std::copy_n(getVec(Name).begin(), Literals.size() - 1, Literals.begin());
+      Literals.back() = Kind;
+    } else
+#endif
+      Decoder >> Literals;
+  }
+};
+
+class SPIRVMemberDecorate : public SPIRVDecorateGeneric {
+public:
+  static const Op OC = OpMemberDecorate;
+  static const SPIRVWord FixedWC = 4;
+  // Complete constructor for decorations without literals
+  SPIRVMemberDecorate(Decoration TheDec, SPIRVWord Member,
+                      SPIRVEntry *TheTarget)
+      : SPIRVDecorateGeneric(OC, 4, TheDec, TheTarget), MemberNumber(Member) {}
+
+  // Complete constructor for decorations with one word literal
+  SPIRVMemberDecorate(Decoration TheDec, SPIRVWord Member,
+                      SPIRVEntry *TheTarget, SPIRVWord V)
+      : SPIRVDecorateGeneric(OC, 5, TheDec, TheTarget, V),
+        MemberNumber(Member) {}
+
+  // Incomplete constructor
+  SPIRVMemberDecorate()
+      : SPIRVDecorateGeneric(OC), MemberNumber(SPIRVWORD_MAX) {}
+
+  SPIRVWord getMemberNumber() const { return MemberNumber; }
+  std::pair<SPIRVWord, Decoration> getPair() const {
+    return std::make_pair(MemberNumber, Dec);
+  }
+
+  _SPIRV_DCL_ENCDEC
+  void setWordCount(SPIRVWord);
+
+  void validate() const {
+    SPIRVDecorateGeneric::validate();
+    assert(WordCount == Literals.size() + FixedWC);
+  }
+
+protected:
+  SPIRVWord MemberNumber;
+};
+
+class SPIRVDecorationGroup : public SPIRVEntry {
+public:
+  static const Op OC = OpDecorationGroup;
+  static const SPIRVWord WC = 2;
+  // Complete constructor. Does not populate Decorations.
+  SPIRVDecorationGroup(SPIRVModule *TheModule, SPIRVId TheId)
+      : SPIRVEntry(TheModule, WC, OC, TheId) {
+    validate();
+  };
+  // Incomplete constructor
+  SPIRVDecorationGroup() : SPIRVEntry(OC) {}
+  void encodeAll(spv_ostream &O) const;
+  _SPIRV_DCL_ENCDEC
+  // Move the given decorates to the decoration group
+  void takeDecorates(SPIRVDecorateSet &Decs) {
+    Decorations = std::move(Decs);
+    for (auto &I : Decorations)
+      const_cast<SPIRVDecorateGeneric *>(I)->setOwner(this);
+    Decs.clear();
+  }
+
+  SPIRVDecorateSet &getDecorations() { return Decorations; }
+
+protected:
+  SPIRVDecorateSet Decorations;
+  void validate() const {
+    assert(OpCode == OC);
+    assert(WordCount == WC);
+  }
+};
+
+class SPIRVGroupDecorateGeneric : public SPIRVEntryNoIdGeneric {
+public:
+  static const SPIRVWord FixedWC = 2;
+  // Complete constructor
+  SPIRVGroupDecorateGeneric(Op OC, SPIRVDecorationGroup *TheGroup,
+                            const std::vector<SPIRVId> &TheTargets)
+      : SPIRVEntryNoIdGeneric(TheGroup->getModule(),
+                              FixedWC + TheTargets.size(), OC),
+        DecorationGroup(TheGroup), Targets(TheTargets) {}
+  // Incomplete constructor
+  SPIRVGroupDecorateGeneric(Op OC)
+      : SPIRVEntryNoIdGeneric(OC), DecorationGroup(nullptr) {}
+
+  void setWordCount(SPIRVWord WC) {
+    SPIRVEntryNoIdGeneric::setWordCount(WC);
+    Targets.resize(WC - FixedWC);
+  }
+  virtual void decorateTargets() = 0;
+  _SPIRV_DCL_ENCDEC
+protected:
+  SPIRVDecorationGroup *DecorationGroup;
+  std::vector<SPIRVId> Targets;
+};
+
+class SPIRVGroupDecorate : public SPIRVGroupDecorateGeneric {
+public:
+  static const Op OC = OpGroupDecorate;
+  // Complete constructor
+  SPIRVGroupDecorate(SPIRVDecorationGroup *TheGroup,
+                     const std::vector<SPIRVId> &TheTargets)
+      : SPIRVGroupDecorateGeneric(OC, TheGroup, TheTargets) {}
+  // Incomplete constructor
+  SPIRVGroupDecorate() : SPIRVGroupDecorateGeneric(OC) {}
+
+  virtual void decorateTargets();
+};
+
+class SPIRVGroupMemberDecorate : public SPIRVGroupDecorateGeneric {
+public:
+  static const Op OC = OpGroupMemberDecorate;
+  // Complete constructor
+  SPIRVGroupMemberDecorate(SPIRVDecorationGroup *TheGroup,
+                           const std::vector<SPIRVId> &TheTargets)
+      : SPIRVGroupDecorateGeneric(OC, TheGroup, TheTargets) {}
+  // Incomplete constructor
+  SPIRVGroupMemberDecorate() : SPIRVGroupDecorateGeneric(OC) {}
+
+  virtual void decorateTargets();
+};
+}
+
+#endif /* SPIRVDECORATE_HPP_ */
diff --git a/lib/SPIRV/libSPIRV/SPIRVEntry.cpp b/lib/SPIRV/libSPIRV/SPIRVEntry.cpp
new file mode 100644
index 0000000..d4d3b3d
--- /dev/null
+++ b/lib/SPIRV/libSPIRV/SPIRVEntry.cpp
@@ -0,0 +1,548 @@
+//===- SPIRVEntry.cpp - Base Class for SPIR-V Entities ----------*- C++ -*-===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+/// \file
+///
+/// This file implements base class for SPIR-V entities.
+///
+//===----------------------------------------------------------------------===//
+
+#include "SPIRVEntry.h"
+#include "SPIRVDebug.h"
+#include "SPIRVType.h"
+#include "SPIRVFunction.h"
+#include "SPIRVBasicBlock.h"
+#include "SPIRVInstruction.h"
+#include "SPIRVDecorate.h"
+#include "SPIRVStream.h"
+
+#include <algorithm>
+#include <map>
+#include <set>
+#include <sstream>
+#include <string>
+#include <utility>
+
+using namespace SPIRV;
+
+namespace SPIRV {
+
+template <typename T> SPIRVEntry *create() { return new T(); }
+
+SPIRVEntry *SPIRVEntry::create(Op OpCode) {
+  typedef SPIRVEntry *(*SPIRVFactoryTy)();
+  struct TableEntry {
+    Op Opn;
+    SPIRVFactoryTy Factory;
+    operator std::pair<const Op, SPIRVFactoryTy>() {
+      return std::make_pair(Opn, Factory);
+    }
+  };
+
+  static TableEntry Table[] = {
+#define _SPIRV_OP(x, ...) {Op##x, &SPIRV::create<SPIRV##x>},
+#include "SPIRVOpCodeEnum.h"
+#undef _SPIRV_OP
+  };
+
+  typedef std::map<Op, SPIRVFactoryTy> OpToFactoryMapTy;
+  static const OpToFactoryMapTy OpToFactoryMap(std::begin(Table),
+                                               std::end(Table));
+
+  OpToFactoryMapTy::const_iterator Loc = OpToFactoryMap.find(OpCode);
+  if (Loc != OpToFactoryMap.end())
+    return Loc->second();
+
+  SPIRVDBG(spvdbgs() << "No factory for OpCode " << (unsigned)OpCode << '\n';)
+  assert(0 && "Not implemented");
+  return 0;
+}
+
+std::unique_ptr<SPIRV::SPIRVEntry> SPIRVEntry::create_unique(Op OC) {
+  return std::unique_ptr<SPIRVEntry>(create(OC));
+}
+
+std::unique_ptr<SPIRV::SPIRVExtInst>
+SPIRVEntry::create_unique(SPIRVExtInstSetKind Set, unsigned ExtOp) {
+  return std::unique_ptr<SPIRVExtInst>(new SPIRVExtInst(Set, ExtOp));
+}
+
+SPIRVErrorLog &SPIRVEntry::getErrorLog() const { return Module->getErrorLog(); }
+
+bool SPIRVEntry::exist(SPIRVId TheId) const { return Module->exist(TheId); }
+
+SPIRVEntry *SPIRVEntry::getOrCreate(SPIRVId TheId) const {
+  SPIRVEntry *Entry = nullptr;
+  bool Found = Module->exist(TheId, &Entry);
+  if (!Found)
+    return Module->addForward(TheId, nullptr);
+  return Entry;
+}
+
+SPIRVValue *SPIRVEntry::getValue(SPIRVId TheId) const {
+  return get<SPIRVValue>(TheId);
+}
+
+SPIRVType *SPIRVEntry::getValueType(SPIRVId TheId) const {
+  return get<SPIRVValue>(TheId)->getType();
+}
+
+SPIRVEncoder SPIRVEntry::getEncoder(spv_ostream &O) const {
+  return SPIRVEncoder(O);
+}
+
+SPIRVDecoder SPIRVEntry::getDecoder(std::istream &I) {
+  return SPIRVDecoder(I, *Module);
+}
+
+void SPIRVEntry::setWordCount(SPIRVWord TheWordCount) {
+  WordCount = TheWordCount;
+}
+
+void SPIRVEntry::setName(const std::string &TheName) {
+  Name = TheName;
+  SPIRVDBG(spvdbgs() << "Set name for obj " << Id << " " << Name << '\n');
+}
+
+void SPIRVEntry::setModule(SPIRVModule *TheModule) {
+  assert(TheModule && "Invalid module");
+  if (TheModule == Module)
+    return;
+  assert(Module == NULL && "Cannot change owner of entry");
+  Module = TheModule;
+}
+
+void SPIRVEntry::encode(spv_ostream &O) const {
+  assert(0 && "Not implemented");
+}
+
+void SPIRVEntry::encodeName(spv_ostream &O) const {
+  if (!Name.empty())
+    O << SPIRVName(this, Name);
+}
+
+void SPIRVEntry::encodeAll(spv_ostream &O) const {
+  encodeWordCountOpCode(O);
+  encode(O);
+  encodeChildren(O);
+}
+
+void SPIRVEntry::encodeChildren(spv_ostream &O) const {}
+
+void SPIRVEntry::encodeWordCountOpCode(spv_ostream &O) const {
+  const Op enc_op = (OpCode == Op::OpUndefValueInternal ? OpUndef : OpCode);
+#ifdef _SPIRV_SUPPORT_TEXT_FMT
+  if (SPIRVUseTextFormat) {
+    getEncoder(O) << WordCount << enc_op;
+    return;
+  }
+#endif
+  getEncoder(O) << mkWord(WordCount, enc_op);
+}
+// Read words from SPIRV binary and create members for SPIRVEntry.
+// The word count and op code has already been read before calling this
+// function for creating the SPIRVEntry. Therefore the input stream only
+// contains the remaining part of the words for the SPIRVEntry.
+void SPIRVEntry::decode(std::istream &I) { assert(0 && "Not implemented"); }
+
+std::vector<SPIRVValue *>
+SPIRVEntry::getValues(const std::vector<SPIRVId> &IdVec) const {
+  std::vector<SPIRVValue *> ValueVec;
+  for (auto i : IdVec)
+    ValueVec.push_back(getValue(i));
+  return ValueVec;
+}
+
+std::vector<SPIRVType *>
+SPIRVEntry::getValueTypes(const std::vector<SPIRVId> &IdVec) const {
+  std::vector<SPIRVType *> TypeVec;
+  for (auto i : IdVec)
+    TypeVec.push_back(getValue(i)->getType());
+  return TypeVec;
+}
+
+std::vector<SPIRVId>
+SPIRVEntry::getIds(const std::vector<SPIRVValue *> ValueVec) const {
+  std::vector<SPIRVId> IdVec;
+  for (auto i : ValueVec)
+    IdVec.push_back(i->getId());
+  return IdVec;
+}
+
+SPIRVEntry *SPIRVEntry::getEntry(SPIRVId TheId) const {
+  return Module->getEntry(TheId);
+}
+
+void SPIRVEntry::validateFunctionControlMask(SPIRVWord TheFCtlMask) const {
+  SPIRVCK(isValidFunctionControlMask(TheFCtlMask), InvalidFunctionControlMask,
+          "");
+}
+
+void SPIRVEntry::validateValues(const std::vector<SPIRVId> &Ids) const {
+  for (auto I : Ids)
+    getValue(I)->validate();
+}
+
+void SPIRVEntry::validateBuiltin(SPIRVWord TheSet, SPIRVWord Index) const {
+  assert(TheSet != SPIRVWORD_MAX && Index != SPIRVWORD_MAX &&
+         "Invalid builtin");
+}
+
+void SPIRVEntry::addDecorate(const SPIRVDecorate *Dec) {
+  auto Kind = Dec->getDecorateKind();
+  Decorates.insert(std::make_pair(Dec->getDecorateKind(), Dec));
+  Module->addDecorate(Dec);
+  SPIRVDBG(spvdbgs() << "[addDecorate] " << *Dec << '\n';)
+}
+
+void SPIRVEntry::addDecorate(Decoration Kind) {
+  addDecorate(new SPIRVDecorate(Kind, this));
+}
+
+void SPIRVEntry::addDecorate(Decoration Kind, SPIRVWord Literal) {
+  addDecorate(new SPIRVDecorate(Kind, this, Literal));
+}
+
+void SPIRVEntry::eraseDecorate(Decoration Dec) { Decorates.erase(Dec); }
+
+void SPIRVEntry::takeDecorates(SPIRVEntry *E) {
+  Decorates = std::move(E->Decorates);
+  SPIRVDBG(spvdbgs() << "[takeDecorates] " << Id << '\n';)
+}
+
+void SPIRVEntry::setLine(SPIRVLine *L) {
+  Line = L;
+  L->setTargetId(Id);
+  SPIRVDBG(spvdbgs() << "[setLine] " << *L << '\n';)
+}
+
+void SPIRVEntry::takeLine(SPIRVEntry *E) {
+  Line = E->Line;
+  if (Line == nullptr)
+    return;
+  Line->setTargetId(Id);
+  E->Line = nullptr;
+}
+
+void SPIRVEntry::addMemberDecorate(const SPIRVMemberDecorate *Dec) {
+  assert(canHaveMemberDecorates() &&
+         MemberDecorates.find(Dec->getPair()) == MemberDecorates.end());
+  MemberDecorates[Dec->getPair()] = Dec;
+  Module->addDecorate(Dec);
+  SPIRVDBG(spvdbgs() << "[addMemberDecorate] " << *Dec << '\n';)
+}
+
+void SPIRVEntry::addMemberDecorate(SPIRVWord MemberNumber, Decoration Kind) {
+  addMemberDecorate(new SPIRVMemberDecorate(Kind, MemberNumber, this));
+}
+
+void SPIRVEntry::addMemberDecorate(SPIRVWord MemberNumber, Decoration Kind,
+                                   SPIRVWord Literal) {
+  addMemberDecorate(new SPIRVMemberDecorate(Kind, MemberNumber, this, Literal));
+}
+
+void SPIRVEntry::eraseMemberDecorate(SPIRVWord MemberNumber, Decoration Dec) {
+  MemberDecorates.erase(std::make_pair(MemberNumber, Dec));
+}
+
+void SPIRVEntry::takeMemberDecorates(SPIRVEntry *E) {
+  MemberDecorates = std::move(E->MemberDecorates);
+  SPIRVDBG(spvdbgs() << "[takeMemberDecorates] " << Id << '\n';)
+}
+
+void SPIRVEntry::takeAnnotations(SPIRVForward *E) {
+  Module->setName(this, E->getName());
+  takeDecorates(E);
+  takeMemberDecorates(E);
+  takeLine(E);
+  if (OpCode == OpFunction)
+    static_cast<SPIRVFunction *>(this)->takeExecutionModes(E);
+}
+
+// Check if an entry has Kind of decoration and get the literal of the
+// first decoration of such kind at Index.
+bool SPIRVEntry::hasDecorate(Decoration Kind, size_t Index,
+                             SPIRVWord *Result) const {
+  DecorateMapType::const_iterator Loc = Decorates.find(Kind);
+  if (Loc == Decorates.end())
+    return false;
+  if (Result)
+    *Result = Loc->second->getLiteral(Index);
+  return true;
+}
+
+// Get literals of all decorations of Kind at Index.
+std::set<SPIRVWord> SPIRVEntry::getDecorate(Decoration Kind,
+                                            size_t Index) const {
+  auto Range = Decorates.equal_range(Kind);
+  std::set<SPIRVWord> Value;
+  for (auto I = Range.first, E = Range.second; I != E; ++I) {
+    assert(Index < I->second->getLiteralCount() && "Invalid index");
+    Value.insert(I->second->getLiteral(Index));
+  }
+  return Value;
+}
+
+bool SPIRVEntry::hasLinkageType() const {
+  return OpCode == OpFunction || OpCode == OpVariable;
+}
+
+void SPIRVEntry::encodeDecorate(spv_ostream &O) const {
+  for (auto &i : Decorates)
+    O << *i.second;
+}
+
+SPIRVLinkageTypeKind SPIRVEntry::getLinkageType() const {
+  assert(hasLinkageType());
+  DecorateMapType::const_iterator Loc =
+      Decorates.find(DecorationLinkageAttributes);
+  if (Loc == Decorates.end())
+    return LinkageTypeInternal;
+  return static_cast<const SPIRVDecorateLinkageAttr *>(Loc->second)
+      ->getLinkageType();
+}
+
+void SPIRVEntry::setLinkageType(SPIRVLinkageTypeKind LT) {
+  assert(isValid(LT));
+  assert(hasLinkageType());
+  addDecorate(new SPIRVDecorateLinkageAttr(this, Name, LT));
+}
+
+void SPIRVEntry::updateModuleVersion() const {
+  if (!Module)
+    return;
+
+  Module->setMinSPIRVVersion(getRequiredSPIRVVersion());
+}
+
+spv_ostream &operator<<(spv_ostream &O, const SPIRVEntry &E) {
+  E.validate();
+  E.encodeAll(O);
+  O << SPIRVNL();
+  return O;
+}
+
+std::istream &operator>>(std::istream &I, SPIRVEntry &E) {
+  E.decode(I);
+  return I;
+}
+
+SPIRVEntryPoint::SPIRVEntryPoint(SPIRVModule *TheModule,
+                                 SPIRVExecutionModelKind TheExecModel,
+                                 SPIRVId TheId, const std::string &TheName,
+                                 const unsigned int io_var_count)
+    : SPIRVAnnotation(TheModule->get<SPIRVFunction>(TheId),
+                      getSizeInWords(TheName) + 3 + io_var_count),
+      ExecModel(TheExecModel), Name(TheName) {}
+
+void SPIRVEntryPoint::encode(spv_ostream &O) const {
+  getEncoder(O) << ExecModel << Target << Name;
+  const auto ep_iter = Module->getEntryPointIO().find(Target);
+  if (ep_iter != Module->getEntryPointIO().end()) {
+    for (const auto &io_var : ep_iter->second) {
+      getEncoder(O) << io_var->getId();
+    }
+  }
+}
+
+void SPIRVEntryPoint::decode(std::istream &I) {
+  getDecoder(I) >> ExecModel >> Target >> Name;
+  Module->setName(getOrCreateTarget(), Name);
+  Module->addEntryPoint(ExecModel, Target);
+  // TODO: decode of i/o vars
+}
+
+void SPIRVExecutionMode::encode(spv_ostream &O) const {
+  getEncoder(O) << Target << ExecMode << WordLiterals;
+}
+
+void SPIRVExecutionMode::decode(std::istream &I) {
+  getDecoder(I) >> Target >> ExecMode;
+  switch (ExecMode) {
+  case ExecutionModeLocalSize:
+  case ExecutionModeLocalSizeHint:
+    WordLiterals.resize(3);
+    break;
+  case ExecutionModeInvocations:
+  case ExecutionModeOutputVertices:
+  case ExecutionModeVecTypeHint:
+    WordLiterals.resize(1);
+    break;
+  default:
+    // Do nothing. Keep this to avoid VS2013 warning.
+    break;
+  }
+  getDecoder(I) >> WordLiterals;
+  getOrCreateTarget()->addExecutionMode(this);
+}
+
+SPIRVForward *SPIRVAnnotationGeneric::getOrCreateTarget() const {
+  SPIRVEntry *Entry = nullptr;
+  bool Found = Module->exist(Target, &Entry);
+  assert((!Found || Entry->getOpCode() == OpForward) &&
+         "Annotations only allowed on forward");
+  if (!Found)
+    Entry = Module->addForward(Target, nullptr);
+  return static_cast<SPIRVForward *>(Entry);
+}
+
+SPIRVName::SPIRVName(const SPIRVEntry *TheTarget, const std::string &TheStr)
+    : SPIRVAnnotation(TheTarget, getSizeInWords(TheStr) + 2), Str(TheStr) {}
+
+void SPIRVName::encode(spv_ostream &O) const { getEncoder(O) << Target << Str; }
+
+void SPIRVName::decode(std::istream &I) {
+  getDecoder(I) >> Target >> Str;
+  Module->setName(getOrCreateTarget(), Str);
+}
+
+void SPIRVName::validate() const {
+  assert(WordCount == getSizeInWords(Str) + 2 && "Incorrect word count");
+}
+
+_SPIRV_IMP_ENCDEC2(SPIRVString, Id, Str)
+_SPIRV_IMP_ENCDEC3(SPIRVMemberName, Target, MemberNumber, Str)
+
+void SPIRVLine::encode(spv_ostream &O) const {
+  getEncoder(O) << Target << FileName << Line << Column;
+}
+
+void SPIRVLine::decode(std::istream &I) {
+  getDecoder(I) >> Target >> FileName >> Line >> Column;
+  Module->addLine(getOrCreateTarget(), get<SPIRVString>(FileName), Line,
+                  Column);
+}
+
+void SPIRVLine::validate() const {
+  assert(OpCode == OpLine);
+  assert(WordCount == 5);
+  assert(get<SPIRVEntry>(Target));
+  assert(get<SPIRVEntry>(FileName)->getOpCode() == OpString);
+  assert(Line != SPIRVWORD_MAX);
+  assert(Column != SPIRVWORD_MAX);
+}
+
+void SPIRVMemberName::validate() const {
+  assert(OpCode == OpMemberName);
+  assert(WordCount == getSizeInWords(Str) + FixedWC);
+  assert(get<SPIRVEntry>(Target)->getOpCode() == OpTypeStruct);
+  assert(MemberNumber < get<SPIRVTypeStruct>(Target)->getStructMemberCount());
+}
+
+SPIRVExtInstImport::SPIRVExtInstImport(SPIRVModule *TheModule, SPIRVId TheId,
+                                       const std::string &TheStr)
+    : SPIRVEntry(TheModule, 2 + getSizeInWords(TheStr), OC, TheId),
+      Str(TheStr) {
+  validate();
+}
+
+void SPIRVExtInstImport::encode(spv_ostream &O) const {
+  getEncoder(O) << Id << Str;
+}
+
+void SPIRVExtInstImport::decode(std::istream &I) {
+  getDecoder(I) >> Id >> Str;
+  Module->importBuiltinSetWithId(Str, Id);
+}
+
+void SPIRVExtInstImport::validate() const {
+  SPIRVEntry::validate();
+  assert(!Str.empty() && "Invalid builtin set");
+}
+
+void SPIRVMemoryModel::encode(spv_ostream &O) const {
+  getEncoder(O) << Module->getAddressingModel() << Module->getMemoryModel();
+}
+
+void SPIRVMemoryModel::decode(std::istream &I) {
+  SPIRVAddressingModelKind AddrModel;
+  SPIRVMemoryModelKind MemModel;
+  getDecoder(I) >> AddrModel >> MemModel;
+  Module->setAddressingModel(AddrModel);
+  Module->setMemoryModel(MemModel);
+}
+
+void SPIRVMemoryModel::validate() const {
+  auto AM = Module->getAddressingModel();
+  auto MM = Module->getMemoryModel();
+  SPIRVCK(isValid(AM), InvalidAddressingModel, "Actual is " + AM);
+  SPIRVCK(isValid(MM), InvalidMemoryModel, "Actual is " + MM);
+}
+
+void SPIRVSource::encode(spv_ostream &O) const {
+  SPIRVWord Ver = SPIRVWORD_MAX;
+  auto Language = Module->getSourceLanguage(&Ver);
+  getEncoder(O) << Language << Ver;
+}
+
+void SPIRVSource::decode(std::istream &I) {
+  SourceLanguage Lang = SourceLanguageUnknown;
+  SPIRVWord Ver = SPIRVWORD_MAX;
+  getDecoder(I) >> Lang >> Ver;
+  Module->setSourceLanguage(Lang, Ver);
+}
+
+SPIRVSourceExtension::SPIRVSourceExtension(SPIRVModule *M,
+                                           const std::string &SS)
+    : SPIRVEntryNoId(M, 1 + getSizeInWords(SS)), S(SS) {}
+
+void SPIRVSourceExtension::encode(spv_ostream &O) const { getEncoder(O) << S; }
+
+void SPIRVSourceExtension::decode(std::istream &I) {
+  getDecoder(I) >> S;
+  Module->getSourceExtension().insert(S);
+}
+
+SPIRVExtension::SPIRVExtension(SPIRVModule *M, const std::string &SS)
+    : SPIRVEntryNoId(M, 1 + getSizeInWords(SS)), S(SS) {}
+
+void SPIRVExtension::encode(spv_ostream &O) const { getEncoder(O) << S; }
+
+void SPIRVExtension::decode(std::istream &I) {
+  getDecoder(I) >> S;
+  Module->getExtension().insert(S);
+}
+
+SPIRVCapability::SPIRVCapability(SPIRVModule *M, SPIRVCapabilityKind K)
+    : SPIRVEntryNoId(M, 2), Kind(K) {
+  updateModuleVersion();
+}
+
+void SPIRVCapability::encode(spv_ostream &O) const { getEncoder(O) << Kind; }
+
+void SPIRVCapability::decode(std::istream &I) {
+  getDecoder(I) >> Kind;
+  Module->addCapability(Kind);
+}
+
+} // namespace SPIRV
diff --git a/lib/SPIRV/libSPIRV/SPIRVEntry.h b/lib/SPIRV/libSPIRV/SPIRVEntry.h
new file mode 100644
index 0000000..74b7311
--- /dev/null
+++ b/lib/SPIRV/libSPIRV/SPIRVEntry.h
@@ -0,0 +1,768 @@
+//===- SPIRVEntry.h - Base Class for SPIR-V Entities ------------*- C++ -*-===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+/// \file
+///
+/// This file defines the base class for SPIRV entities.
+///
+//===----------------------------------------------------------------------===//
+
+#ifndef SPIRVENTRY_HPP_
+#define SPIRVENTRY_HPP_
+
+#include "SPIRVEnum.h"
+#include "SPIRVIsValidEnum.h"
+#include "SPIRVError.h"
+#include <cassert>
+#include <iostream>
+#include <map>
+#include <memory>
+#include <set>
+#include <string>
+#include <vector>
+
+namespace SPIRV {
+
+class SPIRVModule;
+class SPIRVEncoder;
+class SPIRVDecoder;
+class SPIRVType;
+class SPIRVValue;
+class SPIRVDecorate;
+class SPIRVForward;
+class SPIRVMemberDecorate;
+class SPIRVLine;
+class SPIRVString;
+class SPIRVExtInst;
+
+// Add declaration of encode/decode functions to a class.
+// Used inside class definition.
+#define _SPIRV_DCL_ENCDEC                                                      \
+  void encode(spv_ostream &O) const;                                           \
+  void decode(std::istream &I);
+
+#define _REQ_SPIRV_VER(Version)                                                \
+  SPIRVWord getRequiredSPIRVVersion() const override { return Version; }
+
+// Add implementation of encode/decode functions to a class.
+// Used out side of class definition.
+#define _SPIRV_IMP_ENCDEC0(Ty)                                                 \
+  void Ty::encode(spv_ostream &O) const {}                                     \
+  void Ty::decode(std::istream &I) {}
+#define _SPIRV_IMP_ENCDEC1(Ty, x)                                              \
+  void Ty::encode(spv_ostream &O) const { getEncoder(O) << x; }                \
+  void Ty::decode(std::istream &I) { getDecoder(I) >> x; }
+#define _SPIRV_IMP_ENCDEC2(Ty, x, y)                                           \
+  void Ty::encode(spv_ostream &O) const { getEncoder(O) << x << y; }           \
+  void Ty::decode(std::istream &I) { getDecoder(I) >> x >> y; }
+#define _SPIRV_IMP_ENCDEC3(Ty, x, y, z)                                        \
+  void Ty::encode(spv_ostream &O) const { getEncoder(O) << x << y << z; }      \
+  void Ty::decode(std::istream &I) { getDecoder(I) >> x >> y >> z; }
+#define _SPIRV_IMP_ENCDEC4(Ty, x, y, z, u)                                     \
+  void Ty::encode(spv_ostream &O) const { getEncoder(O) << x << y << z << u; } \
+  void Ty::decode(std::istream &I) { getDecoder(I) >> x >> y >> z >> u; }
+#define _SPIRV_IMP_ENCDEC5(Ty, x, y, z, u, v)                                  \
+  void Ty::encode(spv_ostream &O) const {                                      \
+    getEncoder(O) << x << y << z << u << v;                                    \
+  }                                                                            \
+  void Ty::decode(std::istream &I) { getDecoder(I) >> x >> y >> z >> u >> v; }
+#define _SPIRV_IMP_ENCDEC6(Ty, x, y, z, u, v, w)                               \
+  void Ty::encode(spv_ostream &O) const {                                      \
+    getEncoder(O) << x << y << z << u << v << w;                               \
+  }                                                                            \
+  void Ty::decode(std::istream &I) {                                           \
+    getDecoder(I) >> x >> y >> z >> u >> v >> w;                               \
+  }
+#define _SPIRV_IMP_ENCDEC7(Ty, x, y, z, u, v, w, r)                            \
+  void Ty::encode(spv_ostream &O) const {                                      \
+    getEncoder(O) << x << y << z << u << v << w << r;                          \
+  }                                                                            \
+  void Ty::decode(std::istream &I) {                                           \
+    getDecoder(I) >> x >> y >> z >> u >> v >> w >> r;                          \
+  }
+#define _SPIRV_IMP_ENCDEC8(Ty, x, y, z, u, v, w, r, s)                         \
+  void Ty::encode(spv_ostream &O) const {                                      \
+    getEncoder(O) << x << y << z << u << v << w << r << s;                     \
+  }                                                                            \
+  void Ty::decode(std::istream &I) {                                           \
+    getDecoder(I) >> x >> y >> z >> u >> v >> w >> r >> s;                     \
+  }
+#define _SPIRV_IMP_ENCDEC9(Ty, x, y, z, u, v, w, r, s, t)                      \
+  void Ty::encode(spv_ostream &O) const {                                      \
+    getEncoder(O) << x << y << z << u << v << w << r << s << t;                \
+  }                                                                            \
+  void Ty::decode(std::istream &I) {                                           \
+    getDecoder(I) >> x >> y >> z >> u >> v >> w >> r >> s >> t;                \
+  }
+
+// Add definition of encode/decode functions to a class.
+// Used inside class definition.
+#define _SPIRV_DEF_ENCDEC0                                                     \
+  void encode(spv_ostream &O) const {}                                         \
+  void decode(std::istream &I) {}
+#define _SPIRV_DEF_ENCDEC1(x)                                                  \
+  void encode(spv_ostream &O) const { getEncoder(O) << x; }                    \
+  void decode(std::istream &I) { getDecoder(I) >> x; }
+#define _SPIRV_DEF_ENCDEC2(x, y)                                               \
+  void encode(spv_ostream &O) const { getEncoder(O) << x << y; }               \
+  void decode(std::istream &I) { getDecoder(I) >> x >> y; }
+#define _SPIRV_DEF_ENCDEC3(x, y, z)                                            \
+  void encode(spv_ostream &O) const { getEncoder(O) << x << y << z; }          \
+  void decode(std::istream &I) { getDecoder(I) >> x >> y >> z; }
+#define _SPIRV_DEF_ENCDEC4(x, y, z, u)                                         \
+  void encode(spv_ostream &O) const { getEncoder(O) << x << y << z << u; }     \
+  void decode(std::istream &I) { getDecoder(I) >> x >> y >> z >> u; }
+#define _SPIRV_DEF_ENCDEC5(x, y, z, u, v)                                      \
+  void encode(spv_ostream &O) const {                                          \
+    getEncoder(O) << x << y << z << u << v;                                    \
+  }                                                                            \
+  void decode(std::istream &I) { getDecoder(I) >> x >> y >> z >> u >> v; }
+#define _SPIRV_DEF_ENCDEC6(x, y, z, u, v, w)                                   \
+  void encode(spv_ostream &O) const {                                          \
+    getEncoder(O) << x << y << z << u << v << w;                               \
+  }                                                                            \
+  void decode(std::istream &I) { getDecoder(I) >> x >> y >> z >> u >> v >> w; }
+#define _SPIRV_DEF_ENCDEC7(x, y, z, u, v, w, r)                                \
+  void encode(spv_ostream &O) const {                                          \
+    getEncoder(O) << x << y << z << u << v << w << r;                          \
+  }                                                                            \
+  void decode(std::istream &I) {                                               \
+    getDecoder(I) >> x >> y >> z >> u >> v >> w >> r;                          \
+  }
+#define _SPIRV_DEF_ENCDEC8(x, y, z, u, v, w, r, s)                             \
+  void encode(spv_ostream &O) const {                                          \
+    getEncoder(O) << x << y << z << u << v << w << r << s;                     \
+  }                                                                            \
+  void decode(std::istream &I) {                                               \
+    getDecoder(I) >> x >> y >> z >> u >> v >> w >> r >> s;                     \
+  }
+#define _SPIRV_DEF_ENCDEC9(x, y, z, u, v, w, r, s, t)                          \
+  void encode(spv_ostream &O) const {                                          \
+    getEncoder(O) << x << y << z << u << v << w << r << s << t;                \
+  }                                                                            \
+  void decode(std::istream &I) {                                               \
+    getDecoder(I) >> x >> y >> z >> u >> v >> w >> r >> s >> t;                \
+  }
+
+/// All SPIR-V in-memory-representation entities inherits from SPIRVEntry.
+/// Usually there are two flavors of constructors of SPIRV objects:
+///
+/// 1. complete constructor: It requires all the parameters needed to create a
+///    SPIRV entity with complete information which can be validated. It is
+///    usually used by LLVM/SPIR-V translator to create SPIRV object
+///    corresponding to LLVM object. Such constructor calls validate() at
+///    the end of the construction.
+///
+/// 2. incomplete constructor: For leaf classes, it has no parameters.
+///    It is usually called by SPIRVEntry::make(opcode) to create an incomplete
+///    object which should not be validated. Then setWordCount(count) is
+///    called to fix the size of the object if it is variable, and then the
+///    information is filled by the virtual function decode(istream).
+///    After that the object can be validated.
+///
+/// To add a new SPIRV class:
+///
+/// 1. It is recommended to name the class as SPIRVXXX if it has a fixed op code
+///    OpXXX. Although it is not mandatory, doing this facilitates adding it to
+///    the table of the factory function SPIRVEntry::create().
+/// 2. Inherit from proper SPIRV class such as SPIRVType, SPIRVValue,
+///    SPIRVInstruction, etc.
+/// 3. Implement virtual function encode(), decode(), validate().
+/// 4. If the object has variable size, implement virtual function
+///    setWordCount().
+/// 5. If the class has special attributes, e.g. having no id, or having no
+///    type as a value, set them in the constructors.
+/// 6. If the class may represent SPIRV entity which has been added in version
+///    later than 1.0, implement virtual function getRequiredSPIRVVersion().
+///    To automaticly update module's version you can also call protected
+///    function updateModuleVersion() in the constructor.
+/// 7. Add the class to the Table of SPIRVEntry::create().
+/// 8. Add the class to SPIRVToLLVM and LLVMToSPIRV.
+
+class SPIRVEntry {
+public:
+  enum SPIRVEntryAttrib {
+    SPIRVEA_DEFAULT = 0,
+    SPIRVEA_NOID = 1,   // Entry has no valid id
+    SPIRVEA_NOTYPE = 2, // Value has no type
+  };
+
+  // Complete constructor for objects with id
+  SPIRVEntry(SPIRVModule *M, unsigned TheWordCount, Op TheOpCode, SPIRVId TheId)
+      : Module(M), OpCode(TheOpCode), Id(TheId), Attrib(SPIRVEA_DEFAULT),
+        WordCount(TheWordCount), Line(nullptr) {
+    validate();
+  }
+
+  // Complete constructor for objects without id
+  SPIRVEntry(SPIRVModule *M, unsigned TheWordCount, Op TheOpCode)
+      : Module(M), OpCode(TheOpCode), Id(SPIRVID_INVALID), Attrib(SPIRVEA_NOID),
+        WordCount(TheWordCount), Line(nullptr) {
+    validate();
+  }
+
+  // Incomplete constructor
+  SPIRVEntry(Op TheOpCode)
+      : Module(NULL), OpCode(TheOpCode), Id(SPIRVID_INVALID),
+        Attrib(SPIRVEA_DEFAULT), WordCount(0), Line(nullptr) {}
+
+  SPIRVEntry()
+      : Module(NULL), OpCode(OpNop), Id(SPIRVID_INVALID),
+        Attrib(SPIRVEA_DEFAULT), WordCount(0), Line(nullptr) {}
+
+  virtual ~SPIRVEntry() {}
+
+  bool exist(SPIRVId) const;
+  template <class T> T *get(SPIRVId TheId) const {
+    return static_cast<T *>(getEntry(TheId));
+  }
+  SPIRVEntry *getEntry(SPIRVId) const;
+  SPIRVEntry *getOrCreate(SPIRVId TheId) const;
+  SPIRVValue *getValue(SPIRVId TheId) const;
+  std::vector<SPIRVValue *> getValues(const std::vector<SPIRVId> &) const;
+  std::vector<SPIRVId> getIds(const std::vector<SPIRVValue *>) const;
+  SPIRVType *getValueType(SPIRVId TheId) const;
+  std::vector<SPIRVType *> getValueTypes(const std::vector<SPIRVId> &) const;
+
+  virtual SPIRVDecoder getDecoder(std::istream &);
+  virtual SPIRVEncoder getEncoder(spv_ostream &) const;
+  SPIRVErrorLog &getErrorLog() const;
+  SPIRVId getId() const {
+    assert(hasId());
+    return Id;
+  }
+  SPIRVLine *getLine() const { return Line; }
+  SPIRVLinkageTypeKind getLinkageType() const;
+  Op getOpCode() const { return OpCode; }
+  SPIRVModule *getModule() const { return Module; }
+  virtual SPIRVCapVec getRequiredCapability() const { return SPIRVCapVec(); }
+  const std::string &getName() const { return Name; }
+  bool hasDecorate(Decoration Kind, size_t Index = 0,
+                   SPIRVWord *Result = 0) const;
+  std::set<SPIRVWord> getDecorate(Decoration Kind, size_t Index = 0) const;
+  bool hasId() const { return !(Attrib & SPIRVEA_NOID); }
+  bool hasLine() const { return Line != nullptr; }
+  bool hasLinkageType() const;
+  bool isAtomic() const { return isAtomicOpCode(OpCode); }
+  bool isBasicBlock() const { return isLabel(); }
+  bool isBuiltinCall() const { return OpCode == OpExtInst; }
+  bool isDecorate() const { return OpCode == OpDecorate; }
+  bool isMemberDecorate() const { return OpCode == OpMemberDecorate; }
+  bool isForward() const { return OpCode == OpForward; }
+  bool isLabel() const { return OpCode == OpLabel; }
+  bool isUndef() const {
+    return OpCode == OpUndef || OpCode == OpUndefValueInternal;
+  }
+  bool isControlBarrier() const { return OpCode == OpControlBarrier; }
+  bool isMemoryBarrier() const { return OpCode == OpMemoryBarrier; }
+  bool isVariable() const { return OpCode == OpVariable; }
+  virtual bool isInst() const { return false; }
+  virtual bool isOperandLiteral(unsigned Index) const {
+    assert(0 && "not implemented");
+    return false;
+  }
+
+  void addDecorate(const SPIRVDecorate *);
+  void addDecorate(Decoration Kind);
+  void addDecorate(Decoration Kind, SPIRVWord Literal);
+  void eraseDecorate(Decoration);
+  void addMemberDecorate(const SPIRVMemberDecorate *);
+  void addMemberDecorate(SPIRVWord MemberNumber, Decoration Kind);
+  void addMemberDecorate(SPIRVWord MemberNumber, Decoration Kind,
+                         SPIRVWord Literal);
+  void eraseMemberDecorate(SPIRVWord MemberNumber, Decoration Kind);
+  void setHasNoId() { Attrib |= SPIRVEA_NOID; }
+  void setId(SPIRVId TheId) { Id = TheId; }
+  void setLine(SPIRVLine *);
+  void setLinkageType(SPIRVLinkageTypeKind);
+  void setModule(SPIRVModule *TheModule);
+  void setName(const std::string &TheName);
+  virtual void setScope(SPIRVEntry *Scope){};
+  void takeAnnotations(SPIRVForward *);
+  void takeDecorates(SPIRVEntry *);
+  void takeMemberDecorates(SPIRVEntry *);
+  void takeLine(SPIRVEntry *);
+
+  /// After a SPIRV entry is created during reading SPIRV binary by default
+  /// constructor, this function is called to allow the SPIRV entry to resize
+  /// its variable sized member before decoding the remaining words.
+  virtual void setWordCount(SPIRVWord TheWordCount);
+
+  /// Create an empty SPIRV object by op code, e.g. OpTypeInt creates
+  /// SPIRVTypeInt.
+  static SPIRVEntry *create(Op);
+  static std::unique_ptr<SPIRVEntry> create_unique(Op);
+
+  /// Create an empty extended instruction.
+  static std::unique_ptr<SPIRVExtInst> create_unique(SPIRVExtInstSetKind Set,
+                                                     unsigned ExtOp);
+
+  friend spv_ostream &operator<<(spv_ostream &O, const SPIRVEntry &E);
+  friend std::istream &operator>>(std::istream &I, SPIRVEntry &E);
+  virtual void encodeAll(spv_ostream &O) const;
+  virtual void encodeName(spv_ostream &O) const;
+  virtual void encodeChildren(spv_ostream &O) const;
+  virtual void encodeDecorate(spv_ostream &O) const;
+  virtual void encodeWordCountOpCode(spv_ostream &O) const;
+  virtual void encode(spv_ostream &O) const;
+  virtual void decode(std::istream &I);
+
+  friend class SPIRVDecoder;
+
+  /// Checks the integrity of the object.
+  virtual void validate() const {
+    assert(Module && "Invalid module");
+    assert(OpCode != OpNop && "Invalid op code");
+    assert((!hasId() || isValidId(Id)) && "Invalid Id");
+  }
+  void validateFunctionControlMask(SPIRVWord FCtlMask) const;
+  void validateValues(const std::vector<SPIRVId> &) const;
+  void validateBuiltin(SPIRVWord, SPIRVWord) const;
+
+  // By default assume SPIRV 1.0 as required version
+  virtual SPIRVWord getRequiredSPIRVVersion() const { return SPIRV_1_0; }
+
+  virtual std::vector<SPIRVEntry *> getNonLiteralOperands() const {
+    return std::vector<SPIRVEntry *>();
+  }
+
+protected:
+  /// An entry may have multiple FuncParamAttr decorations.
+  typedef std::multimap<Decoration, const SPIRVDecorate *> DecorateMapType;
+  typedef std::map<std::pair<SPIRVWord, Decoration>,
+                   const SPIRVMemberDecorate *>
+      MemberDecorateMapType;
+
+  bool canHaveMemberDecorates() const {
+    return OpCode == OpTypeStruct || OpCode == OpForward;
+  }
+
+  void updateModuleVersion() const;
+
+  SPIRVModule *Module;
+  Op OpCode;
+  SPIRVId Id;
+  std::string Name;
+  unsigned Attrib;
+  SPIRVWord WordCount;
+
+  DecorateMapType Decorates;
+  MemberDecorateMapType MemberDecorates;
+  SPIRVLine *Line;
+
+public:
+  MemberDecorateMapType &getMemberDecorates() {
+    assert(canHaveMemberDecorates());
+    return MemberDecorates;
+  }
+};
+
+class SPIRVEntryNoIdGeneric : public SPIRVEntry {
+public:
+  SPIRVEntryNoIdGeneric(SPIRVModule *M, unsigned TheWordCount, Op OC)
+      : SPIRVEntry(M, TheWordCount, OC) {
+    setAttr();
+  }
+  SPIRVEntryNoIdGeneric(Op OC) : SPIRVEntry(OC) { setAttr(); }
+
+protected:
+  void setAttr() { setHasNoId(); }
+};
+
+template <Op OC> class SPIRVEntryNoId : public SPIRVEntryNoIdGeneric {
+public:
+  SPIRVEntryNoId(SPIRVModule *M, unsigned TheWordCount)
+      : SPIRVEntryNoIdGeneric(M, TheWordCount, OC) {}
+  SPIRVEntryNoId() : SPIRVEntryNoIdGeneric(OC) {}
+};
+
+template <Op TheOpCode>
+class SPIRVEntryOpCodeOnly : public SPIRVEntryNoId<TheOpCode> {
+public:
+  SPIRVEntryOpCodeOnly() {
+    SPIRVEntry::WordCount = 1;
+    validate();
+  }
+
+protected:
+  _SPIRV_DEF_ENCDEC0
+  void validate() const { assert(isValidId(SPIRVEntry::OpCode)); }
+};
+
+class SPIRVAnnotationGeneric : public SPIRVEntryNoIdGeneric {
+public:
+  // Complete constructor
+  SPIRVAnnotationGeneric(SPIRVModule *TheModule, unsigned TheWordCount, Op OC,
+                         SPIRVId TheTarget = SPIRVID_INVALID)
+      : SPIRVEntryNoIdGeneric(TheModule, TheWordCount, OC), Target(TheTarget) {}
+  // Incomplete constructor
+  SPIRVAnnotationGeneric(Op OC)
+      : SPIRVEntryNoIdGeneric(OC), Target(SPIRVID_INVALID) {}
+
+  SPIRVId getTargetId() const { return Target; }
+  SPIRVForward *getOrCreateTarget() const;
+  void setTargetId(SPIRVId T) { Target = T; }
+
+protected:
+  SPIRVId Target;
+};
+
+template <Op OC> class SPIRVAnnotation : public SPIRVAnnotationGeneric {
+public:
+  // Complete constructor
+  SPIRVAnnotation(const SPIRVEntry *TheTarget, unsigned TheWordCount)
+      : SPIRVAnnotationGeneric(TheTarget->getModule(), TheWordCount, OC,
+                               TheTarget->getId()) {}
+  // Incomplete constructor
+  SPIRVAnnotation() : SPIRVAnnotationGeneric(OC) {}
+};
+
+class SPIRVEntryPoint : public SPIRVAnnotation<OpEntryPoint> {
+public:
+  SPIRVEntryPoint(SPIRVModule *TheModule, SPIRVExecutionModelKind,
+                  SPIRVId TheId, const std::string &TheName,
+                  const unsigned int io_var_count);
+  SPIRVEntryPoint() : ExecModel(ExecutionModelKernel) {}
+  _SPIRV_DCL_ENCDEC
+protected:
+  SPIRVExecutionModelKind ExecModel;
+  std::string Name;
+};
+
+class SPIRVName : public SPIRVAnnotation<OpName> {
+public:
+  // Complete constructor
+  SPIRVName(const SPIRVEntry *TheTarget, const std::string &TheStr);
+  // Incomplete constructor
+  SPIRVName() {}
+
+protected:
+  _SPIRV_DCL_ENCDEC
+  void validate() const;
+
+  std::string Str;
+};
+
+class SPIRVMemberName : public SPIRVAnnotation<OpName> {
+public:
+  static const SPIRVWord FixedWC = 3;
+  // Complete constructor
+  SPIRVMemberName(const SPIRVEntry *TheTarget, SPIRVWord TheMemberNumber,
+                  const std::string &TheStr)
+      : SPIRVAnnotation(TheTarget, FixedWC + getSizeInWords(TheStr)),
+        MemberNumber(TheMemberNumber), Str(TheStr) {
+    validate();
+  }
+  // Incomplete constructor
+  SPIRVMemberName() : MemberNumber(SPIRVWORD_MAX) {}
+
+protected:
+  _SPIRV_DCL_ENCDEC
+  void validate() const;
+  SPIRVWord MemberNumber;
+  std::string Str;
+};
+
+class SPIRVString : public SPIRVEntry {
+  static const Op OC = OpString;
+  static const SPIRVWord FixedWC = 2;
+
+public:
+  SPIRVString(SPIRVModule *M, SPIRVId TheId, const std::string &TheStr)
+      : SPIRVEntry(M, FixedWC + getSizeInWords(TheStr), OC, TheId),
+        Str(TheStr) {}
+  SPIRVString() : SPIRVEntry(OC) {}
+  _SPIRV_DCL_ENCDEC
+  const std::string &getStr() const { return Str; }
+
+protected:
+  std::string Str;
+};
+
+class SPIRVLine : public SPIRVAnnotation<OpLine> {
+public:
+  static const SPIRVWord WC = 5;
+  // Complete constructor
+  SPIRVLine(const SPIRVEntry *TheTarget, SPIRVId TheFileName, SPIRVWord TheLine,
+            SPIRVWord TheColumn)
+      : SPIRVAnnotation(TheTarget, WC), FileName(TheFileName), Line(TheLine),
+        Column(TheColumn) {
+    validate();
+  }
+  // Incomplete constructor
+  SPIRVLine()
+      : FileName(SPIRVID_INVALID), Line(SPIRVWORD_MAX), Column(SPIRVWORD_MAX) {}
+
+  SPIRVWord getColumn() const { return Column; }
+
+  void setColumn(SPIRVWord column) { Column = column; }
+
+  SPIRVId getFileName() const { return FileName; }
+
+  const std::string &getFileNameStr() const {
+    return get<SPIRVString>(FileName)->getStr();
+  }
+
+  void setFileName(SPIRVId fileName) { FileName = fileName; }
+
+  SPIRVWord getLine() const { return Line; }
+
+  void setLine(SPIRVWord line) { Line = line; }
+
+protected:
+  _SPIRV_DCL_ENCDEC
+  void validate() const;
+  SPIRVId FileName;
+  SPIRVWord Line;
+  SPIRVWord Column;
+};
+
+class SPIRVExecutionMode : public SPIRVAnnotation<OpExecutionMode> {
+public:
+  // Complete constructor for LocalSize, LocalSizeHint
+  SPIRVExecutionMode(SPIRVEntry *TheTarget, SPIRVExecutionModeKind TheExecMode,
+                     SPIRVWord x, SPIRVWord y, SPIRVWord z)
+      : SPIRVAnnotation(TheTarget, 6), ExecMode(TheExecMode) {
+    WordLiterals.push_back(x);
+    WordLiterals.push_back(y);
+    WordLiterals.push_back(z);
+    updateModuleVersion();
+  }
+  // Complete constructor for VecTypeHint, SubgroupSize, SubgroupsPerWorkgroup
+  SPIRVExecutionMode(SPIRVEntry *TheTarget, SPIRVExecutionModeKind TheExecMode,
+                     SPIRVWord code)
+      : SPIRVAnnotation(TheTarget, 4), ExecMode(TheExecMode) {
+    WordLiterals.push_back(code);
+    updateModuleVersion();
+  }
+  // Complete constructor for ContractionOff
+  SPIRVExecutionMode(SPIRVEntry *TheTarget, SPIRVExecutionModeKind TheExecMode)
+      : SPIRVAnnotation(TheTarget, 3), ExecMode(TheExecMode) {
+    updateModuleVersion();
+  }
+  // Incomplete constructor
+  SPIRVExecutionMode() : ExecMode(ExecutionModeInvocations) {}
+  SPIRVExecutionModeKind getExecutionMode() const { return ExecMode; }
+  const std::vector<SPIRVWord> &getLiterals() const { return WordLiterals; }
+  SPIRVCapVec getRequiredCapability() const { return getCapability(ExecMode); }
+
+  SPIRVWord getRequiredSPIRVVersion() const override {
+    switch (ExecMode) {
+    case ExecutionModeFinalizer:
+    case ExecutionModeInitializer:
+    case ExecutionModeSubgroupSize:
+    case ExecutionModeSubgroupsPerWorkgroup:
+      return SPIRV_1_1;
+
+    default:
+      return SPIRV_1_0;
+    }
+  }
+
+protected:
+  _SPIRV_DCL_ENCDEC
+  SPIRVExecutionModeKind ExecMode;
+  std::vector<SPIRVWord> WordLiterals;
+};
+
+class SPIRVComponentExecutionModes {
+  typedef std::map<SPIRVExecutionModeKind, SPIRVExecutionMode *>
+      SPIRVExecutionModeMap;
+
+public:
+  void addExecutionMode(SPIRVExecutionMode *ExecMode) {
+    ExecModes[ExecMode->getExecutionMode()] = ExecMode;
+  }
+  SPIRVExecutionMode *getExecutionMode(SPIRVExecutionModeKind EMK) const {
+    auto Loc = ExecModes.find(EMK);
+    if (Loc == ExecModes.end())
+      return nullptr;
+    return Loc->second;
+  }
+
+protected:
+  SPIRVExecutionModeMap ExecModes;
+};
+
+class SPIRVExtInstImport : public SPIRVEntry {
+public:
+  const static Op OC = OpExtInstImport;
+  // Complete constructor
+  SPIRVExtInstImport(SPIRVModule *TheModule, SPIRVId TheId,
+                     const std::string &TheStr);
+  // Incomplete constructor
+  SPIRVExtInstImport() : SPIRVEntry(OC) {}
+
+protected:
+  _SPIRV_DCL_ENCDEC
+  void validate() const;
+
+  std::string Str;
+};
+
+class SPIRVMemoryModel : public SPIRVEntryNoId<OpMemoryModel> {
+public:
+  SPIRVMemoryModel(SPIRVModule *M) : SPIRVEntryNoId(M, 3) {}
+  SPIRVMemoryModel() {}
+  _SPIRV_DCL_ENCDEC
+  void validate() const;
+};
+
+class SPIRVSource : public SPIRVEntryNoId<OpSource> {
+public:
+  SPIRVSource(SPIRVModule *M) : SPIRVEntryNoId(M, 3) {}
+  SPIRVSource() {}
+  _SPIRV_DCL_ENCDEC
+};
+
+class SPIRVSourceExtension : public SPIRVEntryNoId<OpSourceExtension> {
+public:
+  SPIRVSourceExtension(SPIRVModule *M, const std::string &SS);
+  SPIRVSourceExtension() {}
+  _SPIRV_DCL_ENCDEC
+private:
+  std::string S;
+};
+
+class SPIRVExtension : public SPIRVEntryNoId<OpExtension> {
+public:
+  SPIRVExtension(SPIRVModule *M, const std::string &SS);
+  SPIRVExtension() {}
+  _SPIRV_DCL_ENCDEC
+private:
+  std::string S;
+};
+
+class SPIRVCapability : public SPIRVEntryNoId<OpCapability> {
+public:
+  SPIRVCapability(SPIRVModule *M, SPIRVCapabilityKind K);
+  SPIRVCapability() : Kind(CapabilityMatrix) {}
+  _SPIRV_DCL_ENCDEC
+
+  SPIRVWord getRequiredSPIRVVersion() const override {
+    switch (Kind) {
+    case CapabilityNamedBarrier:
+    case CapabilitySubgroupDispatch:
+    case CapabilityPipeStorage:
+      return SPIRV_1_1;
+
+    default:
+      return SPIRV_1_0;
+    }
+  }
+
+private:
+  SPIRVCapabilityKind Kind;
+};
+
+template <class T> T *bcast(SPIRVEntry *E) { return static_cast<T *>(E); }
+
+// ToDo: The following typedef's are place holders for SPIRV entity classes
+// to be implemented.
+// Each time a new class is implemented, remove the corresponding typedef.
+// This is also an indication of how much work is left.
+#define _SPIRV_OP(x, ...) typedef SPIRVEntryOpCodeOnly<Op##x> SPIRV##x;
+_SPIRV_OP(Nop)
+_SPIRV_OP(SourceContinued, 2)
+_SPIRV_OP(TypeMatrix)
+_SPIRV_OP(SpecConstantTrue)
+_SPIRV_OP(SpecConstantFalse)
+_SPIRV_OP(SpecConstant)
+_SPIRV_OP(SpecConstantComposite)
+_SPIRV_OP(Image)
+_SPIRV_OP(ImageTexelPointer)
+_SPIRV_OP(CompositeConstruct)
+_SPIRV_OP(ImageSampleDrefImplicitLod)
+_SPIRV_OP(ImageSampleDrefExplicitLod)
+_SPIRV_OP(ImageSampleProjImplicitLod)
+_SPIRV_OP(ImageSampleProjExplicitLod)
+_SPIRV_OP(ImageSampleProjDrefImplicitLod)
+_SPIRV_OP(ImageSampleProjDrefExplicitLod)
+_SPIRV_OP(ImageFetch)
+_SPIRV_OP(ImageGather)
+_SPIRV_OP(ImageDrefGather)
+_SPIRV_OP(QuantizeToF16)
+_SPIRV_OP(Transpose)
+_SPIRV_OP(ArrayLength)
+_SPIRV_OP(VectorTimesScalar)
+_SPIRV_OP(MatrixTimesScalar)
+_SPIRV_OP(VectorTimesMatrix)
+_SPIRV_OP(MatrixTimesVector)
+_SPIRV_OP(MatrixTimesMatrix)
+_SPIRV_OP(OuterProduct)
+_SPIRV_OP(IAddCarry)
+_SPIRV_OP(ISubBorrow)
+_SPIRV_OP(SMulExtended)
+_SPIRV_OP(UMulExtended)
+_SPIRV_OP(BitFieldInsert)
+_SPIRV_OP(BitFieldSExtract)
+_SPIRV_OP(BitFieldUExtract)
+_SPIRV_OP(BitReverse)
+_SPIRV_OP(BitCount)
+_SPIRV_OP(DPdx)
+_SPIRV_OP(DPdy)
+_SPIRV_OP(Fwidth)
+_SPIRV_OP(DPdxFine)
+_SPIRV_OP(DPdyFine)
+_SPIRV_OP(FwidthFine)
+_SPIRV_OP(DPdxCoarse)
+_SPIRV_OP(DPdyCoarse)
+_SPIRV_OP(FwidthCoarse)
+_SPIRV_OP(EmitVertex)
+_SPIRV_OP(EndPrimitive)
+_SPIRV_OP(EmitStreamVertex)
+_SPIRV_OP(EndStreamPrimitive)
+_SPIRV_OP(LifetimeStart)
+_SPIRV_OP(LifetimeStop)
+_SPIRV_OP(ImageSparseSampleImplicitLod, 305)
+_SPIRV_OP(ImageSparseSampleExplicitLod, 306)
+_SPIRV_OP(ImageSparseSampleDrefImplicitLod, 307)
+_SPIRV_OP(ImageSparseSampleDrefExplicitLod, 308)
+_SPIRV_OP(ImageSparseSampleProjImplicitLod, 309)
+_SPIRV_OP(ImageSparseSampleProjExplicitLod, 310)
+_SPIRV_OP(ImageSparseSampleProjDrefImplicitLod, 311)
+_SPIRV_OP(ImageSparseSampleProjDrefExplicitLod, 312)
+_SPIRV_OP(ImageSparseFetch, 313)
+_SPIRV_OP(ImageSparseGather, 314)
+_SPIRV_OP(ImageSparseDrefGather, 315)
+_SPIRV_OP(ImageSparseTexelsResident, 316)
+_SPIRV_OP(NoLine, 317)
+_SPIRV_OP(TypeNamedBarrier)
+_SPIRV_OP(NamedBarrierInitialize)
+_SPIRV_OP(MemoryNamedBarrier)
+_SPIRV_OP(GetKernelMaxNumSubgroups)
+_SPIRV_OP(GetKernelLocalSizeForSubgroupCount)
+_SPIRV_OP(SizeOf)
+#undef _SPIRV_OP
+}
+#endif /* SPIRVENTRY_HPP_ */
diff --git a/lib/SPIRV/libSPIRV/SPIRVEnum.h b/lib/SPIRV/libSPIRV/SPIRVEnum.h
new file mode 100644
index 0000000..73503e6
--- /dev/null
+++ b/lib/SPIRV/libSPIRV/SPIRVEnum.h
@@ -0,0 +1,414 @@
+//===- SPIRVEnum.h - SPIR-V enums -------------------------------*- C++ -*-===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+/// \file
+///
+/// This file defines SPIR-V enums.
+///
+//===----------------------------------------------------------------------===//
+
+#ifndef SPIRVENUM_HPP_
+#define SPIRVENUM_HPP_
+
+#include "spirv.hpp"
+#include "SPIRVOpCode.h"
+#include <cstdint>
+using namespace spv;
+
+namespace SPIRV {
+
+typedef uint32_t SPIRVWord;
+typedef uint32_t SPIRVId;
+#define SPIRVID_MAX ~0U
+#define SPIRVID_INVALID ~0U
+#define SPIRVWORD_MAX ~0U
+
+inline bool isValidId(SPIRVId Id) { return Id != SPIRVID_INVALID && Id != 0; }
+
+inline SPIRVWord mkWord(unsigned WordCount, Op OpCode) {
+  return (WordCount << 16) | OpCode;
+}
+
+const static unsigned kSPIRVMemOrderSemanticMask = 0x1F;
+
+enum SPIRVVersion : SPIRVWord {
+  SPIRV_1_0 = 0x00010000,
+  SPIRV_1_1 = 0x00010100
+};
+
+enum SPIRVGeneratorKind {
+  SPIRVGEN_KhronosLLVMSPIRVTranslator = 6,
+  SPIRVGEN_KhronosSPIRVAssembler = 7,
+};
+
+enum SPIRVInstructionSchemaKind {
+  SPIRVISCH_Default,
+};
+
+enum SPIRVExtInstSetKind {
+  SPIRVEIS_OpenCL,
+  SPIRVEIS_GLSL,
+  SPIRVEIS_Count,
+};
+
+enum SPIRVSamplerAddressingModeKind {
+  SPIRVSAM_None = 0,
+  SPIRVSAM_ClampEdge = 2,
+  SPIRVSAM_Clamp = 4,
+  SPIRVSAM_Repeat = 6,
+  SPIRVSAM_RepeatMirrored = 8,
+  SPIRVSAM_Invalid = 255,
+};
+
+enum SPIRVSamplerFilterModeKind {
+  SPIRVSFM_Nearest = 16,
+  SPIRVSFM_Linear = 32,
+  SPIRVSFM_Invalid = 255,
+};
+
+typedef spv::Capability SPIRVCapabilityKind;
+typedef spv::ExecutionModel SPIRVExecutionModelKind;
+typedef spv::ExecutionMode SPIRVExecutionModeKind;
+typedef spv::AccessQualifier SPIRVAccessQualifierKind;
+typedef spv::AddressingModel SPIRVAddressingModelKind;
+typedef spv::LinkageType SPIRVLinkageTypeKind;
+typedef spv::MemoryModel SPIRVMemoryModelKind;
+typedef spv::StorageClass SPIRVStorageClassKind;
+typedef spv::FunctionControlMask SPIRVFunctionControlMaskKind;
+typedef spv::FPRoundingMode SPIRVFPRoundingModeKind;
+typedef spv::FunctionParameterAttribute SPIRVFuncParamAttrKind;
+typedef spv::BuiltIn SPIRVBuiltinVariableKind;
+typedef spv::MemoryAccessMask SPIRVMemoryAccessKind;
+typedef spv::GroupOperation SPIRVGroupOperationKind;
+typedef spv::Dim SPIRVImageDimKind;
+typedef std::vector<SPIRVCapabilityKind> SPIRVCapVec;
+
+template <> inline void SPIRVMap<SPIRVExtInstSetKind, std::string>::init() {
+  add(SPIRVEIS_OpenCL, "OpenCL.std");
+  add(SPIRVEIS_GLSL, "GLSL.std.450");
+}
+typedef SPIRVMap<SPIRVExtInstSetKind, std::string> SPIRVBuiltinSetNameMap;
+
+template <typename K> SPIRVCapVec getCapability(K Key) {
+  SPIRVCapVec V;
+  SPIRVMap<K, SPIRVCapVec>::find(Key, &V);
+  return V;
+}
+
+#define ADD_VEC_INIT(Cap, ...)                                                 \
+  {                                                                            \
+    SPIRVCapabilityKind C[] = __VA_ARGS__;                                     \
+    SPIRVCapVec V(C, C + sizeof(C) / sizeof(C[0]));                            \
+    add(Cap, V);                                                               \
+  }
+
+template <> inline void SPIRVMap<SPIRVCapabilityKind, SPIRVCapVec>::init() {
+  ADD_VEC_INIT(CapabilityShader, {CapabilityMatrix});
+  ADD_VEC_INIT(CapabilityGeometry, {CapabilityShader});
+  ADD_VEC_INIT(CapabilityTessellation, {CapabilityShader});
+  ADD_VEC_INIT(CapabilityVector16, {CapabilityKernel});
+  ADD_VEC_INIT(CapabilityFloat16Buffer, {CapabilityKernel});
+  ADD_VEC_INIT(CapabilityInt64Atomics, {CapabilityInt64});
+  ADD_VEC_INIT(CapabilityImageBasic, {CapabilityKernel});
+  ADD_VEC_INIT(CapabilityImageReadWrite, {CapabilityImageBasic});
+  ADD_VEC_INIT(CapabilityImageMipmap, {CapabilityImageBasic});
+  ADD_VEC_INIT(CapabilityPipes, {CapabilityKernel});
+  ADD_VEC_INIT(CapabilityDeviceEnqueue, {CapabilityKernel});
+  ADD_VEC_INIT(CapabilityLiteralSampler, {CapabilityKernel});
+  ADD_VEC_INIT(CapabilityAtomicStorage, {CapabilityShader});
+  ADD_VEC_INIT(CapabilityTessellationPointSize, {CapabilityTessellation});
+  ADD_VEC_INIT(CapabilityGeometryPointSize, {CapabilityGeometry});
+  ADD_VEC_INIT(CapabilityImageGatherExtended, {CapabilityShader});
+  ADD_VEC_INIT(CapabilityStorageImageMultisample, {CapabilityShader});
+  ADD_VEC_INIT(CapabilityUniformBufferArrayDynamicIndexing, {CapabilityShader});
+  ADD_VEC_INIT(CapabilitySampledImageArrayDynamicIndexing, {CapabilityShader});
+  ADD_VEC_INIT(CapabilityStorageBufferArrayDynamicIndexing, {CapabilityShader});
+  ADD_VEC_INIT(CapabilityStorageImageArrayDynamicIndexing, {CapabilityShader});
+  ADD_VEC_INIT(CapabilityClipDistance, {CapabilityShader});
+  ADD_VEC_INIT(CapabilityCullDistance, {CapabilityShader});
+  ADD_VEC_INIT(CapabilityImageCubeArray, {CapabilitySampledCubeArray});
+  ADD_VEC_INIT(CapabilitySampleRateShading, {CapabilityShader});
+  ADD_VEC_INIT(CapabilityImageRect, {CapabilitySampledRect});
+  ADD_VEC_INIT(CapabilitySampledRect, {CapabilityShader});
+  ADD_VEC_INIT(CapabilityGenericPointer, {CapabilityAddresses});
+  ADD_VEC_INIT(CapabilityInt8, {CapabilityKernel});
+  ADD_VEC_INIT(CapabilityInputAttachment, {CapabilityShader});
+  ADD_VEC_INIT(CapabilitySparseResidency, {CapabilityShader});
+  ADD_VEC_INIT(CapabilityMinLod, {CapabilityShader});
+  ADD_VEC_INIT(CapabilitySampled1D, {CapabilityShader});
+  ADD_VEC_INIT(CapabilityImage1D, {CapabilitySampled1D});
+  ADD_VEC_INIT(CapabilitySampledCubeArray, {CapabilityShader});
+  ADD_VEC_INIT(CapabilitySampledBuffer, {CapabilityShader});
+  ADD_VEC_INIT(CapabilityImageBuffer, {CapabilitySampledBuffer});
+  ADD_VEC_INIT(CapabilityImageMSArray, {CapabilityShader});
+  ADD_VEC_INIT(CapabilityStorageImageExtendedFormats, {CapabilityShader});
+  ADD_VEC_INIT(CapabilityImageQuery, {CapabilityShader});
+  ADD_VEC_INIT(CapabilityDerivativeControl, {CapabilityShader});
+  ADD_VEC_INIT(CapabilityInterpolationFunction, {CapabilityShader});
+  ADD_VEC_INIT(CapabilityTransformFeedback, {CapabilityShader});
+  ADD_VEC_INIT(CapabilityGeometryStreams, {CapabilityGeometry});
+  ADD_VEC_INIT(CapabilityStorageImageReadWithoutFormat, {CapabilityShader});
+  ADD_VEC_INIT(CapabilityStorageImageWriteWithoutFormat, {CapabilityShader});
+  ADD_VEC_INIT(CapabilityMultiViewport, {CapabilityGeometry});
+}
+
+template <> inline void SPIRVMap<SPIRVExecutionModelKind, SPIRVCapVec>::init() {
+  ADD_VEC_INIT(ExecutionModelVertex, {CapabilityShader});
+  ADD_VEC_INIT(ExecutionModelTessellationControl, {CapabilityTessellation});
+  ADD_VEC_INIT(ExecutionModelTessellationEvaluation, {CapabilityTessellation});
+  ADD_VEC_INIT(ExecutionModelGeometry, {CapabilityGeometry});
+  ADD_VEC_INIT(ExecutionModelFragment, {CapabilityShader});
+  ADD_VEC_INIT(ExecutionModelGLCompute, {CapabilityShader});
+  ADD_VEC_INIT(ExecutionModelKernel, {CapabilityKernel});
+}
+
+template <> inline void SPIRVMap<SPIRVExecutionModeKind, SPIRVCapVec>::init() {
+  ADD_VEC_INIT(ExecutionModeInvocations, {CapabilityGeometry});
+  ADD_VEC_INIT(ExecutionModeSpacingEqual, {CapabilityTessellation});
+  ADD_VEC_INIT(ExecutionModeSpacingFractionalEven, {CapabilityTessellation});
+  ADD_VEC_INIT(ExecutionModeSpacingFractionalOdd, {CapabilityTessellation});
+  ADD_VEC_INIT(ExecutionModeVertexOrderCw, {CapabilityTessellation});
+  ADD_VEC_INIT(ExecutionModeVertexOrderCcw, {CapabilityTessellation});
+  ADD_VEC_INIT(ExecutionModePixelCenterInteger, {CapabilityShader});
+  ADD_VEC_INIT(ExecutionModeOriginUpperLeft, {CapabilityShader});
+  ADD_VEC_INIT(ExecutionModeOriginLowerLeft, {CapabilityShader});
+  ADD_VEC_INIT(ExecutionModeEarlyFragmentTests, {CapabilityShader});
+  ADD_VEC_INIT(ExecutionModePointMode, {CapabilityTessellation});
+  ADD_VEC_INIT(ExecutionModeXfb, {CapabilityTransformFeedback});
+  ADD_VEC_INIT(ExecutionModeDepthReplacing, {CapabilityShader});
+  ADD_VEC_INIT(ExecutionModeDepthGreater, {CapabilityShader});
+  ADD_VEC_INIT(ExecutionModeDepthLess, {CapabilityShader});
+  ADD_VEC_INIT(ExecutionModeDepthUnchanged, {CapabilityShader});
+  ADD_VEC_INIT(ExecutionModeLocalSizeHint, {CapabilityKernel});
+  ADD_VEC_INIT(ExecutionModeInputPoints, {CapabilityGeometry});
+  ADD_VEC_INIT(ExecutionModeInputLines, {CapabilityGeometry});
+  ADD_VEC_INIT(ExecutionModeInputLinesAdjacency, {CapabilityGeometry});
+  ADD_VEC_INIT(ExecutionModeTriangles,
+               {CapabilityGeometry, CapabilityTessellation});
+  ADD_VEC_INIT(ExecutionModeInputTrianglesAdjacency, {CapabilityGeometry});
+  ADD_VEC_INIT(ExecutionModeQuads, {CapabilityTessellation});
+  ADD_VEC_INIT(ExecutionModeIsolines, {CapabilityTessellation});
+  ADD_VEC_INIT(ExecutionModeOutputVertices,
+               {CapabilityGeometry, CapabilityTessellation});
+  ADD_VEC_INIT(ExecutionModeOutputPoints, {CapabilityGeometry});
+  ADD_VEC_INIT(ExecutionModeOutputLineStrip, {CapabilityGeometry});
+  ADD_VEC_INIT(ExecutionModeOutputTriangleStrip, {CapabilityGeometry});
+  ADD_VEC_INIT(ExecutionModeVecTypeHint, {CapabilityKernel});
+  ADD_VEC_INIT(ExecutionModeContractionOff, {CapabilityKernel});
+}
+
+template <> inline void SPIRVMap<SPIRVMemoryModelKind, SPIRVCapVec>::init() {
+  ADD_VEC_INIT(MemoryModelSimple, {CapabilityShader});
+  ADD_VEC_INIT(MemoryModelGLSL450, {CapabilityShader});
+  ADD_VEC_INIT(MemoryModelOpenCL, {CapabilityKernel});
+}
+
+template <> inline void SPIRVMap<SPIRVStorageClassKind, SPIRVCapVec>::init() {
+  ADD_VEC_INIT(StorageClassInput, {CapabilityShader});
+  ADD_VEC_INIT(StorageClassUniform, {CapabilityShader});
+  ADD_VEC_INIT(StorageClassOutput, {CapabilityShader});
+  ADD_VEC_INIT(StorageClassPrivate, {CapabilityShader});
+  ADD_VEC_INIT(StorageClassGeneric, {CapabilityGenericPointer});
+  ADD_VEC_INIT(StorageClassPushConstant, {CapabilityShader});
+  ADD_VEC_INIT(StorageClassAtomicCounter, {CapabilityAtomicStorage});
+}
+
+template <> inline void SPIRVMap<SPIRVImageDimKind, SPIRVCapVec>::init() {
+  ADD_VEC_INIT(Dim1D, {CapabilitySampled1D});
+  ADD_VEC_INIT(DimCube, {CapabilityShader});
+  ADD_VEC_INIT(DimRect, {CapabilitySampledRect});
+  ADD_VEC_INIT(DimBuffer, {CapabilitySampledBuffer});
+  ADD_VEC_INIT(DimSubpassData, {CapabilityInputAttachment});
+}
+
+template <> inline void SPIRVMap<ImageFormat, SPIRVCapVec>::init() {
+  ADD_VEC_INIT(ImageFormatRgba32f, {CapabilityShader});
+  ADD_VEC_INIT(ImageFormatRgba16f, {CapabilityShader});
+  ADD_VEC_INIT(ImageFormatR32f, {CapabilityShader});
+  ADD_VEC_INIT(ImageFormatRgba8, {CapabilityShader});
+  ADD_VEC_INIT(ImageFormatRgba8Snorm, {CapabilityShader});
+  ADD_VEC_INIT(ImageFormatRg32f, {CapabilityStorageImageExtendedFormats});
+  ADD_VEC_INIT(ImageFormatRg16f, {CapabilityStorageImageExtendedFormats});
+  ADD_VEC_INIT(ImageFormatR11fG11fB10f,
+               {CapabilityStorageImageExtendedFormats});
+  ADD_VEC_INIT(ImageFormatR16f, {CapabilityStorageImageExtendedFormats});
+  ADD_VEC_INIT(ImageFormatRgba16, {CapabilityStorageImageExtendedFormats});
+  ADD_VEC_INIT(ImageFormatRgb10A2, {CapabilityStorageImageExtendedFormats});
+  ADD_VEC_INIT(ImageFormatRg16, {CapabilityStorageImageExtendedFormats});
+  ADD_VEC_INIT(ImageFormatRg8, {CapabilityStorageImageExtendedFormats});
+  ADD_VEC_INIT(ImageFormatR16, {CapabilityStorageImageExtendedFormats});
+  ADD_VEC_INIT(ImageFormatR8, {CapabilityStorageImageExtendedFormats});
+  ADD_VEC_INIT(ImageFormatRgba16Snorm, {CapabilityStorageImageExtendedFormats});
+  ADD_VEC_INIT(ImageFormatRg16Snorm, {CapabilityStorageImageExtendedFormats});
+  ADD_VEC_INIT(ImageFormatRg8Snorm, {CapabilityStorageImageExtendedFormats});
+  ADD_VEC_INIT(ImageFormatR16Snorm, {CapabilityStorageImageExtendedFormats});
+  ADD_VEC_INIT(ImageFormatR8Snorm, {CapabilityStorageImageExtendedFormats});
+  ADD_VEC_INIT(ImageFormatRgba32i, {CapabilityShader});
+  ADD_VEC_INIT(ImageFormatRgba16i, {CapabilityShader});
+  ADD_VEC_INIT(ImageFormatRgba8i, {CapabilityShader});
+  ADD_VEC_INIT(ImageFormatR32i, {CapabilityShader});
+  ADD_VEC_INIT(ImageFormatRg32i, {CapabilityStorageImageExtendedFormats});
+  ADD_VEC_INIT(ImageFormatRg16i, {CapabilityStorageImageExtendedFormats});
+  ADD_VEC_INIT(ImageFormatRg8i, {CapabilityStorageImageExtendedFormats});
+  ADD_VEC_INIT(ImageFormatR16i, {CapabilityStorageImageExtendedFormats});
+  ADD_VEC_INIT(ImageFormatR8i, {CapabilityStorageImageExtendedFormats});
+  ADD_VEC_INIT(ImageFormatRgba32ui, {CapabilityShader});
+  ADD_VEC_INIT(ImageFormatRgba16ui, {CapabilityShader});
+  ADD_VEC_INIT(ImageFormatRgba8ui, {CapabilityShader});
+  ADD_VEC_INIT(ImageFormatR32ui, {CapabilityShader});
+  ADD_VEC_INIT(ImageFormatRgb10a2ui, {CapabilityStorageImageExtendedFormats});
+  ADD_VEC_INIT(ImageFormatRg32ui, {CapabilityStorageImageExtendedFormats});
+  ADD_VEC_INIT(ImageFormatRg16ui, {CapabilityStorageImageExtendedFormats});
+  ADD_VEC_INIT(ImageFormatR16ui, {CapabilityStorageImageExtendedFormats});
+  ADD_VEC_INIT(ImageFormatR8ui, {CapabilityStorageImageExtendedFormats});
+}
+
+template <> inline void SPIRVMap<ImageOperandsMask, SPIRVCapVec>::init() {
+  ADD_VEC_INIT(ImageOperandsBiasMask, {CapabilityShader});
+  ADD_VEC_INIT(ImageOperandsOffsetMask, {CapabilityImageGatherExtended});
+  ADD_VEC_INIT(ImageOperandsMinLodMask, {CapabilityMinLod});
+}
+
+template <> inline void SPIRVMap<Decoration, SPIRVCapVec>::init() {
+  ADD_VEC_INIT(DecorationRelaxedPrecision, {CapabilityShader});
+  ADD_VEC_INIT(DecorationSpecId, {CapabilityShader});
+  ADD_VEC_INIT(DecorationBlock, {CapabilityShader});
+  ADD_VEC_INIT(DecorationBufferBlock, {CapabilityShader});
+  ADD_VEC_INIT(DecorationRowMajor, {CapabilityMatrix});
+  ADD_VEC_INIT(DecorationColMajor, {CapabilityMatrix});
+  ADD_VEC_INIT(DecorationArrayStride, {CapabilityShader});
+  ADD_VEC_INIT(DecorationMatrixStride, {CapabilityMatrix});
+  ADD_VEC_INIT(DecorationGLSLShared, {CapabilityShader});
+  ADD_VEC_INIT(DecorationGLSLPacked, {CapabilityShader});
+  ADD_VEC_INIT(DecorationCPacked, {CapabilityKernel});
+  ADD_VEC_INIT(DecorationNoPerspective, {CapabilityShader});
+  ADD_VEC_INIT(DecorationFlat, {CapabilityShader});
+  ADD_VEC_INIT(DecorationPatch, {CapabilityTessellation});
+  ADD_VEC_INIT(DecorationCentroid, {CapabilityShader});
+  ADD_VEC_INIT(DecorationSample, {CapabilitySampleRateShading});
+  ADD_VEC_INIT(DecorationInvariant, {CapabilityShader});
+  ADD_VEC_INIT(DecorationConstant, {CapabilityKernel});
+  ADD_VEC_INIT(DecorationUniform, {CapabilityShader});
+  ADD_VEC_INIT(DecorationSaturatedConversion, {CapabilityKernel});
+  ADD_VEC_INIT(DecorationStream, {CapabilityGeometryStreams});
+  ADD_VEC_INIT(DecorationLocation, {CapabilityShader});
+  ADD_VEC_INIT(DecorationComponent, {CapabilityShader});
+  ADD_VEC_INIT(DecorationIndex, {CapabilityShader});
+  ADD_VEC_INIT(DecorationBinding, {CapabilityShader});
+  ADD_VEC_INIT(DecorationDescriptorSet, {CapabilityShader});
+  ADD_VEC_INIT(DecorationOffset, {CapabilityShader});
+  ADD_VEC_INIT(DecorationXfbBuffer, {CapabilityTransformFeedback});
+  ADD_VEC_INIT(DecorationXfbStride, {CapabilityTransformFeedback});
+  ADD_VEC_INIT(DecorationFuncParamAttr, {CapabilityKernel});
+  ADD_VEC_INIT(DecorationFPRoundingMode, {CapabilityKernel});
+  ADD_VEC_INIT(DecorationFPFastMathMode, {CapabilityKernel});
+  ADD_VEC_INIT(DecorationLinkageAttributes, {CapabilityLinkage});
+  ADD_VEC_INIT(DecorationNoContraction, {CapabilityShader});
+  ADD_VEC_INIT(DecorationInputAttachmentIndex, {CapabilityInputAttachment});
+  ADD_VEC_INIT(DecorationAlignment, {CapabilityKernel});
+}
+
+template <> inline void SPIRVMap<BuiltIn, SPIRVCapVec>::init() {
+  ADD_VEC_INIT(BuiltInPosition, {CapabilityShader});
+  ADD_VEC_INIT(BuiltInPointSize, {CapabilityShader});
+  ADD_VEC_INIT(BuiltInClipDistance, {CapabilityClipDistance});
+  ADD_VEC_INIT(BuiltInCullDistance, {CapabilityCullDistance});
+  ADD_VEC_INIT(BuiltInVertexId, {CapabilityShader});
+  ADD_VEC_INIT(BuiltInInstanceId, {CapabilityShader});
+  ADD_VEC_INIT(BuiltInPrimitiveId,
+               {CapabilityGeometry, CapabilityTessellation});
+  ADD_VEC_INIT(BuiltInInvocationId,
+               {CapabilityGeometry, CapabilityTessellation});
+  ADD_VEC_INIT(BuiltInLayer, {CapabilityGeometry});
+  ADD_VEC_INIT(BuiltInViewportIndex, {CapabilityMultiViewport});
+  ADD_VEC_INIT(BuiltInTessLevelOuter, {CapabilityTessellation});
+  ADD_VEC_INIT(BuiltInTessLevelInner, {CapabilityTessellation});
+  ADD_VEC_INIT(BuiltInTessCoord, {CapabilityTessellation});
+  ADD_VEC_INIT(BuiltInPatchVertices, {CapabilityTessellation});
+  ADD_VEC_INIT(BuiltInFragCoord, {CapabilityShader});
+  ADD_VEC_INIT(BuiltInPointCoord, {CapabilityShader});
+  ADD_VEC_INIT(BuiltInFrontFacing, {CapabilityShader});
+  ADD_VEC_INIT(BuiltInSampleId, {CapabilitySampleRateShading});
+  ADD_VEC_INIT(BuiltInSamplePosition, {CapabilitySampleRateShading});
+  ADD_VEC_INIT(BuiltInSampleMask, {CapabilitySampleRateShading});
+  ADD_VEC_INIT(BuiltInFragDepth, {CapabilityShader});
+  ADD_VEC_INIT(BuiltInHelperInvocation, {CapabilityShader});
+  ADD_VEC_INIT(BuiltInWorkDim, {CapabilityKernel});
+  ADD_VEC_INIT(BuiltInGlobalSize, {CapabilityKernel});
+  ADD_VEC_INIT(BuiltInEnqueuedWorkgroupSize, {CapabilityKernel});
+  ADD_VEC_INIT(BuiltInGlobalOffset, {CapabilityKernel});
+  ADD_VEC_INIT(BuiltInGlobalLinearId, {CapabilityKernel});
+  ADD_VEC_INIT(BuiltInSubgroupSize, {CapabilityKernel});
+  ADD_VEC_INIT(BuiltInSubgroupMaxSize, {CapabilityKernel});
+  ADD_VEC_INIT(BuiltInNumSubgroups, {CapabilityKernel});
+  ADD_VEC_INIT(BuiltInNumEnqueuedSubgroups, {CapabilityKernel});
+  ADD_VEC_INIT(BuiltInSubgroupId, {CapabilityKernel});
+  ADD_VEC_INIT(BuiltInSubgroupLocalInvocationId, {CapabilityKernel});
+  ADD_VEC_INIT(BuiltInVertexIndex, {CapabilityShader});
+  ADD_VEC_INIT(BuiltInInstanceIndex, {CapabilityShader});
+}
+
+template <> inline void SPIRVMap<MemorySemanticsMask, SPIRVCapVec>::init() {
+  ADD_VEC_INIT(MemorySemanticsUniformMemoryMask, {CapabilityShader});
+  ADD_VEC_INIT(MemorySemanticsAtomicCounterMemoryMask,
+               {CapabilityAtomicStorage});
+}
+
+#undef ADD_VEC_INIT
+
+inline unsigned getImageDimension(SPIRVImageDimKind K) {
+  switch (K) {
+  case Dim1D:
+    return 1;
+  case Dim2D:
+    return 2;
+  case Dim3D:
+    return 3;
+  case DimCube:
+    return 2;
+  case DimRect:
+    return 2;
+  case DimBuffer:
+    return 1;
+  default:
+    return 0;
+  }
+}
+
+/// Extract memory order part of SPIR-V memory semantics.
+inline unsigned extractSPIRVMemOrderSemantic(unsigned Sema) {
+  return Sema & kSPIRVMemOrderSemanticMask;
+}
+}
+
+#endif /* SPIRVENUM_HPP_ */
diff --git a/lib/SPIRV/libSPIRV/SPIRVError.h b/lib/SPIRV/libSPIRV/SPIRVError.h
new file mode 100644
index 0000000..324eb70
--- /dev/null
+++ b/lib/SPIRV/libSPIRV/SPIRVError.h
@@ -0,0 +1,125 @@
+//===- SPIRVError.h - SPIR-V error code and checking ------------*- C++ -*-===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+//
+// This file defines SPIRV error code and checking utility.
+//
+//===----------------------------------------------------------------------===//
+
+#ifndef SPIRVERROR_HPP_
+#define SPIRVERROR_HPP_
+
+#include "SPIRVUtil.h"
+#include "SPIRVDebug.h"
+#include <string>
+#include <sstream>
+
+namespace SPIRV {
+
+// Check condition and set error code and error msg.
+// To use this macro, function checkError must be defined in the scope.
+#define SPIRVCK(Condition, ErrCode, ErrMsg)                                    \
+  getErrorLog().checkError(Condition, SPIRVEC_##ErrCode,                       \
+                           std::string() + ErrMsg, #Condition, __FILE__,       \
+                           __LINE__)
+
+// Check condition and set error code and error msg. If fail returns false.
+#define SPIRVCKRT(Condition, ErrCode, ErrMsg)                                  \
+  if (!getErrorLog().checkError(Condition, SPIRVEC_##ErrCode,                  \
+                                std::string() + ErrMsg, #Condition, __FILE__,  \
+                                __LINE__))                                     \
+    return false;
+
+// Defines error code enum type SPIRVErrorCode.
+enum SPIRVErrorCode {
+#define _SPIRV_OP(x, y) SPIRVEC_##x,
+#include "SPIRVErrorEnum.h"
+#undef _SPIRV_OP
+};
+
+// Defines OpErorMap which maps error code to a string describing the error.
+template <> inline void SPIRVMap<SPIRVErrorCode, std::string>::init() {
+#define _SPIRV_OP(x, y) add(SPIRVEC_##x, std::string(#x) + ": " + y);
+#include "SPIRVErrorEnum.h"
+#undef _SPIRV_OP
+}
+
+typedef SPIRVMap<SPIRVErrorCode, std::string> SPIRVErrorMap;
+
+class SPIRVErrorLog {
+public:
+  SPIRVErrorLog() : ErrorCode(SPIRVEC_Success) {}
+  SPIRVErrorCode getError(std::string &ErrMsg) {
+    ErrMsg = ErrorMsg;
+    return ErrorCode;
+  }
+  void setError(SPIRVErrorCode ErrCode, const std::string &ErrMsg) {
+    ErrorCode = ErrCode;
+    ErrorMsg = ErrMsg;
+  }
+  // Check if Condition is satisfied and set ErrCode and DetailedMsg
+  // if not. Returns true if no error.
+  bool checkError(bool Condition, SPIRVErrorCode ErrCode,
+                  const std::string &DetailedMsg = "",
+                  const char *CondString = nullptr,
+                  const char *FileName = nullptr, unsigned LineNumber = 0);
+
+protected:
+  SPIRVErrorCode ErrorCode;
+  std::string ErrorMsg;
+};
+
+inline bool SPIRVErrorLog::checkError(bool Cond, SPIRVErrorCode ErrCode,
+                                      const std::string &Msg,
+                                      const char *CondString,
+                                      const char *FileName, unsigned LineNo) {
+  std::stringstream SS;
+  if (Cond)
+    return Cond;
+  // Do not overwrite previous failure.
+  if (ErrorCode != SPIRVEC_Success)
+    return Cond;
+  SS << SPIRVErrorMap::map(ErrCode) << " " << Msg;
+  if (SPIRVDbgErrorMsgIncludesSourceInfo)
+    SS << " [Src: " << FileName << ":" << LineNo << " " << CondString << " ]";
+  setError(ErrCode, SS.str());
+  if (SPIRVDbgAssertOnError) {
+    spvdbgs() << SS.str() << '\n';
+    spvdbgs().flush();
+    assert(0);
+  }
+  return Cond;
+}
+}
+
+#endif /* SPIRVERROR_HPP_ */
diff --git a/lib/SPIRV/libSPIRV/SPIRVErrorEnum.h b/lib/SPIRV/libSPIRV/SPIRVErrorEnum.h
new file mode 100644
index 0000000..8a348f7
--- /dev/null
+++ b/lib/SPIRV/libSPIRV/SPIRVErrorEnum.h
@@ -0,0 +1,8 @@
+/* The error code name should be meaningful since it is part of error message */
+_SPIRV_OP(Success, "")
+_SPIRV_OP(InvalidTargetTriple,
+          "Expects spir-unknown-unknown or spir64-unknown-unknown.")
+_SPIRV_OP(InvalidAddressingModel, "Expects 0-2.")
+_SPIRV_OP(InvalidMemoryModel, "Expects 0-3.")
+_SPIRV_OP(InvalidFunctionControlMask, "")
+_SPIRV_OP(InvalidBuiltinSetName, "Expects OpenCL.std.")
diff --git a/lib/SPIRV/libSPIRV/SPIRVExtInst.h b/lib/SPIRV/libSPIRV/SPIRVExtInst.h
new file mode 100644
index 0000000..2457b05
--- /dev/null
+++ b/lib/SPIRV/libSPIRV/SPIRVExtInst.h
@@ -0,0 +1,344 @@
+//===- SPIRVBuiltin.h - SPIR-V extended instruction -------------*- C++ -*-===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+/// \file
+///
+/// This file defines SPIR-V extended instructions.
+///
+//===----------------------------------------------------------------------===//
+
+#ifndef SPIRVBUILTIN_HPP_
+#define SPIRVBUILTIN_HPP_
+
+#include "SPIRVUtil.h"
+#include "OpenCL.std.h"
+#include "GLSL.std.450.h"
+
+#include <string>
+#include <vector>
+
+namespace SPIRV {
+
+inline bool isOpenCLBuiltinSet(SPIRVExtInstSetKind Set) {
+  return Set == SPIRVEIS_OpenCL;
+}
+inline bool isGLSLBuiltinSet(SPIRVExtInstSetKind Set) {
+  return Set == SPIRVEIS_GLSL;
+}
+
+typedef OpenCLLIB::Entrypoints OCLExtOpKind;
+typedef GLSLLIB::GLSLstd450 GLSLExtOpKind;
+
+template <> inline void SPIRVMap<OCLExtOpKind, std::string>::init() {
+  add(OpenCLLIB::Acos, "acos");
+  add(OpenCLLIB::Acosh, "acosh");
+  add(OpenCLLIB::Acospi, "acospi");
+  add(OpenCLLIB::Asin, "asin");
+  add(OpenCLLIB::Asinh, "asinh");
+  add(OpenCLLIB::Asinpi, "asinpi");
+  add(OpenCLLIB::Atan, "atan");
+  add(OpenCLLIB::Atan2, "atan2");
+  add(OpenCLLIB::Atanh, "atanh");
+  add(OpenCLLIB::Atanpi, "atanpi");
+  add(OpenCLLIB::Atan2pi, "atan2pi");
+  add(OpenCLLIB::Cbrt, "cbrt");
+  add(OpenCLLIB::Ceil, "ceil");
+  add(OpenCLLIB::Copysign, "copysign");
+  add(OpenCLLIB::Cos, "cos");
+  add(OpenCLLIB::Cosh, "cosh");
+  add(OpenCLLIB::Cospi, "cospi");
+  add(OpenCLLIB::Erfc, "erfc");
+  add(OpenCLLIB::Erf, "erf");
+  add(OpenCLLIB::Exp, "exp");
+  add(OpenCLLIB::Exp2, "exp2");
+  add(OpenCLLIB::Exp10, "exp10");
+  add(OpenCLLIB::Expm1, "expm1");
+  add(OpenCLLIB::Fabs, "fabs");
+  add(OpenCLLIB::Fdim, "fdim");
+  add(OpenCLLIB::Floor, "floor");
+  add(OpenCLLIB::Fma, "fma");
+  add(OpenCLLIB::Fmax, "fmax");
+  add(OpenCLLIB::Fmin, "fmin");
+  add(OpenCLLIB::Fmod, "fmod");
+  add(OpenCLLIB::Fract, "fract");
+  add(OpenCLLIB::Frexp, "frexp");
+  add(OpenCLLIB::Hypot, "hypot");
+  add(OpenCLLIB::Ilogb, "ilogb");
+  add(OpenCLLIB::Ldexp, "ldexp");
+  add(OpenCLLIB::Lgamma, "lgamma");
+  add(OpenCLLIB::Lgamma_r, "lgamma_r");
+  add(OpenCLLIB::Log, "log");
+  add(OpenCLLIB::Log2, "log2");
+  add(OpenCLLIB::Log10, "log10");
+  add(OpenCLLIB::Log1p, "log1p");
+  add(OpenCLLIB::Logb, "logb");
+  add(OpenCLLIB::Mad, "mad");
+  add(OpenCLLIB::Maxmag, "maxmag");
+  add(OpenCLLIB::Minmag, "minmag");
+  add(OpenCLLIB::Modf, "modf");
+  add(OpenCLLIB::Nan, "nan");
+  add(OpenCLLIB::Nextafter, "nextafter");
+  add(OpenCLLIB::Pow, "pow");
+  add(OpenCLLIB::Pown, "pown");
+  add(OpenCLLIB::Powr, "powr");
+  add(OpenCLLIB::Remainder, "remainder");
+  add(OpenCLLIB::Remquo, "remquo");
+  add(OpenCLLIB::Rint, "rint");
+  add(OpenCLLIB::Rootn, "rootn");
+  add(OpenCLLIB::Round, "round");
+  add(OpenCLLIB::Rsqrt, "rsqrt");
+  add(OpenCLLIB::Sin, "sin");
+  add(OpenCLLIB::Sincos, "sincos");
+  add(OpenCLLIB::Sinh, "sinh");
+  add(OpenCLLIB::Sinpi, "sinpi");
+  add(OpenCLLIB::Sqrt, "sqrt");
+  add(OpenCLLIB::Tan, "tan");
+  add(OpenCLLIB::Tanh, "tanh");
+  add(OpenCLLIB::Tanpi, "tanpi");
+  add(OpenCLLIB::Tgamma, "tgamma");
+  add(OpenCLLIB::Trunc, "trunc");
+  add(OpenCLLIB::Half_cos, "half_cos");
+  add(OpenCLLIB::Half_divide, "half_divide");
+  add(OpenCLLIB::Half_exp, "half_exp");
+  add(OpenCLLIB::Half_exp2, "half_exp2");
+  add(OpenCLLIB::Half_exp10, "half_exp10");
+  add(OpenCLLIB::Half_log, "half_log");
+  add(OpenCLLIB::Half_log2, "half_log2");
+  add(OpenCLLIB::Half_log10, "half_log10");
+  add(OpenCLLIB::Half_powr, "half_powr");
+  add(OpenCLLIB::Half_recip, "half_recip");
+  add(OpenCLLIB::Half_rsqrt, "half_rsqrt");
+  add(OpenCLLIB::Half_sin, "half_sin");
+  add(OpenCLLIB::Half_sqrt, "half_sqrt");
+  add(OpenCLLIB::Half_tan, "half_tan");
+  add(OpenCLLIB::Native_cos, "native_cos");
+  add(OpenCLLIB::Native_divide, "native_divide");
+  add(OpenCLLIB::Native_exp, "native_exp");
+  add(OpenCLLIB::Native_exp2, "native_exp2");
+  add(OpenCLLIB::Native_exp10, "native_exp10");
+  add(OpenCLLIB::Native_log, "native_log");
+  add(OpenCLLIB::Native_log2, "native_log2");
+  add(OpenCLLIB::Native_log10, "native_log10");
+  add(OpenCLLIB::Native_powr, "native_powr");
+  add(OpenCLLIB::Native_recip, "native_recip");
+  add(OpenCLLIB::Native_rsqrt, "native_rsqrt");
+  add(OpenCLLIB::Native_sin, "native_sin");
+  add(OpenCLLIB::Native_sqrt, "native_sqrt");
+  add(OpenCLLIB::Native_tan, "native_tan");
+  add(OpenCLLIB::FClamp, "fclamp");
+  add(OpenCLLIB::Degrees, "degrees");
+  add(OpenCLLIB::Mix, "mix");
+  add(OpenCLLIB::FMax_common, "fmax_common");
+  add(OpenCLLIB::FMin_common, "fmin_common");
+  add(OpenCLLIB::Radians, "radians");
+  add(OpenCLLIB::Step, "step");
+  add(OpenCLLIB::Smoothstep, "smoothstep");
+  add(OpenCLLIB::Sign, "sign");
+  add(OpenCLLIB::Cross, "cross");
+  add(OpenCLLIB::Distance, "distance");
+  add(OpenCLLIB::Length, "length");
+  add(OpenCLLIB::Normalize, "normalize");
+  add(OpenCLLIB::Fast_distance, "fast_distance");
+  add(OpenCLLIB::Fast_length, "fast_length");
+  add(OpenCLLIB::Fast_normalize, "fast_normalize");
+  add(OpenCLLIB::Read_imagef, "read_imagef");
+  add(OpenCLLIB::Read_imagei, "read_imagei");
+  add(OpenCLLIB::Read_imageui, "read_imageui");
+  add(OpenCLLIB::Read_imageh, "read_imageh");
+  add(OpenCLLIB::Read_imagef_samplerless, "read_imagef_samplerless");
+  add(OpenCLLIB::Read_imagei_samplerless, "read_imagei_samplerless");
+  add(OpenCLLIB::Read_imageui_samplerless, "read_imageui_samplerless");
+  add(OpenCLLIB::Read_imageh_samplerless, "read_imageh_samplerless");
+  add(OpenCLLIB::Write_imagef, "write_imagef");
+  add(OpenCLLIB::Write_imagei, "write_imagei");
+  add(OpenCLLIB::Write_imageui, "write_imageui");
+  add(OpenCLLIB::Write_imageh, "write_imageh");
+  add(OpenCLLIB::Read_imagef_mipmap_lod, "read_imagef_mipmap_lod");
+  add(OpenCLLIB::Read_imagei_mipmap_lod, "read_imagei_mipmap_lod");
+  add(OpenCLLIB::Read_imageui_mipmap_lod, "read_imageui_mipmap_lod");
+  add(OpenCLLIB::Read_imagef_mipmap_grad, "read_imagef_mipmap_gradient");
+  add(OpenCLLIB::Read_imagei_mipmap_grad, "read_imagei_mipmap_gradient");
+  add(OpenCLLIB::Read_imageui_mipmap_grad, "read_imageui_mipmap_gradient");
+  add(OpenCLLIB::Write_imagef_mipmap_lod, "write_imagef_mipmap_lod");
+  add(OpenCLLIB::Write_imagei_mipmap_lod, "write_imagei_mipmap_lod");
+  add(OpenCLLIB::Write_imageui_mipmap_lod, "write_imageui_mipmap_lod");
+  add(OpenCLLIB::Get_image_width, "get_image_width");
+  add(OpenCLLIB::Get_image_height, "get_image_height");
+  add(OpenCLLIB::Get_image_depth, "get_image_depth");
+  add(OpenCLLIB::Get_image_channel_data_type, "get_image_channel_data_type");
+  add(OpenCLLIB::Get_image_channel_order, "get_image_channel_order");
+  add(OpenCLLIB::Get_image_dim, "get_image_dim");
+  add(OpenCLLIB::Get_image_array_size, "get_image_array_size");
+  add(OpenCLLIB::Get_image_num_samples, "get_image_num_samples");
+  add(OpenCLLIB::Get_image_num_mip_levels, "get_image_num_mip_levels");
+  add(OpenCLLIB::SAbs, "s_abs");
+  add(OpenCLLIB::SAbs_diff, "s_abs_diff");
+  add(OpenCLLIB::SAdd_sat, "s_add_sat");
+  add(OpenCLLIB::UAdd_sat, "u_add_sat");
+  add(OpenCLLIB::SHadd, "s_hadd");
+  add(OpenCLLIB::UHadd, "u_hadd");
+  add(OpenCLLIB::SRhadd, "s_rhadd");
+  add(OpenCLLIB::URhadd, "u_rhadd");
+  add(OpenCLLIB::SClamp, "s_clamp");
+  add(OpenCLLIB::UClamp, "u_clamp");
+  add(OpenCLLIB::Clz, "clz");
+  add(OpenCLLIB::Ctz, "ctz");
+  add(OpenCLLIB::SMad_hi, "s_mad_hi");
+  add(OpenCLLIB::SMad_sat, "s_mad_sat");
+  add(OpenCLLIB::UMad_sat, "u_mad_sat");
+  add(OpenCLLIB::SMax, "s_max");
+  add(OpenCLLIB::SMin, "s_min");
+  add(OpenCLLIB::UMax, "u_max");
+  add(OpenCLLIB::UMin, "u_min");
+  add(OpenCLLIB::SMul_hi, "s_mul_hi");
+  add(OpenCLLIB::Rotate, "rotate");
+  add(OpenCLLIB::SSub_sat, "s_sub_sat");
+  add(OpenCLLIB::USub_sat, "u_sub_sat");
+  add(OpenCLLIB::U_Upsample, "u_upsample");
+  add(OpenCLLIB::S_Upsample, "s_upsample");
+  add(OpenCLLIB::Popcount, "popcount");
+  add(OpenCLLIB::SMad24, "s_mad24");
+  add(OpenCLLIB::UMad24, "u_mad24");
+  add(OpenCLLIB::SMul24, "s_mul24");
+  add(OpenCLLIB::UMul24, "u_mul24");
+  add(OpenCLLIB::Vloadn, "vloadn");
+  add(OpenCLLIB::Vstoren, "vstoren");
+  add(OpenCLLIB::Vload_half, "vload_half");
+  add(OpenCLLIB::Vload_halfn, "vload_halfn");
+  add(OpenCLLIB::Vstore_half, "vstore_half");
+  add(OpenCLLIB::Vstore_half_r, "vstore_half_r");
+  add(OpenCLLIB::Vstore_halfn, "vstore_halfn");
+  add(OpenCLLIB::Vstore_halfn_r, "vstore_halfn_r");
+  add(OpenCLLIB::Vloada_halfn, "vloada_halfn");
+  add(OpenCLLIB::Vstorea_halfn, "vstorea_halfn");
+  add(OpenCLLIB::Vstorea_halfn_r, "vstorea_halfn_r");
+  add(OpenCLLIB::Shuffle, "shuffle");
+  add(OpenCLLIB::Shuffle2, "shuffle2");
+  add(OpenCLLIB::Printf, "printf");
+  add(OpenCLLIB::Prefetch, "prefetch");
+  add(OpenCLLIB::Bitselect, "bitselect");
+  add(OpenCLLIB::Select, "select");
+  add(OpenCLLIB::UAbs, "u_abs");
+  add(OpenCLLIB::UAbs_diff, "u_abs_diff");
+  add(OpenCLLIB::UMul_hi, "u_mul_hi");
+  add(OpenCLLIB::UMad_hi, "u_mad_hi");
+}
+SPIRV_DEF_NAMEMAP(OCLExtOpKind, OCLExtOpMap)
+
+template <> inline void SPIRVMap<GLSLExtOpKind, std::string>::init() {
+  add(GLSLLIB::Acos, "acos");
+  add(GLSLLIB::Acosh, "acosh");
+  add(GLSLLIB::Asin, "asin");
+  add(GLSLLIB::Asinh, "asinh");
+  add(GLSLLIB::Atan, "atan");
+  add(GLSLLIB::Atan2, "atan2");
+  add(GLSLLIB::Atanh, "atanh");
+  add(GLSLLIB::Ceil, "ceil");
+  add(GLSLLIB::Cos, "cos");
+  add(GLSLLIB::Cosh, "cosh");
+  add(GLSLLIB::Cross, "cross");
+  add(GLSLLIB::Degrees, "degrees");
+  add(GLSLLIB::Determinant, "determinant");
+  add(GLSLLIB::Distance, "distance");
+  add(GLSLLIB::Exp, "exp");
+  add(GLSLLIB::Exp2, "exp2");
+  add(GLSLLIB::FAbs, "fabs");
+  add(GLSLLIB::FaceForward, "face_forward");
+  add(GLSLLIB::FClamp, "fclamp");
+  add(GLSLLIB::FindILsb, "find_ilsb");
+  add(GLSLLIB::FindSMsb, "find_smsb");
+  add(GLSLLIB::FindUMsb, "find_umsb");
+  add(GLSLLIB::Floor, "floor");
+  add(GLSLLIB::Fma, "fma");
+  add(GLSLLIB::FMax, "fmax");
+  add(GLSLLIB::FMin, "fmin");
+  add(GLSLLIB::FMix, "fmix");
+  add(GLSLLIB::Fract, "fract");
+  add(GLSLLIB::Frexp, "frexp");
+  add(GLSLLIB::FrexpStruct, "frexp_struct");
+  add(GLSLLIB::FSign, "fsign");
+  add(GLSLLIB::IMix, "imix");
+  add(GLSLLIB::InterpolateAtCentroid, "interpolate_at_centroid");
+  add(GLSLLIB::InterpolateAtOffset, "interpolate_at_offset");
+  add(GLSLLIB::InterpolateAtSample, "interpolate_at_sample");
+  add(GLSLLIB::InverseSqrt, "rsqrt");
+  add(GLSLLIB::Ldexp, "ldexp");
+  add(GLSLLIB::Length, "length");
+  add(GLSLLIB::Log, "log");
+  add(GLSLLIB::Log2, "log2");
+  add(GLSLLIB::MatrixInverse, "matrix_inverse");
+  add(GLSLLIB::Modf, "modf");
+  add(GLSLLIB::ModfStruct, "modf_struct");
+  add(GLSLLIB::NClamp, "nclamp");
+  add(GLSLLIB::NMax, "nmax");
+  add(GLSLLIB::NMin, "nmin");
+  add(GLSLLIB::Normalize, "normalize");
+  add(GLSLLIB::PackDouble2x32, "pack_double_2x32");
+  add(GLSLLIB::PackHalf2x16, "pack_half_2x16");
+  add(GLSLLIB::PackSnorm2x16, "pack_snorm_2x16");
+  add(GLSLLIB::PackSnorm4x8, "pack_snorm4x8");
+  add(GLSLLIB::PackUnorm2x16, "pack_unorm_2x16");
+  add(GLSLLIB::PackUnorm4x8, "pack_unorm_4x8");
+  add(GLSLLIB::Pow, "pow");
+  add(GLSLLIB::Radians, "radians");
+  add(GLSLLIB::Reflect, "reflect");
+  add(GLSLLIB::Refract, "refract");
+  add(GLSLLIB::Round, "round");
+  add(GLSLLIB::RoundEven, "round_even");
+  add(GLSLLIB::SAbs, "s_abs");
+  add(GLSLLIB::SClamp, "s_clamp");
+  add(GLSLLIB::Sin, "sin");
+  add(GLSLLIB::Sinh, "sinh");
+  add(GLSLLIB::SMax, "s_max");
+  add(GLSLLIB::SMin, "s_min");
+  add(GLSLLIB::SmoothStep, "smoothstep");
+  add(GLSLLIB::Sqrt, "sqrt");
+  add(GLSLLIB::SSign, "s_sign");
+  add(GLSLLIB::Step, "step");
+  add(GLSLLIB::Tan, "tan");
+  add(GLSLLIB::Tanh, "tanh");
+  add(GLSLLIB::Trunc, "trunc");
+  add(GLSLLIB::UClamp, "u_clamp");
+  add(GLSLLIB::UMax, "u_max");
+  add(GLSLLIB::UMin, "u_min");
+  add(GLSLLIB::UnpackDouble2x32, "unpack_double_2x32");
+  add(GLSLLIB::UnpackHalf2x16, "unpack_half_2x16");
+  add(GLSLLIB::UnpackSnorm2x16, "unpack_snorm_2x16");
+  add(GLSLLIB::UnpackSnorm4x8, "unpack_snorm_4x8");
+  add(GLSLLIB::UnpackUnorm2x16, "unpack_unorm_2x16");
+  add(GLSLLIB::UnpackUnorm4x8, "unpack_unorm_4x8");
+}
+SPIRV_DEF_NAMEMAP(GLSLExtOpKind, GLSLExtOpMap)
+}
+
+#endif
diff --git a/lib/SPIRV/libSPIRV/SPIRVFunction.cpp b/lib/SPIRV/libSPIRV/SPIRVFunction.cpp
new file mode 100644
index 0000000..2e932b0
--- /dev/null
+++ b/lib/SPIRV/libSPIRV/SPIRVFunction.cpp
@@ -0,0 +1,158 @@
+//===- SPIRVFunction.cpp - Class to represent a SPIR-V Function -*- C++ -*-===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+// This file implements Function class for SPIRV.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+
+#include "SPIRVEntry.h"
+#include "SPIRVFunction.h"
+#include "SPIRVBasicBlock.h"
+#include "SPIRVInstruction.h"
+#include "SPIRVStream.h"
+
+#include <functional>
+#include <algorithm>
+using namespace SPIRV;
+
+SPIRVFunctionParameter::SPIRVFunctionParameter(SPIRVType *TheType,
+                                               SPIRVId TheId,
+                                               SPIRVFunction *TheParent,
+                                               unsigned TheArgNo)
+    : SPIRVValue(TheParent->getModule(), 3, OpFunctionParameter, TheType,
+                 TheId),
+      ParentFunc(TheParent), ArgNo(TheArgNo) {
+  validate();
+}
+
+void SPIRVFunctionParameter::foreachAttr(
+    std::function<void(SPIRVFuncParamAttrKind)> Func) {
+  auto Locs = Decorates.equal_range(DecorationFuncParamAttr);
+  for (auto I = Locs.first, E = Locs.second; I != E; ++I) {
+    auto Attr = static_cast<SPIRVFuncParamAttrKind>(I->second->getLiteral(0));
+    assert(isValid(Attr));
+    Func(Attr);
+  }
+}
+
+SPIRVDecoder SPIRVFunction::getDecoder(std::istream &IS) {
+  return SPIRVDecoder(IS, *this);
+}
+
+void SPIRVFunction::encode(spv_ostream &O) const {
+  getEncoder(O) << Type << Id << FCtrlMask << FuncType;
+}
+
+void SPIRVFunction::encodeChildren(spv_ostream &O) const {
+  O << SPIRVNL();
+  for (auto &I : Parameters)
+    O << *I;
+  O << SPIRVNL();
+  for (auto &I : BBVec)
+    O << *I;
+  O << SPIRVFunctionEnd();
+}
+
+void SPIRVFunction::encodeExecutionModes(spv_ostream &O) const {
+  for (auto &I : ExecModes)
+    O << *I.second;
+}
+
+void SPIRVFunction::decode(std::istream &I) {
+  SPIRVDecoder Decoder = getDecoder(I);
+  Decoder >> Type >> Id >> FCtrlMask >> FuncType;
+  Module->addFunction(this);
+  SPIRVDBG(spvdbgs() << "Decode function: " << Id << '\n');
+
+  Decoder.getWordCountAndOpCode();
+  while (!I.eof()) {
+    if (Decoder.OpCode == OpFunctionEnd)
+      break;
+
+    switch (Decoder.OpCode) {
+    case OpFunctionParameter: {
+      auto Param = static_cast<SPIRVFunctionParameter *>(Decoder.getEntry());
+      assert(Param);
+      Param->setParent(this);
+      Parameters.push_back(Param);
+      Decoder.getWordCountAndOpCode();
+      continue;
+      break;
+    }
+    case OpLabel: {
+      decodeBB(Decoder);
+      break;
+    }
+    default:
+      assert(0 && "Invalid SPIRV format");
+    }
+  }
+}
+
+/// Decode basic block and contained instructions.
+/// Do it here instead of in BB:decode to avoid back track in input stream.
+void SPIRVFunction::decodeBB(SPIRVDecoder &Decoder) {
+  SPIRVBasicBlock *BB = static_cast<SPIRVBasicBlock *>(Decoder.getEntry());
+  assert(BB);
+  addBasicBlock(BB);
+  SPIRVDBG(spvdbgs() << "Decode BB: " << BB->getId() << '\n');
+
+  Decoder.setScope(BB);
+  while (Decoder.getWordCountAndOpCode()) {
+    if (Decoder.OpCode == OpFunctionEnd || Decoder.OpCode == OpLabel) {
+      break;
+    }
+
+    if (Decoder.OpCode == OpName || Decoder.OpCode == OpDecorate) {
+      Decoder.getEntry();
+      continue;
+    }
+
+    SPIRVInstruction *Inst =
+        static_cast<SPIRVInstruction *>(Decoder.getEntry());
+    assert(Inst);
+    BB->addInstruction(Inst);
+  }
+  Decoder.setScope(this);
+}
+
+void SPIRVFunction::foreachReturnValueAttr(
+    std::function<void(SPIRVFuncParamAttrKind)> Func) {
+  auto Locs = Decorates.equal_range(DecorationFuncParamAttr);
+  for (auto I = Locs.first, E = Locs.second; I != E; ++I) {
+    auto Attr = static_cast<SPIRVFuncParamAttrKind>(I->second->getLiteral(0));
+    assert(isValid(Attr));
+    Func(Attr);
+  }
+}
diff --git a/lib/SPIRV/libSPIRV/SPIRVFunction.h b/lib/SPIRV/libSPIRV/SPIRVFunction.h
new file mode 100644
index 0000000..014f398
--- /dev/null
+++ b/lib/SPIRV/libSPIRV/SPIRVFunction.h
@@ -0,0 +1,164 @@
+//===- SPIRVFunction.h - Class to represent a SPIR-V function ---*- C++ -*-===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+// This file defines Function class for SPIRV.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+
+#ifndef SPIRVFUNCTION_HPP_
+#define SPIRVFUNCTION_HPP_
+#include "SPIRVValue.h"
+#include "SPIRVBasicBlock.h"
+#include <functional>
+
+namespace SPIRV {
+
+class BIFunction;
+class SPIRVDecoder;
+
+class SPIRVFunctionParameter : public SPIRVValue {
+public:
+  SPIRVFunctionParameter(SPIRVType *TheType, SPIRVId TheId,
+                         SPIRVFunction *TheParent, unsigned TheArgNo);
+  SPIRVFunctionParameter()
+      : SPIRVValue(OpFunctionParameter), ParentFunc(nullptr), ArgNo(0) {}
+  unsigned getArgNo() const { return ArgNo; }
+  void foreachAttr(std::function<void(SPIRVFuncParamAttrKind)>);
+  void addAttr(SPIRVFuncParamAttrKind Kind) {
+    addDecorate(new SPIRVDecorate(DecorationFuncParamAttr, this, Kind));
+  }
+  void setParent(SPIRVFunction *Parent) { ParentFunc = Parent; }
+  bool hasAttr(SPIRVFuncParamAttrKind Kind) const {
+    return getDecorate(DecorationFuncParamAttr).count(Kind);
+  }
+  bool isByVal() const { return hasAttr(FunctionParameterAttributeByVal); }
+  bool isZext() const { return hasAttr(FunctionParameterAttributeZext); }
+  SPIRVCapVec getRequiredCapability() const {
+    if (hasLinkageType() && getLinkageType() == LinkageTypeImport)
+      return getVec(CapabilityLinkage);
+    return SPIRVCapVec();
+  }
+
+protected:
+  void validate() const {
+    SPIRVValue::validate();
+    assert(ParentFunc && "Invalid parent function");
+  }
+  _SPIRV_DEF_ENCDEC2(Type, Id)
+private:
+  SPIRVFunction *ParentFunc;
+  unsigned ArgNo;
+};
+
+class SPIRVFunction : public SPIRVValue, public SPIRVComponentExecutionModes {
+public:
+  // Complete constructor. It does not construct basic blocks.
+  SPIRVFunction(SPIRVModule *M, SPIRVTypeFunction *FunctionType, SPIRVId TheId)
+      : SPIRVValue(M, 5, OpFunction, FunctionType->getReturnType(), TheId),
+        FuncType(FunctionType), FCtrlMask(FunctionControlMaskNone) {
+    addAllArguments(TheId + 1);
+    validate();
+  }
+
+  // Incomplete constructor
+  SPIRVFunction()
+      : SPIRVValue(OpFunction), FuncType(NULL),
+        FCtrlMask(FunctionControlMaskNone) {}
+
+  SPIRVDecoder getDecoder(std::istream &IS);
+  SPIRVTypeFunction *getFunctionType() const { return FuncType; }
+  SPIRVWord getFuncCtlMask() const { return FCtrlMask; }
+  size_t getNumBasicBlock() const { return BBVec.size(); }
+  SPIRVBasicBlock *getBasicBlock(size_t i) const { return BBVec[i]; }
+  size_t getNumArguments() const {
+    return getFunctionType()->getNumParameters();
+  }
+  SPIRVId getArgumentId(size_t i) const { return Parameters[i]->getId(); }
+  SPIRVFunctionParameter *getArgument(size_t i) const { return Parameters[i]; }
+  void foreachArgument(std::function<void(SPIRVFunctionParameter *)> Func) {
+    for (size_t I = 0, E = getNumArguments(); I != E; ++I)
+      Func(getArgument(I));
+  }
+
+  void foreachReturnValueAttr(std::function<void(SPIRVFuncParamAttrKind)>);
+
+  void setFunctionControlMask(SPIRVWord Mask) { FCtrlMask = Mask; }
+
+  void takeExecutionModes(SPIRVForward *Forward) {
+    ExecModes = std::move(Forward->ExecModes);
+  }
+
+  // Assume BB contains valid Id.
+  SPIRVBasicBlock *addBasicBlock(SPIRVBasicBlock *BB) {
+    Module->add(BB);
+    BB->setParent(this);
+    BBVec.push_back(BB);
+    return BB;
+  }
+
+  void encodeChildren(spv_ostream &) const;
+  void encodeExecutionModes(spv_ostream &) const;
+  _SPIRV_DCL_ENCDEC
+  void validate() const {
+    SPIRVValue::validate();
+    assert(FuncType && "Invalid func type");
+  }
+
+private:
+  SPIRVFunctionParameter *addArgument(unsigned TheArgNo, SPIRVId TheId) {
+    SPIRVFunctionParameter *Arg = new SPIRVFunctionParameter(
+        getFunctionType()->getParameterType(TheArgNo), TheId, this, TheArgNo);
+    Module->add(Arg);
+    Parameters.push_back(Arg);
+    return Arg;
+  }
+
+  void addAllArguments(SPIRVId FirstArgId) {
+    for (size_t i = 0, e = getFunctionType()->getNumParameters(); i != e; ++i)
+      addArgument(i, FirstArgId + i);
+  }
+  void decodeBB(SPIRVDecoder &);
+
+  SPIRVTypeFunction *FuncType; // Function type
+  SPIRVWord FCtrlMask;         // Function control mask
+
+  std::vector<SPIRVFunctionParameter *> Parameters;
+  typedef std::vector<SPIRVBasicBlock *> SPIRVLBasicBlockVector;
+  SPIRVLBasicBlockVector BBVec;
+};
+
+typedef SPIRVEntryOpCodeOnly<OpFunctionEnd> SPIRVFunctionEnd;
+}
+
+#endif /* SPIRVFUNCTION_HPP_ */
diff --git a/lib/SPIRV/libSPIRV/SPIRVInstruction.cpp b/lib/SPIRV/libSPIRV/SPIRVInstruction.cpp
new file mode 100644
index 0000000..ed2019d
--- /dev/null
+++ b/lib/SPIRV/libSPIRV/SPIRVInstruction.cpp
@@ -0,0 +1,222 @@
+//===- SPIRVInstruction.cpp - Class to represent SPIR-V instruction - C++ -===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+/// \file
+///
+/// This file implements SPIR-V instructions.
+///
+//===----------------------------------------------------------------------===//
+
+#include "SPIRVInstruction.h"
+#include "SPIRVBasicBlock.h"
+#include "SPIRVFunction.h"
+
+#include <unordered_set>
+
+namespace SPIRV {
+
+// Complete constructor for instruction with type and id
+SPIRVInstruction::SPIRVInstruction(unsigned TheWordCount, Op TheOC,
+                                   SPIRVType *TheType, SPIRVId TheId,
+                                   SPIRVBasicBlock *TheBB)
+    : SPIRVValue(TheBB->getModule(), TheWordCount, TheOC, TheType, TheId),
+      BB(TheBB) {
+  validate();
+}
+
+SPIRVInstruction::SPIRVInstruction(unsigned TheWordCount, Op TheOC,
+                                   SPIRVType *TheType, SPIRVId TheId,
+                                   SPIRVBasicBlock *TheBB, SPIRVModule *TheBM)
+    : SPIRVValue(TheBM, TheWordCount, TheOC, TheType, TheId), BB(TheBB) {
+  validate();
+}
+
+// Complete constructor for instruction with id but no type
+SPIRVInstruction::SPIRVInstruction(unsigned TheWordCount, Op TheOC,
+                                   SPIRVId TheId, SPIRVBasicBlock *TheBB)
+    : SPIRVValue(TheBB->getModule(), TheWordCount, TheOC, TheId), BB(TheBB) {
+  validate();
+}
+// Complete constructor for instruction without type and id
+SPIRVInstruction::SPIRVInstruction(unsigned TheWordCount, Op TheOC,
+                                   SPIRVBasicBlock *TheBB)
+    : SPIRVValue(TheBB->getModule(), TheWordCount, TheOC), BB(TheBB) {
+  validate();
+}
+// Complete constructor for instruction with type but no id
+SPIRVInstruction::SPIRVInstruction(unsigned TheWordCount, Op TheOC,
+                                   SPIRVType *TheType, SPIRVBasicBlock *TheBB)
+    : SPIRVValue(TheBB->getModule(), TheWordCount, TheOC, TheType), BB(TheBB) {
+  validate();
+}
+
+void SPIRVInstruction::setParent(SPIRVBasicBlock *TheBB) {
+  assert(TheBB && "Invalid BB");
+  if (BB == TheBB)
+    return;
+  assert(BB == NULL && "BB cannot change parent");
+  BB = TheBB;
+}
+
+void SPIRVInstruction::setScope(SPIRVEntry *Scope) {
+  assert(Scope && Scope->getOpCode() == OpLabel && "Invalid scope");
+  setParent(static_cast<SPIRVBasicBlock *>(Scope));
+}
+
+SPIRVFunctionCall::SPIRVFunctionCall(SPIRVId TheId, SPIRVFunction *TheFunction,
+                                     const std::vector<SPIRVWord> &TheArgs,
+                                     SPIRVBasicBlock *BB)
+    : SPIRVFunctionCallGeneric(TheFunction->getFunctionType()->getReturnType(),
+                               TheId, TheArgs, BB),
+      FunctionId(TheFunction->getId()) {
+  validate();
+}
+
+void SPIRVFunctionCall::validate() const {
+  SPIRVFunctionCallGeneric::validate();
+}
+
+// ToDo: Each instruction should implement this function
+std::vector<SPIRVValue *> SPIRVInstruction::getOperands() {
+  std::vector<SPIRVValue *> Empty;
+  assert(0 && "not supported");
+  return Empty;
+}
+
+std::vector<SPIRVType *>
+SPIRVInstruction::getOperandTypes(const std::vector<SPIRVValue *> &Ops) {
+  std::vector<SPIRVType *> Tys;
+  for (auto &I : Ops) {
+    SPIRVType *Ty = nullptr;
+    if (I->getOpCode() == OpFunction)
+      Ty = reinterpret_cast<SPIRVFunction *>(I)->getFunctionType();
+    else
+      Ty = I->getType();
+
+    Tys.push_back(Ty);
+  }
+  return Tys;
+}
+
+std::vector<SPIRVType *> SPIRVInstruction::getOperandTypes() {
+  return getOperandTypes(getOperands());
+}
+
+bool isSpecConstantOpAllowedOp(Op OC) {
+  static SPIRVWord Table[] = {
+      OpSConvert,
+      OpFConvert,
+      OpConvertFToS,
+      OpConvertSToF,
+      OpConvertFToU,
+      OpConvertUToF,
+      OpUConvert,
+      OpConvertPtrToU,
+      OpConvertUToPtr,
+      OpGenericCastToPtr,
+      OpPtrCastToGeneric,
+      OpBitcast,
+      OpQuantizeToF16,
+      OpSNegate,
+      OpNot,
+      OpIAdd,
+      OpISub,
+      OpIMul,
+      OpUDiv,
+      OpSDiv,
+      OpUMod,
+      OpSRem,
+      OpSMod,
+      OpShiftRightLogical,
+      OpShiftRightArithmetic,
+      OpShiftLeftLogical,
+      OpBitwiseOr,
+      OpBitwiseXor,
+      OpBitwiseAnd,
+      OpFNegate,
+      OpFAdd,
+      OpFSub,
+      OpFMul,
+      OpFDiv,
+      OpFRem,
+      OpFMod,
+      OpVectorShuffle,
+      OpCompositeExtract,
+      OpCompositeInsert,
+      OpLogicalOr,
+      OpLogicalAnd,
+      OpLogicalNot,
+      OpLogicalEqual,
+      OpLogicalNotEqual,
+      OpSelect,
+      OpIEqual,
+      OpULessThan,
+      OpSLessThan,
+      OpUGreaterThan,
+      OpSGreaterThan,
+      OpULessThanEqual,
+      OpSLessThanEqual,
+      OpUGreaterThanEqual,
+      OpSGreaterThanEqual,
+      OpAccessChain,
+      OpInBoundsAccessChain,
+      OpPtrAccessChain,
+      OpInBoundsPtrAccessChain,
+  };
+  static std::unordered_set<SPIRVWord> Allow(std::begin(Table),
+                                             std::end(Table));
+  return Allow.count(OC);
+}
+
+SPIRVSpecConstantOp *createSpecConstantOpInst(SPIRVInstruction *Inst) {
+  auto OC = Inst->getOpCode();
+  assert(isSpecConstantOpAllowedOp(OC) &&
+         "Op code not allowed for OpSpecConstantOp");
+  auto Ops = Inst->getIds(Inst->getOperands());
+  Ops.insert(Ops.begin(), OC);
+  return static_cast<SPIRVSpecConstantOp *>(SPIRVSpecConstantOp::create(
+      OpSpecConstantOp, Inst->getType(), Inst->getId(), Ops, nullptr,
+      Inst->getModule()));
+}
+
+SPIRVInstruction *createInstFromSpecConstantOp(SPIRVSpecConstantOp *Inst) {
+  assert(Inst->getOpCode() == OpSpecConstantOp && "Not OpSpecConstantOp");
+  auto Ops = Inst->getOpWords();
+  auto OC = static_cast<Op>(Ops[0]);
+  assert(isSpecConstantOpAllowedOp(OC) &&
+         "Op code not allowed for OpSpecConstantOp");
+  Ops.erase(Ops.begin(), Ops.begin() + 1);
+  return SPIRVInstTemplateBase::create(OC, Inst->getType(), Inst->getId(), Ops,
+                                       nullptr, Inst->getModule());
+}
+}
diff --git a/lib/SPIRV/libSPIRV/SPIRVInstruction.h b/lib/SPIRV/libSPIRV/SPIRVInstruction.h
new file mode 100644
index 0000000..ad367a0
--- /dev/null
+++ b/lib/SPIRV/libSPIRV/SPIRVInstruction.h
@@ -0,0 +1,2004 @@
+//===- SPIRVInstruction.h - Class to represent SPIRV instruction -*- C++ --===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+/// \file
+///
+/// This file defines Instruction class for SPIR-V.
+///
+//===----------------------------------------------------------------------===//
+
+#ifndef SPIRVINSTRUCTION_HPP_
+#define SPIRVINSTRUCTION_HPP_
+
+#include "SPIRVEnum.h"
+#include "SPIRVIsValidEnum.h"
+#include "SPIRVStream.h"
+#include "SPIRVValue.h"
+#include "SPIRVBasicBlock.h"
+#include "SPIRVOpCode.h"
+
+#include <cassert>
+#include <cstdint>
+#include <functional>
+#include <iostream>
+#include <map>
+#include <utility>
+#include <vector>
+#include <unordered_set>
+
+namespace SPIRV {
+
+typedef std::vector<SPIRVValue *> ValueVec;
+typedef std::pair<ValueVec::iterator, ValueVec::iterator> ValueRange;
+
+class SPIRVBasicBlock;
+class SPIRVFunction;
+
+bool isSpecConstantOpAllowedOp(Op OC);
+
+class SPIRVComponentExecutionScope {
+public:
+  SPIRVComponentExecutionScope(Scope TheScope = ScopeInvocation)
+      : ExecScope(TheScope) {}
+  Scope ExecScope;
+};
+
+class SPIRVComponentMemorySemanticsMask {
+public:
+  SPIRVComponentMemorySemanticsMask(SPIRVWord TheSema = SPIRVWORD_MAX)
+      : MemSema(TheSema) {}
+  SPIRVWord MemSema;
+};
+
+class SPIRVComponentOperands {
+public:
+  SPIRVComponentOperands(){};
+  SPIRVComponentOperands(const std::vector<SPIRVValue *> &TheOperands)
+      : Operands(TheOperands){};
+  SPIRVComponentOperands(std::vector<SPIRVValue *> &&TheOperands)
+      : Operands(std::move(TheOperands)){};
+  std::vector<SPIRVValue *> getCompOperands() { return Operands; }
+  std::vector<SPIRVType *> getCompOperandTypes() {
+    std::vector<SPIRVType *> Tys;
+    for (auto &I : getCompOperands())
+      Tys.push_back(I->getType());
+    return Tys;
+  }
+
+protected:
+  std::vector<SPIRVValue *> Operands;
+};
+
+class SPIRVInstruction : public SPIRVValue {
+public:
+  // Complete constructor for instruction with type and id
+  SPIRVInstruction(unsigned TheWordCount, Op TheOC, SPIRVType *TheType,
+                   SPIRVId TheId, SPIRVBasicBlock *TheBB);
+  // Complete constructor for instruction with module, type and id
+  SPIRVInstruction(unsigned TheWordCount, Op TheOC, SPIRVType *TheType,
+                   SPIRVId TheId, SPIRVBasicBlock *TheBB, SPIRVModule *TheBM);
+  // Complete constructor for instruction with id but no type
+  SPIRVInstruction(unsigned TheWordCount, Op TheOC, SPIRVId TheId,
+                   SPIRVBasicBlock *TheBB);
+  // Complete constructor for instruction without type and id
+  SPIRVInstruction(unsigned TheWordCount, Op TheOC, SPIRVBasicBlock *TheBB);
+  // Complete constructor for instruction with type but no id
+  SPIRVInstruction(unsigned TheWordCount, Op TheOC, SPIRVType *TheType,
+                   SPIRVBasicBlock *TheBB);
+  // Incomplete constructor
+  SPIRVInstruction(Op TheOC = OpNop) : SPIRVValue(TheOC), BB(NULL) {}
+
+  virtual bool isInst() const { return true; }
+  SPIRVBasicBlock *getParent() const { return BB; }
+  SPIRVInstruction *getPrevious() const { return BB->getPrevious(this); }
+  SPIRVInstruction *getNext() const { return BB->getNext(this); }
+  virtual std::vector<SPIRVValue *> getOperands();
+  std::vector<SPIRVType *> getOperandTypes();
+  static std::vector<SPIRVType *>
+  getOperandTypes(const std::vector<SPIRVValue *> &Ops);
+
+  void setParent(SPIRVBasicBlock *);
+  void setScope(SPIRVEntry *);
+  void addFPRoundingMode(SPIRVFPRoundingModeKind Kind) {
+    addDecorate(DecorationFPRoundingMode, Kind);
+  }
+  void eraseFPRoundingMode() { eraseDecorate(DecorationFPRoundingMode); }
+  void setSaturatedConversion(bool Enable) {
+    if (Enable)
+      addDecorate(DecorationSaturatedConversion);
+    else
+      eraseDecorate(DecorationSaturatedConversion);
+  }
+  bool hasFPRoundingMode(SPIRVFPRoundingModeKind *Kind = nullptr) {
+    SPIRVWord V;
+    auto Found = hasDecorate(DecorationFPRoundingMode, 0, &V);
+    if (Found && Kind)
+      *Kind = static_cast<SPIRVFPRoundingModeKind>(V);
+    return Found;
+  }
+  bool isSaturatedConversion() {
+    return hasDecorate(DecorationSaturatedConversion) ||
+           OpCode == OpSatConvertSToU || OpCode == OpSatConvertUToS;
+  }
+
+  SPIRVBasicBlock *getBasicBlock() const { return BB; }
+
+  void setBasicBlock(SPIRVBasicBlock *TheBB) {
+    BB = TheBB;
+    if (TheBB)
+      setModule(TheBB->getModule());
+  }
+
+protected:
+  void validate() const { SPIRVValue::validate(); }
+
+private:
+  SPIRVBasicBlock *BB;
+};
+
+class SPIRVInstTemplateBase : public SPIRVInstruction {
+public:
+  /// Create an empty instruction. Mainly for getting format information,
+  /// e.g. whether an operand is literal.
+  static SPIRVInstTemplateBase *create(Op TheOC) {
+    auto Inst = static_cast<SPIRVInstTemplateBase *>(SPIRVEntry::create(TheOC));
+    assert(Inst);
+    Inst->init();
+    return Inst;
+  }
+  /// Create a instruction without operands.
+  static SPIRVInstTemplateBase *create(Op TheOC, SPIRVType *TheType,
+                                       SPIRVId TheId, SPIRVBasicBlock *TheBB,
+                                       SPIRVModule *TheModule) {
+    auto Inst = create(TheOC);
+    Inst->init(TheType, TheId, TheBB, TheModule);
+    return Inst;
+  }
+  /// Create a complete and valid instruction.
+  static SPIRVInstTemplateBase *create(Op TheOC, SPIRVType *TheType,
+                                       SPIRVId TheId,
+                                       const std::vector<SPIRVWord> &TheOps,
+                                       SPIRVBasicBlock *TheBB,
+                                       SPIRVModule *TheModule) {
+    auto Inst = create(TheOC);
+    Inst->init(TheType, TheId, TheBB, TheModule);
+    Inst->setOpWords(TheOps);
+    Inst->validate();
+    return Inst;
+  }
+  SPIRVInstTemplateBase(Op OC = OpNop)
+      : SPIRVInstruction(OC), HasVariWC(false) {
+    init();
+  }
+  virtual ~SPIRVInstTemplateBase() {}
+  SPIRVInstTemplateBase *init(SPIRVType *TheType, SPIRVId TheId,
+                              SPIRVBasicBlock *TheBB, SPIRVModule *TheModule) {
+    assert((TheBB || TheModule) && "Invalid BB or Module");
+    if (TheBB)
+      setBasicBlock(TheBB);
+    else {
+      setModule(TheModule);
+    }
+    setId(hasId() ? TheId : SPIRVID_INVALID);
+    setType(hasType() ? TheType : nullptr);
+    return this;
+  }
+  virtual void init() {}
+  virtual void initImpl(Op OC, bool HasId = true, SPIRVWord WC = 0,
+                        bool VariWC = false, unsigned Lit1 = ~0U,
+                        unsigned Lit2 = ~0U, unsigned Lit3 = ~0U) {
+    OpCode = OC;
+    if (!HasId) {
+      setHasNoId();
+      setHasNoType();
+    }
+    if (WC)
+      SPIRVEntry::setWordCount(WC);
+    setHasVariableWordCount(VariWC);
+    addLit(Lit1);
+    addLit(Lit2);
+    addLit(Lit3);
+  }
+  virtual bool isOperandLiteral(unsigned I) const { return Lit.count(I); }
+  void addLit(unsigned L) {
+    if (L != ~0U)
+      Lit.insert(L);
+  }
+  /// \return Expected number of operands. If the instruction has variable
+  /// number of words, return the minimum.
+  SPIRVWord getExpectedNumOperands() const {
+    assert(WordCount > 0 && "Word count not initialized");
+    auto Exp = WordCount - 1;
+    if (hasId())
+      --Exp;
+    if (hasType())
+      --Exp;
+    return Exp;
+  }
+  virtual void setOpWordsAndValidate(const std::vector<SPIRVWord> &TheOps) {
+    setOpWords(TheOps);
+    validate();
+  }
+  virtual void setOpWords(const std::vector<SPIRVWord> &TheOps) {
+    SPIRVWord WC = TheOps.size() + 1;
+    if (hasId())
+      ++WC;
+    if (hasType())
+      ++WC;
+    if (WordCount) {
+      if (WordCount == WC) {
+        // do nothing
+      } else {
+        assert(HasVariWC && WC >= WordCount && "Invalid word count");
+        SPIRVEntry::setWordCount(WC);
+      }
+    } else
+      SPIRVEntry::setWordCount(WC);
+    Ops = TheOps;
+  }
+  virtual void setWordCount(SPIRVWord TheWordCount) {
+    SPIRVEntry::setWordCount(TheWordCount);
+    auto NumOps = WordCount - 1;
+    if (hasId())
+      --NumOps;
+    if (hasType())
+      --NumOps;
+    Ops.resize(NumOps);
+  }
+
+  std::vector<SPIRVWord> &getOpWords() { return Ops; }
+
+  const std::vector<SPIRVWord> &getOpWords() const { return Ops; }
+
+  SPIRVWord getOpWord(int I) const { return Ops[I]; }
+
+  /// Get operand as value.
+  /// If the operand is a literal, return it as a uint32 constant.
+  SPIRVValue *getOpValue(int I) {
+    return isOperandLiteral(I)
+               ? Module->getLiteralAsConstant(
+                     Ops[I], Module->getSourceLanguage(nullptr) ==
+                                 spv::SourceLanguageGLSL)
+               : getValue(Ops[I]);
+  }
+
+  // Get the offset of operands.
+  // Some instructions skip literals when returning operands.
+  size_t getOperandOffset() const {
+    if (hasExecScope() && !isGroupOpCode(OpCode) && !isPipeOpCode(OpCode))
+      return 1;
+    return 0;
+  }
+
+  // Get operands which are values.
+  // Drop execution scope and group operation literals.
+  // Return other literals as uint32 constants.
+  std::vector<SPIRVValue *> getOperands() override {
+    std::vector<SPIRVValue *> VOps;
+    auto Offset = getOperandOffset();
+    for (size_t I = 0, E = Ops.size() - Offset; I != E; ++I)
+      VOps.push_back(getOperand(I));
+    return VOps;
+  }
+
+  std::vector<SPIRVEntry *> getNonLiteralOperands() const override {
+    std::vector<SPIRVEntry *> Operands;
+    for (size_t I = getOperandOffset(), E = Ops.size(); I < E; ++I)
+      if (!isOperandLiteral(I))
+        Operands.push_back(getEntry(Ops[I]));
+    return Operands;
+  }
+
+  virtual SPIRVValue *getOperand(unsigned I) {
+    return getOpValue(I + getOperandOffset());
+  }
+
+  bool hasExecScope() const { return SPIRV::hasExecScope(OpCode); }
+
+  bool hasGroupOperation() const { return SPIRV::hasGroupOperation(OpCode); }
+
+  bool getSPIRVGroupOperation(SPIRVGroupOperationKind &GroupOp) const {
+    if (!hasGroupOperation())
+      return false;
+    GroupOp = static_cast<SPIRVGroupOperationKind>(Ops[1]);
+    return true;
+  }
+
+  Scope getExecutionScope() const {
+    if (!hasExecScope())
+      return ScopeInvocation;
+    return static_cast<Scope>(
+        static_cast<SPIRVConstant *>(getValue(Ops[0]))->getZExtIntValue());
+  }
+
+  bool hasVariableWordCount() const { return HasVariWC; }
+
+  void setHasVariableWordCount(bool VariWC) { HasVariWC = VariWC; }
+
+protected:
+  virtual void encode(spv_ostream &O) const {
+    auto E = getEncoder(O);
+    if (hasType())
+      E << Type;
+    if (hasId())
+      E << Id;
+    E << Ops;
+  }
+  virtual void decode(std::istream &I) {
+    auto D = getDecoder(I);
+    if (hasType())
+      D >> Type;
+    if (hasId())
+      D >> Id;
+    D >> Ops;
+  }
+  std::vector<SPIRVWord> Ops;
+  bool HasVariWC;
+  std::unordered_set<unsigned> Lit; // Literal operand index
+};
+
+template <typename BT = SPIRVInstTemplateBase, Op OC = OpNop, bool HasId = true,
+          SPIRVWord WC = 0, bool HasVariableWC = false, unsigned Literal1 = ~0U,
+          unsigned Literal2 = ~0U, unsigned Literal3 = ~0U>
+class SPIRVInstTemplate : public BT {
+public:
+  typedef BT BaseTy;
+  SPIRVInstTemplate() { init(); }
+  virtual ~SPIRVInstTemplate() {}
+  virtual void init() {
+    this->initImpl(OC, HasId, WC, HasVariableWC, Literal1, Literal2, Literal3);
+  }
+};
+
+class SPIRVMemoryAccess {
+public:
+  SPIRVMemoryAccess(const std::vector<SPIRVWord> &TheMemoryAccess)
+      : TheMemoryAccessMask(0), Alignment(0) {
+    MemoryAccessUpdate(TheMemoryAccess);
+  }
+
+  SPIRVMemoryAccess() : TheMemoryAccessMask(0), Alignment(0) {}
+
+  void MemoryAccessUpdate(const std::vector<SPIRVWord> &MemoryAccess) {
+    if (!MemoryAccess.size())
+      return;
+    assert((MemoryAccess.size() == 1 || MemoryAccess.size() == 2) &&
+           "Invalid memory access operand size");
+    TheMemoryAccessMask = MemoryAccess[0];
+    if (MemoryAccess[0] & MemoryAccessAlignedMask) {
+      assert(MemoryAccess.size() == 2 && "Alignment operand is missing");
+      Alignment = MemoryAccess[1];
+    }
+  }
+  SPIRVWord isVolatile() const {
+    return getMemoryAccessMask() & MemoryAccessVolatileMask;
+  }
+  SPIRVWord isNonTemporal() const {
+    return getMemoryAccessMask() & MemoryAccessNontemporalMask;
+  }
+  SPIRVWord getMemoryAccessMask() const { return TheMemoryAccessMask; }
+  SPIRVWord getAlignment() const { return Alignment; }
+
+protected:
+  SPIRVWord TheMemoryAccessMask;
+  SPIRVWord Alignment;
+};
+
+class SPIRVVariable : public SPIRVInstruction {
+public:
+  // Complete constructor for integer constant
+  SPIRVVariable(SPIRVType *TheType, SPIRVId TheId, SPIRVValue *TheInitializer,
+                const std::string &TheName,
+                SPIRVStorageClassKind TheStorageClass, SPIRVBasicBlock *TheBB,
+                SPIRVModule *TheM)
+      : SPIRVInstruction(TheInitializer ? 5 : 4, OpVariable, TheType, TheId,
+                         TheBB, TheM),
+        StorageClass(TheStorageClass) {
+    if (TheInitializer)
+      Initializer.push_back(TheInitializer->getId());
+    Name = TheName;
+    validate();
+  }
+  // Incomplete constructor
+  SPIRVVariable()
+      : SPIRVInstruction(OpVariable), StorageClass(StorageClassFunction) {}
+
+  SPIRVStorageClassKind getStorageClass() const { return StorageClass; }
+  SPIRVValue *getInitializer() const {
+    if (Initializer.empty())
+      return nullptr;
+    assert(Initializer.size() == 1);
+    return getValue(Initializer[0]);
+  }
+  bool isConstant() const { return hasDecorate(DecorationConstant); }
+  bool isBuiltin(SPIRVBuiltinVariableKind *BuiltinKind = nullptr) const {
+    SPIRVWord Kind;
+    bool Found = hasDecorate(DecorationBuiltIn, 0, &Kind);
+    if (!Found)
+      return false;
+    if (BuiltinKind)
+      *BuiltinKind = static_cast<SPIRVBuiltinVariableKind>(Kind);
+    return true;
+  }
+  void setBuiltin(SPIRVBuiltinVariableKind Kind) {
+    assert(isValid(Kind));
+    addDecorate(new SPIRVDecorate(DecorationBuiltIn, this, Kind));
+  }
+  void setIsConstant(bool Is) {
+    if (Is)
+      addDecorate(new SPIRVDecorate(DecorationConstant, this));
+    else
+      eraseDecorate(DecorationConstant);
+  }
+  virtual std::vector<SPIRVEntry *> getNonLiteralOperands() const {
+    if (SPIRVValue *V = getInitializer())
+      return std::vector<SPIRVEntry *>(1, V);
+    return std::vector<SPIRVEntry *>();
+  }
+
+protected:
+  void validate() const {
+    SPIRVValue::validate();
+    assert(isValid(StorageClass));
+    assert(Initializer.size() == 1 || Initializer.empty());
+  }
+  void setWordCount(SPIRVWord TheWordCount) {
+    SPIRVEntry::setWordCount(TheWordCount);
+    Initializer.resize(WordCount - 4);
+  }
+  _SPIRV_DEF_ENCDEC4(Type, Id, StorageClass, Initializer)
+
+  SPIRVStorageClassKind StorageClass;
+  std::vector<SPIRVId> Initializer;
+};
+
+class SPIRVStore : public SPIRVInstruction, public SPIRVMemoryAccess {
+public:
+  const static SPIRVWord FixedWords = 3;
+  // Complete constructor
+  SPIRVStore(SPIRVId PointerId, SPIRVId ValueId,
+             const std::vector<SPIRVWord> &TheMemoryAccess,
+             SPIRVBasicBlock *TheBB)
+      : SPIRVInstruction(FixedWords + TheMemoryAccess.size(), OpStore, TheBB),
+        SPIRVMemoryAccess(TheMemoryAccess), MemoryAccess(TheMemoryAccess),
+        PtrId(PointerId), ValId(ValueId) {
+    setAttr();
+    validate();
+    assert(TheBB && "Invalid BB");
+  }
+  // Incomplete constructor
+  SPIRVStore()
+      : SPIRVInstruction(OpStore), SPIRVMemoryAccess(), PtrId(SPIRVID_INVALID),
+        ValId(SPIRVID_INVALID) {
+    setAttr();
+  }
+
+  SPIRVValue *getSrc() const { return getValue(ValId); }
+  SPIRVValue *getDst() const { return getValue(PtrId); }
+
+protected:
+  void setAttr() {
+    setHasNoType();
+    setHasNoId();
+  }
+
+  void setWordCount(SPIRVWord TheWordCount) {
+    SPIRVEntry::setWordCount(TheWordCount);
+    MemoryAccess.resize(TheWordCount - FixedWords);
+  }
+  void encode(spv_ostream &O) const {
+    getEncoder(O) << PtrId << ValId << MemoryAccess;
+  }
+
+  void decode(std::istream &I) {
+    getDecoder(I) >> PtrId >> ValId >> MemoryAccess;
+    MemoryAccessUpdate(MemoryAccess);
+  }
+
+  void validate() const {
+    SPIRVInstruction::validate();
+    if (getSrc()->isForward() || getDst()->isForward())
+      return;
+    assert(getValueType(PtrId)->getPointerElementType() ==
+               getValueType(ValId) &&
+           "Inconsistent operand types");
+  }
+
+private:
+  std::vector<SPIRVWord> MemoryAccess;
+  SPIRVId PtrId;
+  SPIRVId ValId;
+};
+
+class SPIRVLoad : public SPIRVInstruction, public SPIRVMemoryAccess {
+public:
+  const static SPIRVWord FixedWords = 4;
+  // Complete constructor
+  SPIRVLoad(SPIRVId TheId, SPIRVId PointerId,
+            const std::vector<SPIRVWord> &TheMemoryAccess,
+            SPIRVBasicBlock *TheBB)
+      : SPIRVInstruction(
+            FixedWords + TheMemoryAccess.size(), OpLoad,
+            TheBB->getValueType(PointerId)->getPointerElementType(), TheId,
+            TheBB),
+        SPIRVMemoryAccess(TheMemoryAccess), PtrId(PointerId),
+        MemoryAccess(TheMemoryAccess) {
+    validate();
+    assert(TheBB && "Invalid BB");
+  }
+  // Incomplete constructor
+  SPIRVLoad()
+      : SPIRVInstruction(OpLoad), SPIRVMemoryAccess(), PtrId(SPIRVID_INVALID) {}
+
+  SPIRVValue *getSrc() const { return Module->get<SPIRVValue>(PtrId); }
+
+protected:
+  void setWordCount(SPIRVWord TheWordCount) {
+    SPIRVEntry::setWordCount(TheWordCount);
+    MemoryAccess.resize(TheWordCount - FixedWords);
+  }
+
+  void encode(spv_ostream &O) const {
+    getEncoder(O) << Type << Id << PtrId << MemoryAccess;
+  }
+
+  void decode(std::istream &I) {
+    getDecoder(I) >> Type >> Id >> PtrId >> MemoryAccess;
+    MemoryAccessUpdate(MemoryAccess);
+  }
+
+  void validate() const {
+    SPIRVInstruction::validate();
+    assert((getValue(PtrId)->isForward() ||
+            Type == getValueType(PtrId)->getPointerElementType()) &&
+           "Inconsistent types");
+  }
+
+private:
+  SPIRVId PtrId;
+  std::vector<SPIRVWord> MemoryAccess;
+};
+
+class SPIRVBinary : public SPIRVInstTemplateBase {
+protected:
+  void validate() const {
+    SPIRVId Op1 = Ops[0];
+    SPIRVId Op2 = Ops[1];
+    SPIRVType *op1Ty, *op2Ty;
+    SPIRVInstruction::validate();
+    if (getValue(Op1)->isForward() || getValue(Op2)->isForward())
+      return;
+    if (getValueType(Op1)->isTypeVector()) {
+      op1Ty = getValueType(Op1)->getVectorComponentType();
+      op2Ty = getValueType(Op2)->getVectorComponentType();
+      assert(getValueType(Op1)->getVectorComponentCount() ==
+                 getValueType(Op2)->getVectorComponentCount() &&
+             "Inconsistent Vector component width");
+    } else {
+      op1Ty = getValueType(Op1);
+      op2Ty = getValueType(Op2);
+    }
+
+    if (isBinaryOpCode(OpCode)) {
+      assert(getValueType(Op1) == getValueType(Op2) &&
+             "Invalid type for binary instruction");
+      assert((op1Ty->isTypeInt() || op2Ty->isTypeFloat()) &&
+             "Invalid type for Binary instruction");
+      assert((op1Ty->getBitWidth() == op2Ty->getBitWidth()) &&
+             "Inconsistent BitWidth");
+    } else if (isShiftOpCode(OpCode)) {
+      assert((op1Ty->isTypeInt() || op2Ty->isTypeInt()) &&
+             "Invalid type for shift instruction");
+    } else if (isLogicalOpCode(OpCode)) {
+      assert((op1Ty->isTypeBool() || op2Ty->isTypeBool()) &&
+             "Invalid type for logical instruction");
+    } else if (isBitwiseOpCode(OpCode)) {
+      assert((op1Ty->isTypeInt() || op2Ty->isTypeInt()) &&
+             "Invalid type for bitwise instruction");
+      assert((op1Ty->getIntegerBitWidth() == op2Ty->getIntegerBitWidth()) &&
+             "Inconsistent BitWidth");
+    } else {
+      assert(0 && "Invalid op code!");
+    }
+  }
+};
+
+template <Op OC>
+class SPIRVBinaryInst
+    : public SPIRVInstTemplate<SPIRVBinary, OC, true, 5, false> {};
+
+#define _SPIRV_OP(x) typedef SPIRVBinaryInst<Op##x> SPIRV##x;
+_SPIRV_OP(IAdd)
+_SPIRV_OP(FAdd)
+_SPIRV_OP(ISub)
+_SPIRV_OP(FSub)
+_SPIRV_OP(IMul)
+_SPIRV_OP(FMul)
+_SPIRV_OP(UDiv)
+_SPIRV_OP(SDiv)
+_SPIRV_OP(FDiv)
+_SPIRV_OP(SRem)
+_SPIRV_OP(FRem)
+_SPIRV_OP(UMod)
+_SPIRV_OP(SMod)
+_SPIRV_OP(FMod)
+_SPIRV_OP(ShiftLeftLogical)
+_SPIRV_OP(ShiftRightLogical)
+_SPIRV_OP(ShiftRightArithmetic)
+_SPIRV_OP(LogicalAnd)
+_SPIRV_OP(LogicalOr)
+_SPIRV_OP(LogicalEqual)
+_SPIRV_OP(LogicalNotEqual)
+_SPIRV_OP(BitwiseAnd)
+_SPIRV_OP(BitwiseOr)
+_SPIRV_OP(BitwiseXor)
+_SPIRV_OP(Dot)
+#undef _SPIRV_OP
+
+template <Op TheOpCode> class SPIRVInstNoOperand : public SPIRVInstruction {
+public:
+  // Complete constructor
+  SPIRVInstNoOperand(SPIRVBasicBlock *TheBB)
+      : SPIRVInstruction(1, TheOpCode, TheBB) {
+    setAttr();
+    validate();
+  }
+  // Incomplete constructor
+  SPIRVInstNoOperand() : SPIRVInstruction(TheOpCode) { setAttr(); }
+
+protected:
+  void setAttr() {
+    setHasNoId();
+    setHasNoType();
+  }
+  _SPIRV_DEF_ENCDEC0
+};
+
+typedef SPIRVInstNoOperand<OpReturn> SPIRVReturn;
+
+class SPIRVReturnValue : public SPIRVInstruction {
+public:
+  static const Op OC = OpReturnValue;
+  // Complete constructor
+  SPIRVReturnValue(SPIRVValue *TheReturnValue, SPIRVBasicBlock *TheBB)
+      : SPIRVInstruction(2, OC, TheBB), ReturnValueId(TheReturnValue->getId()) {
+    setAttr();
+    validate();
+    assert(TheBB && "Invalid BB");
+  }
+  // Incomplete constructor
+  SPIRVReturnValue() : SPIRVInstruction(OC), ReturnValueId(SPIRVID_INVALID) {
+    setAttr();
+  }
+
+  SPIRVValue *getReturnValue() const { return getValue(ReturnValueId); }
+
+protected:
+  void setAttr() {
+    setHasNoId();
+    setHasNoType();
+  }
+  _SPIRV_DEF_ENCDEC1(ReturnValueId)
+  void validate() const { SPIRVInstruction::validate(); }
+  SPIRVId ReturnValueId;
+};
+
+class SPIRVBranch : public SPIRVInstruction {
+public:
+  static const Op OC = OpBranch;
+  // Complete constructor
+  SPIRVBranch(SPIRVLabel *TheTargetLabel, SPIRVBasicBlock *TheBB)
+      : SPIRVInstruction(2, OC, TheBB), TargetLabelId(TheTargetLabel->getId()) {
+    validate();
+    assert(TheBB && "Invalid BB");
+  }
+  // Incomplete constructor
+  SPIRVBranch() : SPIRVInstruction(OC), TargetLabelId(SPIRVID_INVALID) {
+    setHasNoId();
+    setHasNoType();
+  }
+  SPIRVValue *getTargetLabel() const { return getValue(TargetLabelId); }
+
+protected:
+  _SPIRV_DEF_ENCDEC1(TargetLabelId)
+  void validate() const {
+    SPIRVInstruction::validate();
+    assert(WordCount == 2);
+    assert(OpCode == OC);
+    assert(getTargetLabel()->isLabel() || getTargetLabel()->isForward());
+  }
+  SPIRVId TargetLabelId;
+};
+
+class SPIRVBranchConditional : public SPIRVInstruction {
+public:
+  static const Op OC = OpBranchConditional;
+  // Complete constructor
+  SPIRVBranchConditional(SPIRVValue *TheCondition, SPIRVLabel *TheTrueLabel,
+                         SPIRVLabel *TheFalseLabel, SPIRVBasicBlock *TheBB)
+      : SPIRVInstruction(4, OC, TheBB), ConditionId(TheCondition->getId()),
+        TrueLabelId(TheTrueLabel->getId()),
+        FalseLabelId(TheFalseLabel->getId()) {
+    validate();
+  }
+  SPIRVBranchConditional(SPIRVValue *TheCondition, SPIRVLabel *TheTrueLabel,
+                         SPIRVLabel *TheFalseLabel, SPIRVBasicBlock *TheBB,
+                         SPIRVWord TrueWeight, SPIRVWord FalseWeight)
+      : SPIRVInstruction(6, OC, TheBB), ConditionId(TheCondition->getId()),
+        TrueLabelId(TheTrueLabel->getId()),
+        FalseLabelId(TheFalseLabel->getId()) {
+    BranchWeights.push_back(TrueWeight);
+    BranchWeights.push_back(FalseWeight);
+    validate();
+    assert(TheBB && "Invalid BB");
+  }
+  // Incomplete constructor
+  SPIRVBranchConditional()
+      : SPIRVInstruction(OC), ConditionId(SPIRVID_INVALID),
+        TrueLabelId(SPIRVID_INVALID), FalseLabelId(SPIRVID_INVALID) {
+    setHasNoId();
+    setHasNoType();
+  }
+  SPIRVValue *getCondition() const { return getValue(ConditionId); }
+  SPIRVLabel *getTrueLabel() const { return get<SPIRVLabel>(TrueLabelId); }
+  SPIRVLabel *getFalseLabel() const { return get<SPIRVLabel>(FalseLabelId); }
+
+protected:
+  void setWordCount(SPIRVWord TheWordCount) {
+    SPIRVEntry::setWordCount(TheWordCount);
+    BranchWeights.resize(TheWordCount - 4);
+  }
+  _SPIRV_DEF_ENCDEC4(ConditionId, TrueLabelId, FalseLabelId, BranchWeights)
+  void validate() const {
+    SPIRVInstruction::validate();
+    assert(WordCount == 4 || WordCount == 6);
+    assert(WordCount == BranchWeights.size() + 4);
+    assert(OpCode == OC);
+    assert(getCondition()->isForward() ||
+           getCondition()->getType()->isTypeBool());
+    assert(getTrueLabel()->isForward() || getTrueLabel()->isLabel());
+    assert(getFalseLabel()->isForward() || getFalseLabel()->isLabel());
+  }
+  SPIRVId ConditionId;
+  SPIRVId TrueLabelId;
+  SPIRVId FalseLabelId;
+  std::vector<SPIRVWord> BranchWeights;
+};
+
+class SPIRVUnreachable : public SPIRVInstruction {
+public:
+  static const Op OC = OpUnreachable;
+  // Complete constructor
+  SPIRVUnreachable(SPIRVBasicBlock *TheBB) : SPIRVInstruction(1, OC, TheBB) {
+    setHasNoId();
+    setHasNoType();
+    validate();
+    assert(TheBB && "Invalid BB");
+  }
+  // Incomplete constructor
+  SPIRVUnreachable() : SPIRVInstruction(OC) {
+    setHasNoId();
+    setHasNoType();
+    validate();
+  }
+
+protected:
+  void validate() const {
+    SPIRVInstruction::validate();
+    assert(WordCount == 1);
+    assert(OpCode == OC);
+  }
+  _SPIRV_DEF_ENCDEC0
+};
+
+class SPIRVKill : public SPIRVInstruction {
+public:
+  static const Op OC = OpKill;
+  // Complete constructor
+  SPIRVKill(SPIRVBasicBlock *TheBB) : SPIRVInstruction(1, OC, TheBB) {
+    setHasNoId();
+    setHasNoType();
+    validate();
+    assert(TheBB && "Invalid BB");
+  }
+  // Incomplete constructor
+  SPIRVKill() : SPIRVInstruction(OC) {
+    setHasNoId();
+    setHasNoType();
+    validate();
+  }
+
+protected:
+  void validate() const {
+    SPIRVInstruction::validate();
+    assert(WordCount == 1);
+    assert(OpCode == OC);
+  }
+  _SPIRV_DEF_ENCDEC0
+};
+
+class SPIRVLoopMerge : public SPIRVInstruction {
+public:
+  static const Op OC = OpLoopMerge;
+  // Complete constructor
+  SPIRVLoopMerge(SPIRVBasicBlock *MergeBB, SPIRVBasicBlock *ContinuationBB,
+                 spv::LoopControlMask LoopControl, SPIRVBasicBlock *TheBB)
+      : SPIRVInstruction(4, OC, TheBB), merge(MergeBB),
+        continuation(ContinuationBB), control(LoopControl) {
+    setHasNoId();
+    setHasNoType();
+    validate();
+    assert(TheBB && "Invalid BB");
+  }
+  // Incomplete constructor
+  SPIRVLoopMerge() : SPIRVInstruction(OC) {
+    setHasNoId();
+    setHasNoType();
+    validate();
+  }
+
+protected:
+  SPIRVBasicBlock *merge;
+  SPIRVBasicBlock *continuation;
+  SPIRVWord control;
+  void validate() const {
+    SPIRVInstruction::validate();
+    assert(WordCount == 4);
+    assert(OpCode == OC);
+  }
+  _SPIRV_DEF_ENCDEC3(merge, continuation, control)
+};
+
+class SPIRVSelectionMerge : public SPIRVInstruction {
+public:
+  static const Op OC = OpSelectionMerge;
+  // Complete constructor
+  SPIRVSelectionMerge(SPIRVBasicBlock *MergeBB,
+                      spv::SelectionControlMask SelectionControl,
+                      SPIRVBasicBlock *TheBB)
+      : SPIRVInstruction(3, OC, TheBB), merge(MergeBB),
+        control(SelectionControl) {
+    setHasNoId();
+    setHasNoType();
+    validate();
+    assert(TheBB && "Invalid BB");
+  }
+  // Incomplete constructor
+  SPIRVSelectionMerge() : SPIRVInstruction(OC) {
+    setHasNoId();
+    setHasNoType();
+    validate();
+  }
+
+protected:
+  SPIRVBasicBlock *merge;
+  SPIRVWord control;
+  void validate() const {
+    SPIRVInstruction::validate();
+    assert(WordCount == 3);
+    assert(OpCode == OC);
+  }
+  _SPIRV_DEF_ENCDEC2(merge, control)
+};
+
+class SPIRVUndefInst : public SPIRVInstruction {
+public:
+  static const Op OC = OpUndefValueInternal;
+  // Complete constructor
+  SPIRVUndefInst(SPIRVType *TheType, SPIRVId TheId, SPIRVBasicBlock *TheBB)
+      : SPIRVInstruction(3, OC, TheType, TheId, TheBB) {
+    validate();
+    assert(TheBB && "Invalid BB");
+  }
+  // Incomplete constructor
+  SPIRVUndefInst() { validate(); }
+
+protected:
+  _SPIRV_DEF_ENCDEC2(Type, Id)
+  void validate() const {
+    SPIRVInstruction::validate();
+    assert(WordCount == 3);
+    assert(OpCode == OC);
+  }
+};
+
+class SPIRVPhi : public SPIRVInstruction {
+public:
+  static const Op OC = OpPhi;
+  static const SPIRVWord FixedWordCount = 3;
+  SPIRVPhi(SPIRVType *TheType, SPIRVId TheId,
+           const std::vector<SPIRVValue *> &ThePairs, SPIRVBasicBlock *BB)
+      : SPIRVInstruction(ThePairs.size() + FixedWordCount, OC, TheType, TheId,
+                         BB) {
+    Pairs = getIds(ThePairs);
+    validate();
+    assert(BB && "Invalid BB");
+  }
+  SPIRVPhi() : SPIRVInstruction(OC) {}
+  std::vector<SPIRVValue *> getPairs() { return getValues(Pairs); }
+  void addPair(SPIRVValue *Value, SPIRVBasicBlock *BB) {
+    Pairs.push_back(Value->getId());
+    Pairs.push_back(BB->getId());
+    WordCount = Pairs.size() + FixedWordCount;
+    validate();
+  }
+  void setPairs(const std::vector<SPIRVValue *> &ThePairs) {
+    Pairs = getIds(ThePairs);
+    WordCount = Pairs.size() + FixedWordCount;
+    validate();
+  }
+  void foreachPair(
+      std::function<void(SPIRVValue *, SPIRVBasicBlock *, size_t)> Func) {
+    for (size_t I = 0, E = Pairs.size() / 2; I != E; ++I) {
+      SPIRVEntry *Value, *BB;
+      if (!Module->exist(Pairs[2 * I], &Value) ||
+          !Module->exist(Pairs[2 * I + 1], &BB))
+        continue;
+      Func(static_cast<SPIRVValue *>(Value), static_cast<SPIRVBasicBlock *>(BB),
+           I);
+    }
+  }
+  void
+  foreachPair(std::function<void(SPIRVValue *, SPIRVBasicBlock *)> Func) const {
+    for (size_t I = 0, E = Pairs.size() / 2; I != E; ++I) {
+      SPIRVEntry *Value, *BB;
+      if (!Module->exist(Pairs[2 * I], &Value) ||
+          !Module->exist(Pairs[2 * I + 1], &BB))
+        continue;
+      Func(static_cast<SPIRVValue *>(Value),
+           static_cast<SPIRVBasicBlock *>(BB));
+    }
+  }
+  void setWordCount(SPIRVWord TheWordCount) {
+    SPIRVEntry::setWordCount(TheWordCount);
+    Pairs.resize(TheWordCount - FixedWordCount);
+  }
+  _SPIRV_DEF_ENCDEC3(Type, Id, Pairs)
+  void validate() const {
+    assert(WordCount == Pairs.size() + FixedWordCount);
+    assert(OpCode == OC);
+    assert(Pairs.size() % 2 == 0);
+    foreachPair([=](SPIRVValue *IncomingV, SPIRVBasicBlock *IncomingBB) {
+      assert(IncomingV->isForward() || IncomingV->getType() == Type);
+      assert(IncomingBB->isBasicBlock() || IncomingBB->isForward());
+    });
+    SPIRVInstruction::validate();
+  }
+
+protected:
+  std::vector<SPIRVId> Pairs;
+};
+
+class SPIRVCompare : public SPIRVInstTemplateBase {
+protected:
+  void validate() const {
+    auto Op1 = Ops[0];
+    auto Op2 = Ops[1];
+    SPIRVType *op1Ty, *op2Ty, *resTy;
+    SPIRVInstruction::validate();
+    if (getValue(Op1)->isForward() || getValue(Op2)->isForward())
+      return;
+
+    if (getValueType(Op1)->isTypeVector()) {
+      op1Ty = getValueType(Op1)->getVectorComponentType();
+      op2Ty = getValueType(Op2)->getVectorComponentType();
+      resTy = Type->getVectorComponentType();
+      assert(getValueType(Op1)->getVectorComponentCount() ==
+                 getValueType(Op2)->getVectorComponentCount() &&
+             "Inconsistent Vector component width");
+    } else {
+      op1Ty = getValueType(Op1);
+      op2Ty = getValueType(Op2);
+      resTy = Type;
+    }
+    assert(isCmpOpCode(OpCode) && "Invalid op code for cmp inst");
+    assert((resTy->isTypeBool() || resTy->isTypeInt()) &&
+           "Invalid type for compare instruction");
+    assert(op1Ty == op2Ty && "Inconsistent types");
+  }
+};
+
+template <Op OC>
+class SPIRVCmpInst
+    : public SPIRVInstTemplate<SPIRVCompare, OC, true, 5, false> {};
+
+#define _SPIRV_OP(x) typedef SPIRVCmpInst<Op##x> SPIRV##x;
+_SPIRV_OP(IEqual)
+_SPIRV_OP(FOrdEqual)
+_SPIRV_OP(FUnordEqual)
+_SPIRV_OP(INotEqual)
+_SPIRV_OP(FOrdNotEqual)
+_SPIRV_OP(FUnordNotEqual)
+_SPIRV_OP(ULessThan)
+_SPIRV_OP(SLessThan)
+_SPIRV_OP(FOrdLessThan)
+_SPIRV_OP(FUnordLessThan)
+_SPIRV_OP(UGreaterThan)
+_SPIRV_OP(SGreaterThan)
+_SPIRV_OP(FOrdGreaterThan)
+_SPIRV_OP(FUnordGreaterThan)
+_SPIRV_OP(ULessThanEqual)
+_SPIRV_OP(SLessThanEqual)
+_SPIRV_OP(FOrdLessThanEqual)
+_SPIRV_OP(FUnordLessThanEqual)
+_SPIRV_OP(UGreaterThanEqual)
+_SPIRV_OP(SGreaterThanEqual)
+_SPIRV_OP(FOrdGreaterThanEqual)
+_SPIRV_OP(FUnordGreaterThanEqual)
+_SPIRV_OP(LessOrGreater)
+_SPIRV_OP(Ordered)
+_SPIRV_OP(Unordered)
+#undef _SPIRV_OP
+
+class SPIRVSelect : public SPIRVInstruction {
+public:
+  // Complete constructor
+  SPIRVSelect(SPIRVId TheId, SPIRVId TheCondition, SPIRVId TheOp1,
+              SPIRVId TheOp2, SPIRVBasicBlock *TheBB)
+      : SPIRVInstruction(6, OpSelect, TheBB->getValueType(TheOp1), TheId,
+                         TheBB),
+        Condition(TheCondition), Op1(TheOp1), Op2(TheOp2) {
+    validate();
+    assert(TheBB && "Invalid BB");
+  }
+  // Incomplete constructor
+  SPIRVSelect()
+      : SPIRVInstruction(OpSelect), Condition(SPIRVID_INVALID),
+        Op1(SPIRVID_INVALID), Op2(SPIRVID_INVALID) {}
+  SPIRVValue *getCondition() { return getValue(Condition); }
+  SPIRVValue *getTrueValue() { return getValue(Op1); }
+  SPIRVValue *getFalseValue() { return getValue(Op2); }
+
+protected:
+  _SPIRV_DEF_ENCDEC5(Type, Id, Condition, Op1, Op2)
+  void validate() const {
+    SPIRVInstruction::validate();
+    if (getValue(Condition)->isForward() || getValue(Op1)->isForward() ||
+        getValue(Op2)->isForward())
+      return;
+
+    SPIRVType *conTy = getValueType(Condition)->isTypeVector()
+                           ? getValueType(Condition)->getVectorComponentType()
+                           : getValueType(Condition);
+    assert(conTy->isTypeBool() && "Invalid type");
+    assert(getType() == getValueType(Op1) && getType() == getValueType(Op2) &&
+           "Inconsistent type");
+  }
+  SPIRVId Condition;
+  SPIRVId Op1;
+  SPIRVId Op2;
+};
+
+class SPIRVSwitch : public SPIRVInstruction {
+public:
+  static const Op OC = OpSwitch;
+  static const SPIRVWord FixedWordCount = 3;
+  typedef std::vector<SPIRVWord> LiteralTy;
+  typedef std::pair<LiteralTy, SPIRVBasicBlock *> PairTy;
+
+  SPIRVSwitch(SPIRVValue *TheSelect, SPIRVBasicBlock *TheDefault,
+              const std::vector<PairTy> &ThePairs, SPIRVBasicBlock *BB)
+      : SPIRVInstruction(ThePairs.size() * (ThePairs.at(0).first.size() + 1) +
+                             FixedWordCount,
+                         OC, BB),
+        Select(TheSelect->getId()), Default(TheDefault->getId()) {
+
+    for (auto &I : ThePairs) {
+      for (auto &U : I.first)
+        Pairs.push_back(U);
+      Pairs.push_back(I.second->getId());
+    }
+    validate();
+    assert(BB && "Invalid BB");
+  }
+  SPIRVSwitch()
+      : SPIRVInstruction(OC), Select(SPIRVWORD_MAX), Default(SPIRVWORD_MAX) {
+    setHasNoId();
+    setHasNoType();
+  }
+  std::vector<SPIRVValue *> getPairs() { return getValues(Pairs); }
+  SPIRVValue *getSelect() const { return getValue(Select); }
+  SPIRVBasicBlock *getDefault() const {
+    return static_cast<SPIRVBasicBlock *>(getValue(Default));
+  }
+  size_t getLiteralsCount() const {
+    return getSelect()->getType()->getBitWidth() / (sizeof(SPIRVWord) * 8);
+  }
+  size_t getPairSize() const { return getLiteralsCount() + 1; }
+  size_t getNumPairs() const { return Pairs.size() / getPairSize(); }
+  void
+  foreachPair(std::function<void(LiteralTy, SPIRVBasicBlock *)> Func) const {
+    unsigned PairSize = getPairSize();
+    for (size_t I = 0, E = getNumPairs(); I != E; ++I) {
+      SPIRVEntry *BB;
+      LiteralTy Literals;
+      if (!Module->exist(Pairs[PairSize * I + getLiteralsCount()], &BB))
+        continue;
+
+      for (size_t i = 0; i < getLiteralsCount(); ++i) {
+        Literals.push_back(Pairs.at(PairSize * I + i));
+      }
+      Func(Literals, static_cast<SPIRVBasicBlock *>(BB));
+    }
+  }
+  void setWordCount(SPIRVWord TheWordCount) {
+    SPIRVEntry::setWordCount(TheWordCount);
+    Pairs.resize(TheWordCount - FixedWordCount);
+  }
+  _SPIRV_DEF_ENCDEC3(Select, Default, Pairs)
+  void validate() const {
+    assert(WordCount == Pairs.size() + FixedWordCount);
+    assert(OpCode == OC);
+    assert(Pairs.size() % getPairSize() == 0);
+    foreachPair([=](LiteralTy Literals, SPIRVBasicBlock *BB) {
+      assert(BB->isBasicBlock() || BB->isForward());
+    });
+    SPIRVInstruction::validate();
+  }
+
+protected:
+  SPIRVId Select;
+  SPIRVId Default;
+  std::vector<SPIRVWord> Pairs;
+};
+
+class SPIRVUnary : public SPIRVInstTemplateBase {
+protected:
+  void validate() const {
+    auto Op = Ops[0];
+    SPIRVInstruction::validate();
+    if (getValue(Op)->isForward())
+      return;
+    if (isGenericNegateOpCode(OpCode)) {
+      SPIRVType *resTy =
+          Type->isTypeVector() ? Type->getVectorComponentType() : Type;
+      SPIRVType *opTy = Type->isTypeVector()
+                            ? getValueType(Op)->getVectorComponentType()
+                            : getValueType(Op);
+
+      assert(getType() == getValueType(Op) && "Inconsistent type");
+      assert((resTy->isTypeInt() || resTy->isTypeFloat()) &&
+             "Invalid type for Generic Negate instruction");
+      assert((resTy->getBitWidth() == opTy->getBitWidth()) &&
+             "Invalid bitwidth for Generic Negate instruction");
+      assert((Type->isTypeVector()
+                  ? (Type->getVectorComponentCount() ==
+                     getValueType(Op)->getVectorComponentCount())
+                  : 1) &&
+             "Invalid vector component Width for Generic Negate instruction");
+    }
+  }
+};
+
+template <Op OC>
+class SPIRVUnaryInst
+    : public SPIRVInstTemplate<SPIRVUnary, OC, true, 4, false> {};
+
+#define _SPIRV_OP(x) typedef SPIRVUnaryInst<Op##x> SPIRV##x;
+_SPIRV_OP(ConvertFToU)
+_SPIRV_OP(ConvertFToS)
+_SPIRV_OP(ConvertSToF)
+_SPIRV_OP(ConvertUToF)
+_SPIRV_OP(UConvert)
+_SPIRV_OP(SConvert)
+_SPIRV_OP(FConvert)
+_SPIRV_OP(SatConvertSToU)
+_SPIRV_OP(SatConvertUToS)
+_SPIRV_OP(ConvertPtrToU)
+_SPIRV_OP(ConvertUToPtr)
+_SPIRV_OP(PtrCastToGeneric)
+_SPIRV_OP(GenericCastToPtr)
+_SPIRV_OP(Bitcast)
+_SPIRV_OP(SNegate)
+_SPIRV_OP(FNegate)
+_SPIRV_OP(Not)
+_SPIRV_OP(LogicalNot)
+_SPIRV_OP(IsNan)
+_SPIRV_OP(IsInf)
+_SPIRV_OP(IsFinite)
+_SPIRV_OP(IsNormal)
+_SPIRV_OP(SignBitSet)
+_SPIRV_OP(Any)
+_SPIRV_OP(All)
+#undef _SPIRV_OP
+
+class SPIRVAccessChainBase : public SPIRVInstTemplateBase {
+public:
+  SPIRVValue *getBase() { return this->getValue(this->Ops[0]); }
+  std::vector<SPIRVValue *> getIndices() const {
+    std::vector<SPIRVWord> IndexWords(this->Ops.begin() + 1, this->Ops.end());
+    return this->getValues(IndexWords);
+  }
+  bool isInBounds() {
+    return OpCode == OpInBoundsAccessChain ||
+           OpCode == OpInBoundsPtrAccessChain;
+  }
+  bool hasPtrIndex() {
+    return OpCode == OpPtrAccessChain || OpCode == OpInBoundsPtrAccessChain;
+  }
+};
+
+template <Op OC, unsigned FixedWC>
+class SPIRVAccessChainGeneric
+    : public SPIRVInstTemplate<SPIRVAccessChainBase, OC, true, FixedWC, true> {
+};
+
+typedef SPIRVAccessChainGeneric<OpAccessChain, 4> SPIRVAccessChain;
+typedef SPIRVAccessChainGeneric<OpInBoundsAccessChain, 4>
+    SPIRVInBoundsAccessChain;
+typedef SPIRVAccessChainGeneric<OpPtrAccessChain, 5> SPIRVPtrAccessChain;
+typedef SPIRVAccessChainGeneric<OpInBoundsPtrAccessChain, 5>
+    SPIRVInBoundsPtrAccessChain;
+
+template <Op OC, SPIRVWord FixedWordCount>
+class SPIRVFunctionCallGeneric : public SPIRVInstruction {
+public:
+  SPIRVFunctionCallGeneric(SPIRVType *TheType, SPIRVId TheId,
+                           const std::vector<SPIRVWord> &TheArgs,
+                           SPIRVBasicBlock *BB)
+      : SPIRVInstruction(TheArgs.size() + FixedWordCount, OC, TheType, TheId,
+                         BB),
+        Args(TheArgs) {
+    validate();
+    assert(BB && "Invalid BB");
+  }
+  SPIRVFunctionCallGeneric(SPIRVType *TheType, SPIRVId TheId,
+                           const std::vector<SPIRVValue *> &TheArgs,
+                           SPIRVBasicBlock *BB)
+      : SPIRVInstruction(TheArgs.size() + FixedWordCount, OC, TheType, TheId,
+                         BB) {
+    Args = getIds(TheArgs);
+    validate();
+    assert(BB && "Invalid BB");
+  }
+  SPIRVFunctionCallGeneric() : SPIRVInstruction(OC) {}
+  const std::vector<SPIRVWord> &getArguments() { return Args; }
+  std::vector<SPIRVValue *> getArgumentValues() { return getValues(Args); }
+  std::vector<SPIRVType *> getArgumentValueTypes() const {
+    std::vector<SPIRVType *> ArgTypes;
+    for (auto &I : Args)
+      ArgTypes.push_back(getValue(I)->getType());
+    return ArgTypes;
+  }
+  void setWordCount(SPIRVWord TheWordCount) {
+    SPIRVEntry::setWordCount(TheWordCount);
+    Args.resize(TheWordCount - FixedWordCount);
+  }
+  void validate() const { SPIRVInstruction::validate(); }
+
+protected:
+  std::vector<SPIRVWord> Args;
+};
+
+class SPIRVFunctionCall : public SPIRVFunctionCallGeneric<OpFunctionCall, 4> {
+public:
+  SPIRVFunctionCall(SPIRVId TheId, SPIRVFunction *TheFunction,
+                    const std::vector<SPIRVWord> &TheArgs, SPIRVBasicBlock *BB);
+  SPIRVFunctionCall() : FunctionId(SPIRVID_INVALID) {}
+  SPIRVFunction *getFunction() const { return get<SPIRVFunction>(FunctionId); }
+  _SPIRV_DEF_ENCDEC4(Type, Id, FunctionId, Args)
+  void validate() const;
+  bool isOperandLiteral(unsigned Index) const { return false; }
+
+protected:
+  SPIRVId FunctionId;
+};
+
+class SPIRVExtInst : public SPIRVFunctionCallGeneric<OpExtInst, 5> {
+public:
+  SPIRVExtInst(SPIRVType *TheType, SPIRVId TheId, SPIRVId TheBuiltinSet,
+               SPIRVWord TheEntryPoint, const std::vector<SPIRVWord> &TheArgs,
+               SPIRVBasicBlock *BB)
+      : SPIRVFunctionCallGeneric(TheType, TheId, TheArgs, BB),
+        ExtSetId(TheBuiltinSet), ExtOp(TheEntryPoint) {
+    setExtSetKindById();
+    validate();
+  }
+  SPIRVExtInst(SPIRVType *TheType, SPIRVId TheId, SPIRVId TheBuiltinSet,
+               SPIRVWord TheEntryPoint,
+               const std::vector<SPIRVValue *> &TheArgs, SPIRVBasicBlock *BB)
+      : SPIRVFunctionCallGeneric(TheType, TheId, TheArgs, BB),
+        ExtSetId(TheBuiltinSet), ExtOp(TheEntryPoint) {
+    setExtSetKindById();
+    validate();
+  }
+  SPIRVExtInst(SPIRVExtInstSetKind SetKind = SPIRVEIS_Count,
+               unsigned ExtOC = SPIRVWORD_MAX)
+      : ExtSetId(SPIRVWORD_MAX), ExtOp(ExtOC), ExtSetKind(SetKind) {}
+  void setExtSetId(unsigned Set) { ExtSetId = Set; }
+  void setExtOp(unsigned ExtOC) { ExtOp = ExtOC; }
+  SPIRVId getExtSetId() const { return ExtSetId; }
+  SPIRVWord getExtOp() const { return ExtOp; }
+  void setExtSetKindById() {
+    assert(Module && "Invalid module");
+    ExtSetKind = Module->getBuiltinSet(ExtSetId);
+    assert((ExtSetKind == SPIRVEIS_OpenCL || ExtSetKind == SPIRVEIS_GLSL) &&
+           "not supported");
+  }
+  void encode(spv_ostream &O) const {
+    getEncoder(O) << Type << Id << ExtSetId;
+    switch (ExtSetKind) {
+    case SPIRVEIS_OpenCL:
+      getEncoder(O) << ExtOpOCL;
+      break;
+    case SPIRVEIS_GLSL:
+      getEncoder(O) << ExtOpGLSL;
+      break;
+    default:
+      assert(0 && "not supported");
+      getEncoder(O) << ExtOp;
+    }
+    getEncoder(O) << Args;
+  }
+  void decode(std::istream &I) {
+    getDecoder(I) >> Type >> Id >> ExtSetId;
+    setExtSetKindById();
+    switch (ExtSetKind) {
+    case SPIRVEIS_OpenCL:
+      getDecoder(I) >> ExtOpOCL;
+      break;
+    case SPIRVEIS_GLSL:
+      getDecoder(I) >> ExtOpGLSL;
+      break;
+    default:
+      assert(0 && "not supported");
+      getDecoder(I) >> ExtOp;
+    }
+    getDecoder(I) >> Args;
+  }
+  void validate() const {
+    SPIRVFunctionCallGeneric::validate();
+    validateBuiltin(ExtSetId, ExtOp);
+  }
+  bool isOperandLiteral(unsigned Index) const {
+    assert((ExtSetKind == SPIRVEIS_OpenCL || ExtSetKind == SPIRVEIS_GLSL) &&
+           "Unsupported extended instruction set");
+    if (ExtSetKind == SPIRVEIS_OpenCL) {
+      auto EOC = static_cast<OCLExtOpKind>(ExtOp);
+      switch (EOC) {
+      default:
+        return false;
+      case OpenCLLIB::Vloadn:
+      case OpenCLLIB::Vload_halfn:
+      case OpenCLLIB::Vloada_halfn:
+        return Index == 2;
+      case OpenCLLIB::Vstore_half_r:
+      case OpenCLLIB::Vstore_halfn_r:
+      case OpenCLLIB::Vstorea_halfn_r:
+        return Index == 3;
+      }
+    } else {
+      auto EGLSL = static_cast<GLSLExtOpKind>(ExtOp);
+      switch (EGLSL) { // TODO: necessary?
+      default:
+        return false;
+      }
+    }
+  }
+
+protected:
+  SPIRVId ExtSetId;
+  union {
+    SPIRVWord ExtOp;
+    OCLExtOpKind ExtOpOCL;
+    GLSLExtOpKind ExtOpGLSL;
+  };
+  SPIRVExtInstSetKind ExtSetKind;
+};
+
+class SPIRVCompositeExtract : public SPIRVInstruction {
+public:
+  const static Op OC = OpCompositeExtract;
+  // Complete constructor
+  SPIRVCompositeExtract(SPIRVType *TheType, SPIRVId TheId,
+                        SPIRVValue *TheComposite,
+                        const std::vector<SPIRVWord> &TheIndices,
+                        SPIRVBasicBlock *TheBB)
+      : SPIRVInstruction(TheIndices.size() + 4, OC, TheType, TheId, TheBB),
+        Composite(TheComposite->getId()), Indices(TheIndices) {
+    validate();
+    assert(TheBB && "Invalid BB");
+  }
+  // Incomplete constructor
+  SPIRVCompositeExtract() : SPIRVInstruction(OC), Composite(SPIRVID_INVALID) {}
+
+  SPIRVValue *getComposite() { return getValue(Composite); }
+  const std::vector<SPIRVWord> &getIndices() const { return Indices; }
+
+protected:
+  void setWordCount(SPIRVWord TheWordCount) {
+    SPIRVEntry::setWordCount(TheWordCount);
+    Indices.resize(TheWordCount - 4);
+  }
+  _SPIRV_DEF_ENCDEC4(Type, Id, Composite, Indices)
+  // ToDo: validate the result type is consistent with the base type and indices
+  // need to trace through the base type for struct types
+  void validate() const {
+    SPIRVInstruction::validate();
+    assert(getValueType(Composite)->isTypeArray() ||
+           getValueType(Composite)->isTypeStruct() ||
+           getValueType(Composite)->isTypeVector());
+  }
+  SPIRVId Composite;
+  std::vector<SPIRVWord> Indices;
+};
+
+class SPIRVCompositeInsert : public SPIRVInstruction {
+public:
+  const static Op OC = OpCompositeInsert;
+  const static SPIRVWord FixedWordCount = 5;
+  // Complete constructor
+  SPIRVCompositeInsert(SPIRVId TheId, SPIRVValue *TheObject,
+                       SPIRVValue *TheComposite,
+                       const std::vector<SPIRVWord> &TheIndices,
+                       SPIRVBasicBlock *TheBB)
+      : SPIRVInstruction(TheIndices.size() + FixedWordCount, OC,
+                         TheComposite->getType(), TheId, TheBB),
+        Object(TheObject->getId()), Composite(TheComposite->getId()),
+        Indices(TheIndices) {
+    validate();
+    assert(TheBB && "Invalid BB");
+  }
+  // Incomplete constructor
+  SPIRVCompositeInsert()
+      : SPIRVInstruction(OC), Object(SPIRVID_INVALID),
+        Composite(SPIRVID_INVALID) {}
+
+  SPIRVValue *getObject() { return getValue(Object); }
+  SPIRVValue *getComposite() { return getValue(Composite); }
+  const std::vector<SPIRVWord> &getIndices() const { return Indices; }
+
+protected:
+  void setWordCount(SPIRVWord TheWordCount) {
+    SPIRVEntry::setWordCount(TheWordCount);
+    Indices.resize(TheWordCount - FixedWordCount);
+  }
+  _SPIRV_DEF_ENCDEC5(Type, Id, Object, Composite, Indices)
+  // ToDo: validate the object type is consistent with the base type and indices
+  // need to trace through the base type for struct types
+  void validate() const {
+    SPIRVInstruction::validate();
+    assert(OpCode == OC);
+    assert(WordCount == Indices.size() + FixedWordCount);
+    assert(getValueType(Composite)->isTypeArray() ||
+           getValueType(Composite)->isTypeStruct() ||
+           getValueType(Composite)->isTypeVector());
+    assert(Type == getValueType(Composite));
+  }
+  SPIRVId Object;
+  SPIRVId Composite;
+  std::vector<SPIRVWord> Indices;
+};
+
+class SPIRVCopyObject : public SPIRVInstruction {
+public:
+  const static Op OC = OpCopyObject;
+
+  // Complete constructor
+  SPIRVCopyObject(SPIRVType *TheType, SPIRVId TheId, SPIRVValue *TheOperand,
+                  SPIRVBasicBlock *TheBB)
+      : SPIRVInstruction(4, OC, TheType, TheId, TheBB),
+        Operand(TheOperand->getId()) {
+    validate();
+    assert(TheBB && "Invalid BB");
+  }
+  // Incomplete constructor
+  SPIRVCopyObject() : SPIRVInstruction(OC), Operand(SPIRVID_INVALID) {}
+
+  SPIRVValue *getOperand() { return getValue(Operand); }
+
+protected:
+  _SPIRV_DEF_ENCDEC3(Type, Id, Operand)
+
+  void validate() const { SPIRVInstruction::validate(); }
+  SPIRVId Operand;
+};
+
+class SPIRVCopyMemory : public SPIRVInstruction, public SPIRVMemoryAccess {
+public:
+  const static Op OC = OpCopyMemory;
+  const static SPIRVWord FixedWords = 3;
+  // Complete constructor
+  SPIRVCopyMemory(SPIRVValue *TheTarget, SPIRVValue *TheSource,
+                  const std::vector<SPIRVWord> &TheMemoryAccess,
+                  SPIRVBasicBlock *TheBB)
+      : SPIRVInstruction(FixedWords + TheMemoryAccess.size(), OC, TheBB),
+        SPIRVMemoryAccess(TheMemoryAccess), MemoryAccess(TheMemoryAccess),
+        Target(TheTarget->getId()), Source(TheSource->getId()) {
+    validate();
+    assert(TheBB && "Invalid BB");
+  }
+
+  // Incomplete constructor
+  SPIRVCopyMemory()
+      : SPIRVInstruction(OC), SPIRVMemoryAccess(), Target(SPIRVID_INVALID),
+        Source(SPIRVID_INVALID) {
+    setHasNoId();
+    setHasNoType();
+  }
+
+  SPIRVValue *getSource() { return getValue(Source); }
+  SPIRVValue *getTarget() { return getValue(Target); }
+
+protected:
+  void setWordCount(SPIRVWord TheWordCount) {
+    SPIRVEntry::setWordCount(TheWordCount);
+    MemoryAccess.resize(TheWordCount - FixedWords);
+  }
+
+  void encode(spv_ostream &O) const {
+    getEncoder(O) << Target << Source << MemoryAccess;
+  }
+
+  void decode(std::istream &I) {
+    getDecoder(I) >> Target >> Source >> MemoryAccess;
+    MemoryAccessUpdate(MemoryAccess);
+  }
+
+  void validate() const {
+    assert((getValueType(Id) == getValueType(Source)) && "Inconsistent type");
+    assert(getValueType(Id)->isTypePointer() && "Invalid type");
+    assert(!(getValueType(Id)->getPointerElementType()->isTypeVoid()) &&
+           "Invalid type");
+    SPIRVInstruction::validate();
+  }
+
+  std::vector<SPIRVWord> MemoryAccess;
+  SPIRVId Target;
+  SPIRVId Source;
+};
+
+class SPIRVCopyMemorySized : public SPIRVInstruction, public SPIRVMemoryAccess {
+public:
+  const static Op OC = OpCopyMemorySized;
+  const static SPIRVWord FixedWords = 4;
+  // Complete constructor
+  SPIRVCopyMemorySized(SPIRVValue *TheTarget, SPIRVValue *TheSource,
+                       SPIRVValue *TheSize,
+                       const std::vector<SPIRVWord> &TheMemoryAccess,
+                       SPIRVBasicBlock *TheBB)
+      : SPIRVInstruction(FixedWords + TheMemoryAccess.size(), OC, TheBB),
+        SPIRVMemoryAccess(TheMemoryAccess), MemoryAccess(TheMemoryAccess),
+        Target(TheTarget->getId()), Source(TheSource->getId()),
+        Size(TheSize->getId()) {
+    validate();
+    assert(TheBB && "Invalid BB");
+  }
+  // Incomplete constructor
+  SPIRVCopyMemorySized()
+      : SPIRVInstruction(OC), SPIRVMemoryAccess(), Target(SPIRVID_INVALID),
+        Source(SPIRVID_INVALID), Size(0) {
+    setHasNoId();
+    setHasNoType();
+  }
+
+  SPIRVValue *getSource() { return getValue(Source); }
+  SPIRVValue *getTarget() { return getValue(Target); }
+  SPIRVValue *getSize() { return getValue(Size); }
+
+protected:
+  void setWordCount(SPIRVWord TheWordCount) {
+    SPIRVEntry::setWordCount(TheWordCount);
+    MemoryAccess.resize(TheWordCount - FixedWords);
+  }
+
+  void encode(spv_ostream &O) const {
+    getEncoder(O) << Target << Source << Size << MemoryAccess;
+  }
+
+  void decode(std::istream &I) {
+    getDecoder(I) >> Target >> Source >> Size >> MemoryAccess;
+    MemoryAccessUpdate(MemoryAccess);
+  }
+
+  void validate() const { SPIRVInstruction::validate(); }
+
+  std::vector<SPIRVWord> MemoryAccess;
+  SPIRVId Target;
+  SPIRVId Source;
+  SPIRVId Size;
+};
+
+class SPIRVVectorExtractDynamic : public SPIRVInstruction {
+public:
+  const static Op OC = OpVectorExtractDynamic;
+  // Complete constructor
+  SPIRVVectorExtractDynamic(SPIRVId TheId, SPIRVValue *TheVector,
+                            SPIRVValue *TheIndex, SPIRVBasicBlock *TheBB)
+      : SPIRVInstruction(5, OC, TheVector->getType()->getVectorComponentType(),
+                         TheId, TheBB),
+        VectorId(TheVector->getId()), IndexId(TheIndex->getId()) {
+    validate();
+    assert(TheBB && "Invalid BB");
+  }
+  // Incomplete constructor
+  SPIRVVectorExtractDynamic()
+      : SPIRVInstruction(OC), VectorId(SPIRVID_INVALID),
+        IndexId(SPIRVID_INVALID) {}
+
+  SPIRVValue *getVector() { return getValue(VectorId); }
+  SPIRVValue *getIndex() const { return getValue(IndexId); }
+
+protected:
+  _SPIRV_DEF_ENCDEC4(Type, Id, VectorId, IndexId)
+  void validate() const {
+    SPIRVInstruction::validate();
+    if (getValue(VectorId)->isForward())
+      return;
+    assert(getValueType(VectorId)->isTypeVector());
+  }
+  SPIRVId VectorId;
+  SPIRVId IndexId;
+};
+
+class SPIRVVectorInsertDynamic : public SPIRVInstruction {
+public:
+  const static Op OC = OpVectorInsertDynamic;
+  // Complete constructor
+  SPIRVVectorInsertDynamic(SPIRVId TheId, SPIRVValue *TheVector,
+                           SPIRVValue *TheComponent, SPIRVValue *TheIndex,
+                           SPIRVBasicBlock *TheBB)
+      : SPIRVInstruction(6, OC, TheVector->getType()->getVectorComponentType(),
+                         TheId, TheBB),
+        VectorId(TheVector->getId()), IndexId(TheIndex->getId()),
+        ComponentId(TheComponent->getId()) {
+    validate();
+    assert(TheBB && "Invalid BB");
+  }
+  // Incomplete constructor
+  SPIRVVectorInsertDynamic()
+      : SPIRVInstruction(OC), VectorId(SPIRVID_INVALID),
+        IndexId(SPIRVID_INVALID), ComponentId(SPIRVID_INVALID) {}
+
+  SPIRVValue *getVector() { return getValue(VectorId); }
+  SPIRVValue *getIndex() const { return getValue(IndexId); }
+  SPIRVValue *getComponent() { return getValue(ComponentId); }
+
+protected:
+  _SPIRV_DEF_ENCDEC5(Type, Id, VectorId, ComponentId, IndexId)
+  void validate() const {
+    SPIRVInstruction::validate();
+    if (getValue(VectorId)->isForward())
+      return;
+    assert(getValueType(VectorId)->isTypeVector());
+  }
+  SPIRVId VectorId;
+  SPIRVId IndexId;
+  SPIRVId ComponentId;
+};
+
+class SPIRVVectorShuffle : public SPIRVInstruction {
+public:
+  const static Op OC = OpVectorShuffle;
+  const static SPIRVWord FixedWordCount = 5;
+  // Complete constructor
+  SPIRVVectorShuffle(SPIRVId TheId, SPIRVType *TheType, SPIRVValue *TheVector1,
+                     SPIRVValue *TheVector2,
+                     const std::vector<SPIRVWord> &TheComponents,
+                     SPIRVBasicBlock *TheBB)
+      : SPIRVInstruction(TheComponents.size() + FixedWordCount, OC, TheType,
+                         TheId, TheBB),
+        Vector1(TheVector1->getId()), Vector2(TheVector2->getId()),
+        Components(TheComponents) {
+    validate();
+    assert(TheBB && "Invalid BB");
+  }
+  // Incomplete constructor
+  SPIRVVectorShuffle()
+      : SPIRVInstruction(OC), Vector1(SPIRVID_INVALID),
+        Vector2(SPIRVID_INVALID) {}
+
+  SPIRVValue *getVector1() { return getValue(Vector1); }
+  SPIRVValue *getVector2() { return getValue(Vector2); }
+  const std::vector<SPIRVWord> &getComponents() const { return Components; }
+
+protected:
+  void setWordCount(SPIRVWord TheWordCount) {
+    SPIRVEntry::setWordCount(TheWordCount);
+    Components.resize(TheWordCount - FixedWordCount);
+  }
+  _SPIRV_DEF_ENCDEC5(Type, Id, Vector1, Vector2, Components)
+  void validate() const {
+    SPIRVInstruction::validate();
+    assert(OpCode == OC);
+    assert(WordCount == Components.size() + FixedWordCount);
+    assert(Type->isTypeVector());
+    assert(Type->getVectorComponentType() ==
+           getValueType(Vector1)->getVectorComponentType());
+    if (getValue(Vector1)->isForward() || getValue(Vector2)->isForward())
+      return;
+    assert(getValueType(Vector1) == getValueType(Vector2));
+    size_t CompCount = Type->getVectorComponentCount();
+    assert(Components.size() == CompCount);
+    assert(Components.size() > 1);
+  }
+  SPIRVId Vector1;
+  SPIRVId Vector2;
+  std::vector<SPIRVWord> Components;
+};
+
+class SPIRVControlBarrier : public SPIRVInstruction {
+public:
+  static const Op OC = OpControlBarrier;
+  // Complete constructor
+  SPIRVControlBarrier(SPIRVValue *TheScope, SPIRVValue *TheMemScope,
+                      SPIRVValue *TheMemSema, SPIRVBasicBlock *TheBB)
+      : SPIRVInstruction(4, OC, TheBB), ExecScope(TheScope->getId()),
+        MemScope(TheMemScope->getId()), MemSema(TheMemSema->getId()) {
+    validate();
+    assert(TheBB && "Invalid BB");
+  }
+  // Incomplete constructor
+  SPIRVControlBarrier() : SPIRVInstruction(OC), ExecScope(ScopeInvocation) {
+    setHasNoId();
+    setHasNoType();
+  }
+  void setWordCount(SPIRVWord TheWordCount) {
+    SPIRVEntry::setWordCount(TheWordCount);
+  }
+  SPIRVValue *getExecScope() const { return getValue(ExecScope); }
+  SPIRVValue *getMemScope() const { return getValue(MemScope); }
+  SPIRVValue *getMemSemantic() const { return getValue(MemSema); }
+  std::vector<SPIRVValue *> getOperands() {
+    std::vector<SPIRVId> Operands;
+    Operands.push_back(ExecScope);
+    Operands.push_back(MemScope);
+    Operands.push_back(MemSema);
+    return getValues(Operands);
+  }
+
+protected:
+  _SPIRV_DEF_ENCDEC3(ExecScope, MemScope, MemSema)
+  void validate() const {
+    assert(OpCode == OC);
+    assert(WordCount == 4);
+    SPIRVInstruction::validate();
+  }
+  SPIRVId ExecScope;
+  SPIRVId MemScope;
+  SPIRVId MemSema;
+};
+
+class SPIRVGroupAsyncCopy : public SPIRVInstruction {
+public:
+  static const Op OC = OpGroupAsyncCopy;
+  static const SPIRVWord WC = 9;
+  // Complete constructor
+  SPIRVGroupAsyncCopy(SPIRVValue *TheScope, SPIRVId TheId, SPIRVValue *TheDest,
+                      SPIRVValue *TheSrc, SPIRVValue *TheNumElems,
+                      SPIRVValue *TheStride, SPIRVValue *TheEvent,
+                      SPIRVBasicBlock *TheBB)
+      : SPIRVInstruction(WC, OC, TheEvent->getType(), TheId, TheBB),
+        ExecScope(TheScope->getId()), Destination(TheDest->getId()),
+        Source(TheSrc->getId()), NumElements(TheNumElems->getId()),
+        Stride(TheStride->getId()), Event(TheEvent->getId()) {
+    validate();
+    assert(TheBB && "Invalid BB");
+  }
+  // Incomplete constructor
+  SPIRVGroupAsyncCopy()
+      : SPIRVInstruction(OC), ExecScope(SPIRVID_INVALID),
+        Destination(SPIRVID_INVALID), Source(SPIRVID_INVALID),
+        NumElements(SPIRVID_INVALID), Stride(SPIRVID_INVALID),
+        Event(SPIRVID_INVALID) {}
+  SPIRVValue *getExecScope() const { return getValue(ExecScope); }
+  SPIRVValue *getDestination() const { return getValue(Destination); }
+  SPIRVValue *getSource() const { return getValue(Source); }
+  SPIRVValue *getNumElements() const { return getValue(NumElements); }
+  SPIRVValue *getStride() const { return getValue(Stride); }
+  SPIRVValue *getEvent() const { return getValue(Event); }
+  std::vector<SPIRVValue *> getOperands() override {
+    std::vector<SPIRVId> Operands;
+    Operands.push_back(Destination);
+    Operands.push_back(Source);
+    Operands.push_back(NumElements);
+    Operands.push_back(Stride);
+    Operands.push_back(Event);
+    return getValues(Operands);
+  }
+
+protected:
+  _SPIRV_DEF_ENCDEC8(Type, Id, ExecScope, Destination, Source, NumElements,
+                     Stride, Event)
+  void validate() const {
+    assert(OpCode == OC);
+    assert(WordCount == WC);
+    SPIRVInstruction::validate();
+  }
+  SPIRVId ExecScope;
+  SPIRVId Destination;
+  SPIRVId Source;
+  SPIRVId NumElements;
+  SPIRVId Stride;
+  SPIRVId Event;
+};
+
+enum SPIRVOpKind { SPIRVOPK_Id, SPIRVOPK_Literal, SPIRVOPK_Count };
+
+class SPIRVDevEnqInstBase : public SPIRVInstTemplateBase {
+public:
+  SPIRVCapVec getRequiriedCapability() const {
+    return getVec(CapabilityDeviceEnqueue);
+  }
+};
+
+#define _SPIRV_OP(x, ...)                                                      \
+  typedef SPIRVInstTemplate<SPIRVDevEnqInstBase, Op##x, __VA_ARGS__> SPIRV##x;
+// CL 2.0 enqueue kernel builtins
+_SPIRV_OP(EnqueueMarker, true, 7)
+_SPIRV_OP(EnqueueKernel, true, 13, true)
+_SPIRV_OP(GetKernelNDrangeSubGroupCount, true, 8)
+_SPIRV_OP(GetKernelNDrangeMaxSubGroupSize, true, 8)
+_SPIRV_OP(GetKernelWorkGroupSize, true, 7)
+_SPIRV_OP(GetKernelPreferredWorkGroupSizeMultiple, true, 7)
+_SPIRV_OP(RetainEvent, false, 2)
+_SPIRV_OP(ReleaseEvent, false, 2)
+_SPIRV_OP(CreateUserEvent, true, 3)
+_SPIRV_OP(IsValidEvent, true, 4)
+_SPIRV_OP(SetUserEventStatus, false, 3)
+_SPIRV_OP(CaptureEventProfilingInfo, false, 4)
+_SPIRV_OP(GetDefaultQueue, true, 3)
+_SPIRV_OP(BuildNDRange, true, 6)
+#undef _SPIRV_OP
+
+class SPIRVPipeInstBase : public SPIRVInstTemplateBase {
+public:
+  SPIRVCapVec getRequiriedCapability() const { return getVec(CapabilityPipes); }
+};
+
+#define _SPIRV_OP(x, ...)                                                      \
+  typedef SPIRVInstTemplate<SPIRVPipeInstBase, Op##x, __VA_ARGS__> SPIRV##x;
+// CL 2.0 pipe builtins
+_SPIRV_OP(ReadPipe, true, 7)
+_SPIRV_OP(WritePipe, true, 7)
+_SPIRV_OP(ReservedReadPipe, true, 9)
+_SPIRV_OP(ReservedWritePipe, true, 9)
+_SPIRV_OP(ReserveReadPipePackets, true, 7)
+_SPIRV_OP(ReserveWritePipePackets, true, 7)
+_SPIRV_OP(CommitReadPipe, false, 5)
+_SPIRV_OP(CommitWritePipe, false, 5)
+_SPIRV_OP(IsValidReserveId, true, 4)
+_SPIRV_OP(GetNumPipePackets, true, 6)
+_SPIRV_OP(GetMaxPipePackets, true, 6)
+#undef _SPIRV_OP
+
+class SPIRVPipeStorageInstBase : public SPIRVInstTemplateBase {
+public:
+  SPIRVCapVec getRequiriedCapability() const {
+    return getVec(CapabilityPipeStorage, CapabilityPipes);
+  }
+};
+
+#define _SPIRV_OP(x, ...)                                                      \
+  typedef SPIRVInstTemplate<SPIRVPipeStorageInstBase, Op##x, __VA_ARGS__>      \
+      SPIRV##x;
+
+_SPIRV_OP(CreatePipeFromPipeStorage, true, 4)
+#undef _SPIRV_OP
+
+class SPIRVGroupInstBase : public SPIRVInstTemplateBase {
+public:
+  SPIRVCapVec getRequiriedCapability() const {
+    return getVec(CapabilityGroups);
+  }
+};
+
+#define _SPIRV_OP(x, ...)                                                      \
+  typedef SPIRVInstTemplate<SPIRVGroupInstBase, Op##x, __VA_ARGS__> SPIRV##x;
+// Group instructions
+_SPIRV_OP(GroupWaitEvents, false, 4)
+_SPIRV_OP(GroupAll, true, 5)
+_SPIRV_OP(GroupAny, true, 5)
+_SPIRV_OP(GroupBroadcast, true, 6)
+_SPIRV_OP(GroupIAdd, true, 6, false, 1)
+_SPIRV_OP(GroupFAdd, true, 6, false, 1)
+_SPIRV_OP(GroupFMin, true, 6, false, 1)
+_SPIRV_OP(GroupUMin, true, 6, false, 1)
+_SPIRV_OP(GroupSMin, true, 6, false, 1)
+_SPIRV_OP(GroupFMax, true, 6, false, 1)
+_SPIRV_OP(GroupUMax, true, 6, false, 1)
+_SPIRV_OP(GroupSMax, true, 6, false, 1)
+_SPIRV_OP(GroupReserveReadPipePackets, true, 8)
+_SPIRV_OP(GroupReserveWritePipePackets, true, 8)
+_SPIRV_OP(GroupCommitReadPipe, false, 6)
+_SPIRV_OP(GroupCommitWritePipe, false, 6)
+#undef _SPIRV_OP
+
+class SPIRVAtomicInstBase : public SPIRVInstTemplateBase {
+public:
+  SPIRVCapVec getRequiriedCapability() const {
+    return getVec(CapabilityInt64Atomics);
+  }
+};
+
+#define _SPIRV_OP(x, ...)                                                      \
+  typedef SPIRVInstTemplate<SPIRVAtomicInstBase, Op##x, __VA_ARGS__> SPIRV##x;
+// Atomic builtins
+_SPIRV_OP(AtomicFlagTestAndSet, true, 6)
+_SPIRV_OP(AtomicFlagClear, false, 4)
+_SPIRV_OP(AtomicLoad, true, 6)
+_SPIRV_OP(AtomicStore, false, 5)
+_SPIRV_OP(AtomicExchange, true, 7)
+_SPIRV_OP(AtomicCompareExchange, true, 9)
+_SPIRV_OP(AtomicCompareExchangeWeak, true, 9)
+_SPIRV_OP(AtomicIIncrement, true, 6)
+_SPIRV_OP(AtomicIDecrement, true, 6)
+_SPIRV_OP(AtomicIAdd, true, 7)
+_SPIRV_OP(AtomicISub, true, 7)
+_SPIRV_OP(AtomicUMin, true, 7)
+_SPIRV_OP(AtomicUMax, true, 7)
+_SPIRV_OP(AtomicSMin, true, 7)
+_SPIRV_OP(AtomicSMax, true, 7)
+_SPIRV_OP(AtomicAnd, true, 7)
+_SPIRV_OP(AtomicOr, true, 7)
+_SPIRV_OP(AtomicXor, true, 7)
+_SPIRV_OP(MemoryBarrier, false, 3)
+#undef _SPIRV_OP
+
+class SPIRVImageInstBase : public SPIRVInstTemplateBase {
+public:
+  SPIRVCapVec getRequiriedCapability() const {
+    return getVec(CapabilityImageBasic);
+  }
+};
+
+#define _SPIRV_OP(x, ...)                                                      \
+  typedef SPIRVInstTemplate<SPIRVImageInstBase, Op##x, __VA_ARGS__> SPIRV##x;
+// Image instructions
+_SPIRV_OP(SampledImage, true, 5)
+_SPIRV_OP(ImageSampleImplicitLod, true, 5, true)
+_SPIRV_OP(ImageSampleExplicitLod, true, 7, true, 2)
+_SPIRV_OP(ImageRead, true, 5, true, 2)
+_SPIRV_OP(ImageWrite, false, 4, true, 3)
+_SPIRV_OP(ImageQueryFormat, true, 4)
+_SPIRV_OP(ImageQueryOrder, true, 4)
+_SPIRV_OP(ImageQuerySizeLod, true, 5)
+_SPIRV_OP(ImageQuerySize, true, 4)
+_SPIRV_OP(ImageQueryLod, true, 5)
+_SPIRV_OP(ImageQueryLevels, true, 4)
+_SPIRV_OP(ImageQuerySamples, true, 4)
+#undef _SPIRV_OP
+
+#define _SPIRV_OP(x, ...)                                                      \
+  typedef SPIRVInstTemplate<SPIRVInstTemplateBase, Op##x, __VA_ARGS__> SPIRV##x;
+// Other instructions
+_SPIRV_OP(SpecConstantOp, true, 4, true, 0)
+_SPIRV_OP(GenericPtrMemSemantics, true, 4, false)
+_SPIRV_OP(GenericCastToPtrExplicit, true, 5, false, 1)
+#undef _SPIRV_OP
+
+SPIRVSpecConstantOp *createSpecConstantOpInst(SPIRVInstruction *Inst);
+SPIRVInstruction *createInstFromSpecConstantOp(SPIRVSpecConstantOp *C);
+}
+
+#endif // SPIRVINSTRUCTION_HPP_
diff --git a/lib/SPIRV/libSPIRV/SPIRVIsValidEnum.h b/lib/SPIRV/libSPIRV/SPIRVIsValidEnum.h
new file mode 100644
index 0000000..d1a24ba
--- /dev/null
+++ b/lib/SPIRV/libSPIRV/SPIRVIsValidEnum.h
@@ -0,0 +1,963 @@
+//===- SPIRVIsValidEnum.h - SPIR-V isValid enums ----------------*- C++ -*-===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+/// \file
+///
+/// This file defines SPIR-V isValid enums.
+///
+//===----------------------------------------------------------------------===//
+// WARNING:
+//
+// This file has been generated using `tools/spirv-tool/gen_spirv.bash` and
+// should not be modified manually. If the file needs to be updated, edit the
+// script and any other source file instead, before re-generating this file.
+//===----------------------------------------------------------------------===//
+
+#ifndef SPIRVISVALIDENUM_H_
+#define SPIRVISVALIDENUM_H_
+
+#include "spirv.hpp"
+#include "SPIRVEnum.h"
+
+#pragma clang diagnostic push
+#pragma clang diagnostic ignored "-Wcovered-switch-default"
+
+using namespace spv;
+
+namespace SPIRV {
+
+inline bool isValid(spv::SourceLanguage V) {
+  switch (V) {
+  case SourceLanguageUnknown:
+  case SourceLanguageESSL:
+  case SourceLanguageGLSL:
+  case SourceLanguageOpenCL_C:
+  case SourceLanguageOpenCL_CPP:
+    return true;
+  default:
+    return false;
+  }
+}
+
+inline bool isValid(spv::ExecutionModel V) {
+  switch (V) {
+  case ExecutionModelVertex:
+  case ExecutionModelTessellationControl:
+  case ExecutionModelTessellationEvaluation:
+  case ExecutionModelGeometry:
+  case ExecutionModelFragment:
+  case ExecutionModelGLCompute:
+  case ExecutionModelKernel:
+    return true;
+  default:
+    return false;
+  }
+}
+
+inline bool isValid(spv::AddressingModel V) {
+  switch (V) {
+  case AddressingModelLogical:
+  case AddressingModelPhysical32:
+  case AddressingModelPhysical64:
+    return true;
+  default:
+    return false;
+  }
+}
+
+inline bool isValid(spv::MemoryModel V) {
+  switch (V) {
+  case MemoryModelSimple:
+  case MemoryModelGLSL450:
+  case MemoryModelOpenCL:
+    return true;
+  default:
+    return false;
+  }
+}
+
+inline bool isValid(spv::ExecutionMode V) {
+  switch (V) {
+  case ExecutionModeInvocations:
+  case ExecutionModeSpacingEqual:
+  case ExecutionModeSpacingFractionalEven:
+  case ExecutionModeSpacingFractionalOdd:
+  case ExecutionModeVertexOrderCw:
+  case ExecutionModeVertexOrderCcw:
+  case ExecutionModePixelCenterInteger:
+  case ExecutionModeOriginUpperLeft:
+  case ExecutionModeOriginLowerLeft:
+  case ExecutionModeEarlyFragmentTests:
+  case ExecutionModePointMode:
+  case ExecutionModeXfb:
+  case ExecutionModeDepthReplacing:
+  case ExecutionModeDepthGreater:
+  case ExecutionModeDepthLess:
+  case ExecutionModeDepthUnchanged:
+  case ExecutionModeLocalSize:
+  case ExecutionModeLocalSizeHint:
+  case ExecutionModeInputPoints:
+  case ExecutionModeInputLines:
+  case ExecutionModeInputLinesAdjacency:
+  case ExecutionModeTriangles:
+  case ExecutionModeInputTrianglesAdjacency:
+  case ExecutionModeQuads:
+  case ExecutionModeIsolines:
+  case ExecutionModeOutputVertices:
+  case ExecutionModeOutputPoints:
+  case ExecutionModeOutputLineStrip:
+  case ExecutionModeOutputTriangleStrip:
+  case ExecutionModeVecTypeHint:
+  case ExecutionModeContractionOff:
+  case ExecutionModeInitializer:
+  case ExecutionModeFinalizer:
+  case ExecutionModeSubgroupSize:
+  case ExecutionModeSubgroupsPerWorkgroup:
+    return true;
+  default:
+    return false;
+  }
+}
+
+inline bool isValid(spv::StorageClass V) {
+  switch (V) {
+  case StorageClassUniformConstant:
+  case StorageClassInput:
+  case StorageClassUniform:
+  case StorageClassOutput:
+  case StorageClassWorkgroup:
+  case StorageClassCrossWorkgroup:
+  case StorageClassPrivate:
+  case StorageClassFunction:
+  case StorageClassGeneric:
+  case StorageClassPushConstant:
+  case StorageClassAtomicCounter:
+  case StorageClassImage:
+    return true;
+  default:
+    return false;
+  }
+}
+
+inline bool isValid(spv::Dim V) {
+  switch (V) {
+  case Dim1D:
+  case Dim2D:
+  case Dim3D:
+  case DimCube:
+  case DimRect:
+  case DimBuffer:
+  case DimSubpassData:
+    return true;
+  default:
+    return false;
+  }
+}
+
+inline bool isValid(spv::SamplerAddressingMode V) {
+  switch (V) {
+  case SamplerAddressingModeNone:
+  case SamplerAddressingModeClampToEdge:
+  case SamplerAddressingModeClamp:
+  case SamplerAddressingModeRepeat:
+  case SamplerAddressingModeRepeatMirrored:
+    return true;
+  default:
+    return false;
+  }
+}
+
+inline bool isValid(spv::SamplerFilterMode V) {
+  switch (V) {
+  case SamplerFilterModeNearest:
+  case SamplerFilterModeLinear:
+    return true;
+  default:
+    return false;
+  }
+}
+
+inline bool isValid(spv::ImageFormat V) {
+  switch (V) {
+  case ImageFormatUnknown:
+  case ImageFormatRgba32f:
+  case ImageFormatRgba16f:
+  case ImageFormatR32f:
+  case ImageFormatRgba8:
+  case ImageFormatRgba8Snorm:
+  case ImageFormatRg32f:
+  case ImageFormatRg16f:
+  case ImageFormatR11fG11fB10f:
+  case ImageFormatR16f:
+  case ImageFormatRgba16:
+  case ImageFormatRgb10A2:
+  case ImageFormatRg16:
+  case ImageFormatRg8:
+  case ImageFormatR16:
+  case ImageFormatR8:
+  case ImageFormatRgba16Snorm:
+  case ImageFormatRg16Snorm:
+  case ImageFormatRg8Snorm:
+  case ImageFormatR16Snorm:
+  case ImageFormatR8Snorm:
+  case ImageFormatRgba32i:
+  case ImageFormatRgba16i:
+  case ImageFormatRgba8i:
+  case ImageFormatR32i:
+  case ImageFormatRg32i:
+  case ImageFormatRg16i:
+  case ImageFormatRg8i:
+  case ImageFormatR16i:
+  case ImageFormatR8i:
+  case ImageFormatRgba32ui:
+  case ImageFormatRgba16ui:
+  case ImageFormatRgba8ui:
+  case ImageFormatR32ui:
+  case ImageFormatRgb10a2ui:
+  case ImageFormatRg32ui:
+  case ImageFormatRg16ui:
+  case ImageFormatRg8ui:
+  case ImageFormatR16ui:
+  case ImageFormatR8ui:
+    return true;
+  default:
+    return false;
+  }
+}
+
+inline bool isValid(spv::ImageChannelOrder V) {
+  switch (V) {
+  case ImageChannelOrderR:
+  case ImageChannelOrderA:
+  case ImageChannelOrderRG:
+  case ImageChannelOrderRA:
+  case ImageChannelOrderRGB:
+  case ImageChannelOrderRGBA:
+  case ImageChannelOrderBGRA:
+  case ImageChannelOrderARGB:
+  case ImageChannelOrderIntensity:
+  case ImageChannelOrderLuminance:
+  case ImageChannelOrderRx:
+  case ImageChannelOrderRGx:
+  case ImageChannelOrderRGBx:
+  case ImageChannelOrderDepth:
+  case ImageChannelOrderDepthStencil:
+  case ImageChannelOrderABGR:
+    return true;
+  default:
+    return false;
+  }
+}
+
+inline bool isValid(spv::ImageChannelDataType V) {
+  switch (V) {
+  case ImageChannelDataTypeSnormInt8:
+  case ImageChannelDataTypeSnormInt16:
+  case ImageChannelDataTypeUnormInt8:
+  case ImageChannelDataTypeUnormInt16:
+  case ImageChannelDataTypeUnormShort565:
+  case ImageChannelDataTypeUnormShort555:
+  case ImageChannelDataTypeUnormInt101010:
+  case ImageChannelDataTypeSignedInt8:
+  case ImageChannelDataTypeSignedInt16:
+  case ImageChannelDataTypeSignedInt32:
+  case ImageChannelDataTypeUnsignedInt8:
+  case ImageChannelDataTypeUnsignedInt16:
+  case ImageChannelDataTypeUnsignedInt32:
+  case ImageChannelDataTypeHalfFloat:
+  case ImageChannelDataTypeFloat:
+  case ImageChannelDataTypeUnormInt24:
+  case ImageChannelDataTypeUnormInt101010_2:
+    return true;
+  default:
+    return false;
+  }
+}
+
+inline bool isValid(spv::FPRoundingMode V) {
+  switch (V) {
+  case FPRoundingModeRTE:
+  case FPRoundingModeRTZ:
+  case FPRoundingModeRTP:
+  case FPRoundingModeRTN:
+    return true;
+  default:
+    return false;
+  }
+}
+
+inline bool isValid(spv::LinkageType V) {
+  switch (V) {
+  case LinkageTypeExport:
+  case LinkageTypeImport:
+  case LinkageTypeInternal:
+    return true;
+  default:
+    return false;
+  }
+}
+
+inline bool isValid(spv::AccessQualifier V) {
+  switch (V) {
+  case AccessQualifierReadOnly:
+  case AccessQualifierWriteOnly:
+  case AccessQualifierReadWrite:
+    return true;
+  default:
+    return false;
+  }
+}
+
+inline bool isValid(spv::FunctionParameterAttribute V) {
+  switch (V) {
+  case FunctionParameterAttributeZext:
+  case FunctionParameterAttributeSext:
+  case FunctionParameterAttributeByVal:
+  case FunctionParameterAttributeSret:
+  case FunctionParameterAttributeNoAlias:
+  case FunctionParameterAttributeNoCapture:
+  case FunctionParameterAttributeNoWrite:
+  case FunctionParameterAttributeNoReadWrite:
+    return true;
+  default:
+    return false;
+  }
+}
+
+inline bool isValid(spv::Decoration V) {
+  switch (V) {
+  case DecorationRelaxedPrecision:
+  case DecorationSpecId:
+  case DecorationBlock:
+  case DecorationBufferBlock:
+  case DecorationRowMajor:
+  case DecorationColMajor:
+  case DecorationArrayStride:
+  case DecorationMatrixStride:
+  case DecorationGLSLShared:
+  case DecorationGLSLPacked:
+  case DecorationCPacked:
+  case DecorationBuiltIn:
+  case DecorationNoPerspective:
+  case DecorationFlat:
+  case DecorationPatch:
+  case DecorationCentroid:
+  case DecorationSample:
+  case DecorationInvariant:
+  case DecorationRestrict:
+  case DecorationAliased:
+  case DecorationVolatile:
+  case DecorationConstant:
+  case DecorationCoherent:
+  case DecorationNonWritable:
+  case DecorationNonReadable:
+  case DecorationUniform:
+  case DecorationSaturatedConversion:
+  case DecorationStream:
+  case DecorationLocation:
+  case DecorationComponent:
+  case DecorationIndex:
+  case DecorationBinding:
+  case DecorationDescriptorSet:
+  case DecorationOffset:
+  case DecorationXfbBuffer:
+  case DecorationXfbStride:
+  case DecorationFuncParamAttr:
+  case DecorationFPRoundingMode:
+  case DecorationFPFastMathMode:
+  case DecorationLinkageAttributes:
+  case DecorationNoContraction:
+  case DecorationInputAttachmentIndex:
+  case DecorationAlignment:
+  case DecorationMaxByteOffset:
+    return true;
+  default:
+    return false;
+  }
+}
+
+inline bool isValid(spv::BuiltIn V) {
+  switch (V) {
+  case BuiltInPosition:
+  case BuiltInPointSize:
+  case BuiltInClipDistance:
+  case BuiltInCullDistance:
+  case BuiltInVertexId:
+  case BuiltInInstanceId:
+  case BuiltInPrimitiveId:
+  case BuiltInInvocationId:
+  case BuiltInLayer:
+  case BuiltInViewportIndex:
+  case BuiltInTessLevelOuter:
+  case BuiltInTessLevelInner:
+  case BuiltInTessCoord:
+  case BuiltInPatchVertices:
+  case BuiltInFragCoord:
+  case BuiltInPointCoord:
+  case BuiltInFrontFacing:
+  case BuiltInSampleId:
+  case BuiltInSamplePosition:
+  case BuiltInSampleMask:
+  case BuiltInFragDepth:
+  case BuiltInHelperInvocation:
+  case BuiltInNumWorkgroups:
+  case BuiltInWorkgroupSize:
+  case BuiltInWorkgroupId:
+  case BuiltInLocalInvocationId:
+  case BuiltInGlobalInvocationId:
+  case BuiltInLocalInvocationIndex:
+  case BuiltInWorkDim:
+  case BuiltInGlobalSize:
+  case BuiltInEnqueuedWorkgroupSize:
+  case BuiltInGlobalOffset:
+  case BuiltInGlobalLinearId:
+  case BuiltInSubgroupSize:
+  case BuiltInSubgroupMaxSize:
+  case BuiltInNumSubgroups:
+  case BuiltInNumEnqueuedSubgroups:
+  case BuiltInSubgroupId:
+  case BuiltInSubgroupLocalInvocationId:
+  case BuiltInVertexIndex:
+  case BuiltInInstanceIndex:
+    return true;
+  default:
+    return false;
+  }
+}
+
+inline bool isValid(spv::Scope V) {
+  switch (V) {
+  case ScopeCrossDevice:
+  case ScopeDevice:
+  case ScopeWorkgroup:
+  case ScopeSubgroup:
+  case ScopeInvocation:
+    return true;
+  default:
+    return false;
+  }
+}
+
+inline bool isValid(spv::GroupOperation V) {
+  switch (V) {
+  case GroupOperationReduce:
+  case GroupOperationInclusiveScan:
+  case GroupOperationExclusiveScan:
+    return true;
+  default:
+    return false;
+  }
+}
+
+inline bool isValid(spv::KernelEnqueueFlags V) {
+  switch (V) {
+  case KernelEnqueueFlagsNoWait:
+  case KernelEnqueueFlagsWaitKernel:
+  case KernelEnqueueFlagsWaitWorkGroup:
+    return true;
+  default:
+    return false;
+  }
+}
+
+inline bool isValid(spv::Capability V) {
+  switch (V) {
+  case CapabilityMatrix:
+  case CapabilityShader:
+  case CapabilityGeometry:
+  case CapabilityTessellation:
+  case CapabilityAddresses:
+  case CapabilityLinkage:
+  case CapabilityKernel:
+  case CapabilityVector16:
+  case CapabilityFloat16Buffer:
+  case CapabilityFloat16:
+  case CapabilityFloat64:
+  case CapabilityInt64:
+  case CapabilityInt64Atomics:
+  case CapabilityImageBasic:
+  case CapabilityImageReadWrite:
+  case CapabilityImageMipmap:
+  case CapabilityPipes:
+  case CapabilityGroups:
+  case CapabilityDeviceEnqueue:
+  case CapabilityLiteralSampler:
+  case CapabilityAtomicStorage:
+  case CapabilityInt16:
+  case CapabilityTessellationPointSize:
+  case CapabilityGeometryPointSize:
+  case CapabilityImageGatherExtended:
+  case CapabilityStorageImageMultisample:
+  case CapabilityUniformBufferArrayDynamicIndexing:
+  case CapabilitySampledImageArrayDynamicIndexing:
+  case CapabilityStorageBufferArrayDynamicIndexing:
+  case CapabilityStorageImageArrayDynamicIndexing:
+  case CapabilityClipDistance:
+  case CapabilityCullDistance:
+  case CapabilityImageCubeArray:
+  case CapabilitySampleRateShading:
+  case CapabilityImageRect:
+  case CapabilitySampledRect:
+  case CapabilityGenericPointer:
+  case CapabilityInt8:
+  case CapabilityInputAttachment:
+  case CapabilitySparseResidency:
+  case CapabilityMinLod:
+  case CapabilitySampled1D:
+  case CapabilityImage1D:
+  case CapabilitySampledCubeArray:
+  case CapabilitySampledBuffer:
+  case CapabilityImageBuffer:
+  case CapabilityImageMSArray:
+  case CapabilityStorageImageExtendedFormats:
+  case CapabilityImageQuery:
+  case CapabilityDerivativeControl:
+  case CapabilityInterpolationFunction:
+  case CapabilityTransformFeedback:
+  case CapabilityGeometryStreams:
+  case CapabilityStorageImageReadWithoutFormat:
+  case CapabilityStorageImageWriteWithoutFormat:
+  case CapabilityMultiViewport:
+  case CapabilitySubgroupDispatch:
+  case CapabilityNamedBarrier:
+  case CapabilityPipeStorage:
+    return true;
+  default:
+    return false;
+  }
+}
+
+inline bool isValid(spv::Op V) {
+  switch (V) {
+  case OpNop:
+  case OpUndef:
+  case OpSourceContinued:
+  case OpSource:
+  case OpSourceExtension:
+  case OpName:
+  case OpMemberName:
+  case OpString:
+  case OpLine:
+  case OpExtension:
+  case OpExtInstImport:
+  case OpExtInst:
+  case OpMemoryModel:
+  case OpEntryPoint:
+  case OpExecutionMode:
+  case OpCapability:
+  case OpTypeVoid:
+  case OpTypeBool:
+  case OpTypeInt:
+  case OpTypeFloat:
+  case OpTypeVector:
+  case OpTypeMatrix:
+  case OpTypeImage:
+  case OpTypeSampler:
+  case OpTypeSampledImage:
+  case OpTypeArray:
+  case OpTypeRuntimeArray:
+  case OpTypeStruct:
+  case OpTypeOpaque:
+  case OpTypePointer:
+  case OpTypeFunction:
+  case OpTypeEvent:
+  case OpTypeDeviceEvent:
+  case OpTypeReserveId:
+  case OpTypeQueue:
+  case OpTypePipe:
+  case OpTypeForwardPointer:
+  case OpConstantTrue:
+  case OpConstantFalse:
+  case OpConstant:
+  case OpConstantComposite:
+  case OpConstantSampler:
+  case OpConstantNull:
+  case OpSpecConstantTrue:
+  case OpSpecConstantFalse:
+  case OpSpecConstant:
+  case OpSpecConstantComposite:
+  case OpSpecConstantOp:
+  case OpFunction:
+  case OpFunctionParameter:
+  case OpFunctionEnd:
+  case OpFunctionCall:
+  case OpVariable:
+  case OpImageTexelPointer:
+  case OpLoad:
+  case OpStore:
+  case OpCopyMemory:
+  case OpCopyMemorySized:
+  case OpAccessChain:
+  case OpInBoundsAccessChain:
+  case OpPtrAccessChain:
+  case OpArrayLength:
+  case OpGenericPtrMemSemantics:
+  case OpInBoundsPtrAccessChain:
+  case OpDecorate:
+  case OpMemberDecorate:
+  case OpDecorationGroup:
+  case OpGroupDecorate:
+  case OpGroupMemberDecorate:
+  case OpVectorExtractDynamic:
+  case OpVectorInsertDynamic:
+  case OpVectorShuffle:
+  case OpCompositeConstruct:
+  case OpCompositeExtract:
+  case OpCompositeInsert:
+  case OpCopyObject:
+  case OpTranspose:
+  case OpSampledImage:
+  case OpImageSampleImplicitLod:
+  case OpImageSampleExplicitLod:
+  case OpImageSampleDrefImplicitLod:
+  case OpImageSampleDrefExplicitLod:
+  case OpImageSampleProjImplicitLod:
+  case OpImageSampleProjExplicitLod:
+  case OpImageSampleProjDrefImplicitLod:
+  case OpImageSampleProjDrefExplicitLod:
+  case OpImageFetch:
+  case OpImageGather:
+  case OpImageDrefGather:
+  case OpImageRead:
+  case OpImageWrite:
+  case OpImage:
+  case OpImageQueryFormat:
+  case OpImageQueryOrder:
+  case OpImageQuerySizeLod:
+  case OpImageQuerySize:
+  case OpImageQueryLod:
+  case OpImageQueryLevels:
+  case OpImageQuerySamples:
+  case OpConvertFToU:
+  case OpConvertFToS:
+  case OpConvertSToF:
+  case OpConvertUToF:
+  case OpUConvert:
+  case OpSConvert:
+  case OpFConvert:
+  case OpQuantizeToF16:
+  case OpConvertPtrToU:
+  case OpSatConvertSToU:
+  case OpSatConvertUToS:
+  case OpConvertUToPtr:
+  case OpPtrCastToGeneric:
+  case OpGenericCastToPtr:
+  case OpGenericCastToPtrExplicit:
+  case OpBitcast:
+  case OpSNegate:
+  case OpFNegate:
+  case OpIAdd:
+  case OpFAdd:
+  case OpISub:
+  case OpFSub:
+  case OpIMul:
+  case OpFMul:
+  case OpUDiv:
+  case OpSDiv:
+  case OpFDiv:
+  case OpUMod:
+  case OpSRem:
+  case OpSMod:
+  case OpFRem:
+  case OpFMod:
+  case OpVectorTimesScalar:
+  case OpMatrixTimesScalar:
+  case OpVectorTimesMatrix:
+  case OpMatrixTimesVector:
+  case OpMatrixTimesMatrix:
+  case OpOuterProduct:
+  case OpDot:
+  case OpIAddCarry:
+  case OpISubBorrow:
+  case OpUMulExtended:
+  case OpSMulExtended:
+  case OpAny:
+  case OpAll:
+  case OpIsNan:
+  case OpIsInf:
+  case OpIsFinite:
+  case OpIsNormal:
+  case OpSignBitSet:
+  case OpLessOrGreater:
+  case OpOrdered:
+  case OpUnordered:
+  case OpLogicalEqual:
+  case OpLogicalNotEqual:
+  case OpLogicalOr:
+  case OpLogicalAnd:
+  case OpLogicalNot:
+  case OpSelect:
+  case OpIEqual:
+  case OpINotEqual:
+  case OpUGreaterThan:
+  case OpSGreaterThan:
+  case OpUGreaterThanEqual:
+  case OpSGreaterThanEqual:
+  case OpULessThan:
+  case OpSLessThan:
+  case OpULessThanEqual:
+  case OpSLessThanEqual:
+  case OpFOrdEqual:
+  case OpFUnordEqual:
+  case OpFOrdNotEqual:
+  case OpFUnordNotEqual:
+  case OpFOrdLessThan:
+  case OpFUnordLessThan:
+  case OpFOrdGreaterThan:
+  case OpFUnordGreaterThan:
+  case OpFOrdLessThanEqual:
+  case OpFUnordLessThanEqual:
+  case OpFOrdGreaterThanEqual:
+  case OpFUnordGreaterThanEqual:
+  case OpShiftRightLogical:
+  case OpShiftRightArithmetic:
+  case OpShiftLeftLogical:
+  case OpBitwiseOr:
+  case OpBitwiseXor:
+  case OpBitwiseAnd:
+  case OpNot:
+  case OpBitFieldInsert:
+  case OpBitFieldSExtract:
+  case OpBitFieldUExtract:
+  case OpBitReverse:
+  case OpBitCount:
+  case OpDPdx:
+  case OpDPdy:
+  case OpFwidth:
+  case OpDPdxFine:
+  case OpDPdyFine:
+  case OpFwidthFine:
+  case OpDPdxCoarse:
+  case OpDPdyCoarse:
+  case OpFwidthCoarse:
+  case OpEmitVertex:
+  case OpEndPrimitive:
+  case OpEmitStreamVertex:
+  case OpEndStreamPrimitive:
+  case OpControlBarrier:
+  case OpMemoryBarrier:
+  case OpAtomicLoad:
+  case OpAtomicStore:
+  case OpAtomicExchange:
+  case OpAtomicCompareExchange:
+  case OpAtomicCompareExchangeWeak:
+  case OpAtomicIIncrement:
+  case OpAtomicIDecrement:
+  case OpAtomicIAdd:
+  case OpAtomicISub:
+  case OpAtomicSMin:
+  case OpAtomicUMin:
+  case OpAtomicSMax:
+  case OpAtomicUMax:
+  case OpAtomicAnd:
+  case OpAtomicOr:
+  case OpAtomicXor:
+  case OpPhi:
+  case OpLoopMerge:
+  case OpSelectionMerge:
+  case OpLabel:
+  case OpBranch:
+  case OpBranchConditional:
+  case OpSwitch:
+  case OpKill:
+  case OpReturn:
+  case OpReturnValue:
+  case OpUnreachable:
+  case OpLifetimeStart:
+  case OpLifetimeStop:
+  case OpGroupAsyncCopy:
+  case OpGroupWaitEvents:
+  case OpGroupAll:
+  case OpGroupAny:
+  case OpGroupBroadcast:
+  case OpGroupIAdd:
+  case OpGroupFAdd:
+  case OpGroupFMin:
+  case OpGroupUMin:
+  case OpGroupSMin:
+  case OpGroupFMax:
+  case OpGroupUMax:
+  case OpGroupSMax:
+  case OpReadPipe:
+  case OpWritePipe:
+  case OpReservedReadPipe:
+  case OpReservedWritePipe:
+  case OpReserveReadPipePackets:
+  case OpReserveWritePipePackets:
+  case OpCommitReadPipe:
+  case OpCommitWritePipe:
+  case OpIsValidReserveId:
+  case OpGetNumPipePackets:
+  case OpGetMaxPipePackets:
+  case OpGroupReserveReadPipePackets:
+  case OpGroupReserveWritePipePackets:
+  case OpGroupCommitReadPipe:
+  case OpGroupCommitWritePipe:
+  case OpEnqueueMarker:
+  case OpEnqueueKernel:
+  case OpGetKernelNDrangeSubGroupCount:
+  case OpGetKernelNDrangeMaxSubGroupSize:
+  case OpGetKernelWorkGroupSize:
+  case OpGetKernelPreferredWorkGroupSizeMultiple:
+  case OpRetainEvent:
+  case OpReleaseEvent:
+  case OpCreateUserEvent:
+  case OpIsValidEvent:
+  case OpSetUserEventStatus:
+  case OpCaptureEventProfilingInfo:
+  case OpGetDefaultQueue:
+  case OpBuildNDRange:
+  case OpImageSparseSampleImplicitLod:
+  case OpImageSparseSampleExplicitLod:
+  case OpImageSparseSampleDrefImplicitLod:
+  case OpImageSparseSampleDrefExplicitLod:
+  case OpImageSparseSampleProjImplicitLod:
+  case OpImageSparseSampleProjExplicitLod:
+  case OpImageSparseSampleProjDrefImplicitLod:
+  case OpImageSparseSampleProjDrefExplicitLod:
+  case OpImageSparseFetch:
+  case OpImageSparseGather:
+  case OpImageSparseDrefGather:
+  case OpImageSparseTexelsResident:
+  case OpNoLine:
+  case OpAtomicFlagTestAndSet:
+  case OpAtomicFlagClear:
+  case OpImageSparseRead:
+  case OpSizeOf:
+  case OpTypePipeStorage:
+  case OpConstantPipeStorage:
+  case OpCreatePipeFromPipeStorage:
+  case OpGetKernelLocalSizeForSubgroupCount:
+  case OpGetKernelMaxNumSubgroups:
+  case OpTypeNamedBarrier:
+  case OpNamedBarrierInitialize:
+  case OpMemoryNamedBarrier:
+  case OpModuleProcessed:
+  case OpUndefValueInternal:
+  case OpForward:
+    return true;
+  default:
+    return false;
+  }
+}
+
+inline bool isValidImageOperandsMask(SPIRVWord Mask) {
+  SPIRVWord ValidMask = 0u;
+  ValidMask |= ImageOperandsBiasMask;
+  ValidMask |= ImageOperandsLodMask;
+  ValidMask |= ImageOperandsGradMask;
+  ValidMask |= ImageOperandsConstOffsetMask;
+  ValidMask |= ImageOperandsOffsetMask;
+  ValidMask |= ImageOperandsConstOffsetsMask;
+  ValidMask |= ImageOperandsSampleMask;
+  ValidMask |= ImageOperandsMinLodMask;
+
+  return (Mask & ~ValidMask) == 0;
+}
+
+inline bool isValidFPFastMathModeMask(SPIRVWord Mask) {
+  SPIRVWord ValidMask = 0u;
+  ValidMask |= FPFastMathModeNotNaNMask;
+  ValidMask |= FPFastMathModeNotInfMask;
+  ValidMask |= FPFastMathModeNSZMask;
+  ValidMask |= FPFastMathModeAllowRecipMask;
+  ValidMask |= FPFastMathModeFastMask;
+
+  return (Mask & ~ValidMask) == 0;
+}
+
+inline bool isValidSelectionControlMask(SPIRVWord Mask) {
+  SPIRVWord ValidMask = 0u;
+  ValidMask |= SelectionControlFlattenMask;
+  ValidMask |= SelectionControlDontFlattenMask;
+
+  return (Mask & ~ValidMask) == 0;
+}
+
+inline bool isValidLoopControlMask(SPIRVWord Mask) {
+  SPIRVWord ValidMask = 0u;
+  ValidMask |= LoopControlUnrollMask;
+  ValidMask |= LoopControlDontUnrollMask;
+  ValidMask |= LoopControlDependencyInfiniteMask;
+  ValidMask |= LoopControlDependencyLengthMask;
+
+  return (Mask & ~ValidMask) == 0;
+}
+
+inline bool isValidFunctionControlMask(SPIRVWord Mask) {
+  SPIRVWord ValidMask = 0u;
+  ValidMask |= FunctionControlInlineMask;
+  ValidMask |= FunctionControlDontInlineMask;
+  ValidMask |= FunctionControlPureMask;
+  ValidMask |= FunctionControlConstMask;
+
+  return (Mask & ~ValidMask) == 0;
+}
+
+inline bool isValidMemorySemanticsMask(SPIRVWord Mask) {
+  SPIRVWord ValidMask = 0u;
+  ValidMask |= MemorySemanticsAcquireMask;
+  ValidMask |= MemorySemanticsReleaseMask;
+  ValidMask |= MemorySemanticsAcquireReleaseMask;
+  ValidMask |= MemorySemanticsSequentiallyConsistentMask;
+  ValidMask |= MemorySemanticsUniformMemoryMask;
+  ValidMask |= MemorySemanticsSubgroupMemoryMask;
+  ValidMask |= MemorySemanticsWorkgroupMemoryMask;
+  ValidMask |= MemorySemanticsCrossWorkgroupMemoryMask;
+  ValidMask |= MemorySemanticsAtomicCounterMemoryMask;
+  ValidMask |= MemorySemanticsImageMemoryMask;
+
+  return (Mask & ~ValidMask) == 0;
+}
+
+inline bool isValidMemoryAccessMask(SPIRVWord Mask) {
+  SPIRVWord ValidMask = 0u;
+  ValidMask |= MemoryAccessVolatileMask;
+  ValidMask |= MemoryAccessAlignedMask;
+  ValidMask |= MemoryAccessNontemporalMask;
+
+  return (Mask & ~ValidMask) == 0;
+}
+
+inline bool isValidKernelProfilingInfoMask(SPIRVWord Mask) {
+  SPIRVWord ValidMask = 0u;
+  ValidMask |= KernelProfilingInfoCmdExecTimeMask;
+
+  return (Mask & ~ValidMask) == 0;
+}
+
+} /* namespace SPIRV */
+
+#pragma clang diagnostic pop
+
+#endif /* SPIRVISVALIDENUM_H_ */
diff --git a/lib/SPIRV/libSPIRV/SPIRVModule.cpp b/lib/SPIRV/libSPIRV/SPIRVModule.cpp
new file mode 100644
index 0000000..2287563
--- /dev/null
+++ b/lib/SPIRV/libSPIRV/SPIRVModule.cpp
@@ -0,0 +1,1681 @@
+//===- SPIRVModule.cpp - Class to represent SPIR-V module -------*- C++ -*-===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+/// \file
+///
+/// This file implements Module class for SPIR-V.
+///
+//===----------------------------------------------------------------------===//
+
+#include "SPIRVModule.h"
+#include "SPIRVDebug.h"
+#include "SPIRVEntry.h"
+#include "SPIRVType.h"
+#include "SPIRVValue.h"
+#include "SPIRVExtInst.h"
+#include "SPIRVFunction.h"
+#include "SPIRVInstruction.h"
+#include "SPIRVStream.h"
+
+#include <set>
+#include <unordered_map>
+#include <unordered_set>
+
+namespace SPIRV {
+
+SPIRVModule::SPIRVModule()
+    : AutoAddCapability(true), ValidateCapability(false) {}
+
+SPIRVModule::~SPIRVModule() {}
+
+class SPIRVModuleImpl : public SPIRVModule {
+public:
+  SPIRVModuleImpl()
+      : SPIRVModule(), NextId(1), BoolType(NULL), SPIRVVersion(SPIRV_1_0),
+        GeneratorId(SPIRVGEN_KhronosLLVMSPIRVTranslator), GeneratorVer(0),
+        InstSchema(SPIRVISCH_Default), SrcLang(SourceLanguageOpenCL_C),
+        SrcLangVer(102000) {
+    AddrModel = sizeof(size_t) == 4 ? AddressingModelPhysical32
+                                    : AddressingModelPhysical64;
+  };
+  virtual ~SPIRVModuleImpl();
+
+  // Object query functions
+  bool exist(SPIRVId) const;
+  bool exist(SPIRVId, SPIRVEntry **) const;
+  SPIRVId getId(SPIRVId Id = SPIRVID_INVALID, unsigned Increment = 1);
+  virtual SPIRVEntry *getEntry(SPIRVId Id) const;
+  bool hasDebugInfo() const { return !LineVec.empty(); }
+
+  // Error handling functions
+  SPIRVErrorLog &getErrorLog() { return ErrLog; }
+  SPIRVErrorCode getError(std::string &ErrMsg) {
+    return ErrLog.getError(ErrMsg);
+  }
+
+  // Module query functions
+  SPIRVAddressingModelKind getAddressingModel() { return AddrModel; }
+  SPIRVExtInstSetKind getBuiltinSet(SPIRVId SetId) const;
+  const SPIRVCapMap &getCapability() const { return CapMap; }
+  bool hasCapability(SPIRVCapabilityKind Cap) const {
+    return CapMap.find(Cap) != CapMap.end();
+  }
+  std::set<std::string> &getExtension() { return SPIRVExt; }
+  SPIRVFunction *getFunction(unsigned I) const { return FuncVec[I]; }
+  SPIRVVariable *getVariable(unsigned I) const { return VariableVec[I]; }
+  virtual SPIRVValue *getValue(SPIRVId TheId) const;
+  virtual std::vector<SPIRVValue *>
+  getValues(const std::vector<SPIRVId> &) const;
+  virtual std::vector<SPIRVId> getIds(const std::vector<SPIRVEntry *> &) const;
+  virtual std::vector<SPIRVId> getIds(const std::vector<SPIRVValue *> &) const;
+  virtual SPIRVType *getValueType(SPIRVId TheId) const;
+  virtual std::vector<SPIRVType *>
+  getValueTypes(const std::vector<SPIRVId> &) const;
+  SPIRVMemoryModelKind getMemoryModel() const { return MemoryModel; }
+  virtual SPIRVConstant *getLiteralAsConstant(unsigned Literal, bool is_signed);
+  unsigned getNumEntryPoints(SPIRVExecutionModelKind EM) const {
+    auto Loc = EntryPointVec.find(EM);
+    if (Loc == EntryPointVec.end())
+      return 0;
+    return Loc->second.size();
+  }
+  SPIRVFunction *getEntryPoint(SPIRVExecutionModelKind EM, unsigned I) const {
+    auto Loc = EntryPointVec.find(EM);
+    if (Loc == EntryPointVec.end())
+      return nullptr;
+    assert(I < Loc->second.size());
+    return get<SPIRVFunction>(Loc->second[I]);
+  }
+  const std::unordered_map<SPIRVId, std::vector<SPIRVVariable *>> &
+  getEntryPointIO() const override {
+    return EntryPointIO;
+  }
+  unsigned getNumFunctions() const { return FuncVec.size(); }
+  unsigned getNumVariables() const { return VariableVec.size(); }
+  SourceLanguage getSourceLanguage(SPIRVWord *Ver = nullptr) const {
+    if (Ver)
+      *Ver = SrcLangVer;
+    return SrcLang;
+  }
+  std::set<std::string> &getSourceExtension() { return SrcExtension; }
+  bool isEntryPoint(SPIRVExecutionModelKind, SPIRVId EP) const;
+  unsigned short getGeneratorId() const { return GeneratorId; }
+  unsigned short getGeneratorVer() const { return GeneratorVer; }
+  SPIRVWord getSPIRVVersion() const { return SPIRVVersion; }
+
+  // Module changing functions
+  bool importBuiltinSet(const std::string &, SPIRVId *);
+  bool importBuiltinSetWithId(const std::string &, SPIRVId);
+  void optimizeDecorates();
+  void setAddressingModel(SPIRVAddressingModelKind AM) { AddrModel = AM; }
+  void setAlignment(SPIRVValue *, SPIRVWord);
+  void setMemoryModel(SPIRVMemoryModelKind MM) {
+    MemoryModel = MM;
+    if (MemoryModel == spv::MemoryModelOpenCL)
+      addCapability(CapabilityKernel);
+  }
+  void setName(SPIRVEntry *E, const std::string &Name);
+  void setSourceLanguage(SourceLanguage Lang, SPIRVWord Ver) {
+    SrcLang = Lang;
+    SrcLangVer = Ver;
+  }
+  void setGeneratorId(unsigned short Id) { GeneratorId = Id; }
+  void setGeneratorVer(unsigned short Ver) { GeneratorVer = Ver; }
+  void resolveUnknownStructFields();
+
+  void setSPIRVVersion(SPIRVWord Ver) override { SPIRVVersion = Ver; }
+
+  // Object creation functions
+  template <class T> void addTo(std::vector<T *> &V, SPIRVEntry *E);
+  virtual SPIRVEntry *addEntry(SPIRVEntry *E);
+  virtual SPIRVBasicBlock *addBasicBlock(SPIRVFunction *, SPIRVId);
+  virtual SPIRVString *getString(const std::string &Str);
+  virtual SPIRVMemberName *addMemberName(SPIRVTypeStruct *ST,
+                                         SPIRVWord MemberNumber,
+                                         const std::string &Name);
+  virtual void addUnknownStructField(SPIRVTypeStruct *Struct, unsigned I,
+                                     SPIRVId ID);
+  virtual SPIRVLine *addLine(SPIRVEntry *E, SPIRVString *FileName,
+                             SPIRVWord Line, SPIRVWord Column);
+  virtual void addCapability(SPIRVCapabilityKind);
+  virtual void addCapabilityInternal(SPIRVCapabilityKind);
+  virtual const SPIRVDecorateGeneric *addDecorate(const SPIRVDecorateGeneric *);
+  virtual SPIRVDecorationGroup *addDecorationGroup();
+  virtual SPIRVDecorationGroup *addDecorationGroup(SPIRVDecorationGroup *Group);
+  virtual SPIRVGroupDecorate *
+  addGroupDecorate(SPIRVDecorationGroup *Group,
+                   const std::vector<SPIRVEntry *> &Targets);
+  virtual SPIRVGroupDecorateGeneric *
+  addGroupDecorateGeneric(SPIRVGroupDecorateGeneric *GDec);
+  virtual SPIRVGroupMemberDecorate *
+  addGroupMemberDecorate(SPIRVDecorationGroup *Group,
+                         const std::vector<SPIRVEntry *> &Targets);
+  virtual void addEntryPoint(SPIRVExecutionModelKind ExecModel,
+                             SPIRVId EntryPoint);
+  virtual void addEntryPointIO(SPIRVId EntryPoint, SPIRVVariable *var);
+  virtual SPIRVForward *addForward(SPIRVType *Ty);
+  virtual SPIRVForward *addForward(SPIRVId, SPIRVType *Ty);
+  virtual SPIRVFunction *addFunction(SPIRVFunction *);
+  virtual SPIRVFunction *addFunction(SPIRVTypeFunction *, SPIRVId);
+  virtual SPIRVEntry *replaceForward(SPIRVForward *, SPIRVEntry *);
+
+  // Type creation functions
+  template <class T> T *addType(T *Ty);
+  virtual SPIRVTypeArray *addArrayType(SPIRVType *, SPIRVConstant *);
+  virtual SPIRVTypeRuntimeArray *addRuntimeArrayType(SPIRVType *);
+  virtual SPIRVTypeBool *addBoolType();
+  virtual SPIRVTypeFloat *addFloatType(unsigned BitWidth);
+  virtual SPIRVTypeFunction *addFunctionType(SPIRVType *,
+                                             const std::vector<SPIRVType *> &);
+  virtual SPIRVTypeInt *addIntegerType(unsigned BitWidth, bool is_signed);
+  virtual SPIRVTypeOpaque *addOpaqueType(const std::string &);
+  virtual SPIRVTypePointer *addPointerType(SPIRVStorageClassKind, SPIRVType *);
+  virtual SPIRVTypeImage *addImageType(SPIRVType *,
+                                       const SPIRVTypeImageDescriptor &);
+  virtual SPIRVTypeImage *addImageType(SPIRVType *,
+                                       const SPIRVTypeImageDescriptor &,
+                                       SPIRVAccessQualifierKind);
+  virtual SPIRVTypeSampler *addSamplerType();
+  virtual SPIRVTypePipeStorage *addPipeStorageType();
+  virtual SPIRVTypeSampledImage *addSampledImageType(SPIRVTypeImage *T);
+  virtual SPIRVTypeStruct *openStructType(unsigned, const std::string &);
+  virtual void closeStructType(SPIRVTypeStruct *T, bool);
+  virtual SPIRVTypeVector *addVectorType(SPIRVType *, SPIRVWord);
+  virtual SPIRVType *addOpaqueGenericType(Op);
+  virtual SPIRVTypeDeviceEvent *addDeviceEventType();
+  virtual SPIRVTypeQueue *addQueueType();
+  virtual SPIRVTypePipe *addPipeType();
+  virtual SPIRVTypeVoid *addVoidType();
+  virtual void createForwardPointers();
+
+  // Constant creation functions
+  virtual SPIRVInstruction *addBranchInst(SPIRVLabel *, SPIRVBasicBlock *);
+  virtual SPIRVInstruction *addBranchConditionalInst(SPIRVValue *, SPIRVLabel *,
+                                                     SPIRVLabel *,
+                                                     SPIRVBasicBlock *);
+  virtual SPIRVInstruction *addUnreachableInst(SPIRVBasicBlock *);
+  virtual SPIRVValue *addCompositeConstant(SPIRVType *,
+                                           const std::vector<SPIRVValue *> &);
+  virtual SPIRVValue *addConstant(SPIRVValue *);
+  virtual SPIRVValue *addConstant(SPIRVType *, uint64_t);
+  virtual SPIRVValue *addDoubleConstant(SPIRVTypeFloat *, double);
+  virtual SPIRVValue *addFloatConstant(SPIRVTypeFloat *, float);
+  virtual SPIRVValue *addIntegerConstant(SPIRVTypeInt *, uint64_t);
+  virtual SPIRVValue *addNullConstant(SPIRVType *);
+  virtual SPIRVValue *addUndef(SPIRVType *TheType);
+  virtual SPIRVValue *addUndefInst(SPIRVType *TheType, SPIRVBasicBlock *);
+  virtual SPIRVValue *addSamplerConstant(SPIRVType *TheType, SPIRVWord AddrMode,
+                                         SPIRVWord ParametricMode,
+                                         SPIRVWord FilterMode);
+  virtual SPIRVValue *addPipeStorageConstant(SPIRVType *TheType,
+                                             SPIRVWord PacketSize,
+                                             SPIRVWord PacketAlign,
+                                             SPIRVWord Capacity);
+
+  // Instruction creation functions
+  virtual SPIRVInstruction *addPtrAccessChainInst(SPIRVType *, SPIRVValue *,
+                                                  std::vector<SPIRVValue *>,
+                                                  SPIRVBasicBlock *, bool);
+  virtual SPIRVInstruction *addAccessChainInst(SPIRVType *, SPIRVValue *,
+                                               std::vector<SPIRVValue *>,
+                                               SPIRVBasicBlock *, bool);
+  virtual SPIRVInstruction *
+  addAsyncGroupCopy(SPIRVValue *Scope, SPIRVValue *Dest, SPIRVValue *Src,
+                    SPIRVValue *NumElems, SPIRVValue *Stride, SPIRVValue *Event,
+                    SPIRVBasicBlock *BB);
+  virtual SPIRVInstruction *addExtInst(SPIRVType *, SPIRVWord, SPIRVWord,
+                                       const std::vector<SPIRVWord> &,
+                                       SPIRVBasicBlock *);
+  virtual SPIRVInstruction *addExtInst(SPIRVType *, SPIRVWord, SPIRVWord,
+                                       const std::vector<SPIRVValue *> &,
+                                       SPIRVBasicBlock *);
+  virtual SPIRVInstruction *addBinaryInst(Op, SPIRVType *, SPIRVValue *,
+                                          SPIRVValue *, SPIRVBasicBlock *);
+  virtual SPIRVInstruction *addCallInst(SPIRVFunction *,
+                                        const std::vector<SPIRVWord> &,
+                                        SPIRVBasicBlock *);
+  virtual SPIRVInstruction *addCmpInst(Op, SPIRVType *, SPIRVValue *,
+                                       SPIRVValue *, SPIRVBasicBlock *);
+  virtual SPIRVInstruction *
+  addLoadInst(SPIRVValue *, const std::vector<SPIRVWord> &, SPIRVBasicBlock *);
+  virtual SPIRVInstruction *addPhiInst(SPIRVType *, std::vector<SPIRVValue *>,
+                                       SPIRVBasicBlock *);
+  virtual SPIRVInstruction *
+  addCompositeExtractInst(SPIRVType *, SPIRVValue *,
+                          const std::vector<SPIRVWord> &, SPIRVBasicBlock *);
+  virtual SPIRVInstruction *
+  addCompositeInsertInst(SPIRVValue *Object, SPIRVValue *Composite,
+                         const std::vector<SPIRVWord> &Indices,
+                         SPIRVBasicBlock *BB);
+  virtual SPIRVInstruction *addCopyObjectInst(SPIRVType *TheType,
+                                              SPIRVValue *Operand,
+                                              SPIRVBasicBlock *BB);
+  virtual SPIRVInstruction *addCopyMemoryInst(SPIRVValue *, SPIRVValue *,
+                                              const std::vector<SPIRVWord> &,
+                                              SPIRVBasicBlock *);
+  virtual SPIRVInstruction *
+  addCopyMemorySizedInst(SPIRVValue *, SPIRVValue *, SPIRVValue *,
+                         const std::vector<SPIRVWord> &, SPIRVBasicBlock *);
+  virtual SPIRVInstruction *addControlBarrierInst(SPIRVValue *ExecKind,
+                                                  SPIRVValue *MemKind,
+                                                  SPIRVValue *MemSema,
+                                                  SPIRVBasicBlock *BB);
+  virtual SPIRVInstruction *addGroupInst(Op OpCode, SPIRVType *Type,
+                                         Scope Scope,
+                                         const std::vector<SPIRVValue *> &Ops,
+                                         SPIRVBasicBlock *BB);
+  virtual SPIRVInstruction *addInstruction(SPIRVInstruction *Inst,
+                                           SPIRVBasicBlock *BB);
+  virtual SPIRVInstTemplateBase *addInstTemplate(Op OC, SPIRVBasicBlock *BB,
+                                                 SPIRVType *Ty);
+  virtual SPIRVInstTemplateBase *
+  addInstTemplate(Op OC, const std::vector<SPIRVWord> &Ops, SPIRVBasicBlock *BB,
+                  SPIRVType *Ty);
+  virtual SPIRVInstruction *
+  addMemoryBarrierInst(Scope ScopeKind, SPIRVWord MemFlag, SPIRVBasicBlock *BB);
+  virtual SPIRVInstruction *addReturnInst(SPIRVBasicBlock *);
+  virtual SPIRVInstruction *addReturnValueInst(SPIRVValue *, SPIRVBasicBlock *);
+  virtual SPIRVInstruction *addSelectInst(SPIRVValue *, SPIRVValue *,
+                                          SPIRVValue *, SPIRVBasicBlock *);
+  virtual SPIRVInstruction *addStoreInst(SPIRVValue *, SPIRVValue *,
+                                         const std::vector<SPIRVWord> &,
+                                         SPIRVBasicBlock *);
+  virtual SPIRVInstruction *addSwitchInst(
+      SPIRVValue *, SPIRVBasicBlock *,
+      const std::vector<std::pair<std::vector<SPIRVWord>, SPIRVBasicBlock *>> &,
+      SPIRVBasicBlock *);
+  virtual SPIRVInstruction *addUnaryInst(Op, SPIRVType *, SPIRVValue *,
+                                         SPIRVBasicBlock *);
+  virtual SPIRVInstruction *addVariable(SPIRVType *, bool, SPIRVLinkageTypeKind,
+                                        SPIRVValue *, const std::string &,
+                                        SPIRVStorageClassKind,
+                                        SPIRVBasicBlock *);
+  virtual SPIRVValue *
+  addVectorShuffleInst(SPIRVType *Type, SPIRVValue *Vec1, SPIRVValue *Vec2,
+                       const std::vector<SPIRVWord> &Components,
+                       SPIRVBasicBlock *BB);
+  virtual SPIRVInstruction *
+  addVectorExtractDynamicInst(SPIRVValue *, SPIRVValue *, SPIRVBasicBlock *);
+  virtual SPIRVInstruction *addVectorInsertDynamicInst(SPIRVValue *,
+                                                       SPIRVValue *,
+                                                       SPIRVValue *,
+                                                       SPIRVBasicBlock *);
+
+  // GLSL/shader functions
+  virtual SPIRVInstruction *addKillInst(SPIRVBasicBlock *);
+  virtual SPIRVInstruction *addLoopMergeInst(SPIRVBasicBlock *merge,
+                                             SPIRVBasicBlock *continuation,
+                                             SPIRVBasicBlock *BB);
+  virtual SPIRVInstruction *addSelectionMergeInst(SPIRVBasicBlock *merge,
+                                                  SPIRVBasicBlock *BB);
+
+  // I/O functions
+  friend spv_ostream &operator<<(spv_ostream &O, SPIRVModule &M);
+  friend std::istream &operator>>(std::istream &I, SPIRVModule &M);
+
+private:
+  SPIRVErrorLog ErrLog;
+  SPIRVId NextId;
+  SPIRVTypeInt *BoolType;
+  SPIRVWord SPIRVVersion;
+  unsigned short GeneratorId;
+  unsigned short GeneratorVer;
+  SPIRVInstructionSchemaKind InstSchema;
+  SourceLanguage SrcLang;
+  SPIRVWord SrcLangVer;
+  std::set<std::string> SrcExtension;
+  std::set<std::string> SPIRVExt;
+  SPIRVAddressingModelKind AddrModel;
+  SPIRVMemoryModelKind MemoryModel;
+
+  typedef std::map<SPIRVId, SPIRVEntry *> SPIRVIdToEntryMap;
+  typedef std::vector<SPIRVEntry *> SPIRVEntryVector;
+  typedef std::set<SPIRVId> SPIRVIdSet;
+  typedef std::vector<SPIRVId> SPIRVIdVec;
+  typedef std::vector<SPIRVFunction *> SPIRVFunctionVector;
+  typedef std::vector<SPIRVTypeForwardPointer *> SPIRVForwardPointerVec;
+  typedef std::vector<SPIRVType *> SPIRVTypeVec;
+  typedef std::vector<SPIRVValue *> SPIRVConstantVector;
+  typedef std::vector<SPIRVVariable *> SPIRVVariableVec;
+  typedef std::vector<SPIRVString *> SPIRVStringVec;
+  typedef std::vector<SPIRVMemberName *> SPIRVMemberNameVec;
+  typedef std::vector<SPIRVLine *> SPIRVLineVec;
+  typedef std::vector<SPIRVDecorationGroup *> SPIRVDecGroupVec;
+  typedef std::vector<SPIRVGroupDecorateGeneric *> SPIRVGroupDecVec;
+  typedef std::map<SPIRVId, SPIRVExtInstSetKind> SPIRVIdToBuiltinSetMap;
+  typedef std::map<SPIRVExecutionModelKind, SPIRVIdSet> SPIRVExecModelIdSetMap;
+  typedef std::map<SPIRVExecutionModelKind, SPIRVIdVec> SPIRVExecModelIdVecMap;
+  typedef std::unordered_map<std::string, SPIRVString *> SPIRVStringMap;
+  typedef std::map<SPIRVTypeStruct *, std::vector<std::pair<unsigned, SPIRVId>>>
+      SPIRVUnknownStructFieldMap;
+
+  SPIRVForwardPointerVec ForwardPointerVec;
+  SPIRVTypeVec TypeVec;
+  SPIRVIdToEntryMap IdEntryMap;
+  SPIRVFunctionVector FuncVec;
+  SPIRVConstantVector ConstVec;
+  SPIRVVariableVec VariableVec;
+  SPIRVEntryVector EntryNoId; // Entries without id
+  SPIRVIdToBuiltinSetMap IdBuiltinMap;
+  SPIRVIdSet NamedId;
+  SPIRVStringVec StringVec;
+  SPIRVMemberNameVec MemberNameVec;
+  SPIRVLineVec LineVec;
+  SPIRVDecorateSet DecorateSet;
+  SPIRVDecGroupVec DecGroupVec;
+  SPIRVGroupDecVec GroupDecVec;
+  SPIRVExecModelIdSetMap EntryPointSet;
+  SPIRVExecModelIdVecMap EntryPointVec;
+  std::unordered_map<SPIRVId, std::vector<SPIRVVariable *>> EntryPointIO;
+  SPIRVStringMap StrMap;
+  SPIRVCapMap CapMap;
+  SPIRVUnknownStructFieldMap UnknownStructFieldMap;
+  std::map<unsigned, SPIRVTypeInt *> IntTypeMap;
+  std::map<unsigned, SPIRVTypeInt *> SignedIntTypeMap;
+  std::map<unsigned, SPIRVConstant *> LiteralMap;
+  std::map<unsigned, SPIRVConstant *> SignedLiteralMap;
+
+  void layoutEntry(SPIRVEntry *Entry);
+};
+
+SPIRVModuleImpl::~SPIRVModuleImpl() {
+  // ToDo: Fix bug causing crash
+  // for (auto I:IdEntryMap)
+  //  delete I.second;
+
+  // ToDo: Fix bug causing crash
+  // for (auto I:EntryNoId) {
+  //  bildbgs() << "[delete] " << *I;
+  //  delete I;
+  //}
+
+  for (auto C : CapMap)
+    delete C.second;
+}
+
+SPIRVLine *SPIRVModuleImpl::addLine(SPIRVEntry *E, SPIRVString *FileName,
+                                    SPIRVWord Line, SPIRVWord Column) {
+  auto L = add(new SPIRVLine(E, FileName->getId(), Line, Column));
+  E->setLine(L);
+  return L;
+}
+
+// Creates decoration group and group decorates from decorates shared by
+// multiple targets.
+void SPIRVModuleImpl::optimizeDecorates() {
+  SPIRVDBG(spvdbgs() << "[optimizeDecorates] begin\n");
+  for (auto I = DecorateSet.begin(), E = DecorateSet.end(); I != E;) {
+    auto D = *I;
+    SPIRVDBG(spvdbgs() << "  check " << *D << '\n');
+    if (D->getOpCode() == OpMemberDecorate) {
+      ++I;
+      continue;
+    }
+    auto ER = DecorateSet.equal_range(D);
+    SPIRVDBG(spvdbgs() << "  equal range " << **ER.first << " to ";
+             if (ER.second != DecorateSet.end()) spvdbgs() << **ER.second;
+             else spvdbgs() << "end"; spvdbgs() << '\n');
+    if (std::distance(ER.first, ER.second) < 2) {
+      I = ER.second;
+      SPIRVDBG(spvdbgs() << "  skip equal range \n");
+      continue;
+    }
+    SPIRVDBG(spvdbgs() << "  add deco group. erase equal range\n");
+    auto G = new SPIRVDecorationGroup(this, getId());
+    std::vector<SPIRVId> Targets;
+    Targets.push_back(D->getTargetId());
+    const_cast<SPIRVDecorateGeneric *>(D)->setTargetId(G->getId());
+    G->getDecorations().insert(D);
+    for (I = ER.first; I != ER.second; ++I) {
+      auto E = *I;
+      if (*E == *D)
+        continue;
+      Targets.push_back(E->getTargetId());
+    }
+
+    // WordCount is only 16 bits.  We can only have 65535 - FixedWC targtets per
+    // group.
+    // For now, just skip using a group if the number of targets to too big
+    if (Targets.size() < 65530) {
+      DecorateSet.erase(ER.first, ER.second);
+      auto GD = new SPIRVGroupDecorate(G, Targets);
+      DecGroupVec.push_back(G);
+      GroupDecVec.push_back(GD);
+    }
+  }
+}
+
+SPIRVValue *SPIRVModuleImpl::addSamplerConstant(SPIRVType *TheType,
+                                                SPIRVWord AddrMode,
+                                                SPIRVWord ParametricMode,
+                                                SPIRVWord FilterMode) {
+  return addConstant(new SPIRVConstantSampler(this, TheType, getId(), AddrMode,
+                                              ParametricMode, FilterMode));
+}
+
+SPIRVValue *SPIRVModuleImpl::addPipeStorageConstant(SPIRVType *TheType,
+                                                    SPIRVWord PacketSize,
+                                                    SPIRVWord PacketAlign,
+                                                    SPIRVWord Capacity) {
+  return addConstant(new SPIRVConstantPipeStorage(
+      this, TheType, getId(), PacketSize, PacketAlign, Capacity));
+}
+
+void SPIRVModuleImpl::addCapability(SPIRVCapabilityKind Cap) {
+  addCapabilities(SPIRV::getCapability(Cap));
+  SPIRVDBG(spvdbgs() << "addCapability: " << Cap << '\n');
+  if (hasCapability(Cap))
+    return;
+
+  CapMap.insert(std::make_pair(Cap, new SPIRVCapability(this, Cap)));
+}
+
+void SPIRVModuleImpl::addCapabilityInternal(SPIRVCapabilityKind Cap) {
+  if (AutoAddCapability) {
+    if (hasCapability(Cap))
+      return;
+
+    CapMap.insert(std::make_pair(Cap, new SPIRVCapability(this, Cap)));
+  }
+}
+
+SPIRVConstant *SPIRVModuleImpl::getLiteralAsConstant(unsigned Literal,
+                                                     bool is_signed) {
+  if (!is_signed) {
+    auto Loc = LiteralMap.find(Literal);
+    if (Loc != LiteralMap.end())
+      return Loc->second;
+  } else {
+    auto Loc = SignedLiteralMap.find(Literal);
+    if (Loc != SignedLiteralMap.end())
+      return Loc->second;
+  }
+  auto Ty = addIntegerType(32, is_signed);
+  auto V = new SPIRVConstant(this, Ty, getId(), static_cast<uint64_t>(Literal));
+  if (!is_signed) {
+    LiteralMap[Literal] = V;
+  } else {
+    SignedLiteralMap[Literal] = V;
+  }
+  addConstant(V);
+  return V;
+}
+
+void SPIRVModuleImpl::layoutEntry(SPIRVEntry *E) {
+  auto OC = E->getOpCode();
+  switch (OC) {
+  case OpString:
+    addTo(StringVec, E);
+    break;
+  case OpMemberName:
+    addTo(MemberNameVec, E);
+    break;
+  case OpLine:
+    addTo(LineVec, E);
+    break;
+  case OpVariable: {
+    auto BV = static_cast<SPIRVVariable *>(E);
+    if (!BV->getParent())
+      addTo(VariableVec, E);
+  } break;
+  default:
+    if (isTypeOpCode(OC))
+      TypeVec.push_back(static_cast<SPIRVType *>(E));
+    else if (isConstantOpCode(OC))
+      ConstVec.push_back(static_cast<SPIRVConstant *>(E));
+    break;
+  }
+}
+
+// Add an entry to the id to entry map.
+// Assert if the id is mapped to a different entry.
+// Certain entries need to be add to specific collectors to maintain
+// logic layout of SPIRV.
+SPIRVEntry *SPIRVModuleImpl::addEntry(SPIRVEntry *Entry) {
+  assert(Entry && "Invalid entry");
+  if (Entry->hasId()) {
+    SPIRVId Id = Entry->getId();
+    assert(Entry->getId() != SPIRVID_INVALID && "Invalid id");
+    SPIRVEntry *Mapped = nullptr;
+    if (exist(Id, &Mapped)) {
+      if (Mapped->getOpCode() == OpForward) {
+        replaceForward(static_cast<SPIRVForward *>(Mapped), Entry);
+      } else {
+        assert(Mapped == Entry && "Id used twice");
+      }
+    } else
+      IdEntryMap[Id] = Entry;
+  } else {
+    EntryNoId.push_back(Entry);
+  }
+
+  Entry->setModule(this);
+
+  layoutEntry(Entry);
+  if (AutoAddCapability) {
+    for (auto &I : Entry->getRequiredCapability()) {
+      addCapability(I);
+    }
+  }
+  if (ValidateCapability) {
+    for (auto &I : Entry->getRequiredCapability()) {
+      assert(CapMap.count(I));
+    }
+  }
+  return Entry;
+}
+
+bool SPIRVModuleImpl::exist(SPIRVId Id) const { return exist(Id, nullptr); }
+
+bool SPIRVModuleImpl::exist(SPIRVId Id, SPIRVEntry **Entry) const {
+  assert(Id != SPIRVID_INVALID && "Invalid Id");
+  SPIRVIdToEntryMap::const_iterator Loc = IdEntryMap.find(Id);
+  if (Loc == IdEntryMap.end())
+    return false;
+  if (Entry)
+    *Entry = Loc->second;
+  return true;
+}
+
+// If Id is invalid, returns the next available id.
+// Otherwise returns the given id and adjust the next available id by increment.
+SPIRVId SPIRVModuleImpl::getId(SPIRVId Id, unsigned increment) {
+  if (!isValidId(Id))
+    Id = NextId;
+  else
+    NextId = std::max(Id, NextId);
+  NextId += increment;
+  return Id;
+}
+
+SPIRVEntry *SPIRVModuleImpl::getEntry(SPIRVId Id) const {
+  assert(Id != SPIRVID_INVALID && "Invalid Id");
+  SPIRVIdToEntryMap::const_iterator Loc = IdEntryMap.find(Id);
+  assert(Loc != IdEntryMap.end() && "Id is not in map");
+  return Loc->second;
+}
+
+SPIRVExtInstSetKind SPIRVModuleImpl::getBuiltinSet(SPIRVId SetId) const {
+  auto Loc = IdBuiltinMap.find(SetId);
+  assert(Loc != IdBuiltinMap.end() && "Invalid builtin set id");
+  return Loc->second;
+}
+
+bool SPIRVModuleImpl::isEntryPoint(SPIRVExecutionModelKind ExecModel,
+                                   SPIRVId EP) const {
+  assert(isValid(ExecModel) && "Invalid execution model");
+  assert(EP != SPIRVID_INVALID && "Invalid function id");
+  auto Loc = EntryPointSet.find(ExecModel);
+  if (Loc == EntryPointSet.end())
+    return false;
+  return Loc->second.count(EP);
+}
+
+// Module change functions
+bool SPIRVModuleImpl::importBuiltinSet(const std::string &BuiltinSetName,
+                                       SPIRVId *BuiltinSetId) {
+  SPIRVId TmpBuiltinSetId = getId();
+  if (!importBuiltinSetWithId(BuiltinSetName, TmpBuiltinSetId))
+    return false;
+  if (BuiltinSetId)
+    *BuiltinSetId = TmpBuiltinSetId;
+  return true;
+}
+
+bool SPIRVModuleImpl::importBuiltinSetWithId(const std::string &BuiltinSetName,
+                                             SPIRVId BuiltinSetId) {
+  SPIRVExtInstSetKind BuiltinSet = SPIRVEIS_Count;
+  SPIRVCKRT(SPIRVBuiltinSetNameMap::rfind(BuiltinSetName, &BuiltinSet),
+            InvalidBuiltinSetName, "Actual is " + BuiltinSetName);
+  IdBuiltinMap[BuiltinSetId] = BuiltinSet;
+  return true;
+}
+
+void SPIRVModuleImpl::setAlignment(SPIRVValue *V, SPIRVWord A) {
+  V->setAlignment(A);
+}
+
+void SPIRVModuleImpl::setName(SPIRVEntry *E, const std::string &Name) {
+  E->setName(Name);
+  if (!E->hasId())
+    return;
+  if (!Name.empty())
+    NamedId.insert(E->getId());
+  else
+    NamedId.erase(E->getId());
+}
+
+void SPIRVModuleImpl::resolveUnknownStructFields() {
+  for (auto &KV : UnknownStructFieldMap) {
+    auto *Struct = KV.first;
+    for (auto &Indices : KV.second) {
+      unsigned I = Indices.first;
+      SPIRVId ID = Indices.second;
+
+      auto Ty = static_cast<SPIRVType *>(getEntry(ID));
+      Struct->setMemberType(I, Ty);
+    }
+  }
+}
+
+// Type creation functions
+template <class T> T *SPIRVModuleImpl::addType(T *Ty) {
+  add(Ty);
+  if (!Ty->getName().empty())
+    setName(Ty, Ty->getName());
+  return Ty;
+}
+
+SPIRVTypeVoid *SPIRVModuleImpl::addVoidType() {
+  return addType(new SPIRVTypeVoid(this, getId()));
+}
+
+SPIRVTypeArray *SPIRVModuleImpl::addArrayType(SPIRVType *ElementType,
+                                              SPIRVConstant *Length) {
+  return addType(new SPIRVTypeArray(this, getId(), ElementType, Length));
+}
+
+SPIRVTypeRuntimeArray *
+SPIRVModuleImpl::addRuntimeArrayType(SPIRVType *ElementType) {
+  return addType(new SPIRVTypeRuntimeArray(this, getId(), ElementType));
+}
+
+SPIRVTypeBool *SPIRVModuleImpl::addBoolType() {
+  return addType(new SPIRVTypeBool(this, getId()));
+}
+
+SPIRVTypeInt *SPIRVModuleImpl::addIntegerType(unsigned BitWidth,
+                                              bool is_signed) {
+  if (!is_signed) {
+    auto Loc = IntTypeMap.find(BitWidth);
+    if (Loc != IntTypeMap.end())
+      return Loc->second;
+  } else {
+    auto Loc = SignedIntTypeMap.find(BitWidth);
+    if (Loc != SignedIntTypeMap.end())
+      return Loc->second;
+  }
+  auto Ty = new SPIRVTypeInt(this, getId(), BitWidth, is_signed);
+  if (!is_signed) {
+    IntTypeMap[BitWidth] = Ty;
+  } else {
+    SignedIntTypeMap[BitWidth] = Ty;
+  }
+  return addType(Ty);
+}
+
+SPIRVTypeFloat *SPIRVModuleImpl::addFloatType(unsigned BitWidth) {
+  SPIRVTypeFloat *T = addType(new SPIRVTypeFloat(this, getId(), BitWidth));
+  return T;
+}
+
+SPIRVTypePointer *
+SPIRVModuleImpl::addPointerType(SPIRVStorageClassKind StorageClass,
+                                SPIRVType *ElementType) {
+  return addType(
+      new SPIRVTypePointer(this, getId(), StorageClass, ElementType));
+}
+
+SPIRVTypeFunction *SPIRVModuleImpl::addFunctionType(
+    SPIRVType *ReturnType, const std::vector<SPIRVType *> &ParameterTypes) {
+  return addType(
+      new SPIRVTypeFunction(this, getId(), ReturnType, ParameterTypes));
+}
+
+SPIRVTypeOpaque *SPIRVModuleImpl::addOpaqueType(const std::string &Name) {
+  return addType(new SPIRVTypeOpaque(this, getId(), Name));
+}
+
+SPIRVTypeStruct *SPIRVModuleImpl::openStructType(unsigned NumMembers,
+                                                 const std::string &Name) {
+  auto T = new SPIRVTypeStruct(this, getId(), NumMembers, Name);
+  return T;
+}
+
+void SPIRVModuleImpl::closeStructType(SPIRVTypeStruct *T, bool Packed) {
+  addType(T);
+  T->setPacked(Packed);
+}
+
+SPIRVTypeVector *SPIRVModuleImpl::addVectorType(SPIRVType *CompType,
+                                                SPIRVWord CompCount) {
+  return addType(new SPIRVTypeVector(this, getId(), CompType, CompCount));
+}
+SPIRVType *SPIRVModuleImpl::addOpaqueGenericType(Op TheOpCode) {
+  return addType(new SPIRVTypeOpaqueGeneric(TheOpCode, this, getId()));
+}
+
+SPIRVTypeDeviceEvent *SPIRVModuleImpl::addDeviceEventType() {
+  return addType(new SPIRVTypeDeviceEvent(this, getId()));
+}
+
+SPIRVTypeQueue *SPIRVModuleImpl::addQueueType() {
+  return addType(new SPIRVTypeQueue(this, getId()));
+}
+
+SPIRVTypePipe *SPIRVModuleImpl::addPipeType() {
+  return addType(new SPIRVTypePipe(this, getId()));
+}
+
+SPIRVTypeImage *
+SPIRVModuleImpl::addImageType(SPIRVType *SampledType,
+                              const SPIRVTypeImageDescriptor &Desc) {
+  return addType(new SPIRVTypeImage(
+      this, getId(), SampledType ? SampledType->getId() : 0, Desc));
+}
+
+SPIRVTypeImage *
+SPIRVModuleImpl::addImageType(SPIRVType *SampledType,
+                              const SPIRVTypeImageDescriptor &Desc,
+                              SPIRVAccessQualifierKind Acc) {
+  return addType(new SPIRVTypeImage(
+      this, getId(), SampledType ? SampledType->getId() : 0, Desc, Acc));
+}
+
+SPIRVTypeSampler *SPIRVModuleImpl::addSamplerType() {
+  return addType(new SPIRVTypeSampler(this, getId()));
+}
+
+SPIRVTypePipeStorage *SPIRVModuleImpl::addPipeStorageType() {
+  return addType(new SPIRVTypePipeStorage(this, getId()));
+}
+
+SPIRVTypeSampledImage *SPIRVModuleImpl::addSampledImageType(SPIRVTypeImage *T) {
+  return addType(new SPIRVTypeSampledImage(this, getId(), T));
+}
+
+void SPIRVModuleImpl::createForwardPointers() {
+  std::unordered_set<SPIRVId> Seen;
+
+  for (auto *T : TypeVec) {
+    if (T->hasId())
+      Seen.insert(T->getId());
+
+    if (!T->isTypeStruct())
+      continue;
+
+    auto ST = static_cast<SPIRVTypeStruct *>(T);
+
+    for (unsigned i = 0; i < ST->getStructMemberCount(); ++i) {
+      auto MemberTy = ST->getStructMemberType(i);
+      if (!MemberTy->isTypePointer())
+        continue;
+      auto Ptr = static_cast<SPIRVTypePointer *>(MemberTy);
+
+      if (Seen.find(Ptr->getId()) == Seen.end()) {
+        ForwardPointerVec.push_back(new SPIRVTypeForwardPointer(
+            this, Ptr, Ptr->getPointerStorageClass()));
+      }
+    }
+  }
+}
+
+SPIRVFunction *SPIRVModuleImpl::addFunction(SPIRVFunction *Func) {
+  FuncVec.push_back(add(Func));
+  return Func;
+}
+
+SPIRVFunction *SPIRVModuleImpl::addFunction(SPIRVTypeFunction *FuncType,
+                                            SPIRVId Id) {
+  return addFunction(new SPIRVFunction(
+      this, FuncType, getId(Id, FuncType->getNumParameters() + 1)));
+}
+
+SPIRVBasicBlock *SPIRVModuleImpl::addBasicBlock(SPIRVFunction *Func,
+                                                SPIRVId Id) {
+  return Func->addBasicBlock(new SPIRVBasicBlock(getId(Id), Func));
+}
+
+const SPIRVDecorateGeneric *
+SPIRVModuleImpl::addDecorate(const SPIRVDecorateGeneric *Dec) {
+  SPIRVId Id = Dec->getTargetId();
+  SPIRVEntry *Target = nullptr;
+  bool Found = exist(Id, &Target);
+  assert(Found && "Decorate target does not exist");
+  if (!Dec->getOwner())
+    DecorateSet.insert(Dec);
+  addCapabilities(Dec->getRequiredCapability());
+  return Dec;
+}
+
+void SPIRVModuleImpl::addEntryPoint(SPIRVExecutionModelKind ExecModel,
+                                    SPIRVId EntryPoint) {
+  assert(isValid(ExecModel) && "Invalid execution model");
+  assert(EntryPoint != SPIRVID_INVALID && "Invalid entry point");
+  EntryPointSet[ExecModel].insert(EntryPoint);
+  EntryPointVec[ExecModel].push_back(EntryPoint);
+  addCapabilities(SPIRV::getCapability(ExecModel));
+}
+
+void SPIRVModuleImpl::addEntryPointIO(SPIRVId EntryPoint, SPIRVVariable *var) {
+  assert(EntryPoint != SPIRVID_INVALID && "Invalid entry point");
+  decltype(EntryPointIO)::mapped_type *io_vars = nullptr;
+  const auto ep_iter = EntryPointIO.find(EntryPoint);
+  if (ep_iter != EntryPointIO.end()) {
+    io_vars = &ep_iter->second;
+  } else {
+    const auto empl_iter =
+        EntryPointIO.emplace(EntryPoint, decltype(EntryPointIO)::mapped_type{});
+    assert(empl_iter.second && "failed to insert new entry point i/o");
+    io_vars = &empl_iter.first->second;
+  }
+  io_vars->push_back(var);
+}
+
+SPIRVForward *SPIRVModuleImpl::addForward(SPIRVType *Ty) {
+  return add(new SPIRVForward(this, Ty, getId()));
+}
+
+SPIRVForward *SPIRVModuleImpl::addForward(SPIRVId Id, SPIRVType *Ty) {
+  return add(new SPIRVForward(this, Ty, Id));
+}
+
+SPIRVEntry *SPIRVModuleImpl::replaceForward(SPIRVForward *Forward,
+                                            SPIRVEntry *Entry) {
+  SPIRVId Id = Entry->getId();
+  SPIRVId ForwardId = Forward->getId();
+  if (ForwardId == Id)
+    IdEntryMap[Id] = Entry;
+  else {
+    auto Loc = IdEntryMap.find(Id);
+    assert(Loc != IdEntryMap.end());
+    IdEntryMap.erase(Loc);
+    Entry->setId(ForwardId);
+    IdEntryMap[ForwardId] = Entry;
+  }
+  // Annotations include name, decorations, execution modes
+  Entry->takeAnnotations(Forward);
+  delete Forward;
+  return Entry;
+}
+
+SPIRVValue *SPIRVModuleImpl::addConstant(SPIRVValue *C) { return add(C); }
+
+SPIRVValue *SPIRVModuleImpl::addConstant(SPIRVType *Ty, uint64_t V) {
+  if (Ty->isTypeBool()) {
+    if (V)
+      return addConstant(new SPIRVConstantTrue(this, Ty, getId()));
+    else
+      return addConstant(new SPIRVConstantFalse(this, Ty, getId()));
+  }
+  if (Ty->isTypeInt())
+    return addIntegerConstant(static_cast<SPIRVTypeInt *>(Ty), V);
+  return addConstant(new SPIRVConstant(this, Ty, getId(), V));
+}
+
+SPIRVValue *SPIRVModuleImpl::addIntegerConstant(SPIRVTypeInt *Ty, uint64_t V) {
+  if (Ty->getBitWidth() == 32) {
+    uint32_t I32 = V;
+    assert(I32 == V && "Integer value truncated");
+    return getLiteralAsConstant(I32, Ty->isSigned());
+  }
+  return addConstant(new SPIRVConstant(this, Ty, getId(), V));
+}
+
+SPIRVValue *SPIRVModuleImpl::addFloatConstant(SPIRVTypeFloat *Ty, float V) {
+  return addConstant(new SPIRVConstant(this, Ty, getId(), V));
+}
+
+SPIRVValue *SPIRVModuleImpl::addDoubleConstant(SPIRVTypeFloat *Ty, double V) {
+  return addConstant(new SPIRVConstant(this, Ty, getId(), V));
+}
+
+SPIRVValue *SPIRVModuleImpl::addNullConstant(SPIRVType *Ty) {
+  return addConstant(new SPIRVConstantNull(this, Ty, getId()));
+}
+
+SPIRVValue *SPIRVModuleImpl::addCompositeConstant(
+    SPIRVType *Ty, const std::vector<SPIRVValue *> &Elements) {
+  return addConstant(new SPIRVConstantComposite(this, Ty, getId(), Elements));
+}
+
+SPIRVValue *SPIRVModuleImpl::addUndef(SPIRVType *TheType) {
+  return addConstant(new SPIRVUndef(this, TheType, getId()));
+}
+
+SPIRVValue *SPIRVModuleImpl::addUndefInst(SPIRVType *TheType,
+                                          SPIRVBasicBlock *BB) {
+  return BB->addInstruction(new SPIRVUndefInst(TheType, getId(), BB));
+}
+
+// Instruction creation functions
+
+SPIRVInstruction *
+SPIRVModuleImpl::addStoreInst(SPIRVValue *Target, SPIRVValue *Source,
+                              const std::vector<SPIRVWord> &TheMemoryAccess,
+                              SPIRVBasicBlock *BB) {
+  return BB->addInstruction(
+      new SPIRVStore(Target->getId(), Source->getId(), TheMemoryAccess, BB));
+}
+
+SPIRVInstruction *SPIRVModuleImpl::addSwitchInst(
+    SPIRVValue *Select, SPIRVBasicBlock *Default,
+    const std::vector<std::pair<std::vector<SPIRVWord>, SPIRVBasicBlock *>>
+        &Pairs,
+    SPIRVBasicBlock *BB) {
+  return BB->addInstruction(new SPIRVSwitch(Select, Default, Pairs, BB));
+}
+
+SPIRVInstruction *
+SPIRVModuleImpl::addGroupInst(Op OpCode, SPIRVType *Type, Scope Scope,
+                              const std::vector<SPIRVValue *> &Ops,
+                              SPIRVBasicBlock *BB) {
+  assert(!Type || !Type->isTypeVoid());
+  auto WordOps = getIds(Ops);
+  WordOps.insert(WordOps.begin(), Scope);
+  return addInstTemplate(OpCode, WordOps, BB, Type);
+}
+
+SPIRVInstruction *SPIRVModuleImpl::addInstruction(SPIRVInstruction *Inst,
+                                                  SPIRVBasicBlock *BB) {
+  if (BB)
+    return BB->addInstruction(Inst);
+  if (Inst->getOpCode() != OpSpecConstantOp)
+    Inst = createSpecConstantOpInst(Inst);
+  return static_cast<SPIRVInstruction *>(addConstant(Inst));
+}
+
+SPIRVInstruction *
+SPIRVModuleImpl::addLoadInst(SPIRVValue *Source,
+                             const std::vector<SPIRVWord> &TheMemoryAccess,
+                             SPIRVBasicBlock *BB) {
+  return addInstruction(
+      new SPIRVLoad(getId(), Source->getId(), TheMemoryAccess, BB), BB);
+}
+
+SPIRVInstruction *
+SPIRVModuleImpl::addPhiInst(SPIRVType *Type,
+                            std::vector<SPIRVValue *> IncomingPairs,
+                            SPIRVBasicBlock *BB) {
+  return addInstruction(new SPIRVPhi(Type, getId(), IncomingPairs, BB), BB);
+}
+
+SPIRVInstruction *SPIRVModuleImpl::addExtInst(
+    SPIRVType *TheType, SPIRVWord BuiltinSet, SPIRVWord EntryPoint,
+    const std::vector<SPIRVWord> &Args, SPIRVBasicBlock *BB) {
+  return addInstruction(
+      new SPIRVExtInst(TheType, getId(), BuiltinSet, EntryPoint, Args, BB), BB);
+}
+
+SPIRVInstruction *SPIRVModuleImpl::addExtInst(
+    SPIRVType *TheType, SPIRVWord BuiltinSet, SPIRVWord EntryPoint,
+    const std::vector<SPIRVValue *> &Args, SPIRVBasicBlock *BB) {
+  return addInstruction(
+      new SPIRVExtInst(TheType, getId(), BuiltinSet, EntryPoint, Args, BB), BB);
+}
+
+SPIRVInstruction *
+SPIRVModuleImpl::addCallInst(SPIRVFunction *TheFunction,
+                             const std::vector<SPIRVWord> &TheArguments,
+                             SPIRVBasicBlock *BB) {
+  return addInstruction(
+      new SPIRVFunctionCall(getId(), TheFunction, TheArguments, BB), BB);
+}
+
+SPIRVInstruction *SPIRVModuleImpl::addBinaryInst(Op TheOpCode, SPIRVType *Type,
+                                                 SPIRVValue *Op1,
+                                                 SPIRVValue *Op2,
+                                                 SPIRVBasicBlock *BB) {
+  return addInstruction(SPIRVInstTemplateBase::create(
+                            TheOpCode, Type, getId(),
+                            getVec(Op1->getId(), Op2->getId()), BB, this),
+                        BB);
+}
+
+SPIRVInstruction *SPIRVModuleImpl::addReturnInst(SPIRVBasicBlock *BB) {
+  return addInstruction(new SPIRVReturn(BB), BB);
+}
+
+SPIRVInstruction *SPIRVModuleImpl::addReturnValueInst(SPIRVValue *ReturnValue,
+                                                      SPIRVBasicBlock *BB) {
+  return addInstruction(new SPIRVReturnValue(ReturnValue, BB), BB);
+}
+
+SPIRVInstruction *SPIRVModuleImpl::addUnaryInst(Op TheOpCode,
+                                                SPIRVType *TheType,
+                                                SPIRVValue *Op,
+                                                SPIRVBasicBlock *BB) {
+  return addInstruction(
+      SPIRVInstTemplateBase::create(TheOpCode, TheType, getId(),
+                                    getVec(Op->getId()), BB, this),
+      BB);
+}
+
+SPIRVInstruction *SPIRVModuleImpl::addVectorExtractDynamicInst(
+    SPIRVValue *TheVector, SPIRVValue *Index, SPIRVBasicBlock *BB) {
+  return addInstruction(
+      new SPIRVVectorExtractDynamic(getId(), TheVector, Index, BB), BB);
+}
+
+SPIRVInstruction *SPIRVModuleImpl::addVectorInsertDynamicInst(
+    SPIRVValue *TheVector, SPIRVValue *TheComponent, SPIRVValue *Index,
+    SPIRVBasicBlock *BB) {
+  return addInstruction(
+      new SPIRVVectorInsertDynamic(getId(), TheVector, TheComponent, Index, BB),
+      BB);
+}
+
+SPIRVValue *SPIRVModuleImpl::addVectorShuffleInst(
+    SPIRVType *Type, SPIRVValue *Vec1, SPIRVValue *Vec2,
+    const std::vector<SPIRVWord> &Components, SPIRVBasicBlock *BB) {
+  return addInstruction(
+      new SPIRVVectorShuffle(getId(), Type, Vec1, Vec2, Components, BB), BB);
+}
+
+SPIRVInstruction *SPIRVModuleImpl::addBranchInst(SPIRVLabel *TargetLabel,
+                                                 SPIRVBasicBlock *BB) {
+  return addInstruction(new SPIRVBranch(TargetLabel, BB), BB);
+}
+
+SPIRVInstruction *SPIRVModuleImpl::addBranchConditionalInst(
+    SPIRVValue *Condition, SPIRVLabel *TrueLabel, SPIRVLabel *FalseLabel,
+    SPIRVBasicBlock *BB) {
+  return addInstruction(
+      new SPIRVBranchConditional(Condition, TrueLabel, FalseLabel, BB), BB);
+}
+
+SPIRVInstruction *SPIRVModuleImpl::addUnreachableInst(SPIRVBasicBlock *BB) {
+  return addInstruction(new SPIRVUnreachable(BB), BB);
+}
+
+SPIRVInstruction *SPIRVModuleImpl::addCmpInst(Op TheOpCode, SPIRVType *TheType,
+                                              SPIRVValue *Op1, SPIRVValue *Op2,
+                                              SPIRVBasicBlock *BB) {
+  return addInstruction(SPIRVInstTemplateBase::create(
+                            TheOpCode, TheType, getId(),
+                            getVec(Op1->getId(), Op2->getId()), BB, this),
+                        BB);
+}
+
+SPIRVInstruction *SPIRVModuleImpl::addControlBarrierInst(SPIRVValue *ExecKind,
+                                                         SPIRVValue *MemKind,
+                                                         SPIRVValue *MemSema,
+                                                         SPIRVBasicBlock *BB) {
+  return addInstruction(new SPIRVControlBarrier(ExecKind, MemKind, MemSema, BB),
+                        BB);
+}
+
+SPIRVInstruction *SPIRVModuleImpl::addMemoryBarrierInst(Scope ScopeKind,
+                                                        SPIRVWord MemFlag,
+                                                        SPIRVBasicBlock *BB) {
+  return addInstruction(SPIRVInstTemplateBase::create(
+                            OpMemoryBarrier, nullptr, SPIRVID_INVALID,
+                            getVec(static_cast<SPIRVWord>(ScopeKind), MemFlag),
+                            BB, this),
+                        BB);
+}
+
+SPIRVInstruction *SPIRVModuleImpl::addSelectInst(SPIRVValue *Condition,
+                                                 SPIRVValue *Op1,
+                                                 SPIRVValue *Op2,
+                                                 SPIRVBasicBlock *BB) {
+  return addInstruction(new SPIRVSelect(getId(), Condition->getId(),
+                                        Op1->getId(), Op2->getId(), BB),
+                        BB);
+}
+
+SPIRVInstruction *
+SPIRVModuleImpl::addPtrAccessChainInst(SPIRVType *Type, SPIRVValue *Base,
+                                       std::vector<SPIRVValue *> Indices,
+                                       SPIRVBasicBlock *BB, bool IsInBounds) {
+  return addInstruction(
+      SPIRVInstTemplateBase::create(
+          IsInBounds ? OpInBoundsPtrAccessChain : OpPtrAccessChain, Type,
+          getId(), getVec(Base->getId(), Base->getIds(Indices)), BB, this),
+      BB);
+}
+
+SPIRVInstruction *
+SPIRVModuleImpl::addAccessChainInst(SPIRVType *Type, SPIRVValue *Base,
+                                    std::vector<SPIRVValue *> Indices,
+                                    SPIRVBasicBlock *BB, bool IsInBounds) {
+  // check if this is a run-time array access (SSBO)
+  bool is_rtarr_access = false;
+  if (Base->getType()->isTypePointer() &&
+      Base->getType()->getPointerElementType()->isTypeStruct()) {
+    auto st_type = (SPIRVTypeStruct *)Base->getType()->getPointerElementType();
+    if (st_type->getStructMemberCount() > 0 &&
+        st_type->getMemberType(0)->isTypeRuntimeArray()) {
+      is_rtarr_access = true;
+    }
+  }
+  if (is_rtarr_access) {
+    // add an additional 0 index in front, because we always wrap SSBO/run-time
+    // array data in a struct
+    Indices.insert(
+        begin(Indices),
+        addIntegerConstant((SPIRVTypeInt *)Indices[0]->getType(), 0));
+  } else if (Indices.size() > 1) {
+    // if it's not a run-time array access, remove the first (0) index
+    // TODO: actually make this work for double-GEPs by fusing these with their
+    // users
+    Indices.erase(Indices.begin());
+  }
+  return addInstruction(
+      SPIRVInstTemplateBase::create(
+          IsInBounds ? OpInBoundsAccessChain : OpAccessChain, Type, getId(),
+          getVec(Base->getId(), Base->getIds(Indices)), BB, this),
+      BB);
+}
+
+SPIRVInstruction *SPIRVModuleImpl::addAsyncGroupCopy(
+    SPIRVValue *Scope, SPIRVValue *Dest, SPIRVValue *Src, SPIRVValue *NumElems,
+    SPIRVValue *Stride, SPIRVValue *Event, SPIRVBasicBlock *BB) {
+  return addInstruction(new SPIRVGroupAsyncCopy(Scope, getId(), Dest, Src,
+                                                NumElems, Stride, Event, BB),
+                        BB);
+}
+
+SPIRVInstruction *
+SPIRVModuleImpl::addCompositeExtractInst(SPIRVType *Type, SPIRVValue *TheVector,
+                                         const std::vector<SPIRVWord> &Indices,
+                                         SPIRVBasicBlock *BB) {
+  return addInstruction(
+      new SPIRVCompositeExtract(Type, getId(), TheVector, Indices, BB), BB);
+}
+
+SPIRVInstruction *SPIRVModuleImpl::addCompositeInsertInst(
+    SPIRVValue *Object, SPIRVValue *Composite,
+    const std::vector<SPIRVWord> &Indices, SPIRVBasicBlock *BB) {
+  return addInstruction(
+      new SPIRVCompositeInsert(getId(), Object, Composite, Indices, BB), BB);
+}
+
+SPIRVInstruction *SPIRVModuleImpl::addCopyObjectInst(SPIRVType *TheType,
+                                                     SPIRVValue *Operand,
+                                                     SPIRVBasicBlock *BB) {
+  return addInstruction(new SPIRVCopyObject(TheType, getId(), Operand, BB), BB);
+}
+
+SPIRVInstruction *SPIRVModuleImpl::addCopyMemoryInst(
+    SPIRVValue *TheTarget, SPIRVValue *TheSource,
+    const std::vector<SPIRVWord> &TheMemoryAccess, SPIRVBasicBlock *BB) {
+  return addInstruction(
+      new SPIRVCopyMemory(TheTarget, TheSource, TheMemoryAccess, BB), BB);
+}
+
+SPIRVInstruction *SPIRVModuleImpl::addCopyMemorySizedInst(
+    SPIRVValue *TheTarget, SPIRVValue *TheSource, SPIRVValue *TheSize,
+    const std::vector<SPIRVWord> &TheMemoryAccess, SPIRVBasicBlock *BB) {
+  return addInstruction(new SPIRVCopyMemorySized(TheTarget, TheSource, TheSize,
+                                                 TheMemoryAccess, BB),
+                        BB);
+}
+
+SPIRVInstruction *SPIRVModuleImpl::addVariable(
+    SPIRVType *Type, bool IsConstant, SPIRVLinkageTypeKind LinkageType,
+    SPIRVValue *Initializer, const std::string &Name,
+    SPIRVStorageClassKind StorageClass, SPIRVBasicBlock *BB) {
+  SPIRVVariable *Variable = new SPIRVVariable(Type, getId(), Initializer, Name,
+                                              StorageClass, BB, this);
+  if (BB)
+    return addInstruction(Variable, BB);
+
+  add(Variable);
+  if (LinkageType != LinkageTypeInternal)
+    Variable->setLinkageType(LinkageType);
+
+  // shader doesn't have the constant decoration
+  if (SrcLang != spv::SourceLanguageGLSL) {
+    Variable->setIsConstant(IsConstant);
+  }
+  return Variable;
+}
+
+SPIRVInstruction *SPIRVModuleImpl::addKillInst(SPIRVBasicBlock *BB) {
+  return addInstruction(new SPIRVKill(BB), BB);
+}
+
+SPIRVInstruction *
+SPIRVModuleImpl::addLoopMergeInst(SPIRVBasicBlock *merge,
+                                  SPIRVBasicBlock *continuation,
+                                  SPIRVBasicBlock *BB) {
+  // NOTE: not allowing any control hints, b/c llvm will have already optimized
+  // everything
+  return addInstruction(
+      new SPIRVLoopMerge(merge, continuation, spv::LoopControlMaskNone, BB),
+      BB);
+}
+
+SPIRVInstruction *SPIRVModuleImpl::addSelectionMergeInst(SPIRVBasicBlock *merge,
+                                                         SPIRVBasicBlock *BB) {
+  // NOTE: not allowing any control hints, b/c llvm will have already optimized
+  // everything
+  return addInstruction(
+      new SPIRVSelectionMerge(merge, spv::SelectionControlMaskNone, BB), BB);
+}
+
+template <class T>
+spv_ostream &operator<<(spv_ostream &O, const std::vector<T *> &V) {
+  for (auto &I : V)
+    O << *I;
+  return O;
+}
+
+template <class T, class B>
+spv_ostream &operator<<(spv_ostream &O, const std::multiset<T *, B> &V) {
+  for (auto &I : V)
+    O << *I;
+  return O;
+}
+
+// To satisfy SPIR-V spec requirement:
+// "All operands must be declared before being used",
+// we do DFS based topological sort
+// https://en.wikipedia.org/wiki/Topological_sorting#Depth-first_search
+class TopologicalSort {
+  enum DFSState : char { Unvisited, Discovered, Visited };
+  typedef std::vector<SPIRVType *> SPIRVTypeVec;
+  typedef std::vector<SPIRVValue *> SPIRVConstantVector;
+  typedef std::vector<SPIRVVariable *> SPIRVVariableVec;
+  typedef std::vector<SPIRVTypeForwardPointer *> SPIRVForwardPointerVec;
+  typedef std::function<bool(SPIRVEntry *, SPIRVEntry *)> IdComp;
+  typedef std::map<SPIRVEntry *, DFSState, IdComp> EntryStateMapTy;
+
+  SPIRVTypeVec TypeIntVec;
+  SPIRVConstantVector ConstIntVec;
+  SPIRVTypeVec TypeVec;
+  SPIRVConstantVector ConstVec;
+  SPIRVVariableVec VariableVec;
+  const SPIRVForwardPointerVec &ForwardPointerVec;
+  EntryStateMapTy EntryStateMap;
+
+  friend spv_ostream &operator<<(spv_ostream &O, const TopologicalSort &S);
+
+  // This method implements recursive depth-first search among all Entries in
+  // EntryStateMap. Traversing entries and adding them to corresponding
+  // container
+  // after visiting all dependent entries(post-order traversal) guarantees that
+  // the entry's operands will appear in the container before the entry itslef.
+  void visit(SPIRVEntry *E) {
+    DFSState &State = EntryStateMap[E];
+    assert(State != Discovered && "Cyclic dependency detected");
+    if (State == Visited)
+      return;
+    State = Discovered;
+    for (SPIRVEntry *Op : E->getNonLiteralOperands()) {
+      auto Comp = [&Op](SPIRVTypeForwardPointer *FwdPtr) {
+        return FwdPtr->getPointer() == Op;
+      };
+      // Skip forward referenced pointers
+      if (Op->getOpCode() == OpTypePointer &&
+          find_if(ForwardPointerVec.begin(), ForwardPointerVec.end(), Comp) !=
+              ForwardPointerVec.end())
+        continue;
+      visit(Op);
+    }
+    State = Visited;
+    Op OC = E->getOpCode();
+    if (OC == OpTypeInt)
+      TypeIntVec.push_back(static_cast<SPIRVType *>(E));
+    else if (isConstantOpCode(OC)) {
+      SPIRVConstant *C = static_cast<SPIRVConstant *>(E);
+      if (C->getType()->isTypeInt())
+        ConstIntVec.push_back(C);
+      else
+        ConstVec.push_back(C);
+    } else if (isTypeOpCode(OC))
+      TypeVec.push_back(static_cast<SPIRVType *>(E));
+    else if (E->isVariable())
+      VariableVec.push_back(static_cast<SPIRVVariable *>(E));
+  }
+
+public:
+  TopologicalSort(const SPIRVTypeVec &_TypeVec,
+                  const SPIRVConstantVector &_ConstVec,
+                  const SPIRVVariableVec &_VariableVec,
+                  const SPIRVForwardPointerVec &_ForwardPointerVec)
+      : ForwardPointerVec(_ForwardPointerVec),
+        EntryStateMap([](SPIRVEntry *a, SPIRVEntry *b) -> bool {
+          return a->getId() < b->getId();
+        }) {
+    // Collect entries for sorting
+    for (auto *T : _TypeVec)
+      EntryStateMap[T] = DFSState::Unvisited;
+    for (auto *C : _ConstVec)
+      EntryStateMap[C] = DFSState::Unvisited;
+    for (auto *V : _VariableVec)
+      EntryStateMap[V] = DFSState::Unvisited;
+    // Run topoligical sort
+    for (auto ES : EntryStateMap)
+      visit(ES.first);
+  }
+};
+
+spv_ostream &operator<<(spv_ostream &O, const TopologicalSort &S) {
+  O << S.TypeIntVec << S.ConstIntVec << S.TypeVec << S.ConstVec
+    << S.VariableVec;
+  return O;
+}
+
+spv_ostream &operator<<(spv_ostream &O, SPIRVModule &M) {
+  SPIRVModuleImpl &MI = *static_cast<SPIRVModuleImpl *>(&M);
+
+  SPIRVEncoder Encoder(O);
+  Encoder << MagicNumber << MI.SPIRVVersion
+          << (((SPIRVWord)MI.GeneratorId << 16) | MI.GeneratorVer)
+          << MI.NextId /* Bound for Id */
+          << MI.InstSchema;
+  O << SPIRVNL();
+
+  for (auto &I : MI.CapMap)
+    O << *I.second;
+
+  for (auto &I : M.getExtension()) {
+    assert(!I.empty() && "Invalid extension");
+    O << SPIRVExtension(&M, I);
+  }
+
+  for (auto &I : MI.IdBuiltinMap)
+    O << SPIRVExtInstImport(&M, I.first, SPIRVBuiltinSetNameMap::map(I.second));
+
+  O << SPIRVMemoryModel(&M);
+
+  for (auto &I : MI.EntryPointVec) {
+    for (auto &II : I.second) {
+      unsigned int io_var_count = 0;
+      const auto ep_iter = MI.getEntryPointIO().find(II);
+      if (ep_iter != MI.getEntryPointIO().end()) {
+        io_var_count += (unsigned int)ep_iter->second.size();
+      }
+      O << SPIRVEntryPoint(&M, I.first, II, M.get<SPIRVFunction>(II)->getName(),
+                           io_var_count);
+    }
+  }
+
+  for (auto &I : MI.EntryPointVec)
+    for (auto &II : I.second)
+      MI.get<SPIRVFunction>(II)->encodeExecutionModes(O);
+
+  O << MI.StringVec;
+
+  for (auto &I : M.getSourceExtension()) {
+    assert(!I.empty() && "Invalid source extension");
+    O << SPIRVSourceExtension(&M, I);
+  }
+
+  O << SPIRVSource(&M);
+
+  for (auto &I : MI.NamedId) {
+    M.getEntry(I)->encodeName(O);
+  }
+
+  O << MI.MemberNameVec << MI.LineVec << MI.DecGroupVec << MI.DecorateSet
+    << MI.GroupDecVec << MI.ForwardPointerVec
+    << TopologicalSort(MI.TypeVec, MI.ConstVec, MI.VariableVec,
+                       MI.ForwardPointerVec)
+    << SPIRVNL() << MI.FuncVec;
+  return O;
+}
+
+template <class T>
+void SPIRVModuleImpl::addTo(std::vector<T *> &V, SPIRVEntry *E) {
+  V.push_back(static_cast<T *>(E));
+}
+
+// The first decoration group includes all the previously defined decorates.
+// The second decoration group includes all the decorates defined between the
+// first and second decoration group. So long so forth.
+SPIRVDecorationGroup *SPIRVModuleImpl::addDecorationGroup() {
+  return addDecorationGroup(new SPIRVDecorationGroup(this, getId()));
+}
+
+SPIRVDecorationGroup *
+SPIRVModuleImpl::addDecorationGroup(SPIRVDecorationGroup *Group) {
+  add(Group);
+  Group->takeDecorates(DecorateSet);
+  DecGroupVec.push_back(Group);
+  SPIRVDBG(spvdbgs() << "[addDecorationGroup] {" << *Group << "}\n";
+           spvdbgs() << "  Remaining DecorateSet: {" << DecorateSet << "}\n");
+  assert(DecorateSet.empty());
+  return Group;
+}
+
+SPIRVGroupDecorateGeneric *
+SPIRVModuleImpl::addGroupDecorateGeneric(SPIRVGroupDecorateGeneric *GDec) {
+  add(GDec);
+  GDec->decorateTargets();
+  GroupDecVec.push_back(GDec);
+  return GDec;
+}
+SPIRVGroupDecorate *
+SPIRVModuleImpl::addGroupDecorate(SPIRVDecorationGroup *Group,
+                                  const std::vector<SPIRVEntry *> &Targets) {
+  auto GD = new SPIRVGroupDecorate(Group, getIds(Targets));
+  addGroupDecorateGeneric(GD);
+  return GD;
+}
+
+SPIRVGroupMemberDecorate *SPIRVModuleImpl::addGroupMemberDecorate(
+    SPIRVDecorationGroup *Group, const std::vector<SPIRVEntry *> &Targets) {
+  auto GMD = new SPIRVGroupMemberDecorate(Group, getIds(Targets));
+  addGroupDecorateGeneric(GMD);
+  return GMD;
+}
+
+SPIRVString *SPIRVModuleImpl::getString(const std::string &Str) {
+  auto Loc = StrMap.find(Str);
+  if (Loc != StrMap.end())
+    return Loc->second;
+  auto S = add(new SPIRVString(this, getId(), Str));
+  StrMap[Str] = S;
+  return S;
+}
+
+SPIRVMemberName *SPIRVModuleImpl::addMemberName(SPIRVTypeStruct *ST,
+                                                SPIRVWord MemberNumber,
+                                                const std::string &Name) {
+  return add(new SPIRVMemberName(ST, MemberNumber, Name));
+}
+
+void SPIRVModuleImpl::addUnknownStructField(SPIRVTypeStruct *Struct, unsigned I,
+                                            SPIRVId ID) {
+  UnknownStructFieldMap[Struct].push_back(std::make_pair(I, ID));
+}
+
+std::istream &operator>>(std::istream &I, SPIRVModule &M) {
+  SPIRVDecoder Decoder(I, M);
+  SPIRVModuleImpl &MI = *static_cast<SPIRVModuleImpl *>(&M);
+  // Disable automatic capability filling.
+  MI.setAutoAddCapability(false);
+
+  SPIRVWord Magic;
+  Decoder >> Magic;
+  assert(Magic == MagicNumber && "Invalid magic number");
+
+  Decoder >> MI.SPIRVVersion;
+  assert(MI.SPIRVVersion <= SPV_VERSION && "Unsupported SPIRV version number");
+
+  SPIRVWord Generator = 0;
+  Decoder >> Generator;
+  MI.GeneratorId = Generator >> 16;
+  MI.GeneratorVer = Generator & 0xFFFF;
+
+  // Bound for Id
+  Decoder >> MI.NextId;
+
+  Decoder >> MI.InstSchema;
+  assert(MI.InstSchema == SPIRVISCH_Default &&
+         "Unsupported instruction schema");
+
+  while (Decoder.getWordCountAndOpCode())
+    Decoder.getEntry();
+
+  // MI.optimizeDecorates(); // TODO/NOTE: disabled for now due to external
+  // issues
+  MI.resolveUnknownStructFields();
+  MI.createForwardPointers();
+  return I;
+}
+
+SPIRVModule *SPIRVModule::createSPIRVModule() { return new SPIRVModuleImpl; }
+
+SPIRVValue *SPIRVModuleImpl::getValue(SPIRVId TheId) const {
+  return get<SPIRVValue>(TheId);
+}
+
+SPIRVType *SPIRVModuleImpl::getValueType(SPIRVId TheId) const {
+  return get<SPIRVValue>(TheId)->getType();
+}
+
+std::vector<SPIRVValue *>
+SPIRVModuleImpl::getValues(const std::vector<SPIRVId> &IdVec) const {
+  std::vector<SPIRVValue *> ValueVec;
+  for (auto i : IdVec)
+    ValueVec.push_back(getValue(i));
+  return ValueVec;
+}
+
+std::vector<SPIRVType *>
+SPIRVModuleImpl::getValueTypes(const std::vector<SPIRVId> &IdVec) const {
+  std::vector<SPIRVType *> TypeVec;
+  for (auto i : IdVec)
+    TypeVec.push_back(getValue(i)->getType());
+  return TypeVec;
+}
+
+std::vector<SPIRVId>
+SPIRVModuleImpl::getIds(const std::vector<SPIRVEntry *> &ValueVec) const {
+  std::vector<SPIRVId> IdVec;
+  for (auto i : ValueVec)
+    IdVec.push_back(i->getId());
+  return IdVec;
+}
+
+std::vector<SPIRVId>
+SPIRVModuleImpl::getIds(const std::vector<SPIRVValue *> &ValueVec) const {
+  std::vector<SPIRVId> IdVec;
+  for (auto i : ValueVec)
+    IdVec.push_back(i->getId());
+  return IdVec;
+}
+
+SPIRVInstTemplateBase *
+SPIRVModuleImpl::addInstTemplate(Op OC, SPIRVBasicBlock *BB, SPIRVType *Ty) {
+  assert(!Ty || !Ty->isTypeVoid());
+  SPIRVId Id = Ty ? getId() : SPIRVID_INVALID;
+  auto Ins = SPIRVInstTemplateBase::create(OC, Ty, Id, BB, this);
+  BB->addInstruction(Ins);
+  return Ins;
+}
+
+SPIRVInstTemplateBase *
+SPIRVModuleImpl::addInstTemplate(Op OC, const std::vector<SPIRVWord> &Ops,
+                                 SPIRVBasicBlock *BB, SPIRVType *Ty) {
+  assert(!Ty || !Ty->isTypeVoid());
+  SPIRVId Id = Ty ? getId() : SPIRVID_INVALID;
+  auto Ins = SPIRVInstTemplateBase::create(OC, Ty, Id, Ops, BB, this);
+  BB->addInstruction(Ins);
+  return Ins;
+}
+
+SPIRVDbgInfo::SPIRVDbgInfo(SPIRVModule *TM) : M(TM) {}
+
+std::string SPIRVDbgInfo::getEntryPointFileStr(SPIRVExecutionModelKind EM,
+                                               unsigned I) {
+  if (M->getNumEntryPoints(EM) == 0)
+    return "";
+  return getFunctionFileStr(M->getEntryPoint(EM, I));
+}
+
+std::string SPIRVDbgInfo::getFunctionFileStr(SPIRVFunction *F) {
+  if (F->hasLine())
+    return F->getLine()->getFileNameStr();
+  return "";
+}
+
+unsigned SPIRVDbgInfo::getFunctionLineNo(SPIRVFunction *F) {
+  if (F->hasLine())
+    return F->getLine()->getLine();
+  return 0;
+}
+
+bool IsSPIRVBinary(const std::string &Img) {
+  if (Img.size() < sizeof(unsigned))
+    return false;
+  auto Magic = reinterpret_cast<const unsigned *>(Img.data());
+  return *Magic == MagicNumber;
+}
+
+#ifdef _SPIRV_SUPPORT_TEXT_FMT
+
+bool ConvertSPIRV(std::istream &IS, spv_ostream &OS, std::string &ErrMsg,
+                  bool FromText, bool ToText) {
+  auto SaveOpt = SPIRVUseTextFormat;
+  SPIRVUseTextFormat = FromText;
+  SPIRVModuleImpl M;
+  IS >> M;
+  if (M.getError(ErrMsg) != SPIRVEC_Success) {
+    SPIRVUseTextFormat = SaveOpt;
+    return false;
+  }
+  SPIRVUseTextFormat = ToText;
+  OS << M;
+  if (M.getError(ErrMsg) != SPIRVEC_Success) {
+    SPIRVUseTextFormat = SaveOpt;
+    return false;
+  }
+  SPIRVUseTextFormat = SaveOpt;
+  return true;
+}
+
+bool IsSPIRVText(const std::string &Img) {
+  std::istringstream SS(Img);
+  unsigned Magic = 0;
+  SS >> Magic;
+  if (SS.bad())
+    return false;
+  return Magic == MagicNumber;
+}
+
+bool ConvertSPIRV(std::string &Input, std::string &Out, std::string &ErrMsg,
+                  bool ToText) {
+  auto FromText = IsSPIRVText(Input);
+  if (ToText == FromText) {
+    Out = Input;
+    return true;
+  }
+  std::istringstream IS(Input);
+#ifdef _SPIRV_LLVM_API
+  llvm::raw_string_ostream OS(Out);
+#else
+  std::ostringstream OS;
+#endif
+  if (!ConvertSPIRV(IS, OS, ErrMsg, FromText, ToText))
+    return false;
+  Out = OS.str();
+  return true;
+}
+
+#endif // _SPIRV_SUPPORT_TEXT_FMT
+}
diff --git a/lib/SPIRV/libSPIRV/SPIRVModule.h b/lib/SPIRV/libSPIRV/SPIRVModule.h
new file mode 100644
index 0000000..71db2cc
--- /dev/null
+++ b/lib/SPIRV/libSPIRV/SPIRVModule.h
@@ -0,0 +1,401 @@
+//===- SPIRVModule.h - Class to represent a SPIR-V module -------*- C++ -*-===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+/// \file
+///
+/// This file defines Module class for SPIR-V.
+///
+//===----------------------------------------------------------------------===//
+
+#ifndef SPIRVMODULE_HPP_
+#define SPIRVMODULE_HPP_
+
+#include "SPIRVEntry.h"
+
+#include <iostream>
+#include <set>
+#include <string>
+#include <unordered_map>
+#include <unordered_set>
+#include <vector>
+
+namespace SPIRV {
+
+class SPIRVBasicBlock;
+class SPIRVConstant;
+class SPIRVEntry;
+class SPIRVFunction;
+class SPIRVInstruction;
+class SPIRVType;
+class SPIRVTypeArray;
+class SPIRVTypeRuntimeArray;
+class SPIRVTypeBool;
+class SPIRVTypeFloat;
+class SPIRVTypeFunction;
+class SPIRVTypeInt;
+class SPIRVTypeOpaque;
+class SPIRVTypePointer;
+class SPIRVTypeImage;
+class SPIRVTypeSampler;
+class SPIRVTypeSampledImage;
+class SPIRVTypePipeStorage;
+class SPIRVTypeStruct;
+class SPIRVTypeVector;
+class SPIRVTypeVoid;
+class SPIRVTypeDeviceEvent;
+class SPIRVTypeQueue;
+class SPIRVTypePipe;
+class SPIRVValue;
+class SPIRVVariable;
+class SPIRVDecorateGeneric;
+class SPIRVDecorationGroup;
+class SPIRVGroupDecorate;
+class SPIRVGroupMemberDecorate;
+class SPIRVGroupDecorateGeneric;
+class SPIRVInstTemplateBase;
+
+typedef SPIRVBasicBlock SPIRVLabel;
+struct SPIRVTypeImageDescriptor;
+
+class SPIRVModule {
+public:
+  typedef std::map<SPIRVCapabilityKind, SPIRVCapability *> SPIRVCapMap;
+
+  static SPIRVModule *createSPIRVModule();
+  SPIRVModule();
+  virtual ~SPIRVModule();
+
+  // Object query functions
+  virtual bool exist(SPIRVId) const = 0;
+  virtual bool exist(SPIRVId, SPIRVEntry **) const = 0;
+  template <class T> T *get(SPIRVId Id) const {
+    return static_cast<T *>(getEntry(Id));
+  }
+  virtual SPIRVEntry *getEntry(SPIRVId) const = 0;
+  virtual bool hasDebugInfo() const = 0;
+
+  // Error handling functions
+  virtual SPIRVErrorLog &getErrorLog() = 0;
+  virtual SPIRVErrorCode getError(std::string &) = 0;
+
+  // Module query functions
+  virtual SPIRVAddressingModelKind getAddressingModel() = 0;
+  virtual const SPIRVCapMap &getCapability() const = 0;
+  virtual bool hasCapability(SPIRVCapabilityKind) const = 0;
+  virtual SPIRVExtInstSetKind getBuiltinSet(SPIRVId) const = 0;
+  virtual SPIRVFunction *getEntryPoint(SPIRVExecutionModelKind,
+                                       unsigned) const = 0;
+  virtual const std::unordered_map<SPIRVId, std::vector<SPIRVVariable *>> &
+  getEntryPointIO() const = 0;
+  virtual std::set<std::string> &getExtension() = 0;
+  virtual SPIRVFunction *getFunction(unsigned) const = 0;
+  virtual SPIRVVariable *getVariable(unsigned) const = 0;
+  virtual SPIRVMemoryModelKind getMemoryModel() const = 0;
+  virtual unsigned getNumFunctions() const = 0;
+  virtual unsigned getNumEntryPoints(SPIRVExecutionModelKind) const = 0;
+  virtual unsigned getNumVariables() const = 0;
+  virtual SourceLanguage getSourceLanguage(SPIRVWord *) const = 0;
+  virtual std::set<std::string> &getSourceExtension() = 0;
+  virtual SPIRVValue *getValue(SPIRVId TheId) const = 0;
+  virtual std::vector<SPIRVValue *>
+  getValues(const std::vector<SPIRVId> &) const = 0;
+  virtual std::vector<SPIRVId>
+  getIds(const std::vector<SPIRVEntry *> &) const = 0;
+  virtual std::vector<SPIRVId>
+  getIds(const std::vector<SPIRVValue *> &) const = 0;
+  virtual SPIRVType *getValueType(SPIRVId TheId) const = 0;
+  virtual std::vector<SPIRVType *>
+  getValueTypes(const std::vector<SPIRVId> &) const = 0;
+  virtual SPIRVConstant *getLiteralAsConstant(unsigned Literal,
+                                              bool is_signed) = 0;
+  virtual bool isEntryPoint(SPIRVExecutionModelKind, SPIRVId) const = 0;
+  virtual unsigned short getGeneratorId() const = 0;
+  virtual unsigned short getGeneratorVer() const = 0;
+  virtual SPIRVWord getSPIRVVersion() const = 0;
+
+  // Module changing functions
+  virtual bool importBuiltinSet(const std::string &, SPIRVId *) = 0;
+  virtual bool importBuiltinSetWithId(const std::string &, SPIRVId) = 0;
+  virtual void setAddressingModel(SPIRVAddressingModelKind) = 0;
+  virtual void setAlignment(SPIRVValue *, SPIRVWord) = 0;
+  virtual void setMemoryModel(SPIRVMemoryModelKind) = 0;
+  virtual void setName(SPIRVEntry *, const std::string &) = 0;
+  virtual void setSourceLanguage(SourceLanguage, SPIRVWord) = 0;
+  virtual void optimizeDecorates() = 0;
+  virtual void setAutoAddCapability(bool E) { AutoAddCapability = E; }
+  virtual void setValidateCapability(bool E) { ValidateCapability = E; }
+  virtual void setGeneratorId(unsigned short) = 0;
+  virtual void setGeneratorVer(unsigned short) = 0;
+  virtual void resolveUnknownStructFields() = 0;
+  virtual void setSPIRVVersion(SPIRVWord) = 0;
+
+  void setMinSPIRVVersion(SPIRVWord Ver) {
+    setSPIRVVersion(std::max(Ver, getSPIRVVersion()));
+  }
+
+  // Object creation functions
+  template <class T> T *add(T *Entry) {
+    addEntry(Entry);
+    return Entry;
+  }
+  virtual SPIRVEntry *addEntry(SPIRVEntry *) = 0;
+  virtual SPIRVBasicBlock *addBasicBlock(SPIRVFunction *,
+                                         SPIRVId Id = SPIRVID_INVALID) = 0;
+  virtual SPIRVString *getString(const std::string &Str) = 0;
+  virtual SPIRVMemberName *addMemberName(SPIRVTypeStruct *ST,
+                                         SPIRVWord MemberNumber,
+                                         const std::string &Name) = 0;
+  virtual void addUnknownStructField(SPIRVTypeStruct *, unsigned idx,
+                                     SPIRVId id) = 0;
+  virtual SPIRVLine *addLine(SPIRVEntry *E, SPIRVString *FileName,
+                             SPIRVWord Line, SPIRVWord Column) = 0;
+  virtual const SPIRVDecorateGeneric *
+  addDecorate(const SPIRVDecorateGeneric *) = 0;
+  virtual SPIRVDecorationGroup *addDecorationGroup() = 0;
+  virtual SPIRVDecorationGroup *
+  addDecorationGroup(SPIRVDecorationGroup *Group) = 0;
+  virtual SPIRVGroupDecorate *
+  addGroupDecorate(SPIRVDecorationGroup *Group,
+                   const std::vector<SPIRVEntry *> &Targets) = 0;
+  virtual SPIRVGroupMemberDecorate *
+  addGroupMemberDecorate(SPIRVDecorationGroup *Group,
+                         const std::vector<SPIRVEntry *> &Targets) = 0;
+  virtual SPIRVGroupDecorateGeneric *
+  addGroupDecorateGeneric(SPIRVGroupDecorateGeneric *GDec) = 0;
+  virtual void addEntryPoint(SPIRVExecutionModelKind, SPIRVId) = 0;
+  virtual void addEntryPointIO(SPIRVId EntryPoint, SPIRVVariable *var) = 0;
+  virtual SPIRVForward *addForward(SPIRVType *Ty) = 0;
+  virtual SPIRVForward *addForward(SPIRVId, SPIRVType *Ty) = 0;
+  virtual SPIRVFunction *addFunction(SPIRVFunction *) = 0;
+  virtual SPIRVFunction *addFunction(SPIRVTypeFunction *,
+                                     SPIRVId Id = SPIRVID_INVALID) = 0;
+  virtual SPIRVEntry *replaceForward(SPIRVForward *, SPIRVEntry *) = 0;
+
+  // Type creation functions
+  virtual SPIRVTypeArray *addArrayType(SPIRVType *, SPIRVConstant *) = 0;
+  virtual SPIRVTypeRuntimeArray *addRuntimeArrayType(SPIRVType *) = 0;
+  virtual SPIRVTypeBool *addBoolType() = 0;
+  virtual SPIRVTypeFloat *addFloatType(unsigned) = 0;
+  virtual SPIRVTypeFunction *
+  addFunctionType(SPIRVType *, const std::vector<SPIRVType *> &) = 0;
+  virtual SPIRVTypeImage *addImageType(SPIRVType *,
+                                       const SPIRVTypeImageDescriptor &) = 0;
+  virtual SPIRVTypeImage *addImageType(SPIRVType *,
+                                       const SPIRVTypeImageDescriptor &,
+                                       SPIRVAccessQualifierKind) = 0;
+  virtual SPIRVTypeSampler *addSamplerType() = 0;
+  virtual SPIRVTypePipeStorage *addPipeStorageType() = 0;
+  virtual SPIRVTypeSampledImage *addSampledImageType(SPIRVTypeImage *T) = 0;
+  virtual SPIRVTypeInt *addIntegerType(unsigned, bool) = 0;
+  virtual SPIRVTypeOpaque *addOpaqueType(const std::string &) = 0;
+  virtual SPIRVTypePointer *addPointerType(SPIRVStorageClassKind,
+                                           SPIRVType *) = 0;
+  virtual SPIRVTypeStruct *openStructType(unsigned, const std::string &) = 0;
+  virtual void closeStructType(SPIRVTypeStruct *, bool) = 0;
+  virtual SPIRVTypeVector *addVectorType(SPIRVType *, SPIRVWord) = 0;
+  virtual SPIRVTypeVoid *addVoidType() = 0;
+  virtual SPIRVType *addOpaqueGenericType(Op) = 0;
+  virtual SPIRVTypeDeviceEvent *addDeviceEventType() = 0;
+  virtual SPIRVTypeQueue *addQueueType() = 0;
+  virtual SPIRVTypePipe *addPipeType() = 0;
+  virtual void createForwardPointers() = 0;
+
+  // Constants creation functions
+  virtual SPIRVValue *
+  addCompositeConstant(SPIRVType *, const std::vector<SPIRVValue *> &) = 0;
+  virtual SPIRVValue *addConstant(SPIRVValue *) = 0;
+  virtual SPIRVValue *addConstant(SPIRVType *, uint64_t) = 0;
+  virtual SPIRVValue *addDoubleConstant(SPIRVTypeFloat *, double) = 0;
+  virtual SPIRVValue *addFloatConstant(SPIRVTypeFloat *, float) = 0;
+  virtual SPIRVValue *addIntegerConstant(SPIRVTypeInt *, uint64_t) = 0;
+  virtual SPIRVValue *addNullConstant(SPIRVType *) = 0;
+  virtual SPIRVValue *addUndef(SPIRVType *TheType) = 0;
+  virtual SPIRVValue *addUndefInst(SPIRVType *TheType, SPIRVBasicBlock *) = 0;
+  virtual SPIRVValue *addSamplerConstant(SPIRVType *TheType, SPIRVWord AddrMode,
+                                         SPIRVWord ParametricMode,
+                                         SPIRVWord FilterMode) = 0;
+  virtual SPIRVValue *addPipeStorageConstant(SPIRVType *TheType,
+                                             SPIRVWord PacketSize,
+                                             SPIRVWord PacketAlign,
+                                             SPIRVWord Capacity) = 0;
+
+  // Instruction creation functions
+  virtual SPIRVInstruction *addPtrAccessChainInst(SPIRVType *, SPIRVValue *,
+                                                  std::vector<SPIRVValue *>,
+                                                  SPIRVBasicBlock *, bool) = 0;
+  virtual SPIRVInstruction *addAccessChainInst(SPIRVType *, SPIRVValue *,
+                                               std::vector<SPIRVValue *>,
+                                               SPIRVBasicBlock *, bool) = 0;
+  virtual SPIRVInstruction *
+  addAsyncGroupCopy(SPIRVValue *Scope, SPIRVValue *Dest, SPIRVValue *Src,
+                    SPIRVValue *NumElems, SPIRVValue *Stride, SPIRVValue *Event,
+                    SPIRVBasicBlock *BB) = 0;
+  virtual SPIRVInstruction *addBinaryInst(Op, SPIRVType *, SPIRVValue *,
+                                          SPIRVValue *, SPIRVBasicBlock *) = 0;
+  virtual SPIRVInstruction *addBranchConditionalInst(SPIRVValue *, SPIRVLabel *,
+                                                     SPIRVLabel *,
+                                                     SPIRVBasicBlock *) = 0;
+  virtual SPIRVInstruction *addBranchInst(SPIRVLabel *, SPIRVBasicBlock *) = 0;
+  virtual SPIRVInstruction *addUnreachableInst(SPIRVBasicBlock *) = 0;
+  virtual SPIRVInstruction *addExtInst(SPIRVType *, SPIRVWord, SPIRVWord,
+                                       const std::vector<SPIRVWord> &,
+                                       SPIRVBasicBlock *) = 0;
+  virtual SPIRVInstruction *addExtInst(SPIRVType *, SPIRVWord, SPIRVWord,
+                                       const std::vector<SPIRVValue *> &,
+                                       SPIRVBasicBlock *) = 0;
+  virtual void addCapability(SPIRVCapabilityKind) = 0;
+  template <typename T> void addCapabilities(const T &Caps) {
+    for (auto I : Caps)
+      addCapability(I);
+  }
+  /// Used by SPIRV entries to add required capability internally.
+  /// Should not be used by users directly.
+  virtual void addCapabilityInternal(SPIRVCapabilityKind) = 0;
+  virtual SPIRVInstruction *addCallInst(SPIRVFunction *,
+                                        const std::vector<SPIRVWord> &,
+                                        SPIRVBasicBlock *) = 0;
+  virtual SPIRVInstruction *
+  addCompositeExtractInst(SPIRVType *, SPIRVValue *,
+                          const std::vector<SPIRVWord> &,
+                          SPIRVBasicBlock *) = 0;
+  virtual SPIRVInstruction *
+  addCompositeInsertInst(SPIRVValue *, SPIRVValue *,
+                         const std::vector<SPIRVWord> &, SPIRVBasicBlock *) = 0;
+  virtual SPIRVInstruction *addCopyObjectInst(SPIRVType *, SPIRVValue *,
+                                              SPIRVBasicBlock *) = 0;
+  virtual SPIRVInstruction *addCopyMemoryInst(SPIRVValue *, SPIRVValue *,
+                                              const std::vector<SPIRVWord> &,
+                                              SPIRVBasicBlock *) = 0;
+  virtual SPIRVInstruction *
+  addCopyMemorySizedInst(SPIRVValue *, SPIRVValue *, SPIRVValue *,
+                         const std::vector<SPIRVWord> &, SPIRVBasicBlock *) = 0;
+  virtual SPIRVInstruction *addCmpInst(Op, SPIRVType *, SPIRVValue *,
+                                       SPIRVValue *, SPIRVBasicBlock *) = 0;
+  virtual SPIRVInstruction *addControlBarrierInst(SPIRVValue *ExecKind,
+                                                  SPIRVValue *MemKind,
+                                                  SPIRVValue *MemSema,
+                                                  SPIRVBasicBlock *BB) = 0;
+  virtual SPIRVInstruction *addGroupInst(Op OpCode, SPIRVType *Type,
+                                         Scope Scope,
+                                         const std::vector<SPIRVValue *> &Ops,
+                                         SPIRVBasicBlock *BB) = 0;
+  virtual SPIRVInstTemplateBase *addInstTemplate(Op OC, SPIRVBasicBlock *BB,
+                                                 SPIRVType *Ty) = 0;
+  virtual SPIRVInstTemplateBase *
+  addInstTemplate(Op OC, const std::vector<SPIRVWord> &Ops, SPIRVBasicBlock *BB,
+                  SPIRVType *Ty) = 0;
+  virtual SPIRVInstruction *addLoadInst(SPIRVValue *,
+                                        const std::vector<SPIRVWord> &,
+                                        SPIRVBasicBlock *) = 0;
+  virtual SPIRVInstruction *addMemoryBarrierInst(Scope ScopeKind,
+                                                 SPIRVWord MemFlag,
+                                                 SPIRVBasicBlock *BB) = 0;
+  virtual SPIRVInstruction *addPhiInst(SPIRVType *, std::vector<SPIRVValue *>,
+                                       SPIRVBasicBlock *) = 0;
+  virtual SPIRVInstruction *addReturnInst(SPIRVBasicBlock *) = 0;
+  virtual SPIRVInstruction *addReturnValueInst(SPIRVValue *,
+                                               SPIRVBasicBlock *) = 0;
+  virtual SPIRVInstruction *addSelectInst(SPIRVValue *, SPIRVValue *,
+                                          SPIRVValue *, SPIRVBasicBlock *) = 0;
+  virtual SPIRVInstruction *addStoreInst(SPIRVValue *, SPIRVValue *,
+                                         const std::vector<SPIRVWord> &,
+                                         SPIRVBasicBlock *) = 0;
+  virtual SPIRVInstruction *addSwitchInst(
+      SPIRVValue *, SPIRVBasicBlock *,
+      const std::vector<std::pair<std::vector<SPIRVWord>, SPIRVBasicBlock *>> &,
+      SPIRVBasicBlock *) = 0;
+  virtual SPIRVInstruction *addUnaryInst(Op, SPIRVType *, SPIRVValue *,
+                                         SPIRVBasicBlock *) = 0;
+  virtual SPIRVInstruction *addVariable(SPIRVType *, bool, SPIRVLinkageTypeKind,
+                                        SPIRVValue *, const std::string &,
+                                        SPIRVStorageClassKind,
+                                        SPIRVBasicBlock *) = 0;
+  virtual SPIRVValue *
+  addVectorShuffleInst(SPIRVType *Type, SPIRVValue *Vec1, SPIRVValue *Vec2,
+                       const std::vector<SPIRVWord> &Components,
+                       SPIRVBasicBlock *BB) = 0;
+  virtual SPIRVInstruction *addVectorExtractDynamicInst(SPIRVValue *,
+                                                        SPIRVValue *,
+                                                        SPIRVBasicBlock *) = 0;
+  virtual SPIRVInstruction *addVectorInsertDynamicInst(SPIRVValue *,
+                                                       SPIRVValue *,
+                                                       SPIRVValue *,
+                                                       SPIRVBasicBlock *) = 0;
+
+  // GLSL/shader functions
+  virtual SPIRVInstruction *addKillInst(SPIRVBasicBlock *) = 0;
+  virtual SPIRVInstruction *addLoopMergeInst(SPIRVBasicBlock *merge,
+                                             SPIRVBasicBlock *continuation,
+                                             SPIRVBasicBlock *BB) = 0;
+  virtual SPIRVInstruction *addSelectionMergeInst(SPIRVBasicBlock *merge,
+                                                  SPIRVBasicBlock *BB) = 0;
+
+  // I/O functions
+  friend spv_ostream &operator<<(spv_ostream &O, SPIRVModule &M);
+  friend std::istream &operator>>(std::istream &I, SPIRVModule &M);
+
+protected:
+  bool AutoAddCapability;
+  bool ValidateCapability;
+};
+
+class SPIRVDbgInfo {
+public:
+  SPIRVDbgInfo(SPIRVModule *TM);
+  std::string getEntryPointFileStr(SPIRVExecutionModelKind, unsigned);
+  std::string getFunctionFileStr(SPIRVFunction *);
+  unsigned getFunctionLineNo(SPIRVFunction *);
+
+private:
+  std::unordered_map<SPIRVFunction *, SPIRVLine *> FuncMap;
+  const std::string ModuleFileStr;
+  SPIRVModule *M;
+};
+
+#ifdef _SPIRV_SUPPORT_TEXT_FMT
+
+/// Convert SPIR-V between binary and internel text formats.
+/// This function is not thread safe and should not be used in multi-thread
+/// applications unless guarded by a critical section.
+bool ConvertSPIRV(std::istream &IS, spv_ostream &OS, std::string &ErrMsg,
+                  bool FromText, bool ToText);
+
+/// Convert SPIR-V between binary and internel text formats.
+/// This function is not thread safe and should not be used in multi-thread
+/// applications unless guarded by a critical section.
+bool ConvertSPIRV(std::string &Input, std::string &Out, std::string &ErrMsg,
+                  bool ToText);
+#endif
+}
+
+#endif /* SPIRVMODULE_HPP_ */
diff --git a/lib/SPIRV/libSPIRV/SPIRVNameMapEnum.h b/lib/SPIRV/libSPIRV/SPIRVNameMapEnum.h
new file mode 100644
index 0000000..d6c1b6d
--- /dev/null
+++ b/lib/SPIRV/libSPIRV/SPIRVNameMapEnum.h
@@ -0,0 +1,471 @@
+//===- SPIRVNameMapEnum.h - SPIR-V NameMap enums ----------------*- C++ -*-===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+/// \file
+///
+/// This file defines SPIR-V NameMap enums.
+///
+//===----------------------------------------------------------------------===//
+// WARNING:
+//
+// This file has been generated using `tools/spirv-tool/gen_spirv.bash` and
+// should not be modified manually. If the file needs to be updated, edit the
+// script and any other source file instead, before re-generating this file.
+//===----------------------------------------------------------------------===//
+
+#ifndef SPIRVNAMEMAPENUM_H_
+#define SPIRVNAMEMAPENUM_H_
+
+#include "spirv.hpp"
+#include "SPIRVEnum.h"
+
+using namespace spv;
+
+namespace SPIRV {
+
+template <> inline void SPIRVMap<SourceLanguage, std::string>::init() {
+  add(SourceLanguageUnknown, "Unknown");
+  add(SourceLanguageESSL, "ESSL");
+  add(SourceLanguageGLSL, "GLSL");
+  add(SourceLanguageOpenCL_C, "OpenCL_C");
+  add(SourceLanguageOpenCL_CPP, "OpenCL_CPP");
+}
+SPIRV_DEF_NAMEMAP(SourceLanguage, SPIRVSourceLanguageNameMap)
+
+template <> inline void SPIRVMap<ExecutionModel, std::string>::init() {
+  add(ExecutionModelVertex, "Vertex");
+  add(ExecutionModelTessellationControl, "TessellationControl");
+  add(ExecutionModelTessellationEvaluation, "TessellationEvaluation");
+  add(ExecutionModelGeometry, "Geometry");
+  add(ExecutionModelFragment, "Fragment");
+  add(ExecutionModelGLCompute, "GLCompute");
+  add(ExecutionModelKernel, "Kernel");
+}
+SPIRV_DEF_NAMEMAP(ExecutionModel, SPIRVExecutionModelNameMap)
+
+template <> inline void SPIRVMap<AddressingModel, std::string>::init() {
+  add(AddressingModelLogical, "Logical");
+  add(AddressingModelPhysical32, "Physical32");
+  add(AddressingModelPhysical64, "Physical64");
+}
+SPIRV_DEF_NAMEMAP(AddressingModel, SPIRVAddressingModelNameMap)
+
+template <> inline void SPIRVMap<MemoryModel, std::string>::init() {
+  add(MemoryModelSimple, "Simple");
+  add(MemoryModelGLSL450, "GLSL450");
+  add(MemoryModelOpenCL, "OpenCL");
+}
+SPIRV_DEF_NAMEMAP(MemoryModel, SPIRVMemoryModelNameMap)
+
+template <> inline void SPIRVMap<ExecutionMode, std::string>::init() {
+  add(ExecutionModeInvocations, "Invocations");
+  add(ExecutionModeSpacingEqual, "SpacingEqual");
+  add(ExecutionModeSpacingFractionalEven, "SpacingFractionalEven");
+  add(ExecutionModeSpacingFractionalOdd, "SpacingFractionalOdd");
+  add(ExecutionModeVertexOrderCw, "VertexOrderCw");
+  add(ExecutionModeVertexOrderCcw, "VertexOrderCcw");
+  add(ExecutionModePixelCenterInteger, "PixelCenterInteger");
+  add(ExecutionModeOriginUpperLeft, "OriginUpperLeft");
+  add(ExecutionModeOriginLowerLeft, "OriginLowerLeft");
+  add(ExecutionModeEarlyFragmentTests, "EarlyFragmentTests");
+  add(ExecutionModePointMode, "PointMode");
+  add(ExecutionModeXfb, "Xfb");
+  add(ExecutionModeDepthReplacing, "DepthReplacing");
+  add(ExecutionModeDepthGreater, "DepthGreater");
+  add(ExecutionModeDepthLess, "DepthLess");
+  add(ExecutionModeDepthUnchanged, "DepthUnchanged");
+  add(ExecutionModeLocalSize, "LocalSize");
+  add(ExecutionModeLocalSizeHint, "LocalSizeHint");
+  add(ExecutionModeInputPoints, "InputPoints");
+  add(ExecutionModeInputLines, "InputLines");
+  add(ExecutionModeInputLinesAdjacency, "InputLinesAdjacency");
+  add(ExecutionModeTriangles, "Triangles");
+  add(ExecutionModeInputTrianglesAdjacency, "InputTrianglesAdjacency");
+  add(ExecutionModeQuads, "Quads");
+  add(ExecutionModeIsolines, "Isolines");
+  add(ExecutionModeOutputVertices, "OutputVertices");
+  add(ExecutionModeOutputPoints, "OutputPoints");
+  add(ExecutionModeOutputLineStrip, "OutputLineStrip");
+  add(ExecutionModeOutputTriangleStrip, "OutputTriangleStrip");
+  add(ExecutionModeVecTypeHint, "VecTypeHint");
+  add(ExecutionModeContractionOff, "ContractionOff");
+}
+SPIRV_DEF_NAMEMAP(ExecutionMode, SPIRVExecutionModeNameMap)
+
+template <> inline void SPIRVMap<StorageClass, std::string>::init() {
+  add(StorageClassUniformConstant, "UniformConstant");
+  add(StorageClassInput, "Input");
+  add(StorageClassUniform, "Uniform");
+  add(StorageClassOutput, "Output");
+  add(StorageClassWorkgroup, "Workgroup");
+  add(StorageClassCrossWorkgroup, "CrossWorkgroup");
+  add(StorageClassPrivate, "Private");
+  add(StorageClassFunction, "Function");
+  add(StorageClassGeneric, "Generic");
+  add(StorageClassPushConstant, "PushConstant");
+  add(StorageClassAtomicCounter, "AtomicCounter");
+  add(StorageClassImage, "Image");
+}
+SPIRV_DEF_NAMEMAP(StorageClass, SPIRVStorageClassNameMap)
+
+template <> inline void SPIRVMap<Dim, std::string>::init() {
+  add(Dim1D, "1D");
+  add(Dim2D, "2D");
+  add(Dim3D, "3D");
+  add(DimCube, "Cube");
+  add(DimRect, "Rect");
+  add(DimBuffer, "Buffer");
+  add(DimSubpassData, "SubpassData");
+}
+SPIRV_DEF_NAMEMAP(Dim, SPIRVDimNameMap)
+
+template <> inline void SPIRVMap<SamplerAddressingMode, std::string>::init() {
+  add(SamplerAddressingModeNone, "None");
+  add(SamplerAddressingModeClampToEdge, "ClampToEdge");
+  add(SamplerAddressingModeClamp, "Clamp");
+  add(SamplerAddressingModeRepeat, "Repeat");
+  add(SamplerAddressingModeRepeatMirrored, "RepeatMirrored");
+}
+SPIRV_DEF_NAMEMAP(SamplerAddressingMode, SPIRVSamplerAddressingModeNameMap)
+
+template <> inline void SPIRVMap<SamplerFilterMode, std::string>::init() {
+  add(SamplerFilterModeNearest, "Nearest");
+  add(SamplerFilterModeLinear, "Linear");
+}
+SPIRV_DEF_NAMEMAP(SamplerFilterMode, SPIRVSamplerFilterModeNameMap)
+
+template <> inline void SPIRVMap<ImageFormat, std::string>::init() {
+  add(ImageFormatUnknown, "Unknown");
+  add(ImageFormatRgba32f, "Rgba32f");
+  add(ImageFormatRgba16f, "Rgba16f");
+  add(ImageFormatR32f, "R32f");
+  add(ImageFormatRgba8, "Rgba8");
+  add(ImageFormatRgba8Snorm, "Rgba8Snorm");
+  add(ImageFormatRg32f, "Rg32f");
+  add(ImageFormatRg16f, "Rg16f");
+  add(ImageFormatR11fG11fB10f, "R11fG11fB10f");
+  add(ImageFormatR16f, "R16f");
+  add(ImageFormatRgba16, "Rgba16");
+  add(ImageFormatRgb10A2, "Rgb10A2");
+  add(ImageFormatRg16, "Rg16");
+  add(ImageFormatRg8, "Rg8");
+  add(ImageFormatR16, "R16");
+  add(ImageFormatR8, "R8");
+  add(ImageFormatRgba16Snorm, "Rgba16Snorm");
+  add(ImageFormatRg16Snorm, "Rg16Snorm");
+  add(ImageFormatRg8Snorm, "Rg8Snorm");
+  add(ImageFormatR16Snorm, "R16Snorm");
+  add(ImageFormatR8Snorm, "R8Snorm");
+  add(ImageFormatRgba32i, "Rgba32i");
+  add(ImageFormatRgba16i, "Rgba16i");
+  add(ImageFormatRgba8i, "Rgba8i");
+  add(ImageFormatR32i, "R32i");
+  add(ImageFormatRg32i, "Rg32i");
+  add(ImageFormatRg16i, "Rg16i");
+  add(ImageFormatRg8i, "Rg8i");
+  add(ImageFormatR16i, "R16i");
+  add(ImageFormatR8i, "R8i");
+  add(ImageFormatRgba32ui, "Rgba32ui");
+  add(ImageFormatRgba16ui, "Rgba16ui");
+  add(ImageFormatRgba8ui, "Rgba8ui");
+  add(ImageFormatR32ui, "R32ui");
+  add(ImageFormatRgb10a2ui, "Rgb10a2ui");
+  add(ImageFormatRg32ui, "Rg32ui");
+  add(ImageFormatRg16ui, "Rg16ui");
+  add(ImageFormatRg8ui, "Rg8ui");
+  add(ImageFormatR16ui, "R16ui");
+  add(ImageFormatR8ui, "R8ui");
+}
+SPIRV_DEF_NAMEMAP(ImageFormat, SPIRVImageFormatNameMap)
+
+template <> inline void SPIRVMap<ImageChannelOrder, std::string>::init() {
+  add(ImageChannelOrderR, "R");
+  add(ImageChannelOrderA, "A");
+  add(ImageChannelOrderRG, "RG");
+  add(ImageChannelOrderRA, "RA");
+  add(ImageChannelOrderRGB, "RGB");
+  add(ImageChannelOrderRGBA, "RGBA");
+  add(ImageChannelOrderBGRA, "BGRA");
+  add(ImageChannelOrderARGB, "ARGB");
+  add(ImageChannelOrderIntensity, "Intensity");
+  add(ImageChannelOrderLuminance, "Luminance");
+  add(ImageChannelOrderRx, "Rx");
+  add(ImageChannelOrderRGx, "RGx");
+  add(ImageChannelOrderRGBx, "RGBx");
+  add(ImageChannelOrderDepth, "Depth");
+  add(ImageChannelOrderDepthStencil, "DepthStencil");
+}
+SPIRV_DEF_NAMEMAP(ImageChannelOrder, SPIRVImageChannelOrderNameMap)
+
+template <> inline void SPIRVMap<ImageChannelDataType, std::string>::init() {
+  add(ImageChannelDataTypeSnormInt8, "SnormInt8");
+  add(ImageChannelDataTypeSnormInt16, "SnormInt16");
+  add(ImageChannelDataTypeUnormInt8, "UnormInt8");
+  add(ImageChannelDataTypeUnormInt16, "UnormInt16");
+  add(ImageChannelDataTypeUnormShort565, "UnormShort565");
+  add(ImageChannelDataTypeUnormShort555, "UnormShort555");
+  add(ImageChannelDataTypeUnormInt101010, "UnormInt101010");
+  add(ImageChannelDataTypeSignedInt8, "SignedInt8");
+  add(ImageChannelDataTypeSignedInt16, "SignedInt16");
+  add(ImageChannelDataTypeSignedInt32, "SignedInt32");
+  add(ImageChannelDataTypeUnsignedInt8, "UnsignedInt8");
+  add(ImageChannelDataTypeUnsignedInt16, "UnsignedInt16");
+  add(ImageChannelDataTypeUnsignedInt32, "UnsignedInt32");
+  add(ImageChannelDataTypeHalfFloat, "HalfFloat");
+  add(ImageChannelDataTypeFloat, "Float");
+  add(ImageChannelDataTypeUnormInt24, "UnormInt24");
+  add(ImageChannelDataTypeUnormInt101010_2, "UnormInt101010_2");
+}
+SPIRV_DEF_NAMEMAP(ImageChannelDataType, SPIRVImageChannelDataTypeNameMap)
+
+template <> inline void SPIRVMap<FPRoundingMode, std::string>::init() {
+  add(FPRoundingModeRTE, "RTE");
+  add(FPRoundingModeRTZ, "RTZ");
+  add(FPRoundingModeRTP, "RTP");
+  add(FPRoundingModeRTN, "RTN");
+}
+SPIRV_DEF_NAMEMAP(FPRoundingMode, SPIRVFPRoundingModeNameMap)
+
+template <> inline void SPIRVMap<LinkageType, std::string>::init() {
+  add(LinkageTypeExport, "Export");
+  add(LinkageTypeImport, "Import");
+  add(LinkageTypeInternal, "Internal");
+}
+SPIRV_DEF_NAMEMAP(LinkageType, SPIRVLinkageTypeNameMap)
+
+template <> inline void SPIRVMap<AccessQualifier, std::string>::init() {
+  add(AccessQualifierReadOnly, "ReadOnly");
+  add(AccessQualifierWriteOnly, "WriteOnly");
+  add(AccessQualifierReadWrite, "ReadWrite");
+}
+SPIRV_DEF_NAMEMAP(AccessQualifier, SPIRVAccessQualifierNameMap)
+
+template <>
+inline void SPIRVMap<FunctionParameterAttribute, std::string>::init() {
+  add(FunctionParameterAttributeZext, "Zext");
+  add(FunctionParameterAttributeSext, "Sext");
+  add(FunctionParameterAttributeByVal, "ByVal");
+  add(FunctionParameterAttributeSret, "Sret");
+  add(FunctionParameterAttributeNoAlias, "NoAlias");
+  add(FunctionParameterAttributeNoCapture, "NoCapture");
+  add(FunctionParameterAttributeNoWrite, "NoWrite");
+  add(FunctionParameterAttributeNoReadWrite, "NoReadWrite");
+}
+SPIRV_DEF_NAMEMAP(FunctionParameterAttribute,
+                  SPIRVFunctionParameterAttributeNameMap)
+
+template <> inline void SPIRVMap<Decoration, std::string>::init() {
+  add(DecorationRelaxedPrecision, "RelaxedPrecision");
+  add(DecorationSpecId, "SpecId");
+  add(DecorationBlock, "Block");
+  add(DecorationBufferBlock, "BufferBlock");
+  add(DecorationRowMajor, "RowMajor");
+  add(DecorationColMajor, "ColMajor");
+  add(DecorationArrayStride, "ArrayStride");
+  add(DecorationMatrixStride, "MatrixStride");
+  add(DecorationGLSLShared, "GLSLShared");
+  add(DecorationGLSLPacked, "GLSLPacked");
+  add(DecorationCPacked, "CPacked");
+  add(DecorationBuiltIn, "BuiltIn");
+  add(DecorationNoPerspective, "NoPerspective");
+  add(DecorationFlat, "Flat");
+  add(DecorationPatch, "Patch");
+  add(DecorationCentroid, "Centroid");
+  add(DecorationSample, "Sample");
+  add(DecorationInvariant, "Invariant");
+  add(DecorationRestrict, "Restrict");
+  add(DecorationAliased, "Aliased");
+  add(DecorationVolatile, "Volatile");
+  add(DecorationConstant, "Constant");
+  add(DecorationCoherent, "Coherent");
+  add(DecorationNonWritable, "NonWritable");
+  add(DecorationNonReadable, "NonReadable");
+  add(DecorationUniform, "Uniform");
+  add(DecorationSaturatedConversion, "SaturatedConversion");
+  add(DecorationStream, "Stream");
+  add(DecorationLocation, "Location");
+  add(DecorationComponent, "Component");
+  add(DecorationIndex, "Index");
+  add(DecorationBinding, "Binding");
+  add(DecorationDescriptorSet, "DescriptorSet");
+  add(DecorationOffset, "Offset");
+  add(DecorationXfbBuffer, "XfbBuffer");
+  add(DecorationXfbStride, "XfbStride");
+  add(DecorationFuncParamAttr, "FuncParamAttr");
+  add(DecorationFPRoundingMode, "FPRoundingMode");
+  add(DecorationFPFastMathMode, "FPFastMathMode");
+  add(DecorationLinkageAttributes, "LinkageAttributes");
+  add(DecorationNoContraction, "NoContraction");
+  add(DecorationInputAttachmentIndex, "InputAttachmentIndex");
+  add(DecorationAlignment, "Alignment");
+  add(DecorationMaxByteOffset, "MaxByteOffset");
+}
+SPIRV_DEF_NAMEMAP(Decoration, SPIRVDecorationNameMap)
+
+template <> inline void SPIRVMap<BuiltIn, std::string>::init() {
+  add(BuiltInPosition, "BuiltInPosition");
+  add(BuiltInPointSize, "BuiltInPointSize");
+  add(BuiltInClipDistance, "BuiltInClipDistance");
+  add(BuiltInCullDistance, "BuiltInCullDistance");
+  add(BuiltInVertexId, "BuiltInVertexId");
+  add(BuiltInInstanceId, "BuiltInInstanceId");
+  add(BuiltInPrimitiveId, "BuiltInPrimitiveId");
+  add(BuiltInInvocationId, "BuiltInInvocationId");
+  add(BuiltInLayer, "BuiltInLayer");
+  add(BuiltInViewportIndex, "BuiltInViewportIndex");
+  add(BuiltInTessLevelOuter, "BuiltInTessLevelOuter");
+  add(BuiltInTessLevelInner, "BuiltInTessLevelInner");
+  add(BuiltInTessCoord, "BuiltInTessCoord");
+  add(BuiltInPatchVertices, "BuiltInPatchVertices");
+  add(BuiltInFragCoord, "BuiltInFragCoord");
+  add(BuiltInPointCoord, "BuiltInPointCoord");
+  add(BuiltInFrontFacing, "BuiltInFrontFacing");
+  add(BuiltInSampleId, "BuiltInSampleId");
+  add(BuiltInSamplePosition, "BuiltInSamplePosition");
+  add(BuiltInSampleMask, "BuiltInSampleMask");
+  add(BuiltInFragDepth, "BuiltInFragDepth");
+  add(BuiltInHelperInvocation, "BuiltInHelperInvocation");
+  add(BuiltInNumWorkgroups, "BuiltInNumWorkgroups");
+  add(BuiltInWorkgroupSize, "BuiltInWorkgroupSize");
+  add(BuiltInWorkgroupId, "BuiltInWorkgroupId");
+  add(BuiltInLocalInvocationId, "BuiltInLocalInvocationId");
+  add(BuiltInGlobalInvocationId, "BuiltInGlobalInvocationId");
+  add(BuiltInLocalInvocationIndex, "BuiltInLocalInvocationIndex");
+  add(BuiltInWorkDim, "BuiltInWorkDim");
+  add(BuiltInGlobalSize, "BuiltInGlobalSize");
+  add(BuiltInEnqueuedWorkgroupSize, "BuiltInEnqueuedWorkgroupSize");
+  add(BuiltInGlobalOffset, "BuiltInGlobalOffset");
+  add(BuiltInGlobalLinearId, "BuiltInGlobalLinearId");
+  add(BuiltInSubgroupSize, "BuiltInSubgroupSize");
+  add(BuiltInSubgroupMaxSize, "BuiltInSubgroupMaxSize");
+  add(BuiltInNumSubgroups, "BuiltInNumSubgroups");
+  add(BuiltInNumEnqueuedSubgroups, "BuiltInNumEnqueuedSubgroups");
+  add(BuiltInSubgroupId, "BuiltInSubgroupId");
+  add(BuiltInSubgroupLocalInvocationId, "BuiltInSubgroupLocalInvocationId");
+  add(BuiltInVertexIndex, "BuiltInVertexIndex");
+  add(BuiltInInstanceIndex, "BuiltInInstanceIndex");
+}
+SPIRV_DEF_NAMEMAP(BuiltIn, SPIRVBuiltInNameMap)
+
+template <> inline void SPIRVMap<Scope, std::string>::init() {
+  add(ScopeCrossDevice, "CrossDevice");
+  add(ScopeDevice, "Device");
+  add(ScopeWorkgroup, "Workgroup");
+  add(ScopeSubgroup, "Subgroup");
+  add(ScopeInvocation, "Invocation");
+}
+SPIRV_DEF_NAMEMAP(Scope, SPIRVScopeNameMap)
+
+template <> inline void SPIRVMap<GroupOperation, std::string>::init() {
+  add(GroupOperationReduce, "Reduce");
+  add(GroupOperationInclusiveScan, "InclusiveScan");
+  add(GroupOperationExclusiveScan, "ExclusiveScan");
+}
+SPIRV_DEF_NAMEMAP(GroupOperation, SPIRVGroupOperationNameMap)
+
+template <> inline void SPIRVMap<KernelEnqueueFlags, std::string>::init() {
+  add(KernelEnqueueFlagsNoWait, "NoWait");
+  add(KernelEnqueueFlagsWaitKernel, "WaitKernel");
+  add(KernelEnqueueFlagsWaitWorkGroup, "WaitWorkGroup");
+}
+SPIRV_DEF_NAMEMAP(KernelEnqueueFlags, SPIRVKernelEnqueueFlagsNameMap)
+
+template <> inline void SPIRVMap<Capability, std::string>::init() {
+  add(CapabilityMatrix, "Matrix");
+  add(CapabilityShader, "Shader");
+  add(CapabilityGeometry, "Geometry");
+  add(CapabilityTessellation, "Tessellation");
+  add(CapabilityAddresses, "Addresses");
+  add(CapabilityLinkage, "Linkage");
+  add(CapabilityKernel, "Kernel");
+  add(CapabilityVector16, "Vector16");
+  add(CapabilityFloat16Buffer, "Float16Buffer");
+  add(CapabilityFloat16, "Float16");
+  add(CapabilityFloat64, "Float64");
+  add(CapabilityInt64, "Int64");
+  add(CapabilityInt64Atomics, "Int64Atomics");
+  add(CapabilityImageBasic, "ImageBasic");
+  add(CapabilityImageReadWrite, "ImageReadWrite");
+  add(CapabilityImageMipmap, "ImageMipmap");
+  add(CapabilityPipes, "Pipes");
+  add(CapabilityPipeStorage, "PipeStorage");
+  add(CapabilityGroups, "Groups");
+  add(CapabilityDeviceEnqueue, "DeviceEnqueue");
+  add(CapabilityLiteralSampler, "LiteralSampler");
+  add(CapabilityAtomicStorage, "AtomicStorage");
+  add(CapabilityInt16, "Int16");
+  add(CapabilityTessellationPointSize, "TessellationPointSize");
+  add(CapabilityGeometryPointSize, "GeometryPointSize");
+  add(CapabilityImageGatherExtended, "ImageGatherExtended");
+  add(CapabilityStorageImageMultisample, "StorageImageMultisample");
+  add(CapabilityUniformBufferArrayDynamicIndexing,
+      "UniformBufferArrayDynamicIndexing");
+  add(CapabilitySampledImageArrayDynamicIndexing,
+      "SampledImageArrayDynamicIndexing");
+  add(CapabilityStorageBufferArrayDynamicIndexing,
+      "StorageBufferArrayDynamicIndexing");
+  add(CapabilityStorageImageArrayDynamicIndexing,
+      "StorageImageArrayDynamicIndexing");
+  add(CapabilityClipDistance, "ClipDistance");
+  add(CapabilityCullDistance, "CullDistance");
+  add(CapabilityImageCubeArray, "ImageCubeArray");
+  add(CapabilitySampleRateShading, "SampleRateShading");
+  add(CapabilityImageRect, "ImageRect");
+  add(CapabilitySampledRect, "SampledRect");
+  add(CapabilityGenericPointer, "GenericPointer");
+  add(CapabilityInt8, "Int8");
+  add(CapabilityInputAttachment, "InputAttachment");
+  add(CapabilitySparseResidency, "SparseResidency");
+  add(CapabilityMinLod, "MinLod");
+  add(CapabilitySampled1D, "Sampled1D");
+  add(CapabilityImage1D, "Image1D");
+  add(CapabilitySampledCubeArray, "SampledCubeArray");
+  add(CapabilitySampledBuffer, "SampledBuffer");
+  add(CapabilityImageBuffer, "ImageBuffer");
+  add(CapabilityImageMSArray, "ImageMSArray");
+  add(CapabilityStorageImageExtendedFormats, "StorageImageExtendedFormats");
+  add(CapabilityImageQuery, "ImageQuery");
+  add(CapabilityDerivativeControl, "DerivativeControl");
+  add(CapabilityInterpolationFunction, "InterpolationFunction");
+  add(CapabilityTransformFeedback, "TransformFeedback");
+  add(CapabilityGeometryStreams, "GeometryStreams");
+  add(CapabilityStorageImageReadWithoutFormat, "StorageImageReadWithoutFormat");
+  add(CapabilityStorageImageWriteWithoutFormat,
+      "StorageImageWriteWithoutFormat");
+  add(CapabilityMultiViewport, "MultiViewport");
+}
+SPIRV_DEF_NAMEMAP(Capability, SPIRVCapabilityNameMap)
+
+} /* namespace SPIRV */
+
+#endif /* SPIRVNAMEMAPENUM_H_ */
diff --git a/lib/SPIRV/libSPIRV/SPIRVOpCode.h b/lib/SPIRV/libSPIRV/SPIRVOpCode.h
new file mode 100644
index 0000000..c2c61b3
--- /dev/null
+++ b/lib/SPIRV/libSPIRV/SPIRVOpCode.h
@@ -0,0 +1,157 @@
+//===- SPIRVOpCode.h - Class to represent SPIR-V Operation Codes -*- C++ -*-==//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+/// \file
+///
+/// This file defines Operation Code class for SPIR-V.
+///
+//===----------------------------------------------------------------------===//
+
+#ifndef SPIRVOPCODE_HPP_
+#define SPIRVOPCODE_HPP_
+
+#include "SPIRVUtil.h"
+#include "spirv.hpp"
+#include <string>
+
+using namespace spv;
+namespace SPIRV {
+
+template <> inline void SPIRVMap<Op, std::string>::init() {
+#define _SPIRV_OP(x, ...) add(Op##x, #x);
+#include "SPIRVOpCodeEnum.h"
+#undef _SPIRV_OP
+}
+SPIRV_DEF_NAMEMAP(Op, OpCodeNameMap)
+
+inline bool isAtomicOpCode(Op OpCode) {
+  assert(OpAtomicLoad < OpAtomicXor);
+  return ((unsigned)OpCode >= OpAtomicLoad &&
+          (unsigned)OpCode <= OpAtomicXor) ||
+         OpCode == OpAtomicFlagTestAndSet || OpCode == OpAtomicFlagClear;
+}
+inline bool isBinaryOpCode(Op OpCode) {
+  return ((unsigned)OpCode >= OpIAdd && (unsigned)OpCode <= OpFMod) ||
+         OpCode == OpDot;
+}
+
+inline bool isShiftOpCode(Op OpCode) {
+  return (unsigned)OpCode >= OpShiftRightLogical &&
+         (unsigned)OpCode <= OpShiftLeftLogical;
+}
+
+inline bool isLogicalOpCode(Op OpCode) {
+  return (unsigned)OpCode >= OpLogicalEqual && (unsigned)OpCode <= OpLogicalNot;
+}
+
+inline bool isBitwiseOpCode(Op OpCode) {
+  return (unsigned)OpCode >= OpBitwiseOr && (unsigned)OpCode <= OpBitwiseAnd;
+}
+
+inline bool isBinaryShiftLogicalBitwiseOpCode(Op OpCode) {
+  return (((unsigned)OpCode >= OpShiftRightLogical &&
+           (unsigned)OpCode <= OpBitwiseAnd) ||
+          isBinaryOpCode(OpCode));
+}
+
+inline bool isCmpOpCode(Op OpCode) {
+  return ((unsigned)OpCode >= OpIEqual &&
+          (unsigned)OpCode <= OpFUnordGreaterThanEqual) ||
+         (OpCode >= OpLessOrGreater && OpCode <= OpLogicalNotEqual);
+}
+
+inline bool isCvtOpCode(Op OpCode) {
+  return ((unsigned)OpCode >= OpConvertFToU && (unsigned)OpCode <= OpBitcast) ||
+         OpCode == OpSatConvertSToU || OpCode == OpSatConvertUToS;
+}
+
+inline bool isCvtToUnsignedOpCode(Op OpCode) {
+  return OpCode == OpConvertFToU || OpCode == OpUConvert ||
+         OpCode == OpSatConvertSToU;
+}
+
+inline bool isCvtFromUnsignedOpCode(Op OpCode) {
+  return OpCode == OpConvertUToF || OpCode == OpUConvert ||
+         OpCode == OpSatConvertUToS;
+}
+
+inline bool isOpaqueGenericTypeOpCode(Op OpCode) {
+  return (unsigned)OpCode >= OpTypeEvent && (unsigned)OpCode <= OpTypeQueue;
+}
+
+inline bool isGenericNegateOpCode(Op OpCode) {
+  return (unsigned)OpCode == OpSNegate || (unsigned)OpCode == OpFNegate ||
+         (unsigned)OpCode == OpNot;
+}
+
+inline bool isAccessChainOpCode(Op OpCode) {
+  return OpCode == OpAccessChain || OpCode == OpInBoundsAccessChain;
+}
+
+inline bool hasExecScope(Op OpCode) {
+  unsigned OC = OpCode;
+  return (OpGroupWaitEvents <= OC && OC <= OpGroupSMax) ||
+         (OpGroupReserveReadPipePackets <= OC && OC <= OpGroupCommitWritePipe);
+}
+
+inline bool hasGroupOperation(Op OpCode) {
+  unsigned OC = OpCode;
+  return OpGroupIAdd <= OC && OC <= OpGroupSMax;
+}
+
+inline bool isGroupOpCode(Op OpCode) {
+  unsigned OC = OpCode;
+  return OpGroupAll <= OC && OC <= OpGroupSMax;
+}
+
+inline bool isPipeOpCode(Op OpCode) {
+  unsigned OC = OpCode;
+  return OpReadPipe <= OC && OC <= OpGroupCommitWritePipe;
+}
+inline bool isTypeOpCode(Op OpCode) {
+  unsigned OC = OpCode;
+  return (OpTypeVoid <= OC && OC <= OpTypePipe) || OC == OpTypePipeStorage;
+}
+
+inline bool isConstantOpCode(Op OpCode) {
+  unsigned OC = OpCode;
+  return (OpConstantTrue <= OC && OC <= OpSpecConstantOp) || OC == OpUndef ||
+         OC == OpConstantPipeStorage;
+}
+
+inline bool isModuleScopeAllowedOpCode(Op OpCode) {
+  return OpCode == OpVariable || isConstantOpCode(OpCode);
+}
+}
+
+#endif /* SPIRVOPCODE_HPP_ */
diff --git a/lib/SPIRV/libSPIRV/SPIRVOpCodeEnum.h b/lib/SPIRV/libSPIRV/SPIRVOpCodeEnum.h
new file mode 100644
index 0000000..e4a1b23
--- /dev/null
+++ b/lib/SPIRV/libSPIRV/SPIRVOpCodeEnum.h
@@ -0,0 +1,297 @@
+_SPIRV_OP(Nop, 0)
+_SPIRV_OP(Undef, 1)
+_SPIRV_OP(SourceContinued, 2)
+_SPIRV_OP(Source, 3)
+_SPIRV_OP(SourceExtension, 4)
+_SPIRV_OP(Name, 5)
+_SPIRV_OP(MemberName, 6)
+_SPIRV_OP(String, 7)
+_SPIRV_OP(Line, 8)
+_SPIRV_OP(Extension, 10)
+_SPIRV_OP(ExtInstImport, 11)
+_SPIRV_OP(ExtInst, 12)
+_SPIRV_OP(MemoryModel, 14)
+_SPIRV_OP(EntryPoint, 15)
+_SPIRV_OP(ExecutionMode, 16)
+_SPIRV_OP(Capability, 17)
+_SPIRV_OP(TypeVoid, 19)
+_SPIRV_OP(TypeBool, 20)
+_SPIRV_OP(TypeInt, 21)
+_SPIRV_OP(TypeFloat, 22)
+_SPIRV_OP(TypeVector, 23)
+_SPIRV_OP(TypeMatrix, 24)
+_SPIRV_OP(TypeImage, 25)
+_SPIRV_OP(TypeSampler, 26)
+_SPIRV_OP(TypeSampledImage, 27)
+_SPIRV_OP(TypeArray, 28)
+_SPIRV_OP(TypeRuntimeArray, 29)
+_SPIRV_OP(TypeStruct, 30)
+_SPIRV_OP(TypeOpaque, 31)
+_SPIRV_OP(TypePointer, 32)
+_SPIRV_OP(TypeFunction, 33)
+_SPIRV_OP(TypeEvent, 34)
+_SPIRV_OP(TypeDeviceEvent, 35)
+_SPIRV_OP(TypeReserveId, 36)
+_SPIRV_OP(TypeQueue, 37)
+_SPIRV_OP(TypePipe, 38)
+_SPIRV_OP(TypeForwardPointer, 39)
+_SPIRV_OP(ConstantTrue, 41)
+_SPIRV_OP(ConstantFalse, 42)
+_SPIRV_OP(Constant, 43)
+_SPIRV_OP(ConstantComposite, 44)
+_SPIRV_OP(ConstantSampler, 45)
+_SPIRV_OP(ConstantNull, 46)
+_SPIRV_OP(SpecConstantTrue, 48)
+_SPIRV_OP(SpecConstantFalse, 49)
+_SPIRV_OP(SpecConstant, 50)
+_SPIRV_OP(SpecConstantComposite, 51)
+_SPIRV_OP(SpecConstantOp, 52)
+_SPIRV_OP(Function, 54)
+_SPIRV_OP(FunctionParameter, 55)
+_SPIRV_OP(FunctionEnd, 56)
+_SPIRV_OP(FunctionCall, 57)
+_SPIRV_OP(Variable, 59)
+_SPIRV_OP(ImageTexelPointer, 60)
+_SPIRV_OP(Load, 61)
+_SPIRV_OP(Store, 62)
+_SPIRV_OP(CopyMemory, 63)
+_SPIRV_OP(CopyMemorySized, 64)
+_SPIRV_OP(AccessChain, 65)
+_SPIRV_OP(InBoundsAccessChain, 66)
+_SPIRV_OP(PtrAccessChain, 67)
+_SPIRV_OP(ArrayLength, 68)
+_SPIRV_OP(GenericPtrMemSemantics, 69)
+_SPIRV_OP(InBoundsPtrAccessChain, 70)
+_SPIRV_OP(Decorate, 71)
+_SPIRV_OP(MemberDecorate, 72)
+_SPIRV_OP(DecorationGroup, 73)
+_SPIRV_OP(GroupDecorate, 74)
+_SPIRV_OP(GroupMemberDecorate, 75)
+_SPIRV_OP(VectorExtractDynamic, 77)
+_SPIRV_OP(VectorInsertDynamic, 78)
+_SPIRV_OP(VectorShuffle, 79)
+_SPIRV_OP(CompositeConstruct, 80)
+_SPIRV_OP(CompositeExtract, 81)
+_SPIRV_OP(CompositeInsert, 82)
+_SPIRV_OP(CopyObject, 83)
+_SPIRV_OP(Transpose, 84)
+_SPIRV_OP(SampledImage, 86)
+_SPIRV_OP(ImageSampleImplicitLod, 87)
+_SPIRV_OP(ImageSampleExplicitLod, 88)
+_SPIRV_OP(ImageSampleDrefImplicitLod, 89)
+_SPIRV_OP(ImageSampleDrefExplicitLod, 90)
+_SPIRV_OP(ImageSampleProjImplicitLod, 91)
+_SPIRV_OP(ImageSampleProjExplicitLod, 92)
+_SPIRV_OP(ImageSampleProjDrefImplicitLod, 93)
+_SPIRV_OP(ImageSampleProjDrefExplicitLod, 94)
+_SPIRV_OP(ImageFetch, 95)
+_SPIRV_OP(ImageGather, 96)
+_SPIRV_OP(ImageDrefGather, 97)
+_SPIRV_OP(ImageRead, 98)
+_SPIRV_OP(ImageWrite, 99)
+_SPIRV_OP(Image, 100)
+_SPIRV_OP(ImageQueryFormat, 101)
+_SPIRV_OP(ImageQueryOrder, 102)
+_SPIRV_OP(ImageQuerySizeLod, 103)
+_SPIRV_OP(ImageQuerySize, 104)
+_SPIRV_OP(ImageQueryLod, 105)
+_SPIRV_OP(ImageQueryLevels, 106)
+_SPIRV_OP(ImageQuerySamples, 107)
+_SPIRV_OP(ConvertFToU, 109)
+_SPIRV_OP(ConvertFToS, 110)
+_SPIRV_OP(ConvertSToF, 111)
+_SPIRV_OP(ConvertUToF, 112)
+_SPIRV_OP(UConvert, 113)
+_SPIRV_OP(SConvert, 114)
+_SPIRV_OP(FConvert, 115)
+_SPIRV_OP(QuantizeToF16, 116)
+_SPIRV_OP(ConvertPtrToU, 117)
+_SPIRV_OP(SatConvertSToU, 118)
+_SPIRV_OP(SatConvertUToS, 119)
+_SPIRV_OP(ConvertUToPtr, 120)
+_SPIRV_OP(PtrCastToGeneric, 121)
+_SPIRV_OP(GenericCastToPtr, 122)
+_SPIRV_OP(GenericCastToPtrExplicit, 123)
+_SPIRV_OP(Bitcast, 124)
+_SPIRV_OP(SNegate, 126)
+_SPIRV_OP(FNegate, 127)
+_SPIRV_OP(IAdd, 128)
+_SPIRV_OP(FAdd, 129)
+_SPIRV_OP(ISub, 130)
+_SPIRV_OP(FSub, 131)
+_SPIRV_OP(IMul, 132)
+_SPIRV_OP(FMul, 133)
+_SPIRV_OP(UDiv, 134)
+_SPIRV_OP(SDiv, 135)
+_SPIRV_OP(FDiv, 136)
+_SPIRV_OP(UMod, 137)
+_SPIRV_OP(SRem, 138)
+_SPIRV_OP(SMod, 139)
+_SPIRV_OP(FRem, 140)
+_SPIRV_OP(FMod, 141)
+_SPIRV_OP(VectorTimesScalar, 142)
+_SPIRV_OP(MatrixTimesScalar, 143)
+_SPIRV_OP(VectorTimesMatrix, 144)
+_SPIRV_OP(MatrixTimesVector, 145)
+_SPIRV_OP(MatrixTimesMatrix, 146)
+_SPIRV_OP(OuterProduct, 147)
+_SPIRV_OP(Dot, 148)
+_SPIRV_OP(IAddCarry, 149)
+_SPIRV_OP(ISubBorrow, 150)
+_SPIRV_OP(UMulExtended, 151)
+_SPIRV_OP(SMulExtended, 152)
+_SPIRV_OP(Any, 154)
+_SPIRV_OP(All, 155)
+_SPIRV_OP(IsNan, 156)
+_SPIRV_OP(IsInf, 157)
+_SPIRV_OP(IsFinite, 158)
+_SPIRV_OP(IsNormal, 159)
+_SPIRV_OP(SignBitSet, 160)
+_SPIRV_OP(LessOrGreater, 161)
+_SPIRV_OP(Ordered, 162)
+_SPIRV_OP(Unordered, 163)
+_SPIRV_OP(LogicalEqual, 164)
+_SPIRV_OP(LogicalNotEqual, 165)
+_SPIRV_OP(LogicalOr, 166)
+_SPIRV_OP(LogicalAnd, 167)
+_SPIRV_OP(LogicalNot, 168)
+_SPIRV_OP(Select, 169)
+_SPIRV_OP(IEqual, 170)
+_SPIRV_OP(INotEqual, 171)
+_SPIRV_OP(UGreaterThan, 172)
+_SPIRV_OP(SGreaterThan, 173)
+_SPIRV_OP(UGreaterThanEqual, 174)
+_SPIRV_OP(SGreaterThanEqual, 175)
+_SPIRV_OP(ULessThan, 176)
+_SPIRV_OP(SLessThan, 177)
+_SPIRV_OP(ULessThanEqual, 178)
+_SPIRV_OP(SLessThanEqual, 179)
+_SPIRV_OP(FOrdEqual, 180)
+_SPIRV_OP(FUnordEqual, 181)
+_SPIRV_OP(FOrdNotEqual, 182)
+_SPIRV_OP(FUnordNotEqual, 183)
+_SPIRV_OP(FOrdLessThan, 184)
+_SPIRV_OP(FUnordLessThan, 185)
+_SPIRV_OP(FOrdGreaterThan, 186)
+_SPIRV_OP(FUnordGreaterThan, 187)
+_SPIRV_OP(FOrdLessThanEqual, 188)
+_SPIRV_OP(FUnordLessThanEqual, 189)
+_SPIRV_OP(FOrdGreaterThanEqual, 190)
+_SPIRV_OP(FUnordGreaterThanEqual, 191)
+_SPIRV_OP(ShiftRightLogical, 194)
+_SPIRV_OP(ShiftRightArithmetic, 195)
+_SPIRV_OP(ShiftLeftLogical, 196)
+_SPIRV_OP(BitwiseOr, 197)
+_SPIRV_OP(BitwiseXor, 198)
+_SPIRV_OP(BitwiseAnd, 199)
+_SPIRV_OP(Not, 200)
+_SPIRV_OP(BitFieldInsert, 201)
+_SPIRV_OP(BitFieldSExtract, 202)
+_SPIRV_OP(BitFieldUExtract, 203)
+_SPIRV_OP(BitReverse, 204)
+_SPIRV_OP(BitCount, 205)
+_SPIRV_OP(DPdx, 207)
+_SPIRV_OP(DPdy, 208)
+_SPIRV_OP(Fwidth, 209)
+_SPIRV_OP(DPdxFine, 210)
+_SPIRV_OP(DPdyFine, 211)
+_SPIRV_OP(FwidthFine, 212)
+_SPIRV_OP(DPdxCoarse, 213)
+_SPIRV_OP(DPdyCoarse, 214)
+_SPIRV_OP(FwidthCoarse, 215)
+_SPIRV_OP(EmitVertex, 218)
+_SPIRV_OP(EndPrimitive, 219)
+_SPIRV_OP(EmitStreamVertex, 220)
+_SPIRV_OP(EndStreamPrimitive, 221)
+_SPIRV_OP(ControlBarrier, 224)
+_SPIRV_OP(MemoryBarrier, 225)
+_SPIRV_OP(AtomicLoad, 227)
+_SPIRV_OP(AtomicStore, 228)
+_SPIRV_OP(AtomicExchange, 229)
+_SPIRV_OP(AtomicCompareExchange, 230)
+_SPIRV_OP(AtomicCompareExchangeWeak, 231)
+_SPIRV_OP(AtomicIIncrement, 232)
+_SPIRV_OP(AtomicIDecrement, 233)
+_SPIRV_OP(AtomicIAdd, 234)
+_SPIRV_OP(AtomicISub, 235)
+_SPIRV_OP(AtomicSMin, 236)
+_SPIRV_OP(AtomicUMin, 237)
+_SPIRV_OP(AtomicSMax, 238)
+_SPIRV_OP(AtomicUMax, 239)
+_SPIRV_OP(AtomicAnd, 240)
+_SPIRV_OP(AtomicOr, 241)
+_SPIRV_OP(AtomicXor, 242)
+_SPIRV_OP(Phi, 245)
+_SPIRV_OP(LoopMerge, 246)
+_SPIRV_OP(SelectionMerge, 247)
+_SPIRV_OP(Label, 248)
+_SPIRV_OP(Branch, 249)
+_SPIRV_OP(BranchConditional, 250)
+_SPIRV_OP(Switch, 251)
+_SPIRV_OP(Kill, 252)
+_SPIRV_OP(Return, 253)
+_SPIRV_OP(ReturnValue, 254)
+_SPIRV_OP(Unreachable, 255)
+_SPIRV_OP(LifetimeStart, 256)
+_SPIRV_OP(LifetimeStop, 257)
+_SPIRV_OP(GroupAsyncCopy, 259)
+_SPIRV_OP(GroupWaitEvents, 260)
+_SPIRV_OP(GroupAll, 261)
+_SPIRV_OP(GroupAny, 262)
+_SPIRV_OP(GroupBroadcast, 263)
+_SPIRV_OP(GroupIAdd, 264)
+_SPIRV_OP(GroupFAdd, 265)
+_SPIRV_OP(GroupFMin, 266)
+_SPIRV_OP(GroupUMin, 267)
+_SPIRV_OP(GroupSMin, 268)
+_SPIRV_OP(GroupFMax, 269)
+_SPIRV_OP(GroupUMax, 270)
+_SPIRV_OP(GroupSMax, 271)
+_SPIRV_OP(ReadPipe, 274)
+_SPIRV_OP(WritePipe, 275)
+_SPIRV_OP(ReservedReadPipe, 276)
+_SPIRV_OP(ReservedWritePipe, 277)
+_SPIRV_OP(ReserveReadPipePackets, 278)
+_SPIRV_OP(ReserveWritePipePackets, 279)
+_SPIRV_OP(CommitReadPipe, 280)
+_SPIRV_OP(CommitWritePipe, 281)
+_SPIRV_OP(IsValidReserveId, 282)
+_SPIRV_OP(GetNumPipePackets, 283)
+_SPIRV_OP(GetMaxPipePackets, 284)
+_SPIRV_OP(GroupReserveReadPipePackets, 285)
+_SPIRV_OP(GroupReserveWritePipePackets, 286)
+_SPIRV_OP(GroupCommitReadPipe, 287)
+_SPIRV_OP(GroupCommitWritePipe, 288)
+_SPIRV_OP(EnqueueMarker, 291)
+_SPIRV_OP(EnqueueKernel, 292)
+_SPIRV_OP(GetKernelNDrangeSubGroupCount, 293)
+_SPIRV_OP(GetKernelNDrangeMaxSubGroupSize, 294)
+_SPIRV_OP(GetKernelWorkGroupSize, 295)
+_SPIRV_OP(GetKernelPreferredWorkGroupSizeMultiple, 296)
+_SPIRV_OP(RetainEvent, 297)
+_SPIRV_OP(ReleaseEvent, 298)
+_SPIRV_OP(CreateUserEvent, 299)
+_SPIRV_OP(IsValidEvent, 300)
+_SPIRV_OP(SetUserEventStatus, 301)
+_SPIRV_OP(CaptureEventProfilingInfo, 302)
+_SPIRV_OP(GetDefaultQueue, 303)
+_SPIRV_OP(BuildNDRange, 304)
+_SPIRV_OP(ImageSparseSampleImplicitLod, 305)
+_SPIRV_OP(ImageSparseSampleExplicitLod, 306)
+_SPIRV_OP(ImageSparseSampleDrefImplicitLod, 307)
+_SPIRV_OP(ImageSparseSampleDrefExplicitLod, 308)
+_SPIRV_OP(ImageSparseSampleProjImplicitLod, 309)
+_SPIRV_OP(ImageSparseSampleProjExplicitLod, 310)
+_SPIRV_OP(ImageSparseSampleProjDrefImplicitLod, 311)
+_SPIRV_OP(ImageSparseSampleProjDrefExplicitLod, 312)
+_SPIRV_OP(ImageSparseFetch, 313)
+_SPIRV_OP(ImageSparseGather, 314)
+_SPIRV_OP(ImageSparseDrefGather, 315)
+_SPIRV_OP(ImageSparseTexelsResident, 316)
+_SPIRV_OP(NoLine, 317)
+_SPIRV_OP(AtomicFlagTestAndSet, 318)
+_SPIRV_OP(AtomicFlagClear, 319)
+_SPIRV_OP(TypePipeStorage, 322)
+_SPIRV_OP(ConstantPipeStorage, 323)
+_SPIRV_OP(CreatePipeFromPipeStorage, 324)
+_SPIRV_OP(Forward, 1024)
diff --git a/lib/SPIRV/libSPIRV/SPIRVStream.cpp b/lib/SPIRV/libSPIRV/SPIRVStream.cpp
new file mode 100644
index 0000000..6840893
--- /dev/null
+++ b/lib/SPIRV/libSPIRV/SPIRVStream.cpp
@@ -0,0 +1,253 @@
+//===- SPIRVStream.cpp - Class to represent a SPIR-V Stream -----*- C++ -*-===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+/// \file
+///
+/// This file implements SPIR-V stream class.
+///
+//===----------------------------------------------------------------------===//
+#include "SPIRVDebug.h"
+#include "SPIRVStream.h"
+#include "SPIRVFunction.h"
+#include "SPIRVOpCode.h"
+#include "SPIRVNameMapEnum.h"
+
+namespace SPIRV {
+
+/// Write string with quote. Replace " with \".
+static void writeQuotedString(spv_ostream &O, const std::string &Str) {
+  O << '"';
+  for (auto I : Str) {
+    if (I == '"')
+      O << '\\';
+    O << I;
+  }
+  O << '"';
+}
+
+/// Read quoted string. Replace \" with ".
+static void readQuotedString(std::istream &IS, std::string &Str) {
+  char Ch = ' ';
+  char PreCh = ' ';
+  while (IS >> Ch && Ch != '"')
+    ;
+
+  if (IS >> PreCh && PreCh != '"') {
+    while (IS >> Ch) {
+      if (Ch == '"') {
+        if (PreCh != '\\') {
+          Str += PreCh;
+          break;
+        } else
+          PreCh = Ch;
+      } else {
+        Str += PreCh;
+        PreCh = Ch;
+      }
+    }
+  }
+}
+
+#ifdef _SPIRV_SUPPORT_TEXT_FMT
+bool SPIRVUseTextFormat = false;
+#endif
+
+SPIRVDecoder::SPIRVDecoder(std::istream &InputStream, SPIRVFunction &F)
+    : IS(InputStream), M(*F.getModule()), WordCount(0), OpCode(OpNop),
+      Scope(&F) {}
+
+SPIRVDecoder::SPIRVDecoder(std::istream &InputStream, SPIRVBasicBlock &BB)
+    : IS(InputStream), M(*BB.getModule()), WordCount(0), OpCode(OpNop),
+      Scope(&BB) {}
+
+void SPIRVDecoder::setScope(SPIRVEntry *TheScope) {
+  assert(TheScope && (TheScope->getOpCode() == OpFunction ||
+                      TheScope->getOpCode() == OpLabel));
+  Scope = TheScope;
+}
+
+template <class T> const SPIRVDecoder &decode(const SPIRVDecoder &I, T &V) {
+#ifdef _SPIRV_SUPPORT_TEXT_FMT
+  if (SPIRVUseTextFormat) {
+    std::string W;
+    I.IS >> W;
+    V = getNameMap(V).rmap(W);
+    SPIRVDBG(spvdbgs() << "Read word: W = " << W << " V = " << V << '\n');
+    return I;
+  }
+#endif
+  return DecodeBinary(I, V);
+}
+
+template <class T> const SPIRVEncoder &encode(const SPIRVEncoder &O, T V) {
+#ifdef _SPIRV_SUPPORT_TEXT_FMT
+  if (SPIRVUseTextFormat) {
+    O.OS << getNameMap(V).map(V) << " ";
+    return O;
+  }
+#endif
+  return O << static_cast<SPIRVWord>(V);
+}
+
+#define SPIRV_DEF_ENCDEC(Type)                                                 \
+  const SPIRVDecoder &operator>>(const SPIRVDecoder &I, Type &V) {             \
+    return decode(I, V);                                                       \
+  }                                                                            \
+  const SPIRVEncoder &operator<<(const SPIRVEncoder &O, Type V) {              \
+    return encode(O, V);                                                       \
+  }
+
+SPIRV_DEF_ENCDEC(Op)
+SPIRV_DEF_ENCDEC(Capability)
+SPIRV_DEF_ENCDEC(Decoration)
+SPIRV_DEF_ENCDEC(OCLExtOpKind)
+SPIRV_DEF_ENCDEC(GLSLExtOpKind)
+SPIRV_DEF_ENCDEC(LinkageType)
+
+// Read a string with padded 0's at the end so that they form a stream of
+// words.
+const SPIRVDecoder &operator>>(const SPIRVDecoder &I, std::string &Str) {
+#ifdef _SPIRV_SUPPORT_TEXT_FMT
+  if (SPIRVUseTextFormat) {
+    readQuotedString(I.IS, Str);
+    SPIRVDBG(spvdbgs() << "Read string: \"" << Str << "\"\n");
+    return I;
+  }
+#endif
+
+  uint64_t Count = 0;
+  char Ch;
+  while (I.IS.get(Ch) && Ch != '\0') {
+    Str += Ch;
+    ++Count;
+  }
+  Count = (Count + 1) % 4;
+  Count = Count ? 4 - Count : 0;
+  for (; Count; --Count) {
+    I.IS >> Ch;
+    assert(Ch == '\0' && "Invalid string in SPIRV");
+  }
+  SPIRVDBG(spvdbgs() << "Read string: \"" << Str << "\"\n");
+  return I;
+}
+
+// Write a string with padded 0's at the end so that they form a stream of
+// words.
+const SPIRVEncoder &operator<<(const SPIRVEncoder &O, const std::string &Str) {
+#ifdef _SPIRV_SUPPORT_TEXT_FMT
+  if (SPIRVUseTextFormat) {
+    writeQuotedString(O.OS, Str);
+    return O;
+  }
+#endif
+
+  size_t L = Str.length();
+  O.OS.write(Str.c_str(), L);
+  char Zeros[4] = {0, 0, 0, 0};
+  O.OS.write(Zeros, 4 - L % 4);
+  return O;
+}
+
+bool SPIRVDecoder::getWordCountAndOpCode() {
+  if (IS.eof()) {
+    WordCount = 0;
+    OpCode = OpNop;
+    SPIRVDBG(spvdbgs() << "[SPIRVDecoder] getWordCountAndOpCode EOF "
+                       << WordCount << " " << OpCode << '\n');
+    return false;
+  }
+#ifdef _SPIRV_SUPPORT_TEXT_FMT
+  if (SPIRVUseTextFormat) {
+    *this >> WordCount;
+    assert(!IS.bad() && "SPIRV stream is bad");
+    if (IS.fail()) {
+      WordCount = 0;
+      OpCode = OpNop;
+      SPIRVDBG(spvdbgs() << "[SPIRVDecoder] getWordCountAndOpCode FAIL "
+                         << WordCount << " " << OpCode << '\n');
+      return false;
+    }
+    *this >> OpCode;
+  } else {
+#endif
+    SPIRVWord WordCountAndOpCode;
+    *this >> WordCountAndOpCode;
+    WordCount = WordCountAndOpCode >> 16;
+    OpCode = static_cast<Op>(WordCountAndOpCode & 0xFFFF);
+#ifdef _SPIRV_SUPPORT_TEXT_FMT
+  }
+#endif
+  assert(!IS.bad() && "SPIRV stream is bad");
+  if (IS.fail()) {
+    WordCount = 0;
+    OpCode = OpNop;
+    SPIRVDBG(spvdbgs() << "[SPIRVDecoder] getWordCountAndOpCode FAIL "
+                       << WordCount << " " << OpCode << '\n');
+    return false;
+  }
+  SPIRVDBG(spvdbgs() << "[SPIRVDecoder] getWordCountAndOpCode " << WordCount
+                     << " " << OpCodeNameMap::map(OpCode) << '\n');
+  return true;
+}
+
+SPIRVEntry *SPIRVDecoder::getEntry() {
+  if (WordCount == 0 || OpCode == OpNop)
+    return NULL;
+  SPIRVEntry *Entry = SPIRVEntry::create(OpCode);
+  assert(Entry);
+  Entry->setModule(&M);
+  if (isModuleScopeAllowedOpCode(OpCode) && !Scope) {
+  } else
+    Entry->setScope(Scope);
+  Entry->setWordCount(WordCount);
+  IS >> *Entry;
+  assert(!IS.bad() && !IS.fail() && "SPIRV stream fails");
+  M.add(Entry);
+  return Entry;
+}
+
+void SPIRVDecoder::validate() const {
+  assert(OpCode != OpNop && "Invalid op code");
+  assert(WordCount && "Invalid word count");
+  assert(!IS.bad() && "Bad iInput stream");
+}
+
+spv_ostream &operator<<(spv_ostream &O, const SPIRVNL &E) {
+#ifdef _SPIRV_SUPPORT_TEXT_FMT
+  if (SPIRVUseTextFormat)
+    O << '\n';
+#endif
+  return O;
+}
+
+} // end of SPIRV namespace
diff --git a/lib/SPIRV/libSPIRV/SPIRVStream.h b/lib/SPIRV/libSPIRV/SPIRVStream.h
new file mode 100644
index 0000000..a0f1fd4
--- /dev/null
+++ b/lib/SPIRV/libSPIRV/SPIRVStream.h
@@ -0,0 +1,191 @@
+//===- SPIRVStream.h  Class to represent a SPIR-V Stream -------*- C++ -*-===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+/// \file
+///
+/// This file defines Word class for SPIR-V.
+///
+//===----------------------------------------------------------------------===//
+
+#ifndef SPIRVSTREAM_H
+#define SPIRVSTREAM_H
+
+#include "SPIRVDebug.h"
+#include "SPIRVModule.h"
+#include "SPIRVExtInst.h"
+#include <algorithm>
+#include <cstdint>
+#include <iostream>
+#include <iterator>
+#include <vector>
+#include <string>
+
+namespace SPIRV {
+
+#ifndef _SPIRV_SUPPORT_TEXT_FMT
+#define _SPIRV_SUPPORT_TEXT_FMT
+#endif
+
+#ifdef _SPIRV_SUPPORT_TEXT_FMT
+// Use textual format for SPIRV.
+extern bool SPIRVUseTextFormat;
+#endif
+
+class SPIRVFunction;
+class SPIRVBasicBlock;
+
+class SPIRVDecoder {
+public:
+  SPIRVDecoder(std::istream &InputStream, SPIRVModule &Module)
+      : IS(InputStream), M(Module), WordCount(0), OpCode(OpNop), Scope(NULL) {}
+  SPIRVDecoder(std::istream &InputStream, SPIRVFunction &F);
+  SPIRVDecoder(std::istream &InputStream, SPIRVBasicBlock &BB);
+
+  void setScope(SPIRVEntry *);
+  bool getWordCountAndOpCode();
+  SPIRVEntry *getEntry();
+  void validate() const;
+
+  std::istream &IS;
+  SPIRVModule &M;
+  SPIRVWord WordCount;
+  Op OpCode;
+  SPIRVEntry *Scope; // A function or basic block
+};
+
+class SPIRVEncoder {
+public:
+  explicit SPIRVEncoder(spv_ostream &OutputStream) : OS(OutputStream) {}
+  spv_ostream &OS;
+};
+
+/// Output a new line in text mode. Do nothing in binary mode.
+class SPIRVNL {
+  friend spv_ostream &operator<<(spv_ostream &O, const SPIRVNL &E);
+};
+
+template <typename T>
+const SPIRVDecoder &DecodeBinary(const SPIRVDecoder &I, T &V) {
+  uint32_t W;
+  I.IS.read(reinterpret_cast<char *>(&W), sizeof(W));
+  V = static_cast<T>(W);
+  SPIRVDBG(spvdbgs() << "Read word: W = " << W << " V = " << V << '\n');
+  return I;
+}
+
+template <typename T>
+const SPIRVDecoder &operator>>(const SPIRVDecoder &I, T &V) {
+#ifdef _SPIRV_SUPPORT_TEXT_FMT
+  if (SPIRVUseTextFormat) {
+    uint32_t W;
+    I.IS >> W;
+    V = static_cast<T>(W);
+    SPIRVDBG(spvdbgs() << "Read word: W = " << W << " V = " << V << '\n');
+    return I;
+  }
+#endif
+  return DecodeBinary(I, V);
+}
+
+template <typename T>
+const SPIRVDecoder &operator>>(const SPIRVDecoder &I, T *&P) {
+  SPIRVId Id;
+  I >> Id;
+  P = static_cast<T *>(I.M.getEntry(Id));
+  return I;
+}
+
+template <typename IterTy>
+const SPIRVDecoder &operator>>(const SPIRVDecoder &Decoder,
+                               const std::pair<IterTy, IterTy> &Range) {
+  for (IterTy I = Range.first, E = Range.second; I != E; ++I)
+    Decoder >> *I;
+  return Decoder;
+}
+
+template <typename T>
+const SPIRVDecoder &operator>>(const SPIRVDecoder &I, std::vector<T> &V) {
+  for (size_t i = 0, e = V.size(); i != e; ++i)
+    I >> V[i];
+  return I;
+}
+
+template <typename T>
+const SPIRVEncoder &operator<<(const SPIRVEncoder &O, T V) {
+#ifdef _SPIRV_SUPPORT_TEXT_FMT
+  if (SPIRVUseTextFormat) {
+    O.OS << V << " ";
+    return O;
+  }
+#endif
+  uint32_t W = static_cast<uint32_t>(V);
+  O.OS.write(reinterpret_cast<char *>(&W), sizeof(W));
+  return O;
+}
+
+template <typename T>
+const SPIRVEncoder &operator<<(const SPIRVEncoder &O, T *P) {
+  return O << P->getId();
+}
+
+template <typename T>
+const SPIRVEncoder &operator<<(const SPIRVEncoder &O, const std::vector<T> &V) {
+  for (size_t i = 0, e = V.size(); i != e; ++i)
+    O << V[i];
+  return O;
+}
+
+template <typename IterTy>
+const SPIRVEncoder &operator<<(const SPIRVEncoder &Encoder,
+                               const std::pair<IterTy, IterTy> &Range) {
+  for (IterTy I = Range.first, E = Range.second; I != E; ++I)
+    Encoder << *I;
+  return Encoder;
+}
+
+#define SPIRV_DEC_ENCDEC(Type)                                                 \
+  const SPIRVEncoder &operator<<(const SPIRVEncoder &O, Type V);               \
+  const SPIRVDecoder &operator>>(const SPIRVDecoder &I, Type &V);
+
+SPIRV_DEC_ENCDEC(Op)
+SPIRV_DEC_ENCDEC(Capability)
+SPIRV_DEC_ENCDEC(Decoration)
+SPIRV_DEC_ENCDEC(OCLExtOpKind)
+SPIRV_DEC_ENCDEC(GLSLExtOpKind)
+SPIRV_DEC_ENCDEC(LinkageType)
+
+const SPIRVEncoder &operator<<(const SPIRVEncoder &O, const std::string &Str);
+const SPIRVDecoder &operator>>(const SPIRVDecoder &I, std::string &Str);
+
+} // namespace SPIRV
+#endif
diff --git a/lib/SPIRV/libSPIRV/SPIRVType.cpp b/lib/SPIRV/libSPIRV/SPIRVType.cpp
new file mode 100644
index 0000000..228c206
--- /dev/null
+++ b/lib/SPIRV/libSPIRV/SPIRVType.cpp
@@ -0,0 +1,241 @@
+//===- SPIRVtype.cpp - Class to represent a SPIR-V type ---------*- C++ -*-===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+/// \file
+///
+/// This file implements the types defined in SPIRV spec with op codes.
+///
+//===----------------------------------------------------------------------===//
+
+#include "SPIRVType.h"
+#include "SPIRVModule.h"
+#include "SPIRVDecorate.h"
+#include "SPIRVValue.h"
+
+#include <cassert>
+
+namespace SPIRV {
+
+SPIRVType *SPIRVType::getArrayElementType() const {
+  assert((OpCode == OpTypeArray || OpCode == OpTypeRuntimeArray) &&
+         "Not array type");
+  if (OpCode == OpTypeArray) {
+    return static_cast<const SPIRVTypeArray *const>(this)->getElementType();
+  }
+  return static_cast<const SPIRVTypeRuntimeArray *const>(this)
+      ->getElementType();
+}
+
+uint64_t SPIRVType::getArrayLength() const {
+  assert(OpCode == OpTypeArray && "Not array type");
+  return static_cast<const SPIRVTypeArray *const>(this)
+      ->getLength()
+      ->getZExtIntValue();
+}
+
+SPIRVWord SPIRVType::getBitWidth() const {
+  if (isTypeVector())
+    return getVectorComponentType()->getBitWidth();
+  if (isTypeBool())
+    return 1;
+  return isTypeInt() ? getIntegerBitWidth() : getFloatBitWidth();
+}
+
+SPIRVWord SPIRVType::getFloatBitWidth() const {
+  assert(OpCode == OpTypeFloat && "Not an integer type");
+  return static_cast<const SPIRVTypeFloat *const>(this)->getBitWidth();
+}
+
+SPIRVWord SPIRVType::getIntegerBitWidth() const {
+  assert((OpCode == OpTypeInt || OpCode == OpTypeBool) &&
+         "Not an integer type");
+  if (isTypeBool())
+    return 1;
+  return static_cast<const SPIRVTypeInt *const>(this)->getBitWidth();
+}
+
+SPIRVType *SPIRVType::getFunctionReturnType() const {
+  assert(OpCode == OpTypeFunction);
+  return static_cast<const SPIRVTypeFunction *const>(this)->getReturnType();
+}
+
+SPIRVType *SPIRVType::getPointerElementType() const {
+  assert(OpCode == OpTypePointer && "Not a pointer type");
+  return static_cast<const SPIRVTypePointer *const>(this)->getElementType();
+}
+
+SPIRVStorageClassKind SPIRVType::getPointerStorageClass() const {
+  assert(OpCode == OpTypePointer && "Not a pointer type");
+  return static_cast<const SPIRVTypePointer *const>(this)->getStorageClass();
+}
+
+SPIRVType *SPIRVType::getStructMemberType(size_t Index) const {
+  assert(OpCode == OpTypeStruct && "Not struct type");
+  return static_cast<const SPIRVTypeStruct *const>(this)->getMemberType(Index);
+}
+
+SPIRVWord SPIRVType::getStructMemberCount() const {
+  assert(OpCode == OpTypeStruct && "Not struct type");
+  return static_cast<const SPIRVTypeStruct *const>(this)->getMemberCount();
+}
+
+SPIRVWord SPIRVType::getVectorComponentCount() const {
+  assert(OpCode == OpTypeVector && "Not vector type");
+  return static_cast<const SPIRVTypeVector *const>(this)->getComponentCount();
+}
+
+SPIRVType *SPIRVType::getVectorComponentType() const {
+  assert(OpCode == OpTypeVector && "Not vector type");
+  return static_cast<const SPIRVTypeVector *const>(this)->getComponentType();
+}
+
+bool SPIRVType::isTypeVoid() const { return OpCode == OpTypeVoid; }
+
+bool SPIRVType::isTypeArray() const {
+  return OpCode == OpTypeArray || OpCode == OpTypeRuntimeArray;
+}
+
+bool SPIRVType::isTypeRuntimeArray() const {
+  return OpCode == OpTypeRuntimeArray;
+}
+
+bool SPIRVType::isTypeBool() const { return OpCode == OpTypeBool; }
+
+bool SPIRVType::isTypeComposite() const {
+  return isTypeVector() || isTypeArray() || isTypeStruct();
+}
+
+bool SPIRVType::isTypeFloat(unsigned Bits) const {
+  return isType<SPIRVTypeFloat>(this, Bits);
+}
+
+bool SPIRVType::isTypeOCLImage() const {
+  return isTypeImage() &&
+         static_cast<const SPIRVTypeImage *>(this)->isOCLImage();
+}
+
+bool SPIRVType::isTypePipe() const { return OpCode == OpTypePipe; }
+
+bool SPIRVType::isTypePipeStorage() const {
+  return OpCode == OpTypePipeStorage;
+}
+
+bool SPIRVType::isTypeReserveId() const { return OpCode == OpTypeReserveId; }
+
+bool SPIRVType::isTypeInt(unsigned Bits) const {
+  return isType<SPIRVTypeInt>(this, Bits);
+}
+
+bool SPIRVType::isTypePointer() const { return OpCode == OpTypePointer; }
+
+bool SPIRVType::isTypeOpaque() const { return OpCode == OpTypeOpaque; }
+
+bool SPIRVType::isTypeEvent() const { return OpCode == OpTypeEvent; }
+
+bool SPIRVType::isTypeDeviceEvent() const {
+  return OpCode == OpTypeDeviceEvent;
+}
+
+bool SPIRVType::isTypeSampler() const { return OpCode == OpTypeSampler; }
+
+bool SPIRVType::isTypeImage() const { return OpCode == OpTypeImage; }
+
+bool SPIRVType::isTypeStruct() const { return OpCode == OpTypeStruct; }
+
+bool SPIRVType::isTypeVector() const { return OpCode == OpTypeVector; }
+
+bool SPIRVType::isTypeVectorBool() const {
+  return isTypeVector() && getVectorComponentType()->isTypeBool();
+}
+
+bool SPIRVType::isTypeVectorInt() const {
+  return isTypeVector() && getVectorComponentType()->isTypeInt();
+}
+
+bool SPIRVType::isTypeVectorFloat() const {
+  return isTypeVector() && getVectorComponentType()->isTypeFloat();
+}
+
+bool SPIRVType::isTypeVectorOrScalarBool() const {
+  return isTypeBool() || isTypeVectorBool();
+}
+
+bool SPIRVType::isTypeVectorOrScalarInt() const {
+  return isTypeInt() || isTypeVectorInt();
+}
+
+bool SPIRVType::isTypeVectorOrScalarFloat() const {
+  return isTypeFloat() || isTypeVectorFloat();
+}
+
+bool SPIRVTypeStruct::isPacked() const {
+  return hasDecorate(DecorationCPacked);
+}
+
+void SPIRVTypeStruct::setPacked(bool Packed) {
+  if (Packed)
+    addDecorate(new SPIRVDecorate(DecorationCPacked, this));
+  else
+    eraseDecorate(DecorationCPacked);
+}
+
+SPIRVTypeArray::SPIRVTypeArray(SPIRVModule *M, SPIRVId TheId,
+                               SPIRVType *TheElemType, SPIRVConstant *TheLength)
+    : SPIRVType(M, 4, OpTypeArray, TheId), ElemType(TheElemType),
+      Length(TheLength->getId()) {
+  validate();
+}
+
+void SPIRVTypeArray::validate() const {
+  SPIRVEntry::validate();
+  ElemType->validate();
+  assert(getValue(Length)->getType()->isTypeInt() &&
+         get<SPIRVConstant>(Length)->getZExtIntValue() > 0);
+}
+
+SPIRVConstant *SPIRVTypeArray::getLength() const {
+  return get<SPIRVConstant>(Length);
+}
+
+_SPIRV_IMP_ENCDEC3(SPIRVTypeArray, Id, ElemType, Length)
+
+void SPIRVTypeForwardPointer::encode(spv_ostream &O) const {
+  getEncoder(O) << Pointer << SC;
+}
+
+void SPIRVTypeForwardPointer::decode(std::istream &I) {
+  auto Decoder = getDecoder(I);
+  SPIRVId PointerId;
+  Decoder >> PointerId >> SC;
+}
+}
diff --git a/lib/SPIRV/libSPIRV/SPIRVType.h b/lib/SPIRV/libSPIRV/SPIRVType.h
new file mode 100644
index 0000000..bd354c6
--- /dev/null
+++ b/lib/SPIRV/libSPIRV/SPIRVType.h
@@ -0,0 +1,779 @@
+//===- SPIRVType.h - Class to represent a SPIR-V Type -----------*- C++ -*-===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+/// \file
+///
+/// This file defines the types defined in SPIRV spec with op codes.
+///
+/// The name of the SPIR-V types follow the op code name in the spec, e.g.
+/// SPIR-V type with op code name OpTypeInt is named as SPIRVTypeInt. This is
+/// for readability and ease of using macro to handle types.
+///
+//===----------------------------------------------------------------------===//
+
+#ifndef SPIRVTYPE_HPP_
+#define SPIRVTYPE_HPP_
+
+#include "SPIRVEntry.h"
+#include "SPIRVStream.h"
+
+#include <cassert>
+#include <tuple>
+#include <vector>
+#include <map>
+#include <iostream>
+
+namespace SPIRV {
+
+class SPIRVType : public SPIRVEntry {
+public:
+  // Complete constructor
+  SPIRVType(SPIRVModule *M, unsigned TheWordCount, Op TheOpCode, SPIRVId TheId)
+      : SPIRVEntry(M, TheWordCount, TheOpCode, TheId) {}
+  // Incomplete constructor
+  SPIRVType(Op TheOpCode) : SPIRVEntry(TheOpCode) {}
+
+  SPIRVType *getArrayElementType() const;
+  uint64_t getArrayLength() const;
+  unsigned getBitWidth() const;
+  unsigned getFloatBitWidth() const;
+  SPIRVType *getFunctionReturnType() const;
+  unsigned getIntegerBitWidth() const;
+  SPIRVType *getPointerElementType() const;
+  SPIRVStorageClassKind getPointerStorageClass() const;
+  SPIRVType *getStructMemberType(size_t) const;
+  SPIRVWord getStructMemberCount() const;
+  SPIRVWord getVectorComponentCount() const;
+  SPIRVType *getVectorComponentType() const;
+
+  bool isTypeVoid() const;
+  bool isTypeArray() const;
+  bool isTypeRuntimeArray() const;
+  bool isTypeBool() const;
+  bool isTypeComposite() const;
+  bool isTypeEvent() const;
+  bool isTypeDeviceEvent() const;
+  bool isTypeReserveId() const;
+  bool isTypeFloat(unsigned Bits = 0) const;
+  bool isTypeImage() const;
+  bool isTypeOCLImage() const;
+  bool isTypePipe() const;
+  bool isTypePipeStorage() const;
+  bool isTypeInt(unsigned Bits = 0) const;
+  bool isTypeOpaque() const;
+  bool isTypePointer() const;
+  bool isTypeSampler() const;
+  bool isTypeStruct() const;
+  bool isTypeVector() const;
+  bool isTypeVectorInt() const;
+  bool isTypeVectorFloat() const;
+  bool isTypeVectorBool() const;
+  bool isTypeVectorOrScalarInt() const;
+  bool isTypeVectorOrScalarFloat() const;
+  bool isTypeVectorOrScalarBool() const;
+};
+
+class SPIRVTypeVoid : public SPIRVType {
+public:
+  // Complete constructor
+  SPIRVTypeVoid(SPIRVModule *M, SPIRVId TheId)
+      : SPIRVType(M, 2, OpTypeVoid, TheId) {}
+  // Incomplete constructor
+  SPIRVTypeVoid() : SPIRVType(OpTypeVoid) {}
+
+protected:
+  _SPIRV_DEF_ENCDEC1(Id)
+};
+
+class SPIRVTypeBool : public SPIRVType {
+public:
+  // Complete constructor
+  SPIRVTypeBool(SPIRVModule *M, SPIRVId TheId)
+      : SPIRVType(M, 2, OpTypeBool, TheId) {}
+  // Incomplete constructor
+  SPIRVTypeBool() : SPIRVType(OpTypeBool) {}
+
+protected:
+  _SPIRV_DEF_ENCDEC1(Id)
+};
+
+class SPIRVTypeInt : public SPIRVType {
+public:
+  static const Op OC = OpTypeInt;
+  // Complete constructor
+  SPIRVTypeInt(SPIRVModule *M, SPIRVId TheId, unsigned TheBitWidth,
+               bool ItIsSigned)
+      : SPIRVType(M, 4, OC, TheId), BitWidth(TheBitWidth),
+        IsSigned(ItIsSigned) {
+    validate();
+  }
+  // Incomplete constructor
+  SPIRVTypeInt() : SPIRVType(OC), BitWidth(0), IsSigned(false) {}
+
+  unsigned getBitWidth() const { return BitWidth; }
+  bool isSigned() const { return IsSigned; }
+  SPIRVCapVec getRequiredCapability() const {
+    SPIRVCapVec CV;
+    if (isTypeInt(16))
+      CV.push_back(CapabilityInt16);
+    else if (isTypeInt(64))
+      CV.push_back(CapabilityInt64);
+    return CV;
+  }
+
+protected:
+  _SPIRV_DEF_ENCDEC3(Id, BitWidth, IsSigned)
+  void validate() const {
+    SPIRVEntry::validate();
+    assert(BitWidth > 1 && BitWidth <= 64 && "Invalid bit width");
+  }
+
+private:
+  unsigned BitWidth; // Bit width
+  bool IsSigned;     // Whether it is signed
+};
+
+class SPIRVTypeFloat : public SPIRVType {
+public:
+  static const Op OC = OpTypeFloat;
+  // Complete constructor
+  SPIRVTypeFloat(SPIRVModule *M, SPIRVId TheId, unsigned TheBitWidth)
+      : SPIRVType(M, 3, OC, TheId), BitWidth(TheBitWidth) {}
+  // Incomplete constructor
+  SPIRVTypeFloat() : SPIRVType(OC), BitWidth(0) {}
+
+  unsigned getBitWidth() const { return BitWidth; }
+
+  SPIRVCapVec getRequiredCapability() const {
+    SPIRVCapVec CV;
+    if (isTypeFloat(16))
+      CV.push_back(CapabilityFloat16);
+    else if (isTypeFloat(64))
+      CV.push_back(CapabilityFloat64);
+    return CV;
+  }
+
+protected:
+  _SPIRV_DEF_ENCDEC2(Id, BitWidth)
+  void validate() const {
+    SPIRVEntry::validate();
+    assert(BitWidth >= 16 && BitWidth <= 64 && "Invalid bit width");
+  }
+
+private:
+  unsigned BitWidth; // Bit width
+};
+
+class SPIRVTypePointer : public SPIRVType {
+public:
+  // Complete constructor
+  SPIRVTypePointer(SPIRVModule *M, SPIRVId TheId,
+                   SPIRVStorageClassKind TheStorageClass,
+                   SPIRVType *ElementType)
+      : SPIRVType(M, 4, OpTypePointer, TheId),
+        ElemStorageClass(TheStorageClass), ElemTypeId(ElementType->getId()) {
+    validate();
+  }
+  // Incomplete constructor
+  SPIRVTypePointer()
+      : SPIRVType(OpTypePointer), ElemStorageClass(StorageClassFunction),
+        ElemTypeId(0) {}
+
+  SPIRVType *getElementType() const {
+    return static_cast<SPIRVType *>(getEntry(ElemTypeId));
+  }
+  SPIRVStorageClassKind getStorageClass() const { return ElemStorageClass; }
+  SPIRVCapVec getRequiredCapability() const {
+    // cap requirements are different for shaders and kernels
+    if (Module->getSourceLanguage(nullptr) == spv::SourceLanguageGLSL) {
+      return getCapability(ElemStorageClass);
+    } else {
+      auto Cap = getVec(CapabilityAddresses);
+      if (getElementType()->isTypeFloat(16))
+        Cap.push_back(CapabilityFloat16Buffer);
+      auto C = getCapability(ElemStorageClass);
+      Cap.insert(Cap.end(), C.begin(), C.end());
+      return Cap;
+    }
+  }
+  virtual std::vector<SPIRVEntry *> getNonLiteralOperands() const {
+    return std::vector<SPIRVEntry *>(1, getEntry(ElemTypeId));
+  }
+
+protected:
+  _SPIRV_DEF_ENCDEC3(Id, ElemStorageClass, ElemTypeId)
+  void validate() const {
+    SPIRVEntry::validate();
+    assert(isValid(ElemStorageClass));
+  }
+
+private:
+  SPIRVStorageClassKind ElemStorageClass; // Storage Class
+  SPIRVId ElemTypeId;
+};
+
+class SPIRVTypeForwardPointer : public SPIRVEntryNoId<OpTypeForwardPointer> {
+public:
+  SPIRVTypeForwardPointer(SPIRVModule *M, SPIRVTypePointer *Pointer,
+                          SPIRVStorageClassKind SC)
+      : SPIRVEntryNoId(M, 3), Pointer(Pointer), SC(SC) {}
+
+  SPIRVTypeForwardPointer()
+      : Pointer(nullptr), SC(StorageClassUniformConstant) {}
+
+  SPIRVTypePointer *getPointer() const { return Pointer; }
+  _SPIRV_DCL_ENCDEC
+private:
+  SPIRVTypePointer *Pointer;
+  SPIRVStorageClassKind SC;
+};
+
+class SPIRVTypeVector : public SPIRVType {
+public:
+  // Complete constructor
+  SPIRVTypeVector(SPIRVModule *M, SPIRVId TheId, SPIRVType *TheCompType,
+                  SPIRVWord TheCompCount)
+      : SPIRVType(M, 4, OpTypeVector, TheId), CompType(TheCompType),
+        CompCount(TheCompCount) {
+    validate();
+  }
+  // Incomplete constructor
+  SPIRVTypeVector()
+      : SPIRVType(OpTypeVector), CompType(nullptr), CompCount(0) {}
+
+  SPIRVType *getComponentType() const { return CompType; }
+  SPIRVWord getComponentCount() const { return CompCount; }
+  bool isValidIndex(SPIRVWord Index) const { return Index < CompCount; }
+  SPIRVCapVec getRequiredCapability() const {
+    SPIRVCapVec V(getComponentType()->getRequiredCapability());
+    if (CompCount >= 8)
+      V.push_back(CapabilityVector16);
+    return V;
+  }
+
+  virtual std::vector<SPIRVEntry *> getNonLiteralOperands() const {
+    return std::vector<SPIRVEntry *>(1, CompType);
+  }
+
+protected:
+  _SPIRV_DEF_ENCDEC3(Id, CompType, CompCount)
+  void validate() const {
+    SPIRVEntry::validate();
+    CompType->validate();
+    assert(CompCount == 2 || CompCount == 3 || CompCount == 4 ||
+           CompCount == 8 || CompCount == 16);
+  }
+
+private:
+  SPIRVType *CompType; // Component Type
+  SPIRVWord CompCount; // Component Count
+};
+
+class SPIRVConstant;
+class SPIRVTypeArray : public SPIRVType {
+public:
+  // Complete constructor
+  SPIRVTypeArray(SPIRVModule *M, SPIRVId TheId, SPIRVType *TheElemType,
+                 SPIRVConstant *TheLength);
+  // Incomplete constructor
+  SPIRVTypeArray()
+      : SPIRVType(OpTypeArray), ElemType(nullptr), Length(SPIRVID_INVALID) {}
+
+  SPIRVType *getElementType() const { return ElemType; }
+  SPIRVConstant *getLength() const;
+  SPIRVCapVec getRequiredCapability() const {
+    return getElementType()->getRequiredCapability();
+  }
+  virtual std::vector<SPIRVEntry *> getNonLiteralOperands() const {
+    std::vector<SPIRVEntry *> Operands(2, ElemType);
+    Operands[1] = (SPIRVEntry *)getLength();
+    return Operands;
+  }
+
+protected:
+  _SPIRV_DCL_ENCDEC
+  void validate() const;
+
+private:
+  SPIRVType *ElemType; // Element Type
+  SPIRVId Length;      // Array Length
+};
+
+class SPIRVTypeRuntimeArray : public SPIRVType {
+public:
+  // Complete constructor
+  SPIRVTypeRuntimeArray(SPIRVModule *M, SPIRVId TheId, SPIRVType *TheElemType)
+      : SPIRVType(M, 3, OpTypeRuntimeArray, TheId), ElemType(TheElemType) {
+    validate();
+  }
+  // Incomplete constructor
+  SPIRVTypeRuntimeArray() : SPIRVType(OpTypeRuntimeArray), ElemType(nullptr) {}
+
+  SPIRVType *getElementType() const { return ElemType; }
+  SPIRVCapVec getRequiredCapability() const {
+    return getElementType()->getRequiredCapability();
+  }
+  virtual std::vector<SPIRVEntry *> getNonLiteralOperands() const {
+    std::vector<SPIRVEntry *> Operands(1, ElemType);
+    return Operands;
+  }
+
+protected:
+  _SPIRV_DEF_ENCDEC2(Id, ElemType)
+  void validate() const {
+    SPIRVEntry::validate();
+    ElemType->validate();
+  }
+
+private:
+  SPIRVType *ElemType; // Element Type
+};
+
+class SPIRVTypeOpaque : public SPIRVType {
+public:
+  // Complete constructor
+  SPIRVTypeOpaque(SPIRVModule *M, SPIRVId TheId, const std::string &TheName)
+      : SPIRVType(M, 2 + getSizeInWords(TheName), OpTypeOpaque, TheId) {
+    Name = TheName;
+    validate();
+  }
+  // Incomplete constructor
+  SPIRVTypeOpaque() : SPIRVType(OpTypeOpaque) {}
+
+protected:
+  _SPIRV_DEF_ENCDEC2(Id, Name)
+  void validate() const { SPIRVEntry::validate(); }
+};
+
+struct SPIRVTypeImageDescriptor {
+  SPIRVImageDimKind Dim;
+  SPIRVWord Depth;
+  SPIRVWord Arrayed;
+  SPIRVWord MS;
+  SPIRVWord Sampled;
+  SPIRVWord Format;
+  static std::tuple<
+      std::tuple<SPIRVImageDimKind, SPIRVWord, SPIRVWord, SPIRVWord, SPIRVWord>,
+      SPIRVWord>
+  getAsTuple(const SPIRVTypeImageDescriptor &Desc) {
+    return std::make_tuple(std::make_tuple(Desc.Dim, Desc.Depth, Desc.Arrayed,
+                                           Desc.MS, Desc.Sampled),
+                           Desc.Format);
+  }
+  SPIRVTypeImageDescriptor()
+      : Dim(Dim1D), Depth(0), Arrayed(0), MS(0), Sampled(0), Format(0) {}
+  SPIRVTypeImageDescriptor(SPIRVImageDimKind Dim, SPIRVWord Cont, SPIRVWord Arr,
+                           SPIRVWord Comp, SPIRVWord Mult, SPIRVWord F)
+      : Dim(Dim), Depth(Cont), Arrayed(Arr), MS(Comp), Sampled(Mult),
+        Format(F) {}
+};
+
+template <>
+inline void SPIRVMap<std::string, SPIRVTypeImageDescriptor>::init() {
+#define _SPIRV_OP(x, ...)                                                      \
+  {                                                                            \
+    SPIRVTypeImageDescriptor S(__VA_ARGS__);                                   \
+    add(#x, S);                                                                \
+  }
+  _SPIRV_OP(image1d_t, Dim1D, 0, 0, 0, 0, 0)
+  _SPIRV_OP(image1d_buffer_t, DimBuffer, 0, 0, 0, 0, 0)
+  _SPIRV_OP(image1d_array_t, Dim1D, 0, 1, 0, 0, 0)
+  _SPIRV_OP(image2d_t, Dim2D, 0, 0, 0, 0, 0)
+  _SPIRV_OP(image2d_array_t, Dim2D, 0, 1, 0, 0, 0)
+  _SPIRV_OP(image2d_depth_t, Dim2D, 1, 0, 0, 0, 0)
+  _SPIRV_OP(image2d_array_depth_t, Dim2D, 1, 1, 0, 0, 0)
+  _SPIRV_OP(image2d_msaa_t, Dim2D, 0, 0, 1, 0, 0)
+  _SPIRV_OP(image2d_array_msaa_t, Dim2D, 0, 1, 1, 0, 0)
+  _SPIRV_OP(image2d_msaa_depth_t, Dim2D, 1, 0, 1, 0, 0)
+  _SPIRV_OP(image2d_array_msaa_depth_t, Dim2D, 1, 1, 1, 0, 0)
+  _SPIRV_OP(image3d_t, Dim3D, 0, 0, 0, 0, 0)
+  _SPIRV_OP(imagecube_t, DimCube, 0, 0, 0, 0, 0)
+  _SPIRV_OP(imagecube_array_t, DimCube, 0, 1, 0, 0, 0)
+  _SPIRV_OP(imagecube_depth_t, DimCube, 1, 0, 0, 0, 0)
+  _SPIRV_OP(imagecube_array_depth_t, DimCube, 1, 1, 0, 0, 0)
+#undef _SPIRV_OP
+}
+typedef SPIRVMap<std::string, SPIRVTypeImageDescriptor> OCLSPIRVImageTypeMap;
+
+// Comparision function required to use the struct as map key.
+inline bool operator<(const SPIRVTypeImageDescriptor &A,
+                      const SPIRVTypeImageDescriptor &B) {
+  return SPIRVTypeImageDescriptor::getAsTuple(A) <
+         SPIRVTypeImageDescriptor::getAsTuple(B);
+}
+
+class SPIRVTypeImage : public SPIRVType {
+public:
+  const static Op OC = OpTypeImage;
+  const static SPIRVWord FixedWC = 9;
+  SPIRVTypeImage(SPIRVModule *M, SPIRVId TheId, SPIRVId TheSampledType,
+                 const SPIRVTypeImageDescriptor &TheDesc)
+      : SPIRVType(M, FixedWC, OC, TheId), SampledType(TheSampledType),
+        Desc(TheDesc) {
+    validate();
+  }
+  SPIRVTypeImage(SPIRVModule *M, SPIRVId TheId, SPIRVId TheSampledType,
+                 const SPIRVTypeImageDescriptor &TheDesc,
+                 SPIRVAccessQualifierKind TheAcc)
+      : SPIRVType(M, FixedWC + 1, OC, TheId), SampledType(TheSampledType),
+        Desc(TheDesc) {
+    Acc.push_back(TheAcc);
+    validate();
+  }
+  SPIRVTypeImage() : SPIRVType(OC), SampledType(SPIRVID_INVALID), Desc() {}
+  const SPIRVTypeImageDescriptor &getDescriptor() const { return Desc; }
+  bool isOCLImage() const { return Desc.Sampled == 0 && Desc.Format == 0; }
+  bool hasAccessQualifier() const { return !Acc.empty(); }
+  SPIRVAccessQualifierKind getAccessQualifier() const {
+    assert(hasAccessQualifier());
+    return Acc[0];
+  }
+  SPIRVCapVec getRequiredCapability() const {
+    SPIRVCapVec CV;
+    CV.push_back(CapabilityImageBasic);
+    if (Desc.Dim == 1)
+      CV.push_back(CapabilitySampled1D);
+    else if (Desc.Dim == 5)
+      CV.push_back(CapabilitySampledBuffer);
+    if (Acc.size() > 0 && Acc[0] == AccessQualifierReadWrite)
+      CV.push_back(CapabilityImageReadWrite);
+    if (Desc.MS)
+      CV.push_back(CapabilityImageMipmap);
+    return CV;
+  }
+  SPIRVType *getSampledType() const { return get<SPIRVType>(SampledType); }
+
+  virtual std::vector<SPIRVEntry *> getNonLiteralOperands() const {
+    return std::vector<SPIRVEntry *>(1, get<SPIRVType>(SampledType));
+  }
+
+protected:
+  _SPIRV_DEF_ENCDEC9(Id, SampledType, Desc.Dim, Desc.Depth, Desc.Arrayed,
+                     Desc.MS, Desc.Sampled, Desc.Format, Acc)
+  // The validation assumes OpenCL image or sampler type.
+  void validate() const {
+    assert(OpCode == OC);
+    assert(WordCount == FixedWC + Acc.size());
+    assert(SampledType != SPIRVID_INVALID && "Invalid sampled type");
+    assert(Desc.Dim <= 5);
+    assert(Desc.Depth <= 1);
+    assert(Desc.Arrayed <= 1);
+    assert(Desc.MS <= 1);
+    assert(Desc.Sampled == 0); // For OCL only
+    assert(Desc.Format == 0);  // For OCL only
+    assert(Acc.size() <= 1);
+  }
+  void setWordCount(SPIRVWord TheWC) {
+    WordCount = TheWC;
+    Acc.resize(WordCount - FixedWC);
+  }
+
+private:
+  SPIRVId SampledType;
+  SPIRVTypeImageDescriptor Desc;
+  std::vector<SPIRVAccessQualifierKind> Acc;
+};
+
+class SPIRVTypeSampler : public SPIRVType {
+public:
+  const static Op OC = OpTypeSampler;
+  const static SPIRVWord FixedWC = 2;
+  SPIRVTypeSampler(SPIRVModule *M, SPIRVId TheId)
+      : SPIRVType(M, FixedWC, OC, TheId) {
+    validate();
+  }
+  SPIRVTypeSampler() : SPIRVType(OC) {}
+
+protected:
+  _SPIRV_DEF_ENCDEC1(Id)
+  void validate() const {
+    assert(OpCode == OC);
+    assert(WordCount == FixedWC);
+  }
+};
+
+class SPIRVTypeSampledImage : public SPIRVType {
+public:
+  const static Op OC = OpTypeSampledImage;
+  const static SPIRVWord FixedWC = 3;
+  SPIRVTypeSampledImage(SPIRVModule *M, SPIRVId TheId, SPIRVTypeImage *TheImgTy)
+      : SPIRVType(M, FixedWC, OC, TheId), ImgTy(TheImgTy) {
+    validate();
+  }
+  SPIRVTypeSampledImage() : SPIRVType(OC), ImgTy(nullptr) {}
+
+  const SPIRVTypeImage *getImageType() const { return ImgTy; }
+
+  void setImageType(SPIRVTypeImage *TheImgTy) { ImgTy = TheImgTy; }
+
+  virtual std::vector<SPIRVEntry *> getNonLiteralOperands() const {
+    return std::vector<SPIRVEntry *>(1, ImgTy);
+  }
+
+protected:
+  SPIRVTypeImage *ImgTy;
+  _SPIRV_DEF_ENCDEC2(Id, ImgTy)
+  void validate() const {
+    assert(OpCode == OC);
+    assert(WordCount == FixedWC);
+    assert(ImgTy && ImgTy->isTypeImage());
+  }
+};
+
+class SPIRVTypePipeStorage : public SPIRVType {
+public:
+  const static Op OC = OpTypePipeStorage;
+  const static SPIRVWord FixedWC = 2;
+  SPIRVTypePipeStorage(SPIRVModule *M, SPIRVId TheId)
+      : SPIRVType(M, FixedWC, OC, TheId) {
+    validate();
+  }
+  SPIRVTypePipeStorage() : SPIRVType(OC) {}
+
+protected:
+  _SPIRV_DEF_ENCDEC1(Id)
+  void validate() const {
+    assert(OpCode == OC);
+    assert(WordCount == FixedWC);
+  }
+};
+
+class SPIRVTypeStruct : public SPIRVType {
+public:
+  // Complete constructor
+  SPIRVTypeStruct(SPIRVModule *M, SPIRVId TheId,
+                  const std::vector<SPIRVType *> &TheMemberTypes,
+                  const std::string &TheName)
+      : SPIRVType(M, 2 + TheMemberTypes.size(), OpTypeStruct, TheId) {
+    MemberTypeIdVec.resize(TheMemberTypes.size());
+    for (auto &t : TheMemberTypes)
+      MemberTypeIdVec.push_back(t->getId());
+    Name = TheName;
+    validate();
+  }
+  SPIRVTypeStruct(SPIRVModule *M, SPIRVId TheId, unsigned NumMembers,
+                  const std::string &TheName)
+      : SPIRVType(M, 2 + NumMembers, OpTypeStruct, TheId) {
+    Name = TheName;
+    validate();
+    MemberTypeIdVec.resize(NumMembers);
+  }
+  // Incomplete constructor
+  SPIRVTypeStruct() : SPIRVType(OpTypeStruct) {}
+
+  SPIRVWord getMemberCount() const { return MemberTypeIdVec.size(); }
+  SPIRVType *getMemberType(size_t I) const {
+    return static_cast<SPIRVType *>(getEntry(MemberTypeIdVec[I]));
+  }
+  void setMemberType(size_t I, SPIRVType *Ty) {
+    MemberTypeIdVec[I] = Ty->getId();
+  }
+
+  bool isPacked() const;
+  void setPacked(bool Packed);
+
+  void setWordCount(SPIRVWord WordCount) {
+    SPIRVType::setWordCount(WordCount);
+    MemberTypeIdVec.resize(WordCount - 2);
+  }
+
+  virtual std::vector<SPIRVEntry *> getNonLiteralOperands() const {
+    std::vector<SPIRVEntry *> Operands(MemberTypeIdVec.size());
+    for (size_t I = 0, E = MemberTypeIdVec.size(); I < E; ++I)
+      Operands[I] = getEntry(MemberTypeIdVec[I]);
+    return Operands;
+  }
+
+protected:
+  _SPIRV_DEF_ENCDEC2(Id, MemberTypeIdVec)
+
+  void validate() const { SPIRVEntry::validate(); }
+
+private:
+  std::vector<SPIRVId> MemberTypeIdVec; // Member Type Ids
+};
+
+class SPIRVTypeFunction : public SPIRVType {
+public:
+  // Complete constructor
+  SPIRVTypeFunction(SPIRVModule *M, SPIRVId TheId, SPIRVType *TheReturnType,
+                    const std::vector<SPIRVType *> &TheParameterTypes)
+      : SPIRVType(M, 3 + TheParameterTypes.size(), OpTypeFunction, TheId),
+        ReturnType(TheReturnType), ParamTypeVec(TheParameterTypes) {
+    validate();
+  }
+  // Incomplete constructor
+  SPIRVTypeFunction() : SPIRVType(OpTypeFunction), ReturnType(NULL) {}
+
+  SPIRVType *getReturnType() const { return ReturnType; }
+  SPIRVWord getNumParameters() const { return ParamTypeVec.size(); }
+  SPIRVType *getParameterType(unsigned I) const { return ParamTypeVec[I]; }
+  virtual std::vector<SPIRVEntry *> getNonLiteralOperands() const {
+    std::vector<SPIRVEntry *> Operands(1 + ParamTypeVec.size(), ReturnType);
+    std::copy(ParamTypeVec.begin(), ParamTypeVec.end(), ++Operands.begin());
+    return Operands;
+  }
+
+protected:
+  _SPIRV_DEF_ENCDEC3(Id, ReturnType, ParamTypeVec)
+  void setWordCount(SPIRVWord WordCount) {
+    SPIRVType::setWordCount(WordCount);
+    ParamTypeVec.resize(WordCount - 3);
+  }
+  void validate() const {
+    SPIRVEntry::validate();
+    ReturnType->validate();
+    for (auto T : ParamTypeVec)
+      T->validate();
+  }
+
+private:
+  SPIRVType *ReturnType;                 // Return Type
+  std::vector<SPIRVType *> ParamTypeVec; // Parameter Types
+};
+
+class SPIRVTypeOpaqueGeneric : public SPIRVType {
+public:
+  // Complete constructor
+  SPIRVTypeOpaqueGeneric(Op TheOpCode, SPIRVModule *M, SPIRVId TheId)
+      : SPIRVType(M, 2, TheOpCode, TheId) {
+    validate();
+  }
+
+  // Incomplete constructor
+  SPIRVTypeOpaqueGeneric(Op TheOpCode)
+      : SPIRVType(TheOpCode), Opn(SPIRVID_INVALID) {}
+
+  SPIRVValue *getOperand() { return getValue(Opn); }
+
+protected:
+  _SPIRV_DEF_ENCDEC1(Id)
+  void validate() const { SPIRVEntry::validate(); }
+  SPIRVId Opn;
+};
+
+template <Op TheOpCode>
+class SPIRVOpaqueGenericType : public SPIRVTypeOpaqueGeneric {
+public:
+  // Complete constructor
+  SPIRVOpaqueGenericType(SPIRVModule *M, SPIRVId TheId)
+      : SPIRVTypeOpaqueGeneric(TheOpCode, M, TheId) {}
+  // Incomplete constructor
+  SPIRVOpaqueGenericType() : SPIRVTypeOpaqueGeneric(TheOpCode) {}
+};
+
+#define _SPIRV_OP(x) typedef SPIRVOpaqueGenericType<OpType##x> SPIRVType##x;
+_SPIRV_OP(Event)
+_SPIRV_OP(ReserveId)
+#undef _SPIRV_OP
+
+class SPIRVTypeDeviceEvent : public SPIRVType {
+public:
+  // Complete constructor
+  SPIRVTypeDeviceEvent(SPIRVModule *M, SPIRVId TheId)
+      : SPIRVType(M, 2, OpTypeDeviceEvent, TheId) {
+    validate();
+  }
+
+  // Incomplete constructor
+  SPIRVTypeDeviceEvent() : SPIRVType(OpTypeDeviceEvent) {}
+
+  SPIRVCapVec getRequiredCapability() const {
+    return getVec(CapabilityDeviceEnqueue);
+  }
+
+protected:
+  _SPIRV_DEF_ENCDEC1(Id)
+  void validate() const { SPIRVEntry::validate(); }
+};
+
+class SPIRVTypeQueue : public SPIRVType {
+public:
+  // Complete constructor
+  SPIRVTypeQueue(SPIRVModule *M, SPIRVId TheId)
+      : SPIRVType(M, 2, OpTypeQueue, TheId) {
+    validate();
+  }
+
+  // Incomplete constructor
+  SPIRVTypeQueue() : SPIRVType(OpTypeQueue) {}
+
+  SPIRVCapVec getRequiredCapability() const {
+    return getVec(CapabilityDeviceEnqueue);
+  }
+
+protected:
+  _SPIRV_DEF_ENCDEC1(Id)
+};
+
+class SPIRVTypePipe : public SPIRVType {
+public:
+  // Complete constructor
+  SPIRVTypePipe(SPIRVModule *M, SPIRVId TheId,
+                SPIRVAccessQualifierKind AccessQual = AccessQualifierReadOnly)
+      : SPIRVType(M, 3, OpTypePipe, TheId), AccessQualifier(AccessQual) {
+    validate();
+  }
+
+  // Incomplete constructor
+  SPIRVTypePipe()
+      : SPIRVType(OpTypePipe), AccessQualifier(AccessQualifierReadOnly) {}
+
+  SPIRVAccessQualifierKind getAccessQualifier() const {
+    return AccessQualifier;
+  }
+  void setPipeAcessQualifier(SPIRVAccessQualifierKind AccessQual) {
+    AccessQualifier = AccessQual;
+    assert(isValid(AccessQualifier));
+  }
+  SPIRVCapVec getRequiredCapability() const { return getVec(CapabilityPipes); }
+
+protected:
+  _SPIRV_DEF_ENCDEC2(Id, AccessQualifier)
+  void validate() const { SPIRVEntry::validate(); }
+
+private:
+  SPIRVAccessQualifierKind AccessQualifier; // Access Qualifier
+};
+
+template <typename T2, typename T1>
+bool isType(const T1 *Ty, unsigned Bits = 0) {
+  bool Is = Ty->getOpCode() == T2::OC;
+  if (!Is)
+    return false;
+  if (Bits == 0)
+    return true;
+  return static_cast<const T2 *>(Ty)->getBitWidth() == Bits;
+}
+}
+#endif // SPIRVTYPE_HPP_
diff --git a/lib/SPIRV/libSPIRV/SPIRVUtil.h b/lib/SPIRV/libSPIRV/SPIRVUtil.h
new file mode 100644
index 0000000..1c13280
--- /dev/null
+++ b/lib/SPIRV/libSPIRV/SPIRVUtil.h
@@ -0,0 +1,421 @@
+//===- SPIRVUtil.h - SPIR-V Utility Functions -------------------*- C++ -*-===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+/// \file
+///
+/// This file defines SPIR-V utility functions.
+///
+//===----------------------------------------------------------------------===//
+
+#ifndef SPIRVUTIL_H_
+#define SPIRVUTIL_H_
+
+#ifdef _SPIRV_LLVM_API
+#include "llvm/Support/raw_ostream.h"
+#define spv_ostream llvm::raw_ostream
+#else
+#include <ostream>
+#define spv_ostream std::ostream
+#endif
+
+#include <algorithm>
+#include <cassert>
+#include <cstdint>
+#include <functional>
+#include <limits>
+#include <map>
+#include <set>
+#include <sstream>
+#include <string>
+#include <unordered_set>
+#include <vector>
+
+// MSVC supports "magic statics" since MSVS 2015.
+// For the previous version of MSVS we should guard
+// initialization of local static variables.
+#if defined(_MSC_VER) && (_MSC_VER < 1900)
+#include "llvm/Support/Mutex.h"
+#include "llvm/Support/MutexGuard.h"
+#endif // LLVM_MSC_PREREQ(1900)
+
+namespace SPIRV {
+#if defined(_MSC_VER) && (_MSC_VER < 1900)
+static llvm::sys::Mutex MapLock;
+#endif // LLVM_MSC_PREREQ(1900)
+
+#define SPIRV_DEF_NAMEMAP(Type, MapType)                                       \
+  typedef SPIRVMap<Type, std::string> MapType;                                 \
+  inline MapType getNameMap(Type) {                                            \
+    MapType MT;                                                                \
+    return MT;                                                                 \
+  }
+
+// A bi-way map
+template <class Ty1, class Ty2, class Identifier = void> struct SPIRVMap {
+public:
+  typedef Ty1 KeyTy;
+  typedef Ty2 ValueTy;
+  // Initialize map entries
+  void init();
+
+  static Ty2 map(Ty1 Key) {
+    Ty2 Val;
+    bool Found = find(Key, &Val);
+    assert(Found && "Invalid key");
+    return Val;
+  }
+
+  static Ty1 rmap(Ty2 Key) {
+    Ty1 Val;
+    bool Found = rfind(Key, &Val);
+    assert(Found && "Invalid key");
+    return Val;
+  }
+
+  static SPIRVMap &getMapMod() {
+#if defined(_MSC_VER) && (_MSC_VER < 1900)
+    llvm::sys::ScopedLock mapGuard(MapLock);
+#endif // LLVM_MSC_PREREQ(1900)
+    static SPIRVMap Map(false);
+    return Map;
+  }
+
+  static SPIRVMap &getRMapMod() {
+#if defined(_MSC_VER) && (_MSC_VER < 1900)
+    llvm::sys::ScopedLock mapGuard(MapLock);
+#endif // LLVM_MSC_PREREQ(1900)
+    static SPIRVMap Map(true);
+    return Map;
+  }
+
+  static const SPIRVMap &getMap() { return getMapMod(); }
+
+  static const SPIRVMap &getRMap() { return getRMapMod(); }
+
+  static void foreach (std::function<void(Ty1, Ty2)> F) {
+    for (auto &I : getMap().Map)
+      F(I.first, I.second);
+  }
+
+  // For each key/value in the map executes function \p F.
+  // If \p F returns false break the iteration.
+  static void foreach_conditional(std::function<bool(const Ty1 &, Ty2)> F) {
+    for (auto &I : getMap().Map) {
+      if (!F(I.first, I.second))
+        break;
+    }
+  }
+
+  static bool find(Ty1 Key, Ty2 *Val = nullptr) {
+    const SPIRVMap &Map = getMap();
+    typename MapTy::const_iterator Loc = Map.Map.find(Key);
+    if (Loc == Map.Map.end())
+      return false;
+    if (Val)
+      *Val = Loc->second;
+    return true;
+  }
+
+  static bool rfind(Ty2 Key, Ty1 *Val = nullptr) {
+    const SPIRVMap &Map = getRMap();
+    typename RevMapTy::const_iterator Loc = Map.RevMap.find(Key);
+    if (Loc == Map.RevMap.end())
+      return false;
+    if (Val)
+      *Val = Loc->second;
+    return true;
+  }
+
+  static void replace(Ty1 Key, Ty2 Val) {
+    SPIRVMap &Map = getMapMod();
+    SPIRVMap &RMap = getRMapMod();
+    Map.Map[Key] = Val;
+    RMap.RevMap[Val] = Key;
+  }
+
+  SPIRVMap() : IsReverse(false) {}
+
+protected:
+  SPIRVMap(bool Reverse) : IsReverse(Reverse) { init(); }
+  typedef std::map<Ty1, Ty2> MapTy;
+  typedef std::map<Ty2, Ty1> RevMapTy;
+
+  void add(Ty1 V1, Ty2 V2) {
+    if (IsReverse) {
+      RevMap[V2] = V1;
+      return;
+    }
+    Map[V1] = V2;
+  }
+  MapTy Map;
+  RevMapTy RevMap;
+  bool IsReverse;
+};
+
+inline std::vector<std::string> getVec(const std::string &S, char Delim) {
+  std::vector<std::string> Strs;
+  std::stringstream SS(S);
+  std::string Item;
+  while (std::getline(SS, Item, Delim))
+    Strs.push_back(Item);
+  return Strs;
+}
+
+inline std::unordered_set<std::string> getUnordSet(const std::string &S,
+                                                   char Delim = ' ') {
+  std::unordered_set<std::string> Strs;
+  std::stringstream SS(S);
+  std::string Item;
+  while (std::getline(SS, Item, Delim))
+    Strs.insert(Item);
+  return Strs;
+}
+
+inline std::set<std::string> getSet(const std::string &S, char Delim = ' ') {
+  std::set<std::string> Strs;
+  std::stringstream SS(S);
+  std::string Item;
+  while (std::getline(SS, Item, Delim))
+    Strs.insert(Item);
+  return Strs;
+}
+
+template <typename VT, typename KT> VT map(KT Key) {
+  return SPIRVMap<KT, VT>::map(Key);
+}
+
+template <typename KT, typename VT> KT rmap(VT V) {
+  return SPIRVMap<KT, VT>::rmap(V);
+}
+
+template <typename VT, typename KT>
+std::unordered_set<VT> map(const std::unordered_set<KT> &KSet) {
+  VT V;
+  std::unordered_set<VT> VSet;
+  for (auto &I : KSet)
+    if (SPIRVMap<KT, VT>::find(I, &V))
+      VSet.insert(V);
+  return VSet;
+}
+
+template <typename VT, typename KT> std::set<VT> map(const std::set<KT> &KSet) {
+  VT V;
+  std::set<VT> VSet;
+  for (auto &I : KSet)
+    if (SPIRVMap<KT, VT>::find(I, &V))
+      VSet.insert(V);
+  return VSet;
+}
+
+template <typename KT, typename VT>
+std::unordered_set<KT> rmap(const std::unordered_set<VT> &KSet) {
+  KT V;
+  std::unordered_set<KT> VSet;
+  for (auto &I : KSet)
+    if (SPIRVMap<KT, VT>::rfind(I, &V))
+      VSet.insert(V);
+  return VSet;
+}
+
+template <typename KT, typename VT>
+std::set<KT> rmap(const std::set<VT> &KSet) {
+  KT V;
+  std::set<KT> VSet;
+  for (auto &I : KSet)
+    if (SPIRVMap<KT, VT>::rfind(I, &V))
+      VSet.insert(V);
+  return VSet;
+}
+
+template <typename KT, typename VT, typename Any>
+std::set<KT> rmap(const std::map<VT, Any> &KMap) {
+  KT V;
+  std::set<KT> VSet;
+  for (auto &I : KMap)
+    if (SPIRVMap<KT, VT>::rfind(I.first, &V))
+      VSet.insert(V);
+
+  return VSet;
+}
+
+template <typename K> std::string getName(K Key) {
+  std::string Name;
+  if (SPIRVMap<K, std::string>::find(Key, &Name))
+    return Name;
+  return "";
+}
+
+template <typename K> bool getByName(const std::string &Name, K &Key) {
+  return SPIRVMap<K, std::string>::rfind(Name, &Key);
+}
+
+// Add a number as a string to a string
+template <class T> std::string concat(const std::string &s, const T &n) {
+  std::stringstream ss;
+  ss << s << n;
+  return ss.str();
+}
+
+inline std::string concat(const std::string &S1, const std::string &S2,
+                          char Delim = ' ') {
+  std::string S;
+  if (S1.empty())
+    S = S2;
+  else if (!S2.empty())
+    S = S1 + Delim + S2;
+  return S;
+}
+
+inline std::string operator+(const std::string &s, int n) {
+  return concat(s, n);
+}
+
+inline std::string operator+(const std::string &s, unsigned n) {
+  return concat(s, n);
+}
+
+template <typename T> std::string getStr(const T &C, char Delim = ' ') {
+  std::stringstream SS;
+  bool First = true;
+  for (auto &I : C) {
+    if (!First)
+      SS << Delim;
+    else
+      First = false;
+    SS << I;
+  }
+  return SS.str();
+}
+
+template <class MapTy> unsigned mapBitMask(unsigned BM) {
+  unsigned Res = 0;
+  MapTy::foreach ([&](typename MapTy::KeyTy K, typename MapTy::ValueTy V) {
+    Res |= BM & (unsigned)K ? (unsigned)V : 0;
+  });
+  return Res;
+}
+
+template <class MapTy> unsigned rmapBitMask(unsigned BM) {
+  unsigned Res = 0;
+  MapTy::foreach ([&](typename MapTy::KeyTy K, typename MapTy::ValueTy V) {
+    Res |= BM & (unsigned)V ? (unsigned)K : 0;
+  });
+  return Res;
+}
+
+// Get the number of words used for encoding a string literal in SPIRV
+inline unsigned getSizeInWords(const std::string &Str) {
+  assert(Str.length() / 4 + 1 <= std::numeric_limits<unsigned>::max());
+  return static_cast<unsigned>(Str.length() / 4 + 1);
+}
+
+inline std::string getString(std::vector<uint32_t>::const_iterator Begin,
+                             std::vector<uint32_t>::const_iterator End) {
+  std::string Str = std::string();
+  for (auto I = Begin; I != End; ++I) {
+    uint32_t Word = *I;
+    for (unsigned J = 0u; J < 32u; J += 8u) {
+      char Char = (char)((Word >> J) & 0xff);
+      if (Char == '\0')
+        return Str;
+      Str += Char;
+    }
+  }
+  return Str;
+}
+
+inline std::string getString(const std::vector<uint32_t> &V) {
+  return getString(V.cbegin(), V.cend());
+}
+
+inline std::vector<uint32_t> getVec(const std::string &Str) {
+  std::vector<uint32_t> V;
+  auto StrSize = Str.size();
+  uint32_t CurrentWord = 0u;
+  for (unsigned I = 0u; I < StrSize; ++I) {
+    if (I % 4u == 0u && I != 0u) {
+      V.push_back(CurrentWord);
+      CurrentWord = 0u;
+    }
+    assert(Str[I] && "0 is not allowed in string");
+    CurrentWord += ((uint32_t)Str[I]) << ((I % 4u) * 8u);
+  }
+  if (CurrentWord != 0u)
+    V.push_back(CurrentWord);
+  if (StrSize % 4 == 0)
+    V.push_back(0);
+  return V;
+}
+
+template <typename T> inline std::vector<T> getVec(T Op1) {
+  std::vector<T> V;
+  V.push_back(Op1);
+  return V;
+}
+
+template <typename T> inline std::vector<T> getVec(T Op1, T Op2) {
+  std::vector<T> V;
+  V.push_back(Op1);
+  V.push_back(Op2);
+  return V;
+}
+
+template <typename T> inline std::vector<T> getVec(T Op1, T Op2, T Op3) {
+  std::vector<T> V;
+  V.push_back(Op1);
+  V.push_back(Op2);
+  V.push_back(Op3);
+  return V;
+}
+
+template <typename T>
+inline std::vector<T> getVec(T Op1, const std::vector<T> &Ops2) {
+  std::vector<T> V;
+  V.push_back(Op1);
+  V.insert(V.end(), Ops2.begin(), Ops2.end());
+  return V;
+}
+
+template <typename MapTy, typename FuncTy>
+typename MapTy::mapped_type
+getOrInsert(MapTy &Map, typename MapTy::key_type Key, FuncTy Func) {
+  typename MapTy::iterator Loc = Map.find(Key);
+  if (Loc != Map.end())
+    return Loc->second;
+  typename MapTy::mapped_type NF = Func();
+  Map[Key] = NF;
+  return NF;
+}
+}
+
+#endif /* SPIRVUTIL_HPP_ */
diff --git a/lib/SPIRV/libSPIRV/SPIRVValue.cpp b/lib/SPIRV/libSPIRV/SPIRVValue.cpp
new file mode 100644
index 0000000..29bbdfb
--- /dev/null
+++ b/lib/SPIRV/libSPIRV/SPIRVValue.cpp
@@ -0,0 +1,70 @@
+//===- SPIRVValue.cpp - Class to represent a SPIR-V Value -------*- C++ -*-===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+/// \file
+///
+/// This file defines the values defined in SPIR-V spec with op codes.
+///
+/// The name of the SPIR-V values follow the op code name in the spec.
+/// This is for readability and ease of using macro to handle types.
+//
+//===----------------------------------------------------------------------===//
+
+#include "SPIRVValue.h"
+#include "SPIRVEnum.h"
+namespace SPIRV {
+void SPIRVValue::setAlignment(SPIRVWord A) {
+  if (A == 0) {
+    eraseDecorate(DecorationAlignment);
+    return;
+  }
+  addDecorate(new SPIRVDecorate(DecorationAlignment, this, A));
+  SPIRVDBG(spvdbgs() << "Set alignment " << A << " for obj " << Id << "\n")
+}
+
+bool SPIRVValue::hasAlignment(SPIRVWord *Result) const {
+  return hasDecorate(DecorationAlignment, 0, Result);
+}
+
+bool SPIRVValue::isVolatile() const { return hasDecorate(DecorationVolatile); }
+
+void SPIRVValue::setVolatile(bool IsVolatile) {
+  if (!IsVolatile) {
+    eraseDecorate(DecorationVolatile);
+    return;
+  }
+  addDecorate(new SPIRVDecorate(DecorationVolatile, this));
+  SPIRVDBG(spvdbgs() << "Set volatile "
+                     << " for obj " << Id << "\n")
+}
+}
diff --git a/lib/SPIRV/libSPIRV/SPIRVValue.h b/lib/SPIRV/libSPIRV/SPIRVValue.h
new file mode 100644
index 0000000..7f00280
--- /dev/null
+++ b/lib/SPIRV/libSPIRV/SPIRVValue.h
@@ -0,0 +1,386 @@
+//===- SPIRVValue.h - Class to represent a SPIR-V Value ---------*- C++ -*-===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+/// \file
+///
+/// This file defines the values defined in SPIR-V spec with op codes.
+///
+/// The name of the SPIR-V values follow the op code name in the spec.
+/// This is for readability and ease of using macro to handle types.
+//
+//===----------------------------------------------------------------------===//
+
+#ifndef SPIRVVALUE_HPP_
+#define SPIRVVALUE_HPP_
+
+#include "SPIRVEntry.h"
+#include "SPIRVType.h"
+#include "SPIRVDecorate.h"
+
+#include <iostream>
+#include <map>
+#include <memory>
+
+namespace SPIRV {
+
+class SPIRVValue : public SPIRVEntry {
+public:
+  // Complete constructor for value with id and type
+  SPIRVValue(SPIRVModule *M, unsigned TheWordCount, Op TheOpCode,
+             SPIRVType *TheType, SPIRVId TheId)
+      : SPIRVEntry(M, TheWordCount, TheOpCode, TheId), Type(TheType) {
+    validate();
+  }
+  // Complete constructor for value with type but without id
+  SPIRVValue(SPIRVModule *M, unsigned TheWordCount, Op TheOpCode,
+             SPIRVType *TheType)
+      : SPIRVEntry(M, TheWordCount, TheOpCode), Type(TheType) {
+    setHasNoId();
+    validate();
+  }
+  // Complete constructor for value with id but without type
+  SPIRVValue(SPIRVModule *M, unsigned TheWordCount, Op TheOpCode, SPIRVId TheId)
+      : SPIRVEntry(M, TheWordCount, TheOpCode, TheId), Type(NULL) {
+    setHasNoType();
+    validate();
+  }
+  // Complete constructor for value without id and type
+  SPIRVValue(SPIRVModule *M, unsigned TheWordCount, Op TheOpCode)
+      : SPIRVEntry(M, TheWordCount, TheOpCode), Type(NULL) {
+    setHasNoId();
+    setHasNoType();
+    validate();
+  }
+  // Incomplete constructor
+  SPIRVValue(Op TheOpCode) : SPIRVEntry(TheOpCode), Type(NULL) {}
+
+  bool hasType() const { return !(Attrib & SPIRVEA_NOTYPE); }
+  SPIRVType *getType() const {
+    assert(hasType() && "value has no type");
+    return Type;
+  }
+  bool isVolatile() const;
+  bool hasAlignment(SPIRVWord *Result = 0) const;
+
+  void setAlignment(SPIRVWord);
+  void setVolatile(bool IsVolatile);
+
+  void validate() const {
+    SPIRVEntry::validate();
+    assert((!hasType() || Type) && "Invalid type");
+  }
+
+  void setType(SPIRVType *Ty) {
+    Type = Ty;
+    assert(!Ty || !Ty->isTypeVoid() || OpCode == OpFunction);
+    if (Ty && (!Ty->isTypeVoid() || OpCode == OpFunction))
+      setHasType();
+    else
+      setHasNoType();
+  }
+
+  SPIRVCapVec getRequiredCapability() const {
+    SPIRVCapVec CV;
+    if (!hasType())
+      return CV;
+    return Type->getRequiredCapability();
+  }
+
+protected:
+  void setHasNoType() { Attrib |= SPIRVEA_NOTYPE; }
+  void setHasType() { Attrib &= ~SPIRVEA_NOTYPE; }
+
+  SPIRVType *Type; // Value Type
+};
+
+class SPIRVConstant : public SPIRVValue {
+public:
+  // Complete constructor for integer constant
+  SPIRVConstant(SPIRVModule *M, SPIRVType *TheType, SPIRVId TheId,
+                uint64_t TheValue)
+      : SPIRVValue(M, 0, OpConstant, TheType, TheId) {
+    Union.UInt64Val = TheValue;
+    recalculateWordCount();
+    validate();
+  }
+  // Complete constructor for float constant
+  SPIRVConstant(SPIRVModule *M, SPIRVType *TheType, SPIRVId TheId,
+                float TheValue)
+      : SPIRVValue(M, 0, OpConstant, TheType, TheId) {
+    Union.FloatVal = TheValue;
+    recalculateWordCount();
+    validate();
+  }
+  // Complete constructor for double constant
+  SPIRVConstant(SPIRVModule *M, SPIRVType *TheType, SPIRVId TheId,
+                double TheValue)
+      : SPIRVValue(M, 0, OpConstant, TheType, TheId) {
+    Union.DoubleVal = TheValue;
+    recalculateWordCount();
+    validate();
+  }
+  // Incomplete constructor
+  SPIRVConstant() : SPIRVValue(OpConstant), NumWords(0) {}
+  uint64_t getZExtIntValue() const { return Union.UInt64Val; }
+  float getFloatValue() const { return Union.FloatVal; }
+  double getDoubleValue() const { return Union.DoubleVal; }
+
+protected:
+  void recalculateWordCount() {
+    NumWords = Type->getBitWidth() / 32;
+    if (NumWords < 1)
+      NumWords = 1;
+    WordCount = 3 + NumWords;
+  }
+  void validate() const {
+    SPIRVValue::validate();
+    assert(NumWords >= 1 && NumWords <= 2 && "Invalid constant size");
+  }
+  void encode(spv_ostream &O) const {
+    getEncoder(O) << Type << Id;
+    for (unsigned i = 0; i < NumWords; ++i)
+      getEncoder(O) << Union.Words[i];
+  }
+  void setWordCount(SPIRVWord WordCount) {
+    SPIRVValue::setWordCount(WordCount);
+    NumWords = WordCount - 3;
+  }
+  void decode(std::istream &I) {
+    getDecoder(I) >> Type >> Id;
+    for (unsigned i = 0; i < NumWords; ++i)
+      getDecoder(I) >> Union.Words[i];
+  }
+
+  unsigned NumWords;
+  union UnionType {
+    uint64_t UInt64Val;
+    float FloatVal;
+    double DoubleVal;
+    SPIRVWord Words[2];
+    UnionType() { UInt64Val = 0; }
+  } Union;
+};
+
+template <Op OC> class SPIRVConstantEmpty : public SPIRVValue {
+public:
+  // Complete constructor
+  SPIRVConstantEmpty(SPIRVModule *M, SPIRVType *TheType, SPIRVId TheId)
+      : SPIRVValue(M, 3, OC, TheType, TheId) {
+    validate();
+  }
+  // Incomplete constructor
+  SPIRVConstantEmpty() : SPIRVValue(OC) {}
+
+protected:
+  void validate() const { SPIRVValue::validate(); }
+  _SPIRV_DEF_ENCDEC2(Type, Id)
+};
+
+template <Op OC> class SPIRVConstantBool : public SPIRVConstantEmpty<OC> {
+public:
+  // Complete constructor
+  SPIRVConstantBool(SPIRVModule *M, SPIRVType *TheType, SPIRVId TheId)
+      : SPIRVConstantEmpty<OC>(M, TheType, TheId) {}
+  // Incomplete constructor
+  SPIRVConstantBool() {}
+
+protected:
+  void validate() const {
+    SPIRVConstantEmpty<OC>::validate();
+    assert(this->Type->isTypeBool() && "Invalid type");
+  }
+};
+
+typedef SPIRVConstantBool<OpConstantTrue> SPIRVConstantTrue;
+typedef SPIRVConstantBool<OpConstantFalse> SPIRVConstantFalse;
+
+class SPIRVConstantNull : public SPIRVConstantEmpty<OpConstantNull> {
+public:
+  // Complete constructor
+  SPIRVConstantNull(SPIRVModule *M, SPIRVType *TheType, SPIRVId TheId)
+      : SPIRVConstantEmpty(M, TheType, TheId) {
+    validate();
+  }
+  // Incomplete constructor
+  SPIRVConstantNull() {}
+
+protected:
+  void validate() const {
+    SPIRVConstantEmpty::validate();
+    assert((Type->isTypeComposite() || Type->isTypeOpaque() ||
+            Type->isTypeEvent() || Type->isTypePointer() ||
+            Type->isTypeReserveId() || Type->isTypeDeviceEvent()) &&
+           "Invalid type");
+  }
+};
+
+class SPIRVUndef : public SPIRVConstantEmpty<OpUndef> {
+public:
+  // Complete constructor
+  SPIRVUndef(SPIRVModule *M, SPIRVType *TheType, SPIRVId TheId)
+      : SPIRVConstantEmpty(M, TheType, TheId) {
+    validate();
+  }
+  // Incomplete constructor
+  SPIRVUndef() {}
+
+protected:
+  void validate() const { SPIRVConstantEmpty::validate(); }
+};
+
+class SPIRVConstantComposite : public SPIRVValue {
+public:
+  // Complete constructor for composite constant
+  SPIRVConstantComposite(SPIRVModule *M, SPIRVType *TheType, SPIRVId TheId,
+                         const std::vector<SPIRVValue *> TheElements)
+      : SPIRVValue(M, TheElements.size() + 3, OpConstantComposite, TheType,
+                   TheId) {
+    Elements = getIds(TheElements);
+    validate();
+  }
+  // Incomplete constructor
+  SPIRVConstantComposite() : SPIRVValue(OpConstantComposite) {}
+  std::vector<SPIRVValue *> getElements() const { return getValues(Elements); }
+  std::vector<SPIRVEntry *> getNonLiteralOperands() const {
+    std::vector<SPIRVValue *> Elements = getElements();
+    return std::vector<SPIRVEntry *>(Elements.begin(), Elements.end());
+  }
+
+protected:
+  void validate() const {
+    SPIRVValue::validate();
+    for (auto &I : Elements)
+      getValue(I)->validate();
+  }
+  void setWordCount(SPIRVWord WordCount) { Elements.resize(WordCount - 3); }
+  _SPIRV_DEF_ENCDEC3(Type, Id, Elements)
+
+  std::vector<SPIRVId> Elements;
+};
+
+class SPIRVConstantSampler : public SPIRVValue {
+public:
+  const static Op OC = OpConstantSampler;
+  const static SPIRVWord WC = 6;
+  // Complete constructor
+  SPIRVConstantSampler(SPIRVModule *M, SPIRVType *TheType, SPIRVId TheId,
+                       SPIRVWord TheAddrMode, SPIRVWord TheNormalized,
+                       SPIRVWord TheFilterMode)
+      : SPIRVValue(M, WC, OC, TheType, TheId), AddrMode(TheAddrMode),
+        Normalized(TheNormalized), FilterMode(TheFilterMode) {
+    validate();
+  }
+  // Incomplete constructor
+  SPIRVConstantSampler()
+      : SPIRVValue(OC), AddrMode(SPIRVSAM_Invalid), Normalized(SPIRVWORD_MAX),
+        FilterMode(SPIRVSFM_Invalid) {}
+
+  SPIRVWord getAddrMode() const { return AddrMode; }
+
+  SPIRVWord getFilterMode() const { return FilterMode; }
+
+  SPIRVWord getNormalized() const { return Normalized; }
+  SPIRVCapVec getRequiredCapability() const {
+    return getVec(CapabilityLiteralSampler);
+  }
+
+protected:
+  SPIRVWord AddrMode;
+  SPIRVWord Normalized;
+  SPIRVWord FilterMode;
+  void validate() const {
+    SPIRVValue::validate();
+    assert(OpCode == OC);
+    assert(WordCount == WC);
+    assert(Type->isTypeSampler());
+  }
+  _SPIRV_DEF_ENCDEC5(Type, Id, AddrMode, Normalized, FilterMode)
+};
+
+class SPIRVConstantPipeStorage : public SPIRVValue {
+public:
+  const static Op OC = OpConstantPipeStorage;
+  const static SPIRVWord WC = 6;
+  // Complete constructor
+  SPIRVConstantPipeStorage(SPIRVModule *M, SPIRVType *TheType, SPIRVId TheId,
+                           SPIRVWord ThePacketSize, SPIRVWord ThePacketAlign,
+                           SPIRVWord TheCapacity)
+      : SPIRVValue(M, WC, OC, TheType, TheId), PacketSize(ThePacketSize),
+        PacketAlign(ThePacketAlign), Capacity(TheCapacity) {
+    validate();
+  }
+  // Incomplete constructor
+  SPIRVConstantPipeStorage()
+      : SPIRVValue(OC), PacketSize(0), PacketAlign(0), Capacity(0) {}
+
+  SPIRVWord getPacketSize() const { return PacketSize; }
+
+  SPIRVWord getPacketAlign() const { return PacketAlign; }
+
+  SPIRVWord getCapacity() const { return Capacity; }
+  SPIRVCapVec getRequiredCapability() const {
+    return getVec(CapabilityPipes, CapabilityPipeStorage);
+  }
+
+protected:
+  SPIRVWord PacketSize;
+  SPIRVWord PacketAlign;
+  SPIRVWord Capacity;
+  void validate() const {
+    SPIRVValue::validate();
+    assert(OpCode == OC);
+    assert(WordCount == WC);
+    assert(Type->isTypePipeStorage());
+  }
+  _SPIRV_DEF_ENCDEC5(Type, Id, PacketSize, PacketAlign, Capacity)
+};
+
+class SPIRVForward : public SPIRVValue, public SPIRVComponentExecutionModes {
+public:
+  const static Op OC = OpForward;
+  // Complete constructor
+  SPIRVForward(SPIRVModule *TheModule, SPIRVType *TheTy, SPIRVId TheId)
+      : SPIRVValue(TheModule, 0, OC, TheId) {
+    if (TheTy)
+      setType(TheTy);
+  }
+  SPIRVForward() : SPIRVValue(OC) { assert(0 && "should never be called"); }
+  _SPIRV_DEF_ENCDEC1(Id)
+  friend class SPIRVFunction;
+
+protected:
+  void validate() const {}
+};
+}
+
+#endif /* SPIRVVALUE_HPP_ */
diff --git a/lib/SPIRV/libSPIRV/libSPIRV.h b/lib/SPIRV/libSPIRV/libSPIRV.h
new file mode 100644
index 0000000..a51d843
--- /dev/null
+++ b/lib/SPIRV/libSPIRV/libSPIRV.h
@@ -0,0 +1,52 @@
+//===- libSPIRV.h  SPIR-V Header files -------------------------*- C++ -*-===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+/// \file
+///
+/// This file includes all SPIRV header files.
+///
+//===----------------------------------------------------------------------===//
+
+#ifndef LIBSPIRV_H_
+#define LIBSPIRV_H_
+
+#include "SPIRVOpCode.h"
+#include "SPIRVEntry.h"
+#include "SPIRVType.h"
+#include "SPIRVValue.h"
+#include "SPIRVModule.h"
+#include "SPIRVFunction.h"
+#include "SPIRVBasicBlock.h"
+#include "SPIRVInstruction.h"
+
+#endif
diff --git a/lib/SPIRV/libSPIRV/spirv.hpp b/lib/SPIRV/libSPIRV/spirv.hpp
new file mode 100644
index 0000000..5cc60e5
--- /dev/null
+++ b/lib/SPIRV/libSPIRV/spirv.hpp
@@ -0,0 +1,907 @@
+// Copyright (c) 2014-2016 The Khronos Group Inc.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a copy
+// of this software and/or associated documentation files (the "Materials"),
+// to deal in the Materials without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Materials, and to permit persons to whom the
+// Materials are furnished to do so, subject to the following conditions:
+//
+// The above copyright notice and this permission notice shall be included in
+// all copies or substantial portions of the Materials.
+//
+// MODIFICATIONS TO THIS FILE MAY MEAN IT NO LONGER ACCURATELY REFLECTS KHRONOS
+// STANDARDS. THE UNMODIFIED, NORMATIVE VERSIONS OF KHRONOS SPECIFICATIONS AND
+// HEADER INFORMATION ARE LOCATED AT https://www.khronos.org/registry/
+//
+// THE MATERIALS ARE PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
+// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
+// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+// FROM,OUT OF OR IN CONNECTION WITH THE MATERIALS OR THE USE OR OTHER DEALINGS
+// IN THE MATERIALS.
+
+// This header is automatically generated by the same tool that creates
+// the Binary Section of the SPIR-V specification.
+
+// Enumeration tokens for SPIR-V, in various styles:
+//   C, C++, C++11, JSON, Lua, Python
+//
+// - C will have tokens with a "Spv" prefix, e.g.: SpvSourceLanguageGLSL
+// - C++ will have tokens in the "spv" name space, e.g.: spv::SourceLanguageGLSL
+// - C++11 will use enum classes in the spv namespace, e.g.: spv::SourceLanguage::GLSL
+// - Lua will use tables, e.g.: spv.SourceLanguage.GLSL
+// - Python will use dictionaries, e.g.: spv['SourceLanguage']['GLSL']
+//
+// Some tokens act like mask values, which can be OR'd together,
+// while others are mutually exclusive.  The mask-like ones have
+// "Mask" in their name, and a parallel enum that has the shift
+// amount (1 << x) for each corresponding enumerant.
+
+#ifndef spirv_HPP
+#define spirv_HPP
+
+namespace spv {
+
+typedef unsigned int Id;
+
+#define SPV_VERSION 0x10100
+#define SPV_REVISION 1
+
+static const unsigned int MagicNumber = 0x07230203;
+static const unsigned int Version = 0x00010100;
+static const unsigned int Revision = 1;
+static const unsigned int OpCodeMask = 0xffff;
+static const unsigned int WordCountShift = 16;
+
+enum SourceLanguage {
+    SourceLanguageUnknown = 0,
+    SourceLanguageESSL = 1,
+    SourceLanguageGLSL = 2,
+    SourceLanguageOpenCL_C = 3,
+    SourceLanguageOpenCL_CPP = 4,
+};
+
+enum ExecutionModel {
+    ExecutionModelVertex = 0,
+    ExecutionModelTessellationControl = 1,
+    ExecutionModelTessellationEvaluation = 2,
+    ExecutionModelGeometry = 3,
+    ExecutionModelFragment = 4,
+    ExecutionModelGLCompute = 5,
+    ExecutionModelKernel = 6,
+    ExecutionModelInvalid = 0xFFFFFFFFu
+};
+
+enum AddressingModel {
+    AddressingModelLogical = 0,
+    AddressingModelPhysical32 = 1,
+    AddressingModelPhysical64 = 2,
+};
+
+enum MemoryModel {
+    MemoryModelSimple = 0,
+    MemoryModelGLSL450 = 1,
+    MemoryModelOpenCL = 2,
+};
+
+enum ExecutionMode {
+    ExecutionModeInvocations = 0,
+    ExecutionModeSpacingEqual = 1,
+    ExecutionModeSpacingFractionalEven = 2,
+    ExecutionModeSpacingFractionalOdd = 3,
+    ExecutionModeVertexOrderCw = 4,
+    ExecutionModeVertexOrderCcw = 5,
+    ExecutionModePixelCenterInteger = 6,
+    ExecutionModeOriginUpperLeft = 7,
+    ExecutionModeOriginLowerLeft = 8,
+    ExecutionModeEarlyFragmentTests = 9,
+    ExecutionModePointMode = 10,
+    ExecutionModeXfb = 11,
+    ExecutionModeDepthReplacing = 12,
+    ExecutionModeDepthGreater = 14,
+    ExecutionModeDepthLess = 15,
+    ExecutionModeDepthUnchanged = 16,
+    ExecutionModeLocalSize = 17,
+    ExecutionModeLocalSizeHint = 18,
+    ExecutionModeInputPoints = 19,
+    ExecutionModeInputLines = 20,
+    ExecutionModeInputLinesAdjacency = 21,
+    ExecutionModeTriangles = 22,
+    ExecutionModeInputTrianglesAdjacency = 23,
+    ExecutionModeQuads = 24,
+    ExecutionModeIsolines = 25,
+    ExecutionModeOutputVertices = 26,
+    ExecutionModeOutputPoints = 27,
+    ExecutionModeOutputLineStrip = 28,
+    ExecutionModeOutputTriangleStrip = 29,
+    ExecutionModeVecTypeHint = 30,
+    ExecutionModeContractionOff = 31,
+    ExecutionModeInitializer = 33,
+    ExecutionModeFinalizer = 34,
+    ExecutionModeSubgroupSize = 35,
+    ExecutionModeSubgroupsPerWorkgroup = 36,
+};
+
+enum StorageClass {
+    StorageClassUniformConstant = 0,
+    StorageClassInput = 1,
+    StorageClassUniform = 2,
+    StorageClassOutput = 3,
+    StorageClassWorkgroup = 4,
+    StorageClassCrossWorkgroup = 5,
+    StorageClassPrivate = 6,
+    StorageClassFunction = 7,
+    StorageClassGeneric = 8,
+    StorageClassPushConstant = 9,
+    StorageClassAtomicCounter = 10,
+    StorageClassImage = 11,
+};
+
+enum Dim {
+    Dim1D = 0,
+    Dim2D = 1,
+    Dim3D = 2,
+    DimCube = 3,
+    DimRect = 4,
+    DimBuffer = 5,
+    DimSubpassData = 6,
+};
+
+enum SamplerAddressingMode {
+    SamplerAddressingModeNone = 0,
+    SamplerAddressingModeClampToEdge = 1,
+    SamplerAddressingModeClamp = 2,
+    SamplerAddressingModeRepeat = 3,
+    SamplerAddressingModeRepeatMirrored = 4,
+};
+
+enum SamplerFilterMode {
+    SamplerFilterModeNearest = 0,
+    SamplerFilterModeLinear = 1,
+};
+
+enum ImageFormat {
+    ImageFormatUnknown = 0,
+    ImageFormatRgba32f = 1,
+    ImageFormatRgba16f = 2,
+    ImageFormatR32f = 3,
+    ImageFormatRgba8 = 4,
+    ImageFormatRgba8Snorm = 5,
+    ImageFormatRg32f = 6,
+    ImageFormatRg16f = 7,
+    ImageFormatR11fG11fB10f = 8,
+    ImageFormatR16f = 9,
+    ImageFormatRgba16 = 10,
+    ImageFormatRgb10A2 = 11,
+    ImageFormatRg16 = 12,
+    ImageFormatRg8 = 13,
+    ImageFormatR16 = 14,
+    ImageFormatR8 = 15,
+    ImageFormatRgba16Snorm = 16,
+    ImageFormatRg16Snorm = 17,
+    ImageFormatRg8Snorm = 18,
+    ImageFormatR16Snorm = 19,
+    ImageFormatR8Snorm = 20,
+    ImageFormatRgba32i = 21,
+    ImageFormatRgba16i = 22,
+    ImageFormatRgba8i = 23,
+    ImageFormatR32i = 24,
+    ImageFormatRg32i = 25,
+    ImageFormatRg16i = 26,
+    ImageFormatRg8i = 27,
+    ImageFormatR16i = 28,
+    ImageFormatR8i = 29,
+    ImageFormatRgba32ui = 30,
+    ImageFormatRgba16ui = 31,
+    ImageFormatRgba8ui = 32,
+    ImageFormatR32ui = 33,
+    ImageFormatRgb10a2ui = 34,
+    ImageFormatRg32ui = 35,
+    ImageFormatRg16ui = 36,
+    ImageFormatRg8ui = 37,
+    ImageFormatR16ui = 38,
+    ImageFormatR8ui = 39,
+};
+
+enum ImageChannelOrder {
+    ImageChannelOrderR = 0,
+    ImageChannelOrderA = 1,
+    ImageChannelOrderRG = 2,
+    ImageChannelOrderRA = 3,
+    ImageChannelOrderRGB = 4,
+    ImageChannelOrderRGBA = 5,
+    ImageChannelOrderBGRA = 6,
+    ImageChannelOrderARGB = 7,
+    ImageChannelOrderIntensity = 8,
+    ImageChannelOrderLuminance = 9,
+    ImageChannelOrderRx = 10,
+    ImageChannelOrderRGx = 11,
+    ImageChannelOrderRGBx = 12,
+    ImageChannelOrderDepth = 13,
+    ImageChannelOrderDepthStencil = 14,
+    ImageChannelOrdersRGB = 15,
+    ImageChannelOrdersRGBx = 16,
+    ImageChannelOrdersRGBA = 17,
+    ImageChannelOrdersBGRA = 18,
+    ImageChannelOrderABGR = 19,
+};
+
+enum ImageChannelDataType {
+    ImageChannelDataTypeSnormInt8 = 0,
+    ImageChannelDataTypeSnormInt16 = 1,
+    ImageChannelDataTypeUnormInt8 = 2,
+    ImageChannelDataTypeUnormInt16 = 3,
+    ImageChannelDataTypeUnormShort565 = 4,
+    ImageChannelDataTypeUnormShort555 = 5,
+    ImageChannelDataTypeUnormInt101010 = 6,
+    ImageChannelDataTypeSignedInt8 = 7,
+    ImageChannelDataTypeSignedInt16 = 8,
+    ImageChannelDataTypeSignedInt32 = 9,
+    ImageChannelDataTypeUnsignedInt8 = 10,
+    ImageChannelDataTypeUnsignedInt16 = 11,
+    ImageChannelDataTypeUnsignedInt32 = 12,
+    ImageChannelDataTypeHalfFloat = 13,
+    ImageChannelDataTypeFloat = 14,
+    ImageChannelDataTypeUnormInt24 = 15,
+    ImageChannelDataTypeUnormInt101010_2 = 16,
+};
+
+enum ImageOperandsShift {
+    ImageOperandsBiasShift = 0,
+    ImageOperandsLodShift = 1,
+    ImageOperandsGradShift = 2,
+    ImageOperandsConstOffsetShift = 3,
+    ImageOperandsOffsetShift = 4,
+    ImageOperandsConstOffsetsShift = 5,
+    ImageOperandsSampleShift = 6,
+    ImageOperandsMinLodShift = 7,
+};
+
+enum ImageOperandsMask {
+    ImageOperandsMaskNone = 0,
+    ImageOperandsBiasMask = 0x00000001,
+    ImageOperandsLodMask = 0x00000002,
+    ImageOperandsGradMask = 0x00000004,
+    ImageOperandsConstOffsetMask = 0x00000008,
+    ImageOperandsOffsetMask = 0x00000010,
+    ImageOperandsConstOffsetsMask = 0x00000020,
+    ImageOperandsSampleMask = 0x00000040,
+    ImageOperandsMinLodMask = 0x00000080,
+};
+
+enum FPFastMathModeShift {
+    FPFastMathModeNotNaNShift = 0,
+    FPFastMathModeNotInfShift = 1,
+    FPFastMathModeNSZShift = 2,
+    FPFastMathModeAllowRecipShift = 3,
+    FPFastMathModeFastShift = 4,
+};
+
+enum FPFastMathModeMask {
+    FPFastMathModeMaskNone = 0,
+    FPFastMathModeNotNaNMask = 0x00000001,
+    FPFastMathModeNotInfMask = 0x00000002,
+    FPFastMathModeNSZMask = 0x00000004,
+    FPFastMathModeAllowRecipMask = 0x00000008,
+    FPFastMathModeFastMask = 0x00000010,
+};
+
+enum FPRoundingMode {
+    FPRoundingModeRTE = 0,
+    FPRoundingModeRTZ = 1,
+    FPRoundingModeRTP = 2,
+    FPRoundingModeRTN = 3,
+};
+
+enum LinkageType {
+    LinkageTypeExport = 0,
+    LinkageTypeImport = 1,
+    LinkageTypeInternal, /* internal use only */
+};
+
+enum AccessQualifier {
+    AccessQualifierReadOnly = 0,
+    AccessQualifierWriteOnly = 1,
+    AccessQualifierReadWrite = 2,
+};
+
+enum FunctionParameterAttribute {
+    FunctionParameterAttributeZext = 0,
+    FunctionParameterAttributeSext = 1,
+    FunctionParameterAttributeByVal = 2,
+    FunctionParameterAttributeSret = 3,
+    FunctionParameterAttributeNoAlias = 4,
+    FunctionParameterAttributeNoCapture = 5,
+    FunctionParameterAttributeNoWrite = 6,
+    FunctionParameterAttributeNoReadWrite = 7,
+};
+
+enum Decoration {
+    DecorationRelaxedPrecision = 0,
+    DecorationSpecId = 1,
+    DecorationBlock = 2,
+    DecorationBufferBlock = 3,
+    DecorationRowMajor = 4,
+    DecorationColMajor = 5,
+    DecorationArrayStride = 6,
+    DecorationMatrixStride = 7,
+    DecorationGLSLShared = 8,
+    DecorationGLSLPacked = 9,
+    DecorationCPacked = 10,
+    DecorationBuiltIn = 11,
+    DecorationNoPerspective = 13,
+    DecorationFlat = 14,
+    DecorationPatch = 15,
+    DecorationCentroid = 16,
+    DecorationSample = 17,
+    DecorationInvariant = 18,
+    DecorationRestrict = 19,
+    DecorationAliased = 20,
+    DecorationVolatile = 21,
+    DecorationConstant = 22,
+    DecorationCoherent = 23,
+    DecorationNonWritable = 24,
+    DecorationNonReadable = 25,
+    DecorationUniform = 26,
+    DecorationSaturatedConversion = 28,
+    DecorationStream = 29,
+    DecorationLocation = 30,
+    DecorationComponent = 31,
+    DecorationIndex = 32,
+    DecorationBinding = 33,
+    DecorationDescriptorSet = 34,
+    DecorationOffset = 35,
+    DecorationXfbBuffer = 36,
+    DecorationXfbStride = 37,
+    DecorationFuncParamAttr = 38,
+    DecorationFPRoundingMode = 39,
+    DecorationFPFastMathMode = 40,
+    DecorationLinkageAttributes = 41,
+    DecorationNoContraction = 42,
+    DecorationInputAttachmentIndex = 43,
+    DecorationAlignment = 44,
+    DecorationMaxByteOffset = 45,
+};
+
+enum BuiltIn {
+    BuiltInPosition = 0,
+    BuiltInPointSize = 1,
+    BuiltInClipDistance = 3,
+    BuiltInCullDistance = 4,
+    BuiltInVertexId = 5,
+    BuiltInInstanceId = 6,
+    BuiltInPrimitiveId = 7,
+    BuiltInInvocationId = 8,
+    BuiltInLayer = 9,
+    BuiltInViewportIndex = 10,
+    BuiltInTessLevelOuter = 11,
+    BuiltInTessLevelInner = 12,
+    BuiltInTessCoord = 13,
+    BuiltInPatchVertices = 14,
+    BuiltInFragCoord = 15,
+    BuiltInPointCoord = 16,
+    BuiltInFrontFacing = 17,
+    BuiltInSampleId = 18,
+    BuiltInSamplePosition = 19,
+    BuiltInSampleMask = 20,
+    BuiltInFragDepth = 22,
+    BuiltInHelperInvocation = 23,
+    BuiltInNumWorkgroups = 24,
+    BuiltInWorkgroupSize = 25,
+    BuiltInWorkgroupId = 26,
+    BuiltInLocalInvocationId = 27,
+    BuiltInGlobalInvocationId = 28,
+    BuiltInLocalInvocationIndex = 29,
+    BuiltInWorkDim = 30,
+    BuiltInGlobalSize = 31,
+    BuiltInEnqueuedWorkgroupSize = 32,
+    BuiltInGlobalOffset = 33,
+    BuiltInGlobalLinearId = 34,
+    BuiltInSubgroupSize = 36,
+    BuiltInSubgroupMaxSize = 37,
+    BuiltInNumSubgroups = 38,
+    BuiltInNumEnqueuedSubgroups = 39,
+    BuiltInSubgroupId = 40,
+    BuiltInSubgroupLocalInvocationId = 41,
+    BuiltInVertexIndex = 42,
+    BuiltInInstanceIndex = 43,
+};
+
+enum SelectionControlShift {
+    SelectionControlFlattenShift = 0,
+    SelectionControlDontFlattenShift = 1,
+};
+
+enum SelectionControlMask {
+    SelectionControlMaskNone = 0,
+    SelectionControlFlattenMask = 0x00000001,
+    SelectionControlDontFlattenMask = 0x00000002,
+};
+
+enum LoopControlShift {
+    LoopControlUnrollShift = 0,
+    LoopControlDontUnrollShift = 1,
+    LoopControlDependencyInfiniteShift = 2,
+    LoopControlDependencyLengthShift = 3,
+};
+
+enum LoopControlMask {
+    LoopControlMaskNone = 0,
+    LoopControlUnrollMask = 0x00000001,
+    LoopControlDontUnrollMask = 0x00000002,
+    LoopControlDependencyInfiniteMask = 0x00000004,
+    LoopControlDependencyLengthMask = 0x00000008,
+};
+
+enum FunctionControlShift {
+    FunctionControlInlineShift = 0,
+    FunctionControlDontInlineShift = 1,
+    FunctionControlPureShift = 2,
+    FunctionControlConstShift = 3,
+};
+
+enum FunctionControlMask {
+    FunctionControlMaskNone = 0,
+    FunctionControlInlineMask = 0x00000001,
+    FunctionControlDontInlineMask = 0x00000002,
+    FunctionControlPureMask = 0x00000004,
+    FunctionControlConstMask = 0x00000008,
+};
+
+enum MemorySemanticsShift {
+    MemorySemanticsAcquireShift = 1,
+    MemorySemanticsReleaseShift = 2,
+    MemorySemanticsAcquireReleaseShift = 3,
+    MemorySemanticsSequentiallyConsistentShift = 4,
+    MemorySemanticsUniformMemoryShift = 6,
+    MemorySemanticsSubgroupMemoryShift = 7,
+    MemorySemanticsWorkgroupMemoryShift = 8,
+    MemorySemanticsCrossWorkgroupMemoryShift = 9,
+    MemorySemanticsAtomicCounterMemoryShift = 10,
+    MemorySemanticsImageMemoryShift = 11,
+};
+
+enum MemorySemanticsMask {
+    MemorySemanticsMaskNone = 0,
+    MemorySemanticsAcquireMask = 0x00000002,
+    MemorySemanticsReleaseMask = 0x00000004,
+    MemorySemanticsAcquireReleaseMask = 0x00000008,
+    MemorySemanticsSequentiallyConsistentMask = 0x00000010,
+    MemorySemanticsUniformMemoryMask = 0x00000040,
+    MemorySemanticsSubgroupMemoryMask = 0x00000080,
+    MemorySemanticsWorkgroupMemoryMask = 0x00000100,
+    MemorySemanticsCrossWorkgroupMemoryMask = 0x00000200,
+    MemorySemanticsAtomicCounterMemoryMask = 0x00000400,
+    MemorySemanticsImageMemoryMask = 0x00000800,
+};
+
+enum MemoryAccessShift {
+    MemoryAccessVolatileShift = 0,
+    MemoryAccessAlignedShift = 1,
+    MemoryAccessNontemporalShift = 2,
+};
+
+enum MemoryAccessMask {
+    MemoryAccessMaskNone = 0,
+    MemoryAccessVolatileMask = 0x00000001,
+    MemoryAccessAlignedMask = 0x00000002,
+    MemoryAccessNontemporalMask = 0x00000004,
+};
+
+enum Scope {
+    ScopeCrossDevice = 0,
+    ScopeDevice = 1,
+    ScopeWorkgroup = 2,
+    ScopeSubgroup = 3,
+    ScopeInvocation = 4,
+};
+
+enum GroupOperation {
+    GroupOperationReduce = 0,
+    GroupOperationInclusiveScan = 1,
+    GroupOperationExclusiveScan = 2,
+};
+
+enum KernelEnqueueFlags {
+    KernelEnqueueFlagsNoWait = 0,
+    KernelEnqueueFlagsWaitKernel = 1,
+    KernelEnqueueFlagsWaitWorkGroup = 2,
+};
+
+enum KernelProfilingInfoShift {
+    KernelProfilingInfoCmdExecTimeShift = 0,
+};
+
+enum KernelProfilingInfoMask {
+    KernelProfilingInfoMaskNone = 0,
+    KernelProfilingInfoCmdExecTimeMask = 0x00000001,
+};
+
+enum Capability {
+    CapabilityMatrix = 0,
+    CapabilityShader = 1,
+    CapabilityGeometry = 2,
+    CapabilityTessellation = 3,
+    CapabilityAddresses = 4,
+    CapabilityLinkage = 5,
+    CapabilityKernel = 6,
+    CapabilityVector16 = 7,
+    CapabilityFloat16Buffer = 8,
+    CapabilityFloat16 = 9,
+    CapabilityFloat64 = 10,
+    CapabilityInt64 = 11,
+    CapabilityInt64Atomics = 12,
+    CapabilityImageBasic = 13,
+    CapabilityImageReadWrite = 14,
+    CapabilityImageMipmap = 15,
+    CapabilityPipes = 17,
+    CapabilityGroups = 18,
+    CapabilityDeviceEnqueue = 19,
+    CapabilityLiteralSampler = 20,
+    CapabilityAtomicStorage = 21,
+    CapabilityInt16 = 22,
+    CapabilityTessellationPointSize = 23,
+    CapabilityGeometryPointSize = 24,
+    CapabilityImageGatherExtended = 25,
+    CapabilityStorageImageMultisample = 27,
+    CapabilityUniformBufferArrayDynamicIndexing = 28,
+    CapabilitySampledImageArrayDynamicIndexing = 29,
+    CapabilityStorageBufferArrayDynamicIndexing = 30,
+    CapabilityStorageImageArrayDynamicIndexing = 31,
+    CapabilityClipDistance = 32,
+    CapabilityCullDistance = 33,
+    CapabilityImageCubeArray = 34,
+    CapabilitySampleRateShading = 35,
+    CapabilityImageRect = 36,
+    CapabilitySampledRect = 37,
+    CapabilityGenericPointer = 38,
+    CapabilityInt8 = 39,
+    CapabilityInputAttachment = 40,
+    CapabilitySparseResidency = 41,
+    CapabilityMinLod = 42,
+    CapabilitySampled1D = 43,
+    CapabilityImage1D = 44,
+    CapabilitySampledCubeArray = 45,
+    CapabilitySampledBuffer = 46,
+    CapabilityImageBuffer = 47,
+    CapabilityImageMSArray = 48,
+    CapabilityStorageImageExtendedFormats = 49,
+    CapabilityImageQuery = 50,
+    CapabilityDerivativeControl = 51,
+    CapabilityInterpolationFunction = 52,
+    CapabilityTransformFeedback = 53,
+    CapabilityGeometryStreams = 54,
+    CapabilityStorageImageReadWithoutFormat = 55,
+    CapabilityStorageImageWriteWithoutFormat = 56,
+    CapabilityMultiViewport = 57,
+    CapabilitySubgroupDispatch = 58,
+    CapabilityNamedBarrier = 59,
+    CapabilityPipeStorage = 60,
+};
+
+enum Op {
+    OpNop = 0,
+    OpUndef = 1,
+    OpSourceContinued = 2,
+    OpSource = 3,
+    OpSourceExtension = 4,
+    OpName = 5,
+    OpMemberName = 6,
+    OpString = 7,
+    OpLine = 8,
+    OpExtension = 10,
+    OpExtInstImport = 11,
+    OpExtInst = 12,
+    OpMemoryModel = 14,
+    OpEntryPoint = 15,
+    OpExecutionMode = 16,
+    OpCapability = 17,
+    OpTypeVoid = 19,
+    OpTypeBool = 20,
+    OpTypeInt = 21,
+    OpTypeFloat = 22,
+    OpTypeVector = 23,
+    OpTypeMatrix = 24,
+    OpTypeImage = 25,
+    OpTypeSampler = 26,
+    OpTypeSampledImage = 27,
+    OpTypeArray = 28,
+    OpTypeRuntimeArray = 29,
+    OpTypeStruct = 30,
+    OpTypeOpaque = 31,
+    OpTypePointer = 32,
+    OpTypeFunction = 33,
+    OpTypeEvent = 34,
+    OpTypeDeviceEvent = 35,
+    OpTypeReserveId = 36,
+    OpTypeQueue = 37,
+    OpTypePipe = 38,
+    OpTypeForwardPointer = 39,
+    OpConstantTrue = 41,
+    OpConstantFalse = 42,
+    OpConstant = 43,
+    OpConstantComposite = 44,
+    OpConstantSampler = 45,
+    OpConstantNull = 46,
+    OpSpecConstantTrue = 48,
+    OpSpecConstantFalse = 49,
+    OpSpecConstant = 50,
+    OpSpecConstantComposite = 51,
+    OpSpecConstantOp = 52,
+    OpFunction = 54,
+    OpFunctionParameter = 55,
+    OpFunctionEnd = 56,
+    OpFunctionCall = 57,
+    OpVariable = 59,
+    OpImageTexelPointer = 60,
+    OpLoad = 61,
+    OpStore = 62,
+    OpCopyMemory = 63,
+    OpCopyMemorySized = 64,
+    OpAccessChain = 65,
+    OpInBoundsAccessChain = 66,
+    OpPtrAccessChain = 67,
+    OpArrayLength = 68,
+    OpGenericPtrMemSemantics = 69,
+    OpInBoundsPtrAccessChain = 70,
+    OpDecorate = 71,
+    OpMemberDecorate = 72,
+    OpDecorationGroup = 73,
+    OpGroupDecorate = 74,
+    OpGroupMemberDecorate = 75,
+    OpVectorExtractDynamic = 77,
+    OpVectorInsertDynamic = 78,
+    OpVectorShuffle = 79,
+    OpCompositeConstruct = 80,
+    OpCompositeExtract = 81,
+    OpCompositeInsert = 82,
+    OpCopyObject = 83,
+    OpTranspose = 84,
+    OpSampledImage = 86,
+    OpImageSampleImplicitLod = 87,
+    OpImageSampleExplicitLod = 88,
+    OpImageSampleDrefImplicitLod = 89,
+    OpImageSampleDrefExplicitLod = 90,
+    OpImageSampleProjImplicitLod = 91,
+    OpImageSampleProjExplicitLod = 92,
+    OpImageSampleProjDrefImplicitLod = 93,
+    OpImageSampleProjDrefExplicitLod = 94,
+    OpImageFetch = 95,
+    OpImageGather = 96,
+    OpImageDrefGather = 97,
+    OpImageRead = 98,
+    OpImageWrite = 99,
+    OpImage = 100,
+    OpImageQueryFormat = 101,
+    OpImageQueryOrder = 102,
+    OpImageQuerySizeLod = 103,
+    OpImageQuerySize = 104,
+    OpImageQueryLod = 105,
+    OpImageQueryLevels = 106,
+    OpImageQuerySamples = 107,
+    OpConvertFToU = 109,
+    OpConvertFToS = 110,
+    OpConvertSToF = 111,
+    OpConvertUToF = 112,
+    OpUConvert = 113,
+    OpSConvert = 114,
+    OpFConvert = 115,
+    OpQuantizeToF16 = 116,
+    OpConvertPtrToU = 117,
+    OpSatConvertSToU = 118,
+    OpSatConvertUToS = 119,
+    OpConvertUToPtr = 120,
+    OpPtrCastToGeneric = 121,
+    OpGenericCastToPtr = 122,
+    OpGenericCastToPtrExplicit = 123,
+    OpBitcast = 124,
+    OpSNegate = 126,
+    OpFNegate = 127,
+    OpIAdd = 128,
+    OpFAdd = 129,
+    OpISub = 130,
+    OpFSub = 131,
+    OpIMul = 132,
+    OpFMul = 133,
+    OpUDiv = 134,
+    OpSDiv = 135,
+    OpFDiv = 136,
+    OpUMod = 137,
+    OpSRem = 138,
+    OpSMod = 139,
+    OpFRem = 140,
+    OpFMod = 141,
+    OpVectorTimesScalar = 142,
+    OpMatrixTimesScalar = 143,
+    OpVectorTimesMatrix = 144,
+    OpMatrixTimesVector = 145,
+    OpMatrixTimesMatrix = 146,
+    OpOuterProduct = 147,
+    OpDot = 148,
+    OpIAddCarry = 149,
+    OpISubBorrow = 150,
+    OpUMulExtended = 151,
+    OpSMulExtended = 152,
+    OpAny = 154,
+    OpAll = 155,
+    OpIsNan = 156,
+    OpIsInf = 157,
+    OpIsFinite = 158,
+    OpIsNormal = 159,
+    OpSignBitSet = 160,
+    OpLessOrGreater = 161,
+    OpOrdered = 162,
+    OpUnordered = 163,
+    OpLogicalEqual = 164,
+    OpLogicalNotEqual = 165,
+    OpLogicalOr = 166,
+    OpLogicalAnd = 167,
+    OpLogicalNot = 168,
+    OpSelect = 169,
+    OpIEqual = 170,
+    OpINotEqual = 171,
+    OpUGreaterThan = 172,
+    OpSGreaterThan = 173,
+    OpUGreaterThanEqual = 174,
+    OpSGreaterThanEqual = 175,
+    OpULessThan = 176,
+    OpSLessThan = 177,
+    OpULessThanEqual = 178,
+    OpSLessThanEqual = 179,
+    OpFOrdEqual = 180,
+    OpFUnordEqual = 181,
+    OpFOrdNotEqual = 182,
+    OpFUnordNotEqual = 183,
+    OpFOrdLessThan = 184,
+    OpFUnordLessThan = 185,
+    OpFOrdGreaterThan = 186,
+    OpFUnordGreaterThan = 187,
+    OpFOrdLessThanEqual = 188,
+    OpFUnordLessThanEqual = 189,
+    OpFOrdGreaterThanEqual = 190,
+    OpFUnordGreaterThanEqual = 191,
+    OpShiftRightLogical = 194,
+    OpShiftRightArithmetic = 195,
+    OpShiftLeftLogical = 196,
+    OpBitwiseOr = 197,
+    OpBitwiseXor = 198,
+    OpBitwiseAnd = 199,
+    OpNot = 200,
+    OpBitFieldInsert = 201,
+    OpBitFieldSExtract = 202,
+    OpBitFieldUExtract = 203,
+    OpBitReverse = 204,
+    OpBitCount = 205,
+    OpDPdx = 207,
+    OpDPdy = 208,
+    OpFwidth = 209,
+    OpDPdxFine = 210,
+    OpDPdyFine = 211,
+    OpFwidthFine = 212,
+    OpDPdxCoarse = 213,
+    OpDPdyCoarse = 214,
+    OpFwidthCoarse = 215,
+    OpEmitVertex = 218,
+    OpEndPrimitive = 219,
+    OpEmitStreamVertex = 220,
+    OpEndStreamPrimitive = 221,
+    OpControlBarrier = 224,
+    OpMemoryBarrier = 225,
+    OpAtomicLoad = 227,
+    OpAtomicStore = 228,
+    OpAtomicExchange = 229,
+    OpAtomicCompareExchange = 230,
+    OpAtomicCompareExchangeWeak = 231,
+    OpAtomicIIncrement = 232,
+    OpAtomicIDecrement = 233,
+    OpAtomicIAdd = 234,
+    OpAtomicISub = 235,
+    OpAtomicSMin = 236,
+    OpAtomicUMin = 237,
+    OpAtomicSMax = 238,
+    OpAtomicUMax = 239,
+    OpAtomicAnd = 240,
+    OpAtomicOr = 241,
+    OpAtomicXor = 242,
+    OpPhi = 245,
+    OpLoopMerge = 246,
+    OpSelectionMerge = 247,
+    OpLabel = 248,
+    OpBranch = 249,
+    OpBranchConditional = 250,
+    OpSwitch = 251,
+    OpKill = 252,
+    OpReturn = 253,
+    OpReturnValue = 254,
+    OpUnreachable = 255,
+    OpLifetimeStart = 256,
+    OpLifetimeStop = 257,
+    OpGroupAsyncCopy = 259,
+    OpGroupWaitEvents = 260,
+    OpGroupAll = 261,
+    OpGroupAny = 262,
+    OpGroupBroadcast = 263,
+    OpGroupIAdd = 264,
+    OpGroupFAdd = 265,
+    OpGroupFMin = 266,
+    OpGroupUMin = 267,
+    OpGroupSMin = 268,
+    OpGroupFMax = 269,
+    OpGroupUMax = 270,
+    OpGroupSMax = 271,
+    OpReadPipe = 274,
+    OpWritePipe = 275,
+    OpReservedReadPipe = 276,
+    OpReservedWritePipe = 277,
+    OpReserveReadPipePackets = 278,
+    OpReserveWritePipePackets = 279,
+    OpCommitReadPipe = 280,
+    OpCommitWritePipe = 281,
+    OpIsValidReserveId = 282,
+    OpGetNumPipePackets = 283,
+    OpGetMaxPipePackets = 284,
+    OpGroupReserveReadPipePackets = 285,
+    OpGroupReserveWritePipePackets = 286,
+    OpGroupCommitReadPipe = 287,
+    OpGroupCommitWritePipe = 288,
+    OpEnqueueMarker = 291,
+    OpEnqueueKernel = 292,
+    OpGetKernelNDrangeSubGroupCount = 293,
+    OpGetKernelNDrangeMaxSubGroupSize = 294,
+    OpGetKernelWorkGroupSize = 295,
+    OpGetKernelPreferredWorkGroupSizeMultiple = 296,
+    OpRetainEvent = 297,
+    OpReleaseEvent = 298,
+    OpCreateUserEvent = 299,
+    OpIsValidEvent = 300,
+    OpSetUserEventStatus = 301,
+    OpCaptureEventProfilingInfo = 302,
+    OpGetDefaultQueue = 303,
+    OpBuildNDRange = 304,
+    OpImageSparseSampleImplicitLod = 305,
+    OpImageSparseSampleExplicitLod = 306,
+    OpImageSparseSampleDrefImplicitLod = 307,
+    OpImageSparseSampleDrefExplicitLod = 308,
+    OpImageSparseSampleProjImplicitLod = 309,
+    OpImageSparseSampleProjExplicitLod = 310,
+    OpImageSparseSampleProjDrefImplicitLod = 311,
+    OpImageSparseSampleProjDrefExplicitLod = 312,
+    OpImageSparseFetch = 313,
+    OpImageSparseGather = 314,
+    OpImageSparseDrefGather = 315,
+    OpImageSparseTexelsResident = 316,
+    OpNoLine = 317,
+    OpAtomicFlagTestAndSet = 318,
+    OpAtomicFlagClear = 319,
+    OpImageSparseRead = 320,
+    OpSizeOf = 321,
+    OpTypePipeStorage = 322,
+    OpConstantPipeStorage = 323,
+    OpCreatePipeFromPipeStorage = 324,
+    OpGetKernelLocalSizeForSubgroupCount = 325,
+    OpGetKernelMaxNumSubgroups = 326,
+    OpTypeNamedBarrier = 327,
+    OpNamedBarrierInitialize = 328,
+    OpMemoryNamedBarrier = 329,
+    OpModuleProcessed = 330,
+    OpUndefValueInternal = 1023,
+    OpForward = 1024, /* internal use only */
+};
+
+// Overload operator| for mask bit combining
+
+inline ImageOperandsMask operator|(ImageOperandsMask a, ImageOperandsMask b) { return ImageOperandsMask(unsigned(a) | unsigned(b)); }
+inline FPFastMathModeMask operator|(FPFastMathModeMask a, FPFastMathModeMask b) { return FPFastMathModeMask(unsigned(a) | unsigned(b)); }
+inline SelectionControlMask operator|(SelectionControlMask a, SelectionControlMask b) { return SelectionControlMask(unsigned(a) | unsigned(b)); }
+inline LoopControlMask operator|(LoopControlMask a, LoopControlMask b) { return LoopControlMask(unsigned(a) | unsigned(b)); }
+inline FunctionControlMask operator|(FunctionControlMask a, FunctionControlMask b) { return FunctionControlMask(unsigned(a) | unsigned(b)); }
+inline MemorySemanticsMask operator|(MemorySemanticsMask a, MemorySemanticsMask b) { return MemorySemanticsMask(unsigned(a) | unsigned(b)); }
+inline MemoryAccessMask operator|(MemoryAccessMask a, MemoryAccessMask b) { return MemoryAccessMask(unsigned(a) | unsigned(b)); }
+inline KernelProfilingInfoMask operator|(KernelProfilingInfoMask a, KernelProfilingInfoMask b) { return KernelProfilingInfoMask(unsigned(a) | unsigned(b)); }
+
+}  // end namespace spv
+
+#endif  // #ifndef spirv_HPP
+
diff --git a/lib/SPIRVerifier/CMakeLists.txt b/lib/SPIRVerifier/CMakeLists.txt
new file mode 100644
index 0000000..0b392e7
--- /dev/null
+++ b/lib/SPIRVerifier/CMakeLists.txt
@@ -0,0 +1,8 @@
+add_llvm_library(LLVMSPIRVerifier
+  SpirIterators.cpp
+  SpirTables.cpp
+  SpirErrors.cpp
+  SpirValidation.cpp
+  )
+
+add_dependencies(LLVMSPIRVerifier intrinsics_gen)
diff --git a/lib/SPIRVerifier/LLVMBuild.txt b/lib/SPIRVerifier/LLVMBuild.txt
new file mode 100644
index 0000000..7203f96
--- /dev/null
+++ b/lib/SPIRVerifier/LLVMBuild.txt
@@ -0,0 +1,23 @@
+;===- ./lib/SPIRVerifier/LLVMBuild.txt -------------------------*- Conf -*--===;
+;
+;                     The LLVM Compiler Infrastructure
+;
+; This file is distributed under the University of Illinois Open Source
+; License. See LICENSE.TXT for details.
+;
+;===------------------------------------------------------------------------===;
+;
+; This is an LLVMBuild description file for the components in this subdirectory.
+;
+; For more information on the LLVMBuild system, please see:
+;
+;   http://llvm.org/docs/LLVMBuild.html
+;
+;===------------------------------------------------------------------------===;
+
+
+[component_0]
+type = Library
+name = SPIRVerifier
+parent = Libraries
+required_libraries = Core Support Analysis
diff --git a/lib/SPIRVerifier/Makefile b/lib/SPIRVerifier/Makefile
new file mode 100644
index 0000000..5885e2b
--- /dev/null
+++ b/lib/SPIRVerifier/Makefile
@@ -0,0 +1,14 @@
+##===- lib/SPIRVerifier/Makefile ---------------------------*- Makefile -*-===##
+#
+#                     The LLVM Compiler Infrastructure
+#
+# This file is distributed under the University of Illinois Open Source
+# License. See LICENSE.TXT for details.
+#
+##===----------------------------------------------------------------------===##
+
+LEVEL := ../..
+LIBRARYNAME := LLVMSPIRVerifier
+BUILD_ARCHIVE := 1
+
+include $(LEVEL)/Makefile.common
diff --git a/lib/SPIRVerifier/README.md b/lib/SPIRVerifier/README.md
new file mode 100644
index 0000000..d845066
--- /dev/null
+++ b/lib/SPIRVerifier/README.md
@@ -0,0 +1,8 @@
+SPIR Verifier
+=============
+
+The SPIR verifier tool checks if a given file is valid according to SPIR 1.2 Specification for OpenCL document.
+The verifier is a work in progress, the current implementation is partial and does not check
+all restrictions in the Specification document.
+
+SPIR 1.2 Specification can be found under: http://www.khronos.org/files/opencl-spir-12-provisional.pdf
diff --git a/lib/SPIRVerifier/SpirErrors.cpp b/lib/SPIRVerifier/SpirErrors.cpp
new file mode 100644
index 0000000..1256e5d
--- /dev/null
+++ b/lib/SPIRVerifier/SpirErrors.cpp
@@ -0,0 +1,376 @@
+//===-------------------------- SpirErrors.cpp ---------------------------===//
+//
+//                              SPIR Tools
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===---------------------------------------------------------------------===//
+
+#include "llvm/SPIRVerifier/SpirErrors.h"
+#include "llvm/SPIRVerifier/SpirTables.h"
+#include "llvm/IR/Type.h"
+#include "llvm/IR/Value.h"
+#include "llvm/IR/Metadata.h"
+#include "llvm/Support/raw_ostream.h"
+
+#include <string>
+#include <sstream>
+#include <map>
+
+using namespace llvm;
+
+namespace SPIR {
+
+ typedef enum {
+  INFO_NONE = 0,
+  // Information types
+  INFO_OCL_TYPE,
+  INFO_LLVM_TYPE,
+  INFO_KERNEL_RETURN_TYPE,
+  INFO_KERNEL_ARG_ADDRESS_SPACE,
+  INFO_GLOBAL_AS3_VAR,
+  INFO_GLOBAL_VAR_ADDRES_SPACES,
+  INFO_OCL_TO_LLVM_TYPE,
+  INFO_CORE_FEATURE_METADATA,
+  INFO_KHR_EXT_METADATA,
+  INFO_COMPILER_OPTION_METADATA,
+  INFO_INTRINSIC,
+  INFO_ADDRESS_SPACE,
+  INFO_CALLING_CONVENTION,
+  INFO_LINKAGE_TYPE,
+  INFO_INDIRECT_CALL,
+  INFO_NAMED_METADATA,
+  INFO_METADATA_KERNEL_ARG_INFO,
+  INFO_METADATA_VERSION,
+  INFO_MEM_FENCE,
+
+  SPIR_INFO_NUM
+} SPIR_INFO_TYPE;
+
+
+/// @brief Base error class, all error types inherit from it.
+struct ValidationError {
+public:
+  /// @brief Constructor.
+  /// @param T error type
+  /// @param S error message
+  ValidationError(SPIR_ERROR_TYPE T, llvm::StringRef S) :
+    ErrType(T), ErrMSG(S) {
+  }
+
+  /// @brief Get error type.
+  /// @returns error type
+  virtual SPIR_ERROR_TYPE getErrorType() const {
+    return ErrType;
+  }
+
+  /// @brief Get error message.
+  /// @returns error message
+  virtual llvm::StringRef toString() const {
+    return StringRef(ErrMSG);
+  }
+
+  /// @brief Destructor.
+  virtual ~ValidationError() {}
+
+protected:
+  SPIR_ERROR_TYPE ErrType;
+  std::string ErrMSG;
+};
+
+struct ErrorComperator {
+  const ValidationError * LHS;
+
+  ErrorComperator(const ValidationError *Err) : LHS(Err) {}
+
+  bool operator() (const ValidationError *RHS) {
+    if (LHS == RHS)
+      return true;
+
+    return
+      (LHS->getErrorType() == RHS->getErrorType()) &&
+      (LHS->toString() == RHS->toString());
+  }
+};
+
+#define MAX_ERROR_INFO_PER_ERROR (4)
+struct SPIR_ERROR_DATA {
+  SPIR_ERROR_TYPE T;
+  std::string MSG;
+  SPIR_INFO_TYPE InfoList[MAX_ERROR_INFO_PER_ERROR];
+  std::string ErrTypeStr;
+};
+
+typedef std::string (GetInfoMsgFunc)();
+struct SPIR_INFO_DATA {
+  SPIR_INFO_TYPE T;
+  GetInfoMsgFunc *GetMsg;
+};
+
+typedef std::map<SPIR_INFO_TYPE, unsigned> SPIRInfoTypeNumMap;
+
+const SPIR_ERROR_DATA g_ErrorData[SPIR_ERROR_NUM] = {
+  // Module (general) errors
+  // Type errors
+  {ERR_INVALID_OCL_TYPE, "Invalid OpenCL C type",
+      {INFO_OCL_TYPE, INFO_CORE_FEATURE_METADATA, INFO_KHR_EXT_METADATA}, "ERR_INVALID_OCL_TYPE"},
+  {ERR_INVALID_LLVM_TYPE, "Invalid LLVM type",
+      {INFO_LLVM_TYPE, INFO_CORE_FEATURE_METADATA, INFO_KHR_EXT_METADATA}, "ERR_INVALID_LLVM_TYPE"},
+  {ERR_INVALID_KERNEL_RETURN_TYPE, "Invalid SPIR kernel return type",
+      {INFO_KERNEL_RETURN_TYPE}, "ERR_INVALID_KERNEL_RETURN_TYPE"},
+  {ERR_KERNEL_ARG_PTRPTR, "SPIR kernel argument is a pointer to pointer",
+      {}, "ERR_KERNEL_ARG_PTRPTR"},
+  {ERR_KERNEL_ARG_AS0, "SPIR kernel argument is a pointer to private address space",
+      {INFO_KERNEL_ARG_ADDRESS_SPACE}, "ERR_KERNEL_ARG_AS0"},
+  {ERR_MISMATCH_OCL_AND_LLVM_TYPES, "Mismatch between OpenCL C and LLVM types",
+      {INFO_OCL_TO_LLVM_TYPE}, "ERR_MISMATCH_OCL_AND_LLVM_TYPES"},
+  {ERR_INVALID_GLOBAL_AS3_VAR, "Invalid program scope __local variable",
+    {INFO_GLOBAL_AS3_VAR}, "ERR_INVALID_GLOBAL_AS3_VAR"},
+  {ERR_INVALID_GLOBAL_VAR_ADDRESS_SPACE, "program scope variable in a wrong address space",
+    {INFO_GLOBAL_VAR_ADDRES_SPACES}, "ERR_INVALID_GLOBAL_VAR_ADDRESS_SPACE"},
+  // Instruction errors
+  {ERR_INVALID_INTRINSIC, "Invalid intrinsic",
+      {INFO_INTRINSIC},"ERR_INVALID_INTRINSIC"},
+  {ERR_INVALID_ADDR_SPACE, "Invalid address space",
+      {INFO_ADDRESS_SPACE}, "ERR_INVALID_ADDR_SPACE"},
+  {ERR_INVALID_ADDR_SPACE_CAST, "Invalid address space cast",
+      {INFO_ADDRESS_SPACE}, "ERR_INVALID_ADDR_SPACE_CAST"},
+  {ERR_INVALID_INDIRECT_CALL, "Invalid indirect call",
+      {INFO_INDIRECT_CALL}, "ERR_INVALID_INDIRECT_CALL"},
+  {ERR_INVALID_MEM_FENCE, "Invalid cl_mem_fence value",
+      {INFO_MEM_FENCE}, "ERR_INVALID_MEM_FENCE"},
+  // Function errors
+  {ERR_INVALID_CALLING_CONVENTION, "Invalid calling convention",
+      {INFO_CALLING_CONVENTION}, "ERR_INVALID_CALLING_CONVENTION"},
+  {ERR_INVALID_LINKAGE_TYPE, "Invalid linkage type",
+      {INFO_LINKAGE_TYPE}, "ERR_INVALID_LINKAGE_TYPE"},
+  // Metadata errors
+  {ERR_INVALID_CORE_FEATURE, "Invalid core features",
+      {INFO_CORE_FEATURE_METADATA}, "ERR_INVALID_CORE_FEATURE"},
+  {ERR_INVALID_KHR_EXT, "Invalid KHR extensions",
+      {INFO_KHR_EXT_METADATA}, "ERR_INVALID_KHR_EXT"},
+  {ERR_INVALID_COMPILER_OPTION, "Invalid compiler options",
+      {INFO_COMPILER_OPTION_METADATA},"ERR_INVALID_COMPILER_OPTION"},
+  {ERR_MISSING_NAMED_METADATA, "Named Metadata is missing",
+      {INFO_NAMED_METADATA}, "ERR_MISSING_NAMED_METADATA"},
+  {ERR_INVALID_METADATA_KERNEL, "Invalid kernel metatdata",
+      {}, "ERR_INVALID_METADATA_KERNEL"},
+  {ERR_INVALID_METADATA_KERNEL_INFO, "Invalid kernel metadata ARG Info",
+      {INFO_METADATA_KERNEL_ARG_INFO}, "ERR_INVALID_METADATA_KERNEL_INFO"},
+  {ERR_MISSING_METADATA_KERNEL_INFO, "Kernel metadata is missing ARG Info",
+      {INFO_METADATA_KERNEL_ARG_INFO}, "ERR_MISSING_METADATA_KERNEL_INFO"},
+  {ERR_INVALID_METADATA_VERSION, "Invalid OpenCL (OCL/SPIR) version",
+      {INFO_METADATA_VERSION}, "ERR_INVALID_METADATA_VERSION"},
+  {ERR_MISMATCH_METADATA_ADDR_SPACE, "Address space mismatch between kernel prototype and metadata",
+      {}, "ERR_MISMATCH_METADATA_ADDR_SPACE"}
+};
+
+const SPIR_INFO_DATA g_InfoData[SPIR_INFO_NUM] = {
+  {INFO_NONE, nullptr},
+  {INFO_OCL_TYPE, getValidOpenCLTypeMsg},
+  {INFO_LLVM_TYPE, getValidLLVMTypeMsg},
+  {INFO_KERNEL_RETURN_TYPE, getValidKernelReturnTypeMsg},
+  {INFO_KERNEL_ARG_ADDRESS_SPACE, getValidKernelArgAddressSpaceMsg},
+  {INFO_GLOBAL_AS3_VAR, getValidGlobalAS3VariableMsg},
+  {INFO_GLOBAL_VAR_ADDRES_SPACES, getValidGlobalVarAddressSpacesMsg},
+  {INFO_OCL_TO_LLVM_TYPE, getMapOpenCLToLLVMMsg},
+  {INFO_CORE_FEATURE_METADATA, getValidCoreFeaturesMsg},
+  {INFO_KHR_EXT_METADATA, getValidKHRExtensionsMsg},
+  {INFO_COMPILER_OPTION_METADATA, getValidCompilerOptionsMsg},
+  {INFO_INTRINSIC, getValidIntrinsicMsg},
+  {INFO_ADDRESS_SPACE, getValidAddressSpaceMsg},
+  {INFO_CALLING_CONVENTION, getValidCallingConventionMsg},
+  {INFO_LINKAGE_TYPE, getValidLinkageTypeMsg},
+  {INFO_INDIRECT_CALL, getValidIndirectCallMsg},
+  {INFO_NAMED_METADATA, getValidNamedMetadataMsg},
+  {INFO_METADATA_KERNEL_ARG_INFO, getValidKernelArgInfoMsg},
+  {INFO_METADATA_VERSION, getValidVersionMsg},
+  {INFO_MEM_FENCE, getValidMemFenceMsg}
+};
+
+static bool isValidTables() {
+  for (unsigned i=0; i<SPIR_ERROR_NUM; i++) {
+    if (g_ErrorData[i].T != (SPIR_ERROR_TYPE)i)
+      return false;
+  }
+
+  for (unsigned i=0; i<SPIR_INFO_NUM; i++) {
+    if (g_InfoData[i].T != (SPIR_INFO_TYPE)i)
+      return false;
+  }
+
+  return true;
+}
+
+//
+// Validation Errors
+//
+
+/// @brief Returns type's name.
+/// @param Ty type
+/// @returns type's name as std::string.
+static std::string getObjectAsString(const Type *Ty) {
+  std::string type_str;
+  llvm::raw_string_ostream rso(type_str);
+  Ty->print(rso);
+  return rso.str();
+}
+
+/// @brief Returns Value as string.
+/// @param V value
+/// @returns value as std::string.
+static std::string getObjectAsString(const llvm::Value *V) {
+  std::string type_str;
+  llvm::raw_string_ostream rso(type_str);
+  V->print(rso);
+  return rso.str();
+}
+
+/// @brief Returns Metadata as string.
+/// @param V value
+/// @returns value as std::string.
+static std::string getObjectAsString(const llvm::Metadata *MD) {
+  std::string type_str;
+  llvm::raw_string_ostream rso(type_str);
+  MD->print(rso);
+  return rso.str();
+}
+
+/// @brief Returns NamedMDNode as string.
+/// @param NMD named metadata node
+/// @returns named metadata node as std::string.
+static std::string getObjectAsString(const llvm::NamedMDNode *NMD) {
+  std::string type_str;
+  llvm::raw_string_ostream rso(type_str);
+  NMD->print(rso);
+  return rso.str();
+}
+
+ErrorHolder::ErrorHolder() {
+  assert(isValidTables() && "SPIR Error/Info data tables are invalid!");
+}
+
+ErrorHolder::~ErrorHolder() {
+  for (ErrorList::iterator ei=EL.begin(), ee=EL.end(); ei!=ee; ei++) {
+    const ValidationError *Err = *ei;
+    delete Err;
+  }
+}
+
+void ErrorHolder::addError(SPIR_ERROR_TYPE Err, const llvm::StringRef S) {
+  std::string ErrMsg;
+  ErrMsg += S.str() + "\n";
+  ValidationError *VE = new ValidationError(Err, ErrMsg);
+  EL.push_back(VE);
+}
+
+void ErrorHolder::addError(SPIR_ERROR_TYPE Err, const llvm::Value *V) {
+  ValidationError *VE = new ValidationError(Err, getObjectAsString(V));
+  EL.push_back(VE);
+}
+
+void ErrorHolder::addError(SPIR_ERROR_TYPE Err, const llvm::Metadata *MD) {
+  ValidationError *VE = new ValidationError(Err, getObjectAsString(MD));
+  EL.push_back(VE);
+}
+
+void ErrorHolder::addError(SPIR_ERROR_TYPE Err, const llvm::NamedMDNode *NMD) {
+  ValidationError *VE = new ValidationError(Err, getObjectAsString(NMD));
+  EL.push_back(VE);
+}
+
+void ErrorHolder::addError(SPIR_ERROR_TYPE Err, const llvm::Type *T,
+                                                const llvm::StringRef S) {
+  std::string ErrMsg;
+  ErrMsg += "Type: " + getObjectAsString(T) + "\n";
+  ErrMsg += "Found in prototype of Function: " + S.str() + "\n";
+  ValidationError *VE = new ValidationError(Err, ErrMsg);
+  EL.push_back(VE);
+}
+
+void ErrorHolder::addError(SPIR_ERROR_TYPE Err, const llvm::Type *T,
+                                                const llvm::Value *V) {
+  std::string ErrMsg;
+  ErrMsg += "Type: " + getObjectAsString(T) + "\n";
+  ErrMsg += "Found in: " + getObjectAsString(V) + "\n";
+  ValidationError *VE = new ValidationError(Err, ErrMsg);
+  EL.push_back(VE);
+}
+
+void ErrorHolder::print(llvm::raw_ostream &S, bool LITMode) const {
+  ErrorList UEL;
+  SPIRInfoTypeNumMap ITmap;
+  // Calculate unique error list
+  // Collect relevant info types
+  for (ErrorList::const_iterator ei=EL.begin(), ee=EL.end(); ei!=ee; ei++) {
+    const ValidationError *Err = *ei;
+    ErrorComperator Dup(Err);
+    if (std::find_if(UEL.begin(), UEL.end(), Dup) == UEL.end()) {
+      // Add to unique error list
+      UEL.push_back(Err);
+      // Add to info type map, initialize number to zero
+      SPIR_ERROR_TYPE ErrType = Err->getErrorType();
+      for (unsigned i=0; i<MAX_ERROR_INFO_PER_ERROR; i++) {
+        SPIR_INFO_TYPE InfoType = g_ErrorData[ErrType].InfoList[i];
+        if (InfoType != INFO_NONE) {
+          ITmap[InfoType] = 0;
+        }
+      }
+    }
+  }
+
+  // Assign error info number for each relevant info type
+  // Create SPIR Info message
+  std::string InfoMsg;
+  if (!LITMode) {
+    unsigned ErrInfoNum = 0;
+    InfoMsg += "---------------------------------------------";
+    InfoMsg += "---------------------------------------------\n";
+    for (unsigned i=0; i<SPIR_INFO_NUM; i++) {
+      SPIR_INFO_TYPE InfoType = g_InfoData[i].T;
+      if (ITmap.count(InfoType) != 0) {
+        // Set error info number
+        ITmap[InfoType] = ++ErrInfoNum;
+        // Append error info message
+        std::stringstream SS;
+        SS << "[" << ErrInfoNum << "] " << g_InfoData[i].GetMsg() << "\n";
+        InfoMsg += SS.str();
+      }
+    }
+  }
+
+  // Create error message
+  std::string ErrMsg;
+  unsigned ErrNum = 0;
+
+  for (ErrorList::const_iterator ei=UEL.begin(), ee=UEL.end(); ei!=ee; ei++) {
+    const ValidationError *Err = *ei;
+    std::stringstream SS;
+    SPIR_ERROR_TYPE ErrType = Err->getErrorType();
+    SS << "(" << ++ErrNum << ") Error";
+    if(!LITMode) {
+      for (unsigned i=0; i<MAX_ERROR_INFO_PER_ERROR; i++) {
+        SPIR_INFO_TYPE InfoType = g_ErrorData[ErrType].InfoList[i];
+        if (InfoType != INFO_NONE) {
+          SS << "[" << ITmap[InfoType] << "]";
+        }
+      }
+      SS << " " << g_ErrorData[ErrType].MSG.c_str() << ":\n";
+    } else {
+      SS << " " << g_ErrorData[ErrType].ErrTypeStr << ":\n";
+    }
+    SS << Err->toString().str().c_str() << "\n";
+    ErrMsg += SS.str();
+  }
+
+  // Print error message and SPIR info message to output stream
+  S << ErrMsg;
+  S << InfoMsg;
+}
+
+bool ErrorHolder::hasErrors() const {
+  return !EL.empty();
+}
+
+} // End SPIR namespace
diff --git a/lib/SPIRVerifier/SpirIterators.cpp b/lib/SPIRVerifier/SpirIterators.cpp
new file mode 100644
index 0000000..e478e12
--- /dev/null
+++ b/lib/SPIRVerifier/SpirIterators.cpp
@@ -0,0 +1,1029 @@
+//===------------------------ SpirValidation.h ---------------------------===//
+//
+//                              SPIR Tools
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===---------------------------------------------------------------------===//
+
+#include "llvm/SPIRVerifier/SpirIterators.h"
+#include "llvm/SPIRVerifier/SpirErrors.h"
+#include "llvm/SPIRVerifier/SpirTables.h"
+#include "llvm/IR/Constants.h"
+#include "llvm/IR/Module.h"
+#include "llvm/IR/Function.h"
+#include "llvm/IR/Instruction.h"
+#include "llvm/IR/Instructions.h"
+#include "llvm/IR/Value.h"
+#include <sstream>
+#include <algorithm>
+
+namespace SPIR {
+
+//
+// Iterator classes (impl).
+//
+
+void BasicBlockIterator::execute(const llvm::BasicBlock& BB) {
+  // Run over all instructions in basic block.
+  BasicBlock::const_iterator ii = BB.begin(), ie = BB.end();
+  for (; ii != ie; ii++) {
+    // For each instruction apply all executors from the list.
+    const Instruction *I = &*ii;
+    InstructionExecutorList::iterator iei = m_iel.begin(), iee = m_iel.end();
+    for (; iei != iee; iei++) {
+      (*iei)->execute(I);
+    }
+  }
+}
+
+void FunctionIterator::execute(const llvm::Function& F) {
+  // Apply all executors from the list on the given function.
+  FunctionExecutorList::iterator fei = m_fel.begin(), fee = m_fel.end();
+  for (; fei != fee; fei++) {
+    (*fei)->execute(&F);
+  }
+  // If basic block iterator available
+  // Apply it for each basic block in the given function.
+  if (m_bbi) {
+    Function::const_iterator bi = F.begin(), be = F.end();
+    for (; bi != be; bi++) {
+      const BasicBlock *BB = &*bi;
+      m_bbi->execute(*BB);
+    }
+  }
+}
+
+void GlobalVariableIterator::execute(const llvm::GlobalVariable& GV) {
+  // Apply all executors from the list on the given global variable.
+  GlobalVariableExecutorList::iterator gei = m_gvel.begin(),
+                                       gee = m_gvel.end();
+  for (; gei != gee; gei++) {
+    (*gei)->execute(&GV);
+  }
+}
+
+void ModuleIterator::execute(const llvm::Module& M) {
+  // Apply all executors from the list on the given module.
+  ModuleExecutorList::iterator mei = m_mel.begin(), mee = m_mel.end();
+  for (; mei != mee; mei++) {
+    (*mei)->execute(&M);
+  }
+  // If function iterator available
+  // Apply it for each function in the given module.
+  if (m_fi) {
+    Module::const_iterator fi = M.begin(), fe = M.end();
+    for (; fi != fe; fi++) {
+      const Function *F = &*fi;
+      m_fi->execute(*F);
+    }
+  }
+  // If global variable iterator available
+  // Apply it for each global variable in the given module.
+  if (m_gi) {
+    Module::const_global_iterator gi = M.global_begin(), ge = M.global_end();
+    for (; gi != ge; gi++) {
+      const GlobalVariable *GV = &*gi;
+      m_gi->execute(*GV);
+    }
+  }
+}
+
+void MetaDataIterator::execute(const llvm::MDNode& Node) {
+  // Apply all executors from the list on the given Metadata node.
+  for (unsigned int i=0; i<Node.getNumOperands(); ++i) {
+    const llvm::MDNode *Op = dyn_cast<llvm::MDNode>(Node.getOperand(i));
+    if (Op) {
+      MDNodeExecutorList::iterator nei = m_nel.begin(), nee = m_nel.end();
+      for (; nei != nee; nei++) {
+        (*nei)->execute(Op);
+      }
+    }
+  }
+}
+
+//
+// Utility functions.
+//
+
+/// @brief Check if given name is valid according to given valid list.
+/// @param Name given name to validate.
+/// @param ValidList given valid list to validate against.
+/// @returns true if name is valid, false otherwise.
+static bool isValidNameOf(StringRef Name, const char *ValidList[], unsigned len) {
+  for (unsigned i=0; i<len; i++) {
+    StringRef candidate(ValidList[i]);
+    if (Name == candidate)
+      return true;
+  }
+  return false;
+}
+
+/// @brief Check if given name start with valid prefix according to given valid list.
+/// @param Name given name to validate.
+/// @param ValidList given valid list to validate against.
+/// @returns size of valid prefix, 0 if no valid prefix.
+static int hasPrefixValidNameOf(StringRef Name, const char *ValidList[], unsigned len) {
+  for (unsigned i=0; i<len; i++) {
+    StringRef candidate(ValidList[i]);
+    if (Name.startswith(candidate))
+      return candidate.size();
+  }
+  return 0;
+}
+
+// Returns true if the string is a legal name.
+static bool isValidTypeName(StringRef TyName) {
+  // Check if type start with a prefix of ignored type
+  if (hasPrefixValidNameOf(TyName, g_ignored_ocl_types,
+                                   g_ignored_ocl_types_len)) {
+    return true;
+  }
+  // Check if type is a valid OCL type.
+  if( isValidNameOf(TyName, g_valid_ocl_opaque_types,
+                            g_valid_ocl_opaque_types_len) ) {
+    return true;
+  }
+  // Check if type is a valid vector element type.
+  int prefixLen = hasPrefixValidNameOf(TyName,
+    g_valid_ocl_vector_element_types, g_valid_ocl_vector_element_types_len);
+  if (prefixLen) {
+    TyName = TyName.substr(prefixLen);
+    // Check for vector length suffix.
+    prefixLen = hasPrefixValidNameOf(TyName,
+      g_valid_vector_type_lengths, g_valid_vector_type_lengths_len);
+    TyName = TyName.substr(prefixLen);
+  } else {
+    // Check if type is a valid scalar primitive type.
+    prefixLen = hasPrefixValidNameOf(TyName,
+      g_valid_ocl_primitives, g_valid_ocl_primitives_len);
+    TyName = TyName.substr(prefixLen);
+  }
+  // '*' is the only possible suffix now (spaces are ignored).
+    for (unsigned int pos = 0; pos < TyName.size(); ++pos) {
+      if (TyName[pos] == ' ')
+        continue;
+      if (TyName[pos] == '[') {
+        // Array types are ignored. TODO: are they allowed?
+        return true;
+      }
+      if (TyName[pos] != '*')
+        return false;
+    }
+    return true;
+}
+
+/// @brief Check if given Value is an MDNode of given Type name.
+/// @param V given value to validate.
+/// @param type given type name validate against.
+/// @returns true if match, false otherwise.
+static bool isMDNodeTypeOf(const Metadata *V, StringRef type) {
+  if (!isa<MDNode>(V))
+    return false;
+
+  const MDNode *N = cast<MDNode>(V);
+  const MDString *StringVal = dyn_cast<MDString>(N->getOperand(0));
+  return StringVal && StringVal->getString() == type;
+}
+
+static bool isAllowedIntrinsic(StringRef FName) {
+  bool IsValidIntrinsic = hasPrefixValidNameOf(FName,
+    g_valid_instrinsic, g_valid_instrinsic_len) != 0;
+  bool IsIgnoredIntrinsic = hasPrefixValidNameOf(FName,
+    g_ignored_instrinsic, g_ignored_instrinsic_len) != 0;
+  return IsValidIntrinsic || IsIgnoredIntrinsic;
+}
+
+//
+// LLVM types validaiton
+//
+static bool isValidPrimitiveType(Type *Ty, DataHolder *D, bool isPointer) {
+  return
+    (Ty->isDoubleTy() && D->HasDoubleFeature) ||
+    (Ty->isHalfTy() && (D->HASFp16Extension || isPointer)) ||
+    Ty->isFloatTy() ||
+    Ty->isIntegerTy(1) || Ty->isIntegerTy(8) || Ty->isIntegerTy(16) ||
+    Ty->isIntegerTy(32) || Ty->isIntegerTy(64) || Ty->isVoidTy();
+}
+
+static bool isIgnoredPrimitiveType(Type *Ty) {
+  return Ty->isMetadataTy();
+}
+
+static bool isValidVectorElementType(Type *Ty, DataHolder *D, bool isPointer) {
+  return
+    (Ty->isDoubleTy() && D->HasDoubleFeature) ||
+    (Ty->isHalfTy() && (D->HASFp16Extension || isPointer)) ||
+    Ty->isFloatTy() ||
+    Ty->isIntegerTy(8) || Ty->isIntegerTy(16) || Ty->isIntegerTy(32) ||
+    Ty->isIntegerTy(64);
+}
+
+static bool isValidVectorElementsNum(unsigned ElementsNum) {
+  return ElementsNum == 2 || ElementsNum == 3 || ElementsNum == 4 ||
+    ElementsNum == 8 || ElementsNum == 16;
+}
+
+static bool isValidOCLOpaqueType(const StructType *Ty, DataHolder *D) {
+  return
+    isValidNameOf(Ty->getName(), g_valid_llvm_opaque_types,
+                                 g_valid_llvm_opaque_types_len) ||
+    (isValidNameOf(Ty->getName(), g_valid_llvm_image_types,
+                                  g_valid_llvm_image_types_len) &&
+     (!D || D->HasImageFeature));
+}
+
+static bool isValidType(Type *Ty, DataHolder *D,
+                        bool isBoolAllowed, bool isOpaqueAllowed,
+                        bool isBoolVecAllowed, bool isPointer) {
+  // Check if it is a pointer
+  if (Ty->isPointerTy()) {
+    return isValidType(Ty->getContainedType(0), D,
+      true, true, isBoolVecAllowed, true);
+  }
+
+  // Check if it is an Array
+  if (Ty->isArrayTy()) {
+    return isValidType(Ty->getContainedType(0), D,
+      false, false, isBoolVecAllowed, isPointer);
+  }
+
+  // Check if it is a Structure
+  if (const StructType *STy = dyn_cast<StructType>(Ty)) {
+    if (STy->isOpaque()) {
+      if (!isOpaqueAllowed) {
+        return false;
+      }
+      // Check of it is allowed OpenCL opaque types
+      if (isValidOCLOpaqueType(STy, D)) {
+        return true;
+      }
+      // Ignor other opaque type
+      // TODO: check if it is supported by SPIR
+      return true;
+    }
+    for (unsigned i=0; i<STy->getStructNumElements(); i++) {
+      if (!isValidType(STy->getStructElementType(i), D,
+          false, false, isBoolVecAllowed, isPointer)) {
+        return false;
+      }
+    }
+    return true;
+  }
+
+  // Check if it is a vector
+  if (const VectorType *VTy = dyn_cast<VectorType>(Ty)) {
+    if (!isValidVectorElementsNum(VTy->getNumElements())) {
+      return false;
+    }
+    if (isBoolVecAllowed) {
+      return isValidType(VTy->getElementType(), D,
+        isBoolAllowed, false, isBoolVecAllowed, isPointer);
+    }
+    return isValidType(VTy->getElementType(), D,
+      false, false, isBoolVecAllowed, isPointer);
+  }
+
+  // Check if it is a valid primitive type
+  if (!isBoolAllowed) {
+    return isValidVectorElementType(Ty, D, isPointer);
+  }
+  return isValidPrimitiveType(Ty, D, isPointer) || isIgnoredPrimitiveType(Ty);
+
+}
+
+static std::string MapLLVMToOCL(Type *Ty, bool &Ignore) {
+  // Check if it is a pointer
+  if (Ty->isPointerTy()) {
+    return MapLLVMToOCL(Ty->getContainedType(0), Ignore) + "*";
+  }
+
+  // Check if it is an Array
+  if (Ty->isArrayTy()) {
+    // Do not know how to handle Array, mark this check as ignored
+    Ignore = true;
+    return "";
+  }
+
+  // Check if it is a Structure
+  if (const StructType *STy = dyn_cast<StructType>(Ty)) {
+    if (STy->isOpaque() && isValidOCLOpaqueType(STy, nullptr)) {
+      std::string TypeName = STy->getStructName();
+      TypeName = TypeName.substr(StringRef(g_llvm_opaque_prefix).size());
+      return TypeName;
+    }
+    std::string TypeName = STy->getStructName();
+    TypeName = "struct " + TypeName.substr(StringRef("struct.").size());
+    // TODO: maybe it is better to just Ignore this check
+    Ignore = true;
+    return TypeName;
+  }
+
+  // Check if it is a vector
+  if (const VectorType *VTy = dyn_cast<VectorType>(Ty)) {
+    std::stringstream SS;
+    SS << MapLLVMToOCL(VTy->getElementType(), Ignore) << VTy->getNumElements();
+    return SS.str();
+  }
+
+  // Check if it is a valid primitive type
+  if (Ty->isFloatTy()) {
+    return "float";
+  }
+  if (Ty->isDoubleTy()) {
+    return "double";
+  }
+  if (Ty->isHalfTy()) {
+    return "half";
+  }
+  if (Ty->isIntegerTy(1)) {
+    return "bool";
+  }
+  if (Ty->isIntegerTy(8)) {
+    return "char";
+  }
+  if (Ty->isIntegerTy(16)) {
+    return "short";
+  }
+  if (Ty->isIntegerTy(32)) {
+    return "int";
+  }
+  if (Ty->isIntegerTy(64)) {
+    return "long";
+  }
+  // Any other type is not allowed, return empty string
+  return "";
+}
+
+static bool isValidMapOCLToLLVM(StringRef TyName, Type *Ty, DataHolder *D) {
+  // Check if type start with a prefix of ignored type
+  if (hasPrefixValidNameOf(TyName, g_ignored_ocl_types,
+                                   g_ignored_ocl_types_len)) {
+    return true;
+  }
+
+  bool Ignore = false;
+  std::string ConvertedName = MapLLVMToOCL(Ty, Ignore);
+
+  if (Ignore) {
+    // Do not know how to convert, ignore this check.
+    return true;
+  }
+
+  if (TyName.find("void") != std::string::npos) {
+    // TODO: Can 'void' be verified?
+    return true;
+  }
+
+  std::string StrName = TyName;
+  // Handle special type conversions
+  if( isValidNameOf(TyName, g_valid_ocl_opaque_types,
+                            g_valid_ocl_opaque_types_len) ) {
+    if (TyName == "sampler_t") {
+      StrName = "int"; //"i32"
+    }
+    else if (TyName == "size_t" || TyName == "ptrdiff_t" ||
+        TyName == "uintptr_t" || TyName == "intptr_t") {
+      if (D->Is32Bit) {
+        StrName = "int"; //"i32"
+      }
+      else {
+        StrName = "long";
+      }
+    }
+    else {
+      StrName += "*";
+    }
+  }
+  else if (TyName.startswith("unsigned")) {
+    StrName = TyName.substr(StringRef("unsigned").size());
+  }
+  else if (TyName.startswith("u")) {
+    StrName = TyName.substr(StringRef("u").size());
+  }
+
+  return (StrName == ConvertedName);
+}
+
+static bool isValidAddrSpaceCast(const BitCastInst *BI) {
+  const PointerType *LHS = dyn_cast<PointerType>(BI->getDestTy()),
+                    *RHS = dyn_cast<PointerType>(BI->getSrcTy());
+  if (!LHS || !RHS)
+    return true;
+
+  const unsigned int DstAddress = LHS->getAddressSpace();
+  const unsigned int SrcAddress = RHS->getAddressSpace();
+  return (SrcAddress == DstAddress);
+}
+
+static bool isValidAddrSpaceCast(const User *V) {
+
+  for (unsigned i = 0; i < V->getNumOperands(); i++) {
+    // If the operand is not a constant expression, we will (or already did),
+    // visit it as a command from the main block iteration.
+    if (const ConstantExpr *CE = dyn_cast<ConstantExpr>(V->getOperand(i)))
+      isValidAddrSpaceCast(CE);
+  }
+
+  const ConstantExpr *CE = dyn_cast<ConstantExpr>(V);
+  if (!CE)
+    return true;
+
+  const PointerType *PTy  = dyn_cast<PointerType>(CE->getType());
+  if (!PTy)
+    return true;
+
+  const unsigned int DstAddress = PTy->getAddressSpace();
+  if (Instruction::BitCast == CE->getOpcode()) {
+    const PointerType *STy = dyn_cast<PointerType>(CE->getOperand(0)->getType());
+    if (STy) {
+      const unsigned int SrcAddress = STy->getAddressSpace();
+      return (SrcAddress == DstAddress);
+    }
+  }
+
+  return true;
+}
+
+static bool isValidAddrSpace(unsigned AddSpace) {
+  assert(g_valid_address_space_len == 4 &&
+    "In SPIR 1.2 we have only 4 address spaces");
+  return AddSpace < g_valid_address_space_len;
+}
+
+static bool isValidOCLVersion(unsigned Major, unsigned Minor) {
+  return (Major == 1 && Minor == 2);
+}
+
+static bool isValidSPIRVersion(unsigned Major, unsigned Minor) {
+  return (Major == 1 && Minor == 2);
+}
+
+static bool isValidMemfence(unsigned Val) {
+  return (Val == 1 || Val == 2 || Val == 3);
+}
+
+static bool isValidLinkageType(llvm::GlobalValue::LinkageTypes LT) {
+  return LT == llvm::GlobalValue::ExternalLinkage
+      || LT == llvm::GlobalValue::PrivateLinkage
+      || LT == llvm::GlobalValue::InternalLinkage
+      || LT == llvm::GlobalValue::AvailableExternallyLinkage;
+}
+
+//
+// Verify Executor classes (impl).
+//
+void VerifyCall::execute(const Instruction *I) {
+  const CallInst *CI = dyn_cast<CallInst>(I);
+  if (!CI)
+    return;
+
+  // Verify that this call is not indirect.
+  const Function *F = CI->getCalledFunction();
+  if (!F) {
+    ErrCreator->addError(ERR_INVALID_INDIRECT_CALL, I);
+    return;
+  }
+
+  if (!F->isDeclaration()) {
+    // Verify that this call has valid calling convention.
+    if (CI->getCallingConv() != CallingConv::FLOOR_KERNEL &&
+        CI->getCallingConv() != CallingConv::FLOOR_FUNC) {
+        ErrCreator->addError(ERR_INVALID_CALLING_CONVENTION, I);
+    }
+  }
+
+  // Verify valid memfence for synchronize functions
+  if (hasPrefixValidNameOf(F->getName(), g_valid_sync_bi, g_valid_sync_bi_len)) {
+    if (CI->getNumArgOperands() != 1) {
+      ErrCreator->addError(ERR_INVALID_MEM_FENCE, I);
+    }
+    ConstantInt *MemfenceVal = dyn_cast<ConstantInt>(CI->getOperand(0));
+    if (!MemfenceVal ||
+      !isValidMemfence((unsigned)MemfenceVal->getZExtValue())) {
+      ErrCreator->addError(ERR_INVALID_MEM_FENCE, I);
+    }
+  }
+
+  // Verify that this call is valid intrinsic.
+  if (F->isIntrinsic() && !isAllowedIntrinsic(F->getName())) {
+    ErrCreator->addError(ERR_INVALID_INTRINSIC, I);
+  }
+}
+
+void VerifyBitcast::execute(const Instruction *I) {
+  if (const BitCastInst *BI = dyn_cast<BitCastInst>(I)) {
+    // Verify that this bitcast is not adress space cast.
+    if (!isValidAddrSpaceCast(BI))
+      ErrCreator->addError(ERR_INVALID_ADDR_SPACE_CAST, I);
+  }
+
+  for (unsigned i = 0; i < I->getNumOperands(); i++) {
+    // Verify that each opernad is not const expression adress space cast.
+    if (const User *Usr = dyn_cast<User>(I->getOperand(i)))
+      if (!isValidAddrSpaceCast(Usr) )
+        ErrCreator->addError(ERR_INVALID_ADDR_SPACE_CAST, I);
+  }
+}
+
+void VerifyInstructionType::execute(const Instruction *I) {
+  Type *Ty = I->getType();
+  bool isValid = true;
+  switch(I->getOpcode()) {
+  case Instruction::ICmp:
+  case Instruction::FCmp:
+    isValid = isValidType(Ty, Data, true, true, true, false);
+    break;
+  default:
+    isValid = isValidType(Ty, Data, true, true, false, false);
+    break;
+  }
+  if (!isValid)
+    ErrCreator->addError(ERR_INVALID_LLVM_TYPE, Ty, I);
+}
+
+void VerifyFunctionPrototype::execute(const Function *F) {
+  if (!F->isDeclaration()) {
+    // Verify calling convention for user defined functions
+    if (F->getCallingConv() != CallingConv::FLOOR_KERNEL &&
+        F->getCallingConv() != CallingConv::FLOOR_FUNC)
+          ErrCreator->addError(ERR_INVALID_CALLING_CONVENTION, F->getName());
+  }
+  Function::const_arg_iterator ai = F->arg_begin(), ae = F->arg_end();
+  for (; ai != ae; ai++) {
+    Type *Ty = ai->getType();
+    if (!isValidType(Ty, Data, true, true, false, false)) {
+      ErrCreator->addError(ERR_INVALID_LLVM_TYPE, Ty, F->getName());
+    }
+  }
+  // Verify function linkage
+  if (!isValidLinkageType(F->getLinkage())) {
+    ErrCreator->addError(ERR_INVALID_LINKAGE_TYPE, F->getName());
+  }
+  // Verify function return type.
+  if (!isValidType(F->getReturnType(), Data, true, true, false, false)) {
+    ErrCreator->addError(
+      ERR_INVALID_LLVM_TYPE, F->getReturnType(), F->getName());
+  }
+}
+
+void VerifyKernelPrototype::execute(const Function *F) {
+  // detect kernel by looking at the calling convention
+  if (F->getCallingConv() != CallingConv::FLOOR_KERNEL)
+    return;
+
+  // check arguments
+  Function::const_arg_iterator ai = F->arg_begin(), ae = F->arg_end();
+  for (; ai != ae; ai++) {
+    Type *Ty = ai->getType();
+
+    // kernel arguments shall not be pointers to pointers
+    if (Ty->isPointerTy() && Ty->getPointerElementType()->isPointerTy()) {
+      ErrCreator->addError(ERR_KERNEL_ARG_PTRPTR, Ty, F->getName());
+    }
+
+    // kernel arguments shall not be pointers to a private addrspace
+	// except for aggregate types which are always pointer types
+    if (Ty->isPointerTy() &&
+        !Ty->getPointerElementType()->isStructTy() &&
+        Ty->getPointerAddressSpace() == PRIVATE_ADDR_SPACE) {
+      ErrCreator->addError(ERR_KERNEL_ARG_AS0, Ty, F->getName());
+    }
+  }
+
+  // the return type shall be void
+  if (!F->getReturnType()->isVoidTy()) {
+    ErrCreator->addError(
+      ERR_INVALID_KERNEL_RETURN_TYPE, F->getReturnType(), F->getName());
+  }
+}
+
+void VerifyGlobalVariable::execute(const GlobalVariable *GV) {
+  // Verify variable linkage
+  if (!isValidLinkageType(GV->getLinkage())) {
+    ErrCreator->addError(ERR_INVALID_LINKAGE_TYPE, GV->getName());
+  }
+
+  // check the global variable address space
+  switch (GV->getType()->getPointerAddressSpace()) {
+  case CONSTANT_ADDR_SPACE:
+    // constant address space: everything OK
+    break;
+  case LOCAL_ADDR_SPACE: {
+    // local address space:
+    // it is a function-scope variable,
+    // must contain a prefix that is equal to the name of a function
+    // and should be used only in it
+    for (Value::const_use_iterator ib = GV->use_begin(), ie = GV->use_end(); ib != ie; ++ib) {
+      if (const Instruction *Inst = dyn_cast<Instruction>(*ib)) {
+        const Function * func = Inst->getParent()->getParent();
+        if (!(GV->getName().startswith(func->getName().str() + "."))) {
+           ErrCreator->addError(ERR_INVALID_GLOBAL_AS3_VAR, GV);
+           break;
+        }
+      }
+    }
+    break;
+  }
+  default:
+    ErrCreator->addError(ERR_INVALID_GLOBAL_VAR_ADDRESS_SPACE, GV);
+    break;
+  }
+}
+
+void VerifyMetadataArgAddrSpace::execute(const llvm::MDNode *Node) {
+  if (!isMDNodeTypeOf(Node, KERNEL_ARG_ADDR_SPACE))
+    return;
+
+  WasFound = true;
+  // Verify that kernel arg base type metadata list is valid.
+  for (unsigned i=1; i<Node->getNumOperands(); i++) {
+    auto *AddrSpaceMD = dyn_cast<ConstantAsMetadata>(Node->getOperand(i));
+    if (!AddrSpaceMD) {
+      ErrCreator->addError(ERR_INVALID_METADATA_KERNEL_INFO, Node);
+      continue;
+    }
+    ConstantInt *AddrSpace = dyn_cast<ConstantInt>(AddrSpaceMD->getValue());
+    if (!AddrSpace) {
+      ErrCreator->addError(ERR_INVALID_METADATA_KERNEL_INFO, Node);
+      continue;
+    }
+    unsigned AddrSpaceVal = (unsigned)AddrSpace->getZExtValue();
+    if (!isValidAddrSpace(AddrSpaceVal)) {
+      ErrCreator->addError(ERR_INVALID_ADDR_SPACE, Node);
+    }
+    // Verify that LLVM Type of relevant function prototype argument
+    // has same address space.
+    const unsigned ArgIndex = i-1;
+    Type *Ty = Func->getFunctionType()->getParamType(ArgIndex);
+    unsigned ArgAddrSpace = 0;
+    if (PointerType *PTy = dyn_cast<PointerType>(Ty)) {
+      ArgAddrSpace = PTy->getAddressSpace();
+    }
+    if (ArgAddrSpace != AddrSpaceVal) {
+      ErrCreator->addError(ERR_INVALID_METADATA_KERNEL_INFO, Node);
+      ErrCreator->addError(ERR_MISMATCH_METADATA_ADDR_SPACE, Ty,
+                                                            Func->getName());
+    }
+  }
+}
+
+void VerifyMetadataArgType::execute(const llvm::MDNode *Node) {
+  if (isMDNodeTypeOf(Node, KERNEL_ARG_TY)) {
+    WasFound = true;
+  }
+}
+
+void VerifyMetadataArgBaseType::execute(const llvm::MDNode *Node) {
+  if (!isMDNodeTypeOf(Node, KERNEL_ARG_BASE_TY))
+    return;
+
+  WasFound = true;
+  // Verify that kernel arg base type metadata list is valid.
+  for (unsigned i=1; i<Node->getNumOperands(); i++) {
+    MDString *StringValue = dyn_cast<MDString>(Node->getOperand(i));
+    if (!StringValue) {
+      ErrCreator->addError(ERR_INVALID_METADATA_KERNEL_INFO, Node);
+      continue;
+    }
+    StringRef S = StringValue->getString();
+    if (!isValidTypeName(S)) {
+      ErrCreator->addError(ERR_INVALID_OCL_TYPE, Node);
+      continue;
+    }
+    // Verify that LLVM Type of relevant function prototype argument
+    // has same address space.
+    const unsigned ArgIndex = i-1;
+    Type *Ty = Func->getFunctionType()->getParamType(ArgIndex);
+    if (!isValidMapOCLToLLVM(S, Ty, Data)) {
+      ErrCreator->addError(ERR_MISMATCH_OCL_AND_LLVM_TYPES, Node);
+      ErrCreator->addError(ERR_MISMATCH_OCL_AND_LLVM_TYPES, Ty,
+                                                            Func->getName());
+    }
+  }
+}
+
+void VerifyMetadataKernel::execute(const llvm::MDNode *Node) {
+  // Verify that first operand is a valid function type.
+  if (Node->getNumOperands() < 1) {
+    ErrCreator->addError(ERR_INVALID_METADATA_KERNEL, Node);
+    return;
+  }
+  ValueAsMetadata* FMD = dyn_cast<ValueAsMetadata>(Node->getOperand(0));
+  if (!FMD) {
+    ErrCreator->addError(ERR_INVALID_METADATA_KERNEL, Node);
+    return;
+  }
+  Function *F = dyn_cast<Function>(FMD->getValue());
+  if (!F) {
+    ErrCreator->addError(ERR_INVALID_METADATA_KERNEL, Node);
+    return;
+  }
+  if (F->getCallingConv() != CallingConv::FLOOR_KERNEL) {
+    ErrCreator->addError(ERR_INVALID_METADATA_KERNEL, Node);
+  }
+  if (FoundMap.count(F)) {
+    // Function has two kernel metadata nodes
+    // Mark both of them as invalid metadata kernel
+    ErrCreator->addError(ERR_INVALID_METADATA_KERNEL, FoundMap[F]);
+    ErrCreator->addError(ERR_INVALID_METADATA_KERNEL, Node);
+  }
+  // Insert <F, Node> pair to the found map.
+  FoundMap[F] = Node;
+
+  // Initialize second level executors.
+  MDNodeExecutorList nel;
+  // kernel arg address space metadata verifier.
+  VerifyMetadataArgAddrSpace vmdaas(ErrCreator, F);
+  nel.push_back(&vmdaas);
+  // kernel arg type metadata verifier.
+  VerifyMetadataArgType vmdat(ErrCreator);
+  nel.push_back(&vmdat);
+  // kernel arg base type metadata verifier.
+  VerifyMetadataArgBaseType vmdabt(ErrCreator, F, Data);
+  nel.push_back(&vmdabt);
+
+  MetaDataIterator mdi(nel);
+  mdi.execute(*Node);
+
+  // Varify that metadata arg address space exists.
+  if (!vmdaas.found()) {
+    ErrCreator->addError(ERR_MISSING_METADATA_KERNEL_INFO, Node);
+  }
+
+  // Varify that metadata arg type exists.
+  if (!vmdat.found()) {
+    ErrCreator->addError(ERR_MISSING_METADATA_KERNEL_INFO, Node);
+  }
+
+  // Varify that metadata arg base type exists.
+  if (!vmdabt.found()) {
+    ErrCreator->addError(ERR_MISSING_METADATA_KERNEL_INFO, Node);
+  }
+}
+
+void VerifyMetadataKernels::execute(const llvm::Module *M) {
+  // Counting the number of kernels in the module.
+  unsigned int NumKernels = 0;
+  Module::const_iterator fi = M->begin(), fe = M->end();
+  for (; fi != fe; fi++) {
+    const Function *F = &*fi;
+    if (F->getCallingConv() == CallingConv::FLOOR_KERNEL) {
+      NumKernels++;
+    }
+  }
+
+  // Acquiring kernels node.
+  NamedMDNode *MDKernels = M->getNamedMetadata(OPENCL_KERNELS);
+  if (!MDKernels) {
+    ErrCreator->addError(ERR_MISSING_NAMED_METADATA, OPENCL_KERNELS);
+    return;
+  }
+
+  // Verify that number of function kernels mach number of metadata kernels.
+  const unsigned int NumMDKernels = MDKernels->getNumOperands();
+
+  if (NumKernels != NumMDKernels) {
+    std::stringstream Msg;
+    Msg << "inconsistency in kernels nodes. ";
+    Msg << "The module has " << NumMDKernels << " metadata nodes, but ";
+    Msg << NumKernels << " kernels";
+    ErrCreator->addError(ERR_INVALID_METADATA_KERNEL, Msg.str());
+  }
+
+  // If there are no kernels, we have no more tests to do.
+  if (!NumKernels)
+    return;
+
+  //Kernel MetaData structure:
+  // !opencl.kernels = {!0, !1, ...}
+  // !0 = {llvm::Function*, !10, !11, ...}
+  // ...
+  // !10 = {metadata !"kernel_arg_base_type", metadata !"<TY1>", ...}
+  // !11 = {metadata !"kernel_arg_type", metadata !"<TY1>", ...}
+
+  FunctionToMDNodeMap FoundMap;
+  VerifyMetadataKernel vmk(ErrCreator, Data, FoundMap);
+  for (unsigned i = 0; i < NumMDKernels; i++) {
+    MDNode *N = dyn_cast<MDNode>(MDKernels->getOperand(i));
+    if (!N) {
+      // Is this possible for LLVM valid IR?
+      ErrCreator->addError(ERR_INVALID_METADATA_KERNEL, MDKernels);
+    }
+    // Apply Metadata kernel executor.
+    vmk.execute(N);
+  }
+}
+
+void VerifyMetadataVersions::execute(const llvm::Module *M) {
+  const char *VersionName = nullptr;
+  switch (VType) {
+  case VERSION_OCL:
+    VersionName = OPENCL_OCL_VERSION;
+    break;
+  case VERSION_SPIR:
+    VersionName = OPENCL_SPIR_VERSION;
+    break;
+  default:
+    assert(false && "Unknown OpenCL version type");
+  }
+
+  // Verify version exists.
+  NamedMDNode *NMDVersion = M->getNamedMetadata(VersionName);
+  if (!NMDVersion) {
+    ErrCreator->addError(ERR_MISSING_NAMED_METADATA, VersionName);
+    return;
+  }
+
+  // version MetaData structure:
+  // !opencl.ocl.version  = {!6}
+  // !opencl.spir.version = {!7}
+  // ...
+  // !6 = metadata !{i32 1, i32 2}
+  // !7 = metadata !{i32 1, i32 2}
+
+  // Verify that there is exactly one version.
+  if (NMDVersion->getNumOperands() != 1) {
+    ErrCreator->addError(ERR_INVALID_METADATA_VERSION, NMDVersion);
+    return;
+  }
+
+  MDNode *VersionNode = NMDVersion->getOperand(0);
+
+  // Verify valid version node
+  if (VersionNode->getNumOperands() != 2) {
+    ErrCreator->addError(ERR_INVALID_METADATA_VERSION, VersionNode);
+    return;
+  }
+
+  ConstantAsMetadata *VersionMajorMD = dyn_cast<ConstantAsMetadata>(VersionNode->getOperand(0));
+  ConstantAsMetadata *VersionMinorMD = dyn_cast<ConstantAsMetadata>(VersionNode->getOperand(1));
+
+  if (!VersionMajorMD || !VersionMinorMD) {
+    ErrCreator->addError(ERR_INVALID_METADATA_VERSION, VersionNode);
+    return;
+  }
+
+  ConstantInt *VersionMajor = dyn_cast<ConstantInt>(VersionMajorMD->getValue());
+  ConstantInt *VersionMinor = dyn_cast<ConstantInt>(VersionMinorMD->getValue());
+
+  if (!VersionMajor || !VersionMinor) {
+    ErrCreator->addError(ERR_INVALID_METADATA_VERSION, VersionNode);
+    return;
+  }
+
+  unsigned Major = (unsigned)VersionMajor->getZExtValue();
+  unsigned Minor = (unsigned)VersionMinor->getZExtValue();
+
+  bool IsValidVersion = false;
+  switch (VType) {
+  case VERSION_OCL:
+    IsValidVersion = isValidOCLVersion(Major, Minor);
+    break;
+  case VERSION_SPIR:
+    IsValidVersion = isValidSPIRVersion(Major, Minor);
+    break;
+  default:
+    assert(false && "Unknown OpenCL version type");
+  }
+
+  if (!IsValidVersion) {
+    ErrCreator->addError(ERR_INVALID_METADATA_VERSION, VersionNode);
+    return;
+  }
+}
+
+void VerifyMetadataCoreFeatures::execute(const llvm::Module *M) {
+  // Verify OpenCL optional core features metadata exists.
+  NamedMDNode *NMDCoreFeatures = M->getNamedMetadata(OPENCL_CORE_FEATURES);
+  if (!NMDCoreFeatures) {
+    ErrCreator->addError(ERR_MISSING_NAMED_METADATA, OPENCL_CORE_FEATURES);
+    return;
+  }
+
+  // Optional core features MetaData structure:
+  // !opencl.used.optional.core.features  = {!8}
+  // ...
+  // !8 = metadata !{metadata !"cl_doubles", metadata !"cl_images"}
+
+  // Verify that there is exactly one entry.
+  if (NMDCoreFeatures->getNumOperands() != 1) {
+    ErrCreator->addError(ERR_INVALID_CORE_FEATURE, NMDCoreFeatures);
+    return;
+  }
+
+  MDNode *Node = NMDCoreFeatures->getOperand(0);
+
+  // Verify valid optional core feature nodes
+  for (unsigned i=0; i<Node->getNumOperands(); i++) {
+    MDString *StringValue = dyn_cast<MDString>(Node->getOperand(i));
+    if (!StringValue || !isValidNameOf(StringValue->getString(),
+                                       g_valid_core_feature,
+                                       g_valid_core_feature_len)) {
+      ErrCreator->addError(ERR_INVALID_CORE_FEATURE, Node);
+      continue;
+    }
+    if (StringValue->getString() == CORE_FEATURE_CL_DOUBLES) {
+      if (Data->HasDoubleFeature) {
+        // Core feature appears twice
+        ErrCreator->addError(ERR_INVALID_CORE_FEATURE, Node);
+        continue;
+      }
+      Data->HasDoubleFeature = true;
+    }
+    else if(StringValue->getString() == CORE_FEATURE_CL_IMAGES) {
+      if (Data->HasImageFeature) {
+        // Core feature appears twice
+        ErrCreator->addError(ERR_INVALID_CORE_FEATURE, Node);
+        continue;
+      }
+      Data->HasImageFeature = true;
+    }
+    else {
+      assert(false && "Unhandled core feature");
+    }
+  }
+}
+
+
+void VerifyMetadataKHRExtensions::execute(const llvm::Module *M) {
+  // Verify OpenCL optional KHR extensions metadata exists.
+  NamedMDNode *NMDExts = M->getNamedMetadata(OPENCL_KHR_EXTENSIONS);
+  if (!NMDExts) {
+    ErrCreator->addError(ERR_MISSING_NAMED_METADATA, OPENCL_KHR_EXTENSIONS);
+    return;
+  }
+
+  // KHR extensions MetaData structure:
+  // !opencl.used.extensions = !{!6}
+  // ...
+  // !6 = metadata !{metadata !"cl_khr_fp16", metadata !"cl_khr_int64_base_atomics"}
+
+  // Verify that there is exactly one entry.
+  if (NMDExts->getNumOperands() != 1) {
+    ErrCreator->addError(ERR_INVALID_CORE_FEATURE, NMDExts);
+    return;
+  }
+
+  MDNode *Node = NMDExts->getOperand(0);
+
+  // Verify valid optional core feature nodes
+  for (unsigned i=0; i<Node->getNumOperands(); i++) {
+    MDString *StringValue = dyn_cast<MDString>(Node->getOperand(i));
+    if (!StringValue || !isValidNameOf(StringValue->getString(),
+                                       g_valid_khr_ext,
+                                       g_valid_khr_ext_len)) {
+      ErrCreator->addError(ERR_INVALID_KHR_EXT, Node);
+      continue;
+    }
+    if (StringValue->getString() == EXTENSION_CL_KHR_FP16) {
+      if (Data->HASFp16Extension) {
+        // KHR extension appears twice
+        ErrCreator->addError(ERR_INVALID_KHR_EXT, Node);
+        continue;
+      }
+      Data->HasDoubleFeature = true;
+    }
+    else {
+      // TODO enable the following assertion once all extensions are handled.
+      //assert(false && "Unhandled KHR extension");
+    }
+  }
+}
+
+void VerifyMetadataCompilerOptions::execute(const llvm::Module *M) {
+  // Verify OpenCL compiler options metadata exists.
+  NamedMDNode *NMDOptions = M->getNamedMetadata(OPENCL_COMPILER_OPTIONS);
+  if (!NMDOptions) {
+    ErrCreator->addError(ERR_MISSING_NAMED_METADATA, OPENCL_COMPILER_OPTIONS);
+    return;
+  }
+
+  // Compiler options MetaData structure:
+  // !opencl.compiler.options = !{!9}
+  // ...
+  // !9 = metadata !{metadata !"-cl-mad-enable", metadata !"-cl-denorms-are-zero"}
+
+  // Verify that there is exactly one entry.
+  if (NMDOptions->getNumOperands() != 1) {
+    ErrCreator->addError(ERR_INVALID_COMPILER_OPTION, NMDOptions);
+    return;
+  }
+
+  MDNode *Node = NMDOptions->getOperand(0);
+
+  // Verify valid optional core feature nodes
+  for (unsigned i=0; i<Node->getNumOperands(); i++) {
+    MDString *StringValue = dyn_cast<MDString>(Node->getOperand(i));
+    if (!StringValue || !isValidNameOf(StringValue->getString(),
+                                       g_valid_compiler_options,
+                                       g_valid_compiler_options_len)) {
+      ErrCreator->addError(ERR_INVALID_COMPILER_OPTION, Node);
+      continue;
+    }
+  }
+}
+
+} // End SPIR namespace
+
diff --git a/lib/SPIRVerifier/SpirTables.cpp b/lib/SPIRVerifier/SpirTables.cpp
new file mode 100644
index 0000000..1df07e7
--- /dev/null
+++ b/lib/SPIRVerifier/SpirTables.cpp
@@ -0,0 +1,567 @@
+//===-------------------------- SpirTables.cpp ---------------------------===//
+//
+//                              SPIR Tools
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===---------------------------------------------------------------------===//
+
+#include "llvm/SPIRVerifier/SpirTables.h"
+#include <string>
+#include <sstream>
+
+namespace SPIR {
+
+//
+// Constant definitions.
+//
+
+#define DCL_ARRAY_LENGTH(arr) \
+  const unsigned arr##_len = (sizeof(arr)/sizeof(char*))
+
+#define STR_IND1 std::string("  ")
+#define STR_IND2 std::string("    ")
+#define STR_SPIR std::string("SPIR")
+#define STR_NOTE std::string("Note: ")
+
+
+const char *CORE_FEATURE_CL_DOUBLES = "cl_doubles";
+const char *CORE_FEATURE_CL_IMAGES = "cl_images";
+const char *g_valid_core_feature[] = {
+  CORE_FEATURE_CL_DOUBLES,
+  CORE_FEATURE_CL_IMAGES
+};
+DCL_ARRAY_LENGTH(g_valid_core_feature);
+const char *g_valid_core_feature_prefix = "cl_";
+
+
+const char *EXTENSION_CL_KHR_FP16 = "cl_khr_fp16";
+const char *g_valid_khr_ext[] = {
+  "cl_khr_int64_base_atomics",
+  "cl_khr_int64_extended_atomics",
+  EXTENSION_CL_KHR_FP16,
+  "cl_khr_fp64",
+  "cl_khr_gl_sharing",
+  "cl_khr_gl_event",
+  "cl_khr_d3d10_sharing",
+  "cl_khr_media_sharing",
+  "cl_khr_d3d11_sharing",
+  "cl_khr_global_int32_base_atomics",
+  "cl_khr_global_int32_extended_atomics",
+  "cl_khr_local_int32_base_atomics",
+  "cl_khr_local_int32_extended_atomics",
+  "cl_khr_byte_addressable_store",
+  "cl_khr_3d_image_writes",
+  "cl_khr_gl_msaa_sharing",
+  "cl_khr_depth_images",
+  "cl_khr_gl_depth_images",
+  "cl_khr_mipmap_image",
+  "cl_khr_mipmap_image_writes",
+};
+DCL_ARRAY_LENGTH(g_valid_khr_ext);
+const char *g_valid_khr_ext_prefix = "cl_khr_";
+
+
+const char *g_valid_compiler_options[] = {
+  "-cl-single-precision-constant",
+  "-cl-denorms-are-zero",
+  "-cl-fp32-correctly-rounded-divide-sqrt",
+  "-cl-opt-disable",
+  "-cl-mad-enable",
+  "-cl-no-signed-zeros",
+  "-cl-unsafe-math-optimizations",
+  "-cl-finite-math-only",
+  "-cl-fast-relaxed-math",
+  "-w",
+  "-Werror",
+  "-cl-kernel-arg-info"
+};
+DCL_ARRAY_LENGTH(g_valid_compiler_options);
+
+///
+/// OpenCL C Type tables
+///
+const char *g_valid_ocl_primitives[] = {
+  "bool"  ,
+  "char"  , "uchar" , "unsigned char" ,
+  "short" , "ushort", "unsigned short",
+  "int"   , "uint"  , "unsigned int"  ,
+  "long"  , "ulong" , "unsigned long" ,
+  "half"  ,
+  "float" ,
+  "double",
+  "void"
+};
+DCL_ARRAY_LENGTH(g_valid_ocl_primitives);
+
+const char *g_valid_ocl_vector_element_types[] = {
+  "char"  , "uchar" , "unsigned char" ,
+  "short" , "ushort", "unsigned short",
+  "int"   , "uint"  , "unsigned int"  ,
+  "long"  , "ulong" , "unsigned long" ,
+  "half"  ,
+  "float" ,
+  "double"
+};
+DCL_ARRAY_LENGTH(g_valid_ocl_vector_element_types);
+
+const char *g_valid_ocl_opaque_types[] = {
+  "image1d_t",
+  "image1d_array_t",
+  "image1d_buffer_t",
+  "image2d_t",
+  "image2d_depth_t",
+  "image2d_msaa_t",
+  "image2d_msaa_depth_t",
+  "image2d_array_t",
+  "image2d_array_depth_t",
+  "image2d_array_msaa_t",
+  "image2d_array_msaa_depth_t",
+  "image3d_t",
+  "event_t",
+  "sampler_t",
+  // TODO: The following are not part of 'kernel_arg_base_type' metadata -
+  // according to SPIR generator. Should they still be allowed (ignored)?
+  "size_t",
+  "ptrdiff_t",
+  "uintptr_t",
+  "intptr_t"
+};
+DCL_ARRAY_LENGTH(g_valid_ocl_opaque_types);
+
+const char *g_opencl_opaque_sufix = "_t";
+
+const char *g_ignored_ocl_types[] = {
+  "struct ", "union ", "enum "
+};
+DCL_ARRAY_LENGTH(g_ignored_ocl_types);
+
+///
+/// OpenCL C Type tables
+///
+const char *g_valid_llvm_primitives[] = {
+  "i1", "i8", "i16", "i32", "i64", "half", "float", "double", "void"
+};
+DCL_ARRAY_LENGTH(g_valid_llvm_primitives);
+
+const char *g_valid_llvm_vector_element_types[] = {
+  "i8", "i16", "i32", "i64", "half", "float", "double"
+};
+DCL_ARRAY_LENGTH(g_valid_llvm_vector_element_types);
+
+const char *g_valid_llvm_image_types[] = {
+  "opencl.image1d_t",
+  "opencl.image1d_array_t",
+  "opencl.image1d_buffer_t",
+  "opencl.image2d_t",
+  "opencl.image2d_depth_t",
+  "opencl.image2d_msaa_t",
+  "opencl.image2d_msaa_depth_t",
+  "opencl.image2d_array_t",
+  "opencl.image2d_array_msaa_t",
+  "opencl.image2d_array_msaa_depth_t",
+  "opencl.image2d_array_depth_t",
+  "opencl.image3d_t",
+};
+DCL_ARRAY_LENGTH(g_valid_llvm_image_types);
+
+const char *g_valid_llvm_opaque_types[] = {
+  "opencl.event_t"
+};
+DCL_ARRAY_LENGTH(g_valid_llvm_opaque_types);
+
+const char *g_llvm_opaque_prefix = "opencl.";
+
+const char *g_valid_vector_type_lengths[] = {
+  "2" , "3" , "4" , "8" , "16"
+};
+DCL_ARRAY_LENGTH(g_valid_vector_type_lengths);
+
+
+const char *g_valid_instrinsic[] = {
+  "llvm.memcpy."
+};
+DCL_ARRAY_LENGTH(g_valid_instrinsic);
+
+const char *g_ignored_instrinsic[] = {
+  "llvm.dbg."
+};
+DCL_ARRAY_LENGTH(g_ignored_instrinsic);
+
+
+const char *g_valid_sync_bi[] = {
+  "_Z7barrier"
+};
+DCL_ARRAY_LENGTH(g_valid_sync_bi);
+
+const char *g_valid_address_space[] = {
+  "private",
+  "global",
+  "constant",
+  "local"
+};
+DCL_ARRAY_LENGTH(g_valid_address_space);
+
+const char *g_valid_calling_convention[] = {
+  "SPIR_FUNC",
+  "SPIR_KERNEL"
+};
+DCL_ARRAY_LENGTH(g_valid_calling_convention);
+
+const char *g_valid_linkage_type[] = {
+  "private",
+  "internal",
+  "available_externally",
+  "external"
+};
+DCL_ARRAY_LENGTH(g_valid_linkage_type);
+
+
+const char *OPENCL_KERNELS = "opencl.kernels";
+const char *OPENCL_SPIR_VERSION = "opencl.spir.version";
+const char *OPENCL_OCL_VERSION = "opencl.ocl.version";
+const char *OPENCL_KHR_EXTENSIONS = "opencl.used.extensions";
+const char *OPENCL_CORE_FEATURES = "opencl.used.optional.core.features";
+const char *OPENCL_COMPILER_OPTIONS = "opencl.compiler.options";
+const char *g_valid_named_metadata[] = {
+  "opencl.kernels",
+  "opencl.enable.FP_CONTRACT",
+  OPENCL_SPIR_VERSION,
+  OPENCL_OCL_VERSION,
+  OPENCL_KHR_EXTENSIONS,
+  OPENCL_CORE_FEATURES,
+  OPENCL_COMPILER_OPTIONS
+};
+DCL_ARRAY_LENGTH(g_valid_named_metadata);
+
+const char *KERNEL_ARG_ADDR_SPACE = "kernel_arg_addr_space";
+const char *KERNEL_ARG_TY = "kernel_arg_type";
+const char *KERNEL_ARG_BASE_TY = "kernel_arg_base_type";
+const char *g_valid_kernel_arg_info[] = {
+  KERNEL_ARG_ADDR_SPACE,
+  "kernel_arg_access_qual",
+  KERNEL_ARG_TY,
+  KERNEL_ARG_BASE_TY,
+  "kernel_arg_type_qual",
+  "kernel_arg_name",
+};
+DCL_ARRAY_LENGTH(g_valid_kernel_arg_info);
+
+const char *g_valid_version_names[] = {
+  "opencl.ocl.version",
+  "opencl.spir.version"
+};
+DCL_ARRAY_LENGTH(g_valid_version_names);
+
+const char *g_valid_spir_versions[][2] = {
+  {"1", "2"}
+};
+DCL_ARRAY_LENGTH(g_valid_spir_versions)/2;
+
+const char *g_valid_ocl_versions[][2] = {
+  {"1", "2"}
+};
+DCL_ARRAY_LENGTH(g_valid_ocl_versions)/2;
+
+
+///
+/// get error info message functions
+///
+
+std::string getValidOpenCLTypeMsg() {
+  std::string Msg;
+  Msg += "Valid OpenCL C Types in " + STR_SPIR + "\n";
+  Msg += STR_IND1 + "Primitive types: ";
+  for (unsigned i=0; i<g_valid_ocl_primitives_len; i++) {
+    Msg += ((i==0) ? "" : ", ");
+    Msg += g_valid_ocl_primitives[i];
+  }
+  Msg += "\n\n";
+  Msg += STR_IND1 + "Opaque types:";
+  for (unsigned i=0; i<g_valid_ocl_opaque_types_len; i++) {
+    Msg += "\n" + STR_IND2;
+    Msg += g_valid_ocl_opaque_types[i];
+  }
+  Msg += "\n\n";
+  Msg += STR_IND1 + "Vector element types: ";
+  for (unsigned i=0; i<g_valid_ocl_vector_element_types_len; i++) {
+    Msg += ((i==0) ? "" : ", ");
+    Msg += g_valid_ocl_vector_element_types[i];
+  }
+  Msg += "\n\n";
+  Msg += STR_IND1 + "Vector type lengthes: ";
+  for (unsigned i=0; i<g_valid_vector_type_lengths_len; i++) {
+    Msg += ((i==0) ? "" : ", ");
+    Msg += g_valid_vector_type_lengths[i];
+  }
+  Msg += "\n";
+  return Msg;
+}
+
+std::string getValidLLVMTypeMsg() {
+  std::string Msg;
+  Msg += "Valid LLVM Types in " + STR_SPIR + "\n";
+  Msg += STR_IND1 + "Primitive types: ";
+  for (unsigned i=0; i<g_valid_llvm_primitives_len; i++) {
+    Msg += ((i==0) ? "" : ", ");
+    Msg += g_valid_llvm_primitives[i];
+  }
+  Msg += "\n\n";
+  Msg += STR_IND1 + "Image opaque types:";
+  for (unsigned i=0; i<g_valid_llvm_image_types_len; i++) {
+    Msg += "\n" + STR_IND2;
+    Msg += g_valid_llvm_image_types[i];
+  }
+  Msg += "\n\n";
+  Msg += STR_IND1 + "Other opaque types:";
+  for (unsigned i=0; i<g_valid_llvm_opaque_types_len; i++) {
+    Msg += "\n" + STR_IND2;
+    Msg += g_valid_llvm_opaque_types[i];
+  }
+  Msg += "\n\n";
+  Msg += STR_IND1 + "Vector element types: ";
+  for (unsigned i=0; i<g_valid_llvm_vector_element_types_len; i++) {
+    Msg += ((i==0) ? "" : ", ");
+    Msg += g_valid_llvm_vector_element_types[i];
+  }
+  Msg += "\n\n";
+  Msg += STR_IND1 + "Vector type lengthes: ";
+  for (unsigned i=0; i<g_valid_vector_type_lengths_len; i++) {
+    Msg += ((i==0) ? "" : ", ");
+    Msg += g_valid_vector_type_lengths[i];
+  }
+  Msg += "\n";
+  Msg += "\n" + STR_IND1 + STR_NOTE +
+    "In addition, arrays and structures of the above types are allowed.\n";
+  return Msg;
+}
+
+std::string getValidKernelReturnTypeMsg() {
+  return "SPIR kernel has to return void";
+}
+
+std::string getValidIntrinsicMsg() {
+  std::string Msg;
+  Msg += "Valid intrinsic in " + STR_SPIR + " are:\n";
+  for (unsigned i=0; i<g_valid_instrinsic_len; i++) {
+    std::stringstream SS;
+    SS << STR_IND1 << g_valid_instrinsic[i] << "\n";
+    Msg += SS.str();
+  }
+  return Msg;
+}
+
+std::string getValidAddressSpaceMsg() {
+  std::string Msg;
+  Msg += "Valid address space in " + STR_SPIR + " are:\n";
+  for (unsigned i=0; i<g_valid_address_space_len; i++) {
+    std::stringstream SS;
+    SS << STR_IND1 << i << " - " << g_valid_address_space[i] << "\n";
+    Msg += SS.str();
+  }
+  Msg += "\n" + STR_IND1 + STR_NOTE +
+    "Casts between address spaces is disallowed in " + STR_SPIR + "\n";
+
+  return Msg;
+}
+
+std::string getValidKernelArgAddressSpaceMsg() {
+  std::string Msg;
+  Msg += "Valid address spaces for kernel arguments in " + STR_SPIR + " are:\n";
+  std::stringstream SS;
+  SS << STR_IND1 << GLOBAL_ADDR_SPACE << " - " << g_valid_address_space[GLOBAL_ADDR_SPACE] << "\n";
+  SS << STR_IND1 << CONSTANT_ADDR_SPACE << " - " << g_valid_address_space[CONSTANT_ADDR_SPACE] << "\n";
+  SS << STR_IND1 << LOCAL_ADDR_SPACE << " - " << g_valid_address_space[LOCAL_ADDR_SPACE] << "\n";
+  Msg += SS.str();
+  return Msg;
+}
+
+extern std::string getValidGlobalAS3VariableMsg() {
+  std::string Msg = "Function-scope variables in the local address space\n";
+  Msg += STR_IND1 + "are represented by module-scope variables with addrspace(3).\n";
+  Msg += STR_IND1 + "The name of the variables has to have the following format:\n";
+  Msg += STR_IND1 + "@<function_name>.<variable_name>\n";
+  return Msg;
+}
+
+extern std::string getValidGlobalVarAddressSpacesMsg() {
+  std::string Msg;
+  Msg += "Valid address spaces for module-scope variables " + STR_SPIR + " are:\n";
+  std::stringstream SS;
+  SS << STR_IND1 << CONSTANT_ADDR_SPACE << " - " << g_valid_address_space[CONSTANT_ADDR_SPACE] << "\n";
+  SS << STR_IND1 << LOCAL_ADDR_SPACE << " - " << g_valid_address_space[LOCAL_ADDR_SPACE] << "\n";
+  Msg += SS.str();
+  return Msg;
+}
+
+std::string getValidCallingConventionMsg() {
+  std::string Msg;
+  Msg += "Valid user defined functions calling convention in ";
+  Msg += STR_SPIR + " are:\n";
+  for (unsigned i=0; i<g_valid_calling_convention_len; i++) {
+    Msg += STR_IND1 + g_valid_calling_convention[i] + "\n";
+  }
+  return Msg;
+}
+
+std::string getValidLinkageTypeMsg() {
+  std::string Msg;
+  Msg += "Valid linkage types in " + STR_SPIR + " are:\n";
+  for (unsigned i = 0; i < g_valid_linkage_type_len; i++) {
+    Msg += STR_IND1 + g_valid_linkage_type[i] + "\n";
+  }
+  return Msg;
+}
+
+std::string getValidIndirectCallMsg() {
+  std::string Msg;
+  Msg += "Indirect Calls are not allowed in " + STR_SPIR +"\n";
+  return Msg;
+}
+
+std::string getValidKernelArgInfoMsg() {
+  std::string Msg;
+  Msg += "Valid kernel arg info in " + STR_SPIR + " are:\n";
+  for (unsigned i=0; i<g_valid_kernel_arg_info_len; i++) {
+    Msg += STR_IND1 + g_valid_kernel_arg_info[i] + "\n";
+  }
+  Msg += "\n" + STR_IND1 + STR_NOTE +
+    "All above are mandatory for each metadata kernel,"
+    "except 'kernel_arg_name' which is optional.\n";
+  return Msg;
+}
+
+std::string getValidVersionMsg() {
+  std::string Msg;
+  Msg += "Module in " + STR_SPIR + " must have these metadata versions:\n";
+  for (unsigned i=0; i<g_valid_version_names_len; i++) {
+    Msg += STR_IND1 + g_valid_version_names[i] + "\n";
+  }
+  Msg += "\n";
+  Msg += STR_IND1 + "Valid versions for '" + OPENCL_OCL_VERSION + "'\n";
+  for (unsigned i=0; i<g_valid_ocl_versions_len; i++) {
+    const char *Major = g_valid_ocl_versions[i][0];
+    const char *Minor = g_valid_ocl_versions[i][1];
+    Msg += STR_IND2 + "{" + Major + "," + Minor + "}" + "\n";
+  }
+  Msg += "\n";
+  Msg += STR_IND1 + "Valid versions for '" + OPENCL_SPIR_VERSION + "'\n";
+  for (unsigned i=0; i<g_valid_spir_versions_len; i++) {
+    const char *Major = g_valid_spir_versions[i][0];
+    const char *Minor = g_valid_spir_versions[i][1];
+    Msg += STR_IND2 + "{" + Major + "," + Minor + "}" + "\n";
+  }
+
+  return Msg;
+}
+
+std::string getValidMemFenceMsg() {
+  std::string Msg;
+  Msg += "Synchronization functions accept 'cl_mem_fence_flags' enumeration "
+         "as an argument. This argument is i32 bitmap value.\n";
+  Msg += STR_IND1 + "Valid values for 'cl_mem_fence_flags' are:\n";
+  Msg += STR_IND2 + "1 - CLK_LOCAL_MEM_FENCE\n";
+  Msg += STR_IND2 + "2 - CLK_GLOBAL_MEM_FENCE\n";
+  Msg += STR_IND2 + "3 - CLK_LOCAL_MEM_FENCE | CLK_GLOBAL_MEM_FENCE\n";
+  return Msg;
+}
+
+std::string getMapOpenCLToLLVMMsg() {
+  std::string Msg;
+  Msg += "OpenCL C mapping to SPIR\n";
+  Msg += STR_IND1 + "Built-in Scalar Data Types:\n";
+  Msg += STR_IND2 + "bool                          -> i1\n";
+  Msg += STR_IND2 + "char, unsigned char, uchar    -> i8\n";
+  Msg += STR_IND2 + "short, unsigned short, ushort -> i16\n";
+  Msg += STR_IND2 + "int, unsigned int, uint       -> i32\n";
+  Msg += STR_IND2 + "long, unsigned long, ulong    -> i64\n";
+  Msg += STR_IND2 + "float                         -> float\n";
+  Msg += STR_IND2 + "double                        -> double\n";
+  Msg += STR_IND2 + "half                          -> half\n";
+  Msg += STR_IND2 + "void                          -> void\n";
+  Msg += "\n";
+  Msg += STR_IND1 + "Built-in Vector Data Types (n = 2, 3, 4, 8, and 16):\n";
+  Msg += STR_IND2 + "charn    -> < n x i8 >\n";
+  Msg += STR_IND2 + "ucharn   -> < n x i8 >\n";
+  Msg += STR_IND2 + "shortn   -> < n x i16 >\n";
+  Msg += STR_IND2 + "ushortn  -> < n x i16 >\n";
+  Msg += STR_IND2 + "intn     -> < n x i32 >\n";
+  Msg += STR_IND2 + "uintn    -> < n x i32 >\n";
+  Msg += STR_IND2 + "longn    -> < n x i64 >\n";
+  Msg += STR_IND2 + "ulongn   -> < n x i64 >\n";
+  Msg += STR_IND2 + "halfn    -> < n x half >\n";
+  Msg += STR_IND2 + "floatn   -> < n x float >\n";
+  Msg += STR_IND2 + "doublen  -> < n x double >\n";
+  Msg += "\n";
+  Msg += STR_IND1 + "Other Built-in Data Types:\n";
+  Msg += STR_IND2 + "image1d_t                  -> opencl.image1d_t\n";
+  Msg += STR_IND2 + "image1d_array_t            -> opencl.image1d_array_t\n";
+  Msg += STR_IND2 + "image1d_buffer_t           -> opencl.image1d_buffer_t\n";
+  Msg += STR_IND2 + "image2d_t                  -> opencl.image2d_t\n";
+  Msg += STR_IND2 + "image2d_depth_t            -> opencl.image2d_depth_t\n";
+  Msg += STR_IND2 + "image2d_msaa_t             -> opencl.image2d_msaa_t\n";
+  Msg += STR_IND2 + "image2d_msaa_depth_t       -> opencl.image2d_msaa_depth_t\n";
+  Msg += STR_IND2 + "image2d_array_t            -> opencl.image2d_array_t\n";
+  Msg += STR_IND2 + "image2d_array_depth_t      -> opencl.image2d_array_depth_t\n";
+  Msg += STR_IND2 + "image2d_array_msaa_t       -> opencl.image2d_array_msaa_t\n";
+  Msg += STR_IND2 + "image2d_array_msaa_depth_t -> opencl.image2d_array_msaa_depth_t\n";
+  Msg += STR_IND2 + "image3d_t                  -> opencl.image3d_t\n";
+  Msg += STR_IND2 + "event_t                    -> opencl.event_t\n";
+  Msg += STR_IND2 + "sampler_t                  -> i32\n";
+  Msg += STR_IND2 + "size_t                     -> i32 or i64\n";
+  Msg += STR_IND2 + "ptrdiff_t                  -> i32 or i64\n";
+  Msg += STR_IND2 + "uintptr_t                  -> i32 or i64\n";
+  Msg += STR_IND2 + "intptr_t                   -> i32 or i64\n";
+  return Msg;
+}
+
+std::string getValidNamedMetadataMsg() {
+  std::string Msg;
+  Msg += "Valid named metadata in " + STR_SPIR + " are:\n";
+  for (unsigned i=0; i<g_valid_named_metadata_len; i++) {
+    Msg += STR_IND1 + g_valid_named_metadata[i] + "\n";
+  }
+  Msg += "\n" + STR_IND1 + STR_NOTE +
+    "Except 'opencl.enable.FP_CONTRACT' all the others are mandatory.\n";
+  return Msg;
+}
+
+std::string getValidCoreFeaturesMsg() {
+  std::string Msg;
+  Msg += "Valid optional core features:\n";
+  for (unsigned i=0; i<g_valid_core_feature_len; i++) {
+    std::string Str = g_valid_core_feature[i];
+    Str = Str.substr(std::string(g_valid_core_feature_prefix).size());
+    Msg += STR_IND2 + g_valid_core_feature[i];
+    Msg += " - must be declared to indicate that " + Str + " types are used";
+    Msg += "\n";
+  }
+  return Msg;
+}
+
+std::string getValidKHRExtensionsMsg() {
+  std::string Msg;
+  Msg += "Valid KHR extensions:\n";
+  for (unsigned i=0; i<g_valid_khr_ext_len; i++) {
+    std::string Str = g_valid_khr_ext[i];
+    Str = Str.substr(std::string(g_valid_khr_ext_prefix).size());
+    Msg += STR_IND2 + g_valid_khr_ext[i];
+    //Msg += " - must be declared to indicate that " + Str + " extension is used";
+    Msg += "\n";
+  }
+  return Msg;
+}
+
+std::string getValidCompilerOptionsMsg() {
+  std::string Msg;
+  Msg += "Valid compiler options:\n";
+  for (unsigned i=0; i<g_valid_compiler_options_len; i++) {
+    Msg += STR_IND2 + g_valid_compiler_options[i];
+    Msg += "\n";
+  }
+  return Msg;
+}
+
+} // End SPIR namespace
+
diff --git a/lib/SPIRVerifier/SpirValidation.cpp b/lib/SPIRVerifier/SpirValidation.cpp
new file mode 100644
index 0000000..38053e5
--- /dev/null
+++ b/lib/SPIRVerifier/SpirValidation.cpp
@@ -0,0 +1,125 @@
+//===------------------------ SpirValidation.cpp -------------------------===//
+//
+//                              SPIR Tools
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===---------------------------------------------------------------------===//
+
+#include "llvm/SPIRVerifier/SpirValidation.h"
+#include "llvm/SPIRVerifier/SpirErrors.h"
+#include "llvm/SPIRVerifier/SpirIterators.h"
+#include "llvm/IR/Module.h"
+#include "llvm/IR/Instructions.h"
+#include "llvm/IR/DataLayout.h"
+#include "llvm/Support/raw_ostream.h"
+
+using namespace llvm;
+
+namespace SPIR {
+
+//
+// SpirValidation class public methods.
+//
+
+char SpirValidation::ID = 0;
+
+SpirValidation::SpirValidation() : ModulePass(ID) {
+}
+
+SpirValidation::~SpirValidation() {
+}
+
+const char* SpirValidation::getPassName() const {
+  return "Spir validation";
+}
+
+bool SpirValidation::runOnModule(Module& M) {
+  // Holder for initialized data in the module
+  DataHolder Data;
+
+  // Initialize instruction verifiers.
+  InstructionExecutorList iel;
+  // Bitcast instruction verifier.
+  VerifyBitcast vb(&ErrHolder);
+  iel.push_back(&vb);
+  // Call instruction verifier.
+  VerifyCall vc(&ErrHolder);
+  iel.push_back(&vc);
+  // Instruction type verifier.
+  VerifyInstructionType vit(&ErrHolder, &Data);
+  iel.push_back(&vit);
+
+  // Initialize function verifiers.
+  FunctionExecutorList fel;
+  // Function prototype verifier.
+  VerifyFunctionPrototype vfp(&ErrHolder, &Data);
+  fel.push_back(&vfp);
+  // Kernel prototype verifier
+  VerifyKernelPrototype vkp(&ErrHolder, &Data);
+  fel.push_back(&vkp);
+
+  // Initialize global variable verifiers
+  GlobalVariableExecutorList gel;
+  // Global variable verifier
+  VerifyGlobalVariable vgv(&ErrHolder, &Data);
+  gel.push_back(&vgv);
+
+  // Initialize module verifiers.
+  ModuleExecutorList mel;
+  // Module metadata kernels verifier.
+  VerifyMetadataKernels vkmd(&ErrHolder, &Data);
+  mel.push_back(&vkmd);
+  // Module OCL version verifier.
+  VerifyMetadataVersions voclv(
+    &ErrHolder, VerifyMetadataVersions::VERSION_OCL);
+  mel.push_back(&voclv);
+  // Module SPIR version verifier.
+  VerifyMetadataVersions vspirv(
+    &ErrHolder, VerifyMetadataVersions::VERSION_SPIR);
+  mel.push_back(&vspirv);
+  // Module metadata optional core features verifier.
+  VerifyMetadataCoreFeatures vmdcf(&ErrHolder, &Data);
+  mel.push_back(&vmdcf);
+  // Module metadata KHR extensions verifier.
+  VerifyMetadataKHRExtensions vmdext(&ErrHolder, &Data);
+  mel.push_back(&vmdext);
+  // Module metadata compiler options verifier.
+  VerifyMetadataCompilerOptions vmdco(&ErrHolder, &Data);
+  mel.push_back(&vmdco);
+
+  // Initialize basic block iterator.
+  BasicBlockIterator BBI(iel);
+
+  // Initialize function iterator.
+  FunctionIterator FI(fel, &BBI);
+
+  // Initialize global variable iterator.
+  GlobalVariableIterator GI(gel);
+
+  // Initialize module iterator.
+  ModuleIterator MI(mel, &FI, &GI);
+
+  // Run validation.
+  MI.execute(M);
+
+  // always print any errors that occured
+  const SPIR::ErrorPrinter *EP = getErrorPrinter();
+  if (EP->hasErrors()) {
+    errs() << "According to this SPIR Verifier, this is an invalid SPIR module.\n";
+    errs() << "The module contains the following errors:\n\n";
+    EP->print(errs(), false);
+  }
+
+  return false;
+}
+
+
+} // End SPIR namespace
+
+namespace llvm {
+  ModulePass *createSpirValidationPass() {
+    return new SPIR::SpirValidation();
+  }
+}
diff --git a/lib/Support/Triple.cpp b/lib/Support/Triple.cpp
index 2bac2a3..9d66369 100644
--- a/lib/Support/Triple.cpp
+++ b/lib/Support/Triple.cpp
@@ -59,6 +59,7 @@ const char *Triple::getArchTypeName(ArchType Kind) {
   case hsail64:        return "hsail64";
   case spir:           return "spir";
   case spir64:         return "spir64";
+  case air64:          return "air64";
   case kalimba:        return "kalimba";
   case lanai:          return "lanai";
   case shave:          return "shave";
@@ -129,6 +130,7 @@ const char *Triple::getArchTypePrefix(ArchType Kind) {
 
   case spir:
   case spir64:      return "spir";
+  case air64:       return "air64";
   case kalimba:     return "kalimba";
   case lanai:       return "lanai";
   case shave:       return "shave";
@@ -216,6 +218,7 @@ const char *Triple::getEnvironmentTypeName(EnvironmentType Kind) {
   case Itanium: return "itanium";
   case Cygnus: return "cygnus";
   case AMDOpenCL: return "amdopencl";
+  case Vulkan: return "vulkan";
   case CoreCLR: return "coreclr";
   }
 
@@ -279,6 +282,7 @@ Triple::ArchType Triple::getArchTypeForLLVMName(StringRef Name) {
     .Case("hsail64", hsail64)
     .Case("spir", spir)
     .Case("spir64", spir64)
+    .Case("air64", air64)
     .Case("kalimba", kalimba)
     .Case("lanai", lanai)
     .Case("shave", shave)
@@ -390,6 +394,7 @@ static Triple::ArchType parseArch(StringRef ArchName) {
     .Case("hsail64", Triple::hsail64)
     .Case("spir", Triple::spir)
     .Case("spir64", Triple::spir64)
+    .Case("air64", Triple::air64)
     .StartsWith("kalimba", Triple::kalimba)
     .Case("lanai", Triple::lanai)
     .Case("shave", Triple::shave)
@@ -483,6 +488,7 @@ static Triple::EnvironmentType parseEnvironment(StringRef EnvironmentName) {
     .StartsWith("itanium", Triple::Itanium)
     .StartsWith("cygnus", Triple::Cygnus)
     .StartsWith("amdopencl", Triple::AMDOpenCL)
+    .StartsWith("vulkan", Triple::Vulkan)
     .StartsWith("coreclr", Triple::CoreCLR)
     .Default(Triple::UnknownEnvironment);
 }
@@ -611,6 +617,7 @@ static Triple::ObjectFormatType getDefaultFormat(const Triple &T) {
   case Triple::sparcv9:
   case Triple::spir:
   case Triple::spir64:
+  case Triple::air64:
   case Triple::systemz:
   case Triple::tce:
   case Triple::thumbeb:
@@ -1166,6 +1173,7 @@ static unsigned getArchPointerBitWidth(llvm::Triple::ArchType Arch) {
   case llvm::Triple::amdil64:
   case llvm::Triple::hsail64:
   case llvm::Triple::spir64:
+  case llvm::Triple::air64:
   case llvm::Triple::wasm64:
   case llvm::Triple::renderscript64:
     return 64;
@@ -1196,6 +1204,7 @@ Triple Triple::get32BitArchVariant() const {
   case Triple::msp430:
   case Triple::systemz:
   case Triple::ppc64le:
+  case Triple::air64:
     T.setArch(UnknownArch);
     break;
 
@@ -1270,6 +1279,7 @@ Triple Triple::get64BitArchVariant() const {
   case Triple::amdgcn:
   case Triple::hsail64:
   case Triple::spir64:
+  case Triple::air64:
   case Triple::mips64:
   case Triple::mips64el:
   case Triple::nvptx64:
@@ -1327,6 +1337,7 @@ Triple Triple::getBigEndianArchVariant() const {
   case Triple::shave:
   case Triple::spir64:
   case Triple::spir:
+  case Triple::air64:
   case Triple::wasm32:
   case Triple::wasm64:
   case Triple::x86:
@@ -1412,6 +1423,7 @@ bool Triple::isLittleEndian() const {
   case Triple::sparcel:
   case Triple::spir64:
   case Triple::spir:
+  case Triple::air64:
   case Triple::thumb:
   case Triple::wasm32:
   case Triple::wasm64:
diff --git a/lib/Target/AMDGPU/AMDGPUMachineFunction.cpp b/lib/Target/AMDGPU/AMDGPUMachineFunction.cpp
index 40c3327..566dd96 100644
--- a/lib/Target/AMDGPU/AMDGPUMachineFunction.cpp
+++ b/lib/Target/AMDGPU/AMDGPUMachineFunction.cpp
@@ -20,7 +20,7 @@ AMDGPUMachineFunction::AMDGPUMachineFunction(const MachineFunction &MF) :
   LDSSize(0),
   ABIArgOffset(0),
   IsKernel(MF.getFunction()->getCallingConv() == CallingConv::AMDGPU_KERNEL ||
-           MF.getFunction()->getCallingConv() == CallingConv::SPIR_KERNEL) {
+           MF.getFunction()->getCallingConv() == CallingConv::FLOOR_KERNEL) {
   // FIXME: Should initialize KernArgSize based on ExplicitKernelArgOffset,
   // except reserved size is not correctly aligned.
 }
diff --git a/lib/Target/NVPTX/NVPTX.td b/lib/Target/NVPTX/NVPTX.td
index 032991a..933c328 100644
--- a/lib/Target/NVPTX/NVPTX.td
+++ b/lib/Target/NVPTX/NVPTX.td
@@ -26,10 +26,12 @@ include "NVPTXInstrInfo.td"
 //===----------------------------------------------------------------------===//
 
 // SM Versions
+// Fermi
 def SM20 : SubtargetFeature<"sm_20", "SmVersion", "20",
                             "Target SM 2.0">;
 def SM21 : SubtargetFeature<"sm_21", "SmVersion", "21",
                             "Target SM 2.1">;
+// Kepler
 def SM30 : SubtargetFeature<"sm_30", "SmVersion", "30",
                             "Target SM 3.0">;
 def SM32 : SubtargetFeature<"sm_32", "SmVersion", "32",
@@ -38,18 +40,24 @@ def SM35 : SubtargetFeature<"sm_35", "SmVersion", "35",
                             "Target SM 3.5">;
 def SM37 : SubtargetFeature<"sm_37", "SmVersion", "37",
                             "Target SM 3.7">;
+// Maxwell
 def SM50 : SubtargetFeature<"sm_50", "SmVersion", "50",
                             "Target SM 5.0">;
 def SM52 : SubtargetFeature<"sm_52", "SmVersion", "52",
                             "Target SM 5.2">;
 def SM53 : SubtargetFeature<"sm_53", "SmVersion", "53",
                             "Target SM 5.3">;
+
+// Pascal
 def SM60 : SubtargetFeature<"sm_60", "SmVersion", "60",
-                             "Target SM 6.0">;
+                            "Target SM 6.0">;
 def SM61 : SubtargetFeature<"sm_61", "SmVersion", "61",
-                             "Target SM 6.1">;
+                            "Target SM 6.1">;
 def SM62 : SubtargetFeature<"sm_62", "SmVersion", "62",
-                             "Target SM 6.2">;
+                            "Target SM 6.2">;
+// Volta
+def SM70 : SubtargetFeature<"sm_70", "SmVersion", "70",
+                            "Target SM 7.0">;
 
 // PTX Versions
 def PTX32 : SubtargetFeature<"ptx32", "PTXVersion", "32",
@@ -84,6 +92,7 @@ def : Proc<"sm_53", [SM53, PTX42]>;
 def : Proc<"sm_60", [SM60, PTX50]>;
 def : Proc<"sm_61", [SM61, PTX50]>;
 def : Proc<"sm_62", [SM62, PTX50]>;
+def : Proc<"sm_70", [SM70, PTX50]>;
 
 def NVPTXInstrInfo : InstrInfo {
 }
diff --git a/lib/Target/NVPTX/NVPTXAsmPrinter.h b/lib/Target/NVPTX/NVPTXAsmPrinter.h
index 85660fb..806e536 100644
--- a/lib/Target/NVPTX/NVPTXAsmPrinter.h
+++ b/lib/Target/NVPTX/NVPTXAsmPrinter.h
@@ -206,6 +206,12 @@ private:
   void EmitFunctionBodyEnd() override;
   void emitImplicitDef(const MachineInstr *MI) const override;
 
+  /// superfluous function header fix: nop these three functions
+  void EmitGlobalVariable(const GlobalVariable *GV) override {}
+  void EmitLinkage(const GlobalValue *GV, MCSymbol *GVSym) const override {}
+  void EmitAlignment(unsigned NumBits, const GlobalObject *GO = nullptr) const override {}
+  ///
+
   void EmitInstruction(const MachineInstr *) override;
   void lowerToMCInst(const MachineInstr *MI, MCInst &OutMI);
   bool lowerOperand(const MachineOperand &MO, MCOperand &MCOp);
diff --git a/lib/Target/NVPTX/NVPTXSubtarget.cpp b/lib/Target/NVPTX/NVPTXSubtarget.cpp
index bd2509a..55c1aca 100644
--- a/lib/Target/NVPTX/NVPTXSubtarget.cpp
+++ b/lib/Target/NVPTX/NVPTXSubtarget.cpp
@@ -35,9 +35,9 @@ NVPTXSubtarget &NVPTXSubtarget::initializeSubtargetDependencies(StringRef CPU,
 
   ParseSubtargetFeatures(TargetName, FS);
 
-  // Set default to PTX 3.2 (CUDA 5.5)
+  // Set default to PTX 4.3
   if (PTXVersion == 0) {
-    PTXVersion = 32;
+    PTXVersion = 43;
   }
 
   return *this;
diff --git a/lib/Target/NVPTX/NVPTXTargetMachine.cpp b/lib/Target/NVPTX/NVPTXTargetMachine.cpp
index 05df3e4c..822bcac 100644
--- a/lib/Target/NVPTX/NVPTXTargetMachine.cpp
+++ b/lib/Target/NVPTX/NVPTXTargetMachine.cpp
@@ -56,10 +56,11 @@ static cl::opt<bool> UseInferAddressSpaces(
 
 // LSV is still relatively new; this switch lets us turn it off in case we
 // encounter (or suspect) a bug.
+// TODO/NOTE: don't want this when under register pressure
 static cl::opt<bool>
     DisableLoadStoreVectorizer("disable-nvptx-load-store-vectorizer",
                                cl::desc("Disable load/store vectorizer"),
-                               cl::init(false), cl::Hidden);
+                               cl::init(true), cl::Hidden);
 
 namespace llvm {
 void initializeNVVMIntrRangePass(PassRegistry&);
diff --git a/lib/Target/NVPTX/NVPTXUtilities.cpp b/lib/Target/NVPTX/NVPTXUtilities.cpp
index 8c980a6..63654c4 100644
--- a/lib/Target/NVPTX/NVPTXUtilities.cpp
+++ b/lib/Target/NVPTX/NVPTXUtilities.cpp
@@ -295,7 +295,8 @@ bool llvm::isKernelFunction(const Function &F) {
       &F, llvm::PropertyAnnotationNames[llvm::PROPERTY_ISKERNEL_FUNCTION], x);
   if (!retval) {
     // There is no NVVM metadata, check the calling convention
-    return F.getCallingConv() == llvm::CallingConv::PTX_Kernel;
+    return (F.getCallingConv() == llvm::CallingConv::PTX_Kernel ||
+            F.getCallingConv() == llvm::CallingConv::FLOOR_KERNEL);
   }
   return (x == 1);
 }
diff --git a/lib/Transforms/IPO/CMakeLists.txt b/lib/Transforms/IPO/CMakeLists.txt
index 341ce55..259bdef 100644
--- a/lib/Transforms/IPO/CMakeLists.txt
+++ b/lib/Transforms/IPO/CMakeLists.txt
@@ -15,6 +15,7 @@ add_llvm_library(LLVMipo
   IPConstantPropagation.cpp
   IPO.cpp
   InferFunctionAttrs.cpp
+  InlineEverything.cpp
   InlineSimple.cpp
   Inliner.cpp
   Internalize.cpp
diff --git a/lib/Transforms/IPO/FunctionAttrs.cpp b/lib/Transforms/IPO/FunctionAttrs.cpp
index 2d897b5..3c2e483 100644
--- a/lib/Transforms/IPO/FunctionAttrs.cpp
+++ b/lib/Transforms/IPO/FunctionAttrs.cpp
@@ -1013,6 +1013,13 @@ static bool addNoRecurseAttrs(const SCCNodeSet &SCCNodes) {
   if (!F || F->isDeclaration() || F->doesNotRecurse())
     return false;
 
+  // set norecurse for all compute kernels and vertex/fragment shaders
+  if (F->getCallingConv() == CallingConv::FLOOR_KERNEL ||
+      F->getCallingConv() == CallingConv::FLOOR_VERTEX ||
+      F->getCallingConv() == CallingConv::FLOOR_FRAGMENT) {
+    return setDoesNotRecurse(*F);
+  }
+
   // If all of the calls in F are identifiable and are to norecurse functions, F
   // is norecurse. This check also detects self-recursion as F is not currently
   // marked norecurse, so any called from F to F will not be marked norecurse.
diff --git a/lib/Transforms/IPO/GlobalOpt.cpp b/lib/Transforms/IPO/GlobalOpt.cpp
index 52c1cc5..59d1713 100644
--- a/lib/Transforms/IPO/GlobalOpt.cpp
+++ b/lib/Transforms/IPO/GlobalOpt.cpp
@@ -20,6 +20,7 @@
 #include "llvm/ADT/SmallSet.h"
 #include "llvm/ADT/SmallVector.h"
 #include "llvm/ADT/Statistic.h"
+#include "llvm/ADT/Triple.h"
 #include "llvm/Analysis/ConstantFolding.h"
 #include "llvm/Analysis/MemoryBuiltins.h"
 #include "llvm/Analysis/TargetLibraryInfo.h"
@@ -1988,6 +1989,17 @@ static void ChangeCalleesToFastCall(Function *F) {
   }
 }
 
+/// ChangeCalleesToFloorFunc - Walk all of the direct calls of the specified
+/// function, changing them to floor_func calling convention.
+static void ChangeCalleesToFloorFunc(Function *F) {
+  for (User *U : F->users()) {
+    if (isa<BlockAddress>(U))
+      continue;
+    CallSite CS(cast<Instruction>(U));
+    CS.setCallingConv(CallingConv::FLOOR_FUNC);
+  }
+}
+
 static AttributeSet StripNest(LLVMContext &C, const AttributeSet &Attrs) {
   for (unsigned i = 0, e = Attrs.getNumSlots(); i != e; ++i) {
     unsigned Index = Attrs.getSlotIndex(i);
@@ -2047,8 +2059,19 @@ OptimizeFunctions(Module &M, TargetLibraryInfo *TLI,
       // If this function has a calling convention worth changing, is not a
       // varargs function, and is only called directly, promote it to use the
       // Fast calling convention.
-      F->setCallingConv(CallingConv::Fast);
-      ChangeCalleesToFastCall(F);
+      // with OpenCL/SPIR, Metal/AIR and CUDA: change it to floor_func instead (fastcc is invalid)
+      const llvm::Triple triple(M.getTargetTriple());
+      if (triple.getArch() == llvm::Triple::ArchType::spir ||
+          triple.getArch() == llvm::Triple::ArchType::spir64 ||
+          triple.getArch() == llvm::Triple::ArchType::air64 ||
+          triple.getOS() == llvm::Triple::OSType::CUDA) {
+        F->setCallingConv(CallingConv::FLOOR_FUNC);
+        ChangeCalleesToFloorFunc(F);
+      }
+      else {
+        F->setCallingConv(CallingConv::Fast);
+        ChangeCalleesToFastCall(F);
+      }
       ++NumFastCallFns;
       Changed = true;
     }
diff --git a/lib/Transforms/IPO/IPO.cpp b/lib/Transforms/IPO/IPO.cpp
index 58b89b2..3409389 100644
--- a/lib/Transforms/IPO/IPO.cpp
+++ b/lib/Transforms/IPO/IPO.cpp
@@ -34,6 +34,7 @@ void llvm::initializeIPO(PassRegistry &Registry) {
   initializeGlobalOptLegacyPassPass(Registry);
   initializeIPCPPass(Registry);
   initializeAlwaysInlinerLegacyPassPass(Registry);
+  initializeEverythingInlinerPass(Registry);
   initializeSimpleInlinerPass(Registry);
   initializeInferFunctionAttrsLegacyPassPass(Registry);
   initializeInternalizeLegacyPassPass(Registry);
@@ -86,6 +87,10 @@ void LLVMAddAlwaysInlinerPass(LLVMPassManagerRef PM) {
   unwrap(PM)->add(llvm::createAlwaysInlinerLegacyPass());
 }
 
+void LLVMAddEverythingInlinerPass(LLVMPassManagerRef PM) {
+  unwrap(PM)->add(llvm::createEverythingInlinerPass());
+}
+
 void LLVMAddGlobalDCEPass(LLVMPassManagerRef PM) {
   unwrap(PM)->add(createGlobalDCEPass());
 }
diff --git a/lib/Transforms/IPO/InlineEverything.cpp b/lib/Transforms/IPO/InlineEverything.cpp
new file mode 100644
index 0000000..48595e0
--- /dev/null
+++ b/lib/Transforms/IPO/InlineEverything.cpp
@@ -0,0 +1,92 @@
+//===- InlineEverything.cpp - Code to inline all functions ----------------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+// This file implements a custom inliner that inlines everything, unless it was
+// marked "noinline".
+//
+//===----------------------------------------------------------------------===//
+
+#include "llvm/Transforms/IPO.h"
+#include "llvm/ADT/SmallPtrSet.h"
+#include "llvm/Analysis/AssumptionCache.h"
+#include "llvm/Analysis/CallGraph.h"
+#include "llvm/Analysis/InlineCost.h"
+#include "llvm/Analysis/TargetLibraryInfo.h"
+#include "llvm/IR/CallSite.h"
+#include "llvm/IR/CallingConv.h"
+#include "llvm/IR/DataLayout.h"
+#include "llvm/IR/Instructions.h"
+#include "llvm/IR/IntrinsicInst.h"
+#include "llvm/IR/Module.h"
+#include "llvm/IR/Type.h"
+#include "llvm/Transforms/IPO/InlinerPass.h"
+
+using namespace llvm;
+
+#define DEBUG_TYPE "inline"
+
+namespace {
+
+/// \brief Inliner pass which inlines everything unless it was marked "noinline".
+class EverythingInliner : public Inliner {
+
+public:
+  EverythingInliner() : Inliner(ID, /*InsertLifetime*/ true) {
+    initializeEverythingInlinerPass(*PassRegistry::getPassRegistry());
+  }
+
+  EverythingInliner(bool InsertLifetime)
+      : Inliner(ID, InsertLifetime) {
+    initializeEverythingInlinerPass(*PassRegistry::getPassRegistry());
+  }
+
+  /// Main run interface method.  We override here to avoid calling skipSCC().
+  bool runOnSCC(CallGraphSCC &SCC) override { return inlineCalls(SCC); }
+
+  static char ID; // Pass identification, replacement for typeid
+
+  InlineCost getInlineCost(CallSite CS) override;
+
+  using llvm::Pass::doFinalization;
+  bool doFinalization(CallGraph &CG) override {
+    return removeDeadFunctions(CG, /*AlwaysInlineOnly=*/ false);
+  }
+};
+
+}
+
+char EverythingInliner::ID = 0;
+INITIALIZE_PASS_BEGIN(EverythingInliner, "everything-inline",
+					  "everything inliner", false, false)
+INITIALIZE_PASS_DEPENDENCY(AssumptionCacheTracker)
+INITIALIZE_PASS_DEPENDENCY(CallGraphWrapperPass)
+INITIALIZE_PASS_DEPENDENCY(ProfileSummaryInfoWrapperPass)
+INITIALIZE_PASS_DEPENDENCY(TargetLibraryInfoWrapperPass)
+INITIALIZE_PASS_END(EverythingInliner, "everything-inline",
+                    "everything inliner", false, false)
+
+Pass *llvm::createEverythingInlinerPass() { return new EverythingInliner(); }
+
+Pass *llvm::createEverythingInlinerPass(bool InsertLifetime) {
+  return new EverythingInliner(InsertLifetime);
+}
+
+InlineCost EverythingInliner::getInlineCost(CallSite CS) {
+  Function *Callee = CS.getCalledFunction();
+
+  if (Callee && !Callee->isDeclaration() &&
+      (CS.hasFnAttr(Attribute::NoInline) ||
+	   Callee->hasFnAttribute(Attribute::NoInline) ||
+	   !isInlineViable(*Callee))) {
+    return InlineCost::getNever();
+  }
+
+  return InlineCost::getAlways();
+}
+
diff --git a/lib/Transforms/IPO/Internalize.cpp b/lib/Transforms/IPO/Internalize.cpp
index 26db146..5e91105 100644
--- a/lib/Transforms/IPO/Internalize.cpp
+++ b/lib/Transforms/IPO/Internalize.cpp
@@ -24,6 +24,7 @@
 #include "llvm/ADT/Statistic.h"
 #include "llvm/ADT/StringSet.h"
 #include "llvm/Analysis/CallGraph.h"
+#include "llvm/IR/Function.h"
 #include "llvm/IR/Module.h"
 #include "llvm/Pass.h"
 #include "llvm/Support/CommandLine.h"
@@ -110,6 +111,17 @@ bool InternalizePass::shouldPreserveGV(const GlobalValue &GV) {
   if (AlwaysPreserved.count(GV.getName()))
     return true;
 
+  // is this a compute (opencl/cuda/metal/vulkan) kernel or graphics function?
+  if (isa<Function>(GV)) {
+    const Function* F = dyn_cast<Function>(&GV);
+    if (F &&
+        (F->getCallingConv() == CallingConv::FLOOR_KERNEL ||
+         F->getCallingConv() == CallingConv::FLOOR_VERTEX ||
+         F->getCallingConv() == CallingConv::FLOOR_FRAGMENT)) {
+      return true;
+    }
+  }
+
   return MustPreserveGV(GV);
 }
 
diff --git a/lib/Transforms/IPO/LLVMBuild.txt b/lib/Transforms/IPO/LLVMBuild.txt
index bc3df98..ad5dbb0 100644
--- a/lib/Transforms/IPO/LLVMBuild.txt
+++ b/lib/Transforms/IPO/LLVMBuild.txt
@@ -20,4 +20,4 @@ type = Library
 name = IPO
 parent = Transforms
 library_name = ipo
-required_libraries = Analysis Core InstCombine IRReader Linker Object ProfileData Scalar Support TransformUtils Vectorize Instrumentation
+required_libraries = Analysis Core InstCombine IRReader Linker Object ProfileData Scalar Support TransformUtils Vectorize Instrumentation SPIRVerifier
diff --git a/lib/Transforms/IPO/PassManagerBuilder.cpp b/lib/Transforms/IPO/PassManagerBuilder.cpp
index 71e479a..0aed168 100644
--- a/lib/Transforms/IPO/PassManagerBuilder.cpp
+++ b/lib/Transforms/IPO/PassManagerBuilder.cpp
@@ -39,6 +39,7 @@
 #include "llvm/Transforms/Scalar.h"
 #include "llvm/Transforms/Scalar/GVN.h"
 #include "llvm/Transforms/Vectorize.h"
+#include "llvm/SPIRVerifier/SpirValidation.h"
 
 using namespace llvm;
 
@@ -165,6 +166,15 @@ PassManagerBuilder::PassManagerBuilder() {
     PGOInstrUse = RunPGOInstrUse;
     PrepareForThinLTO = false;
     PerformThinLTO = false;
+    EnableAddressSpaceFix = false;
+    EnableCUDAPasses = false;
+    EnableMetalPasses = false;
+    EnableMetalIntelWorkarounds = false;
+    EnableMetalNvidiaWorkarounds = false;
+    EnableSPIRPasses = false;
+    EnableSPIRIntelWorkarounds = false;
+    EnableVerifySPIR = false;
+    EnableVulkanPasses = false;
 }
 
 PassManagerBuilder::~PassManagerBuilder() {
@@ -222,7 +232,9 @@ void PassManagerBuilder::addInitialAliasAnalysisPasses(
 
 void PassManagerBuilder::addInstructionCombiningPass(
     legacy::PassManagerBase &PM) const {
-  bool ExpensiveCombines = OptLevel > 2;
+  // don't want this for vulkan (leads to illegal pointer bitcasts)
+  // TODO: might only want to disable pointer combinations
+  bool ExpensiveCombines = (OptLevel > 2 && !EnableVulkanPasses);
   PM.add(createInstructionCombiningPass(ExpensiveCombines));
 }
 
@@ -373,9 +385,40 @@ void PassManagerBuilder::addFunctionSimplificationPasses(
 
 void PassManagerBuilder::populateModulePassManager(
     legacy::PassManagerBase &MPM) {
+  // Add LibraryInfo if we have some.
+  if (LibraryInfo) MPM.add(new TargetLibraryInfoWrapperPass(*LibraryInfo));
+
   // Allow forcing function attributes as a debugging and tuning aid.
   MPM.add(createForceFunctionAttrsLegacyPass());
 
+  if (EnableAddressSpaceFix) {
+    // address space fixing should be run as early as possible, but it also
+    // requires readonly/nocapture/etc function and argument attributes,
+    // which in turn requires certain alias analysis to be run first
+    // NOTE: the original FunctionAttrs pass should still be run later on,
+    // because the code will have changed significantly due to optimizations
+    // and other pass changes
+    addInitialAliasAnalysisPasses(MPM);
+    MPM.add(createAAResultsWrapperPass());
+    MPM.add(createPostOrderFunctionAttrsLegacyPass());
+    MPM.add(createAddressSpaceFixPass());
+    MPM.add(createInternalizePass()); // kill cloned functions
+    //MPM.add(createBarrierNoopPass());
+  }
+
+  // run "first" passes that should run before all else
+  // if(EnableCUDAPasses) --none
+  if(EnableMetalPasses) {
+    MPM.add(createMetalFirstPass(EnableMetalIntelWorkarounds, EnableMetalNvidiaWorkarounds));
+  }
+  // if(EnableSPIRPasses) --none
+
+  // run this before any other major optimizations (it will be helpful to them)
+  MPM.add(createPropagateRangeInfoPass());
+
+  // run this again, since functions might have changed
+  MPM.add(createForceFunctionAttrsLegacyPass());
+
   // If all optimizations are disabled, just run the always-inline pass and,
   // if enabled, the function merging pass.
   if (OptLevel == 0) {
@@ -403,7 +446,9 @@ void PassManagerBuilder::populateModulePassManager(
   if (LibraryInfo)
     MPM.add(new TargetLibraryInfoWrapperPass(*LibraryInfo));
 
-  addInitialAliasAnalysisPasses(MPM);
+  if (!EnableAddressSpaceFix) {
+    addInitialAliasAnalysisPasses(MPM);
+  }
 
   if (!DisableUnitAtATime) {
     // Infer attributes about declarations if possible.
@@ -458,6 +503,28 @@ void PassManagerBuilder::populateModulePassManager(
   // we must insert a no-op module pass to reset the pass manager.
   MPM.add(createBarrierNoopPass());
 
+  // run image read/write function passes after inling everything,
+  // this way we can actually check each use of these functions and their arguments,
+  // with constants potentially changing/improving the behavior and allowing
+  // additional checking (like oob offsets).
+  if(EnableCUDAPasses || EnableMetalPasses || EnableSPIRPasses) {
+    if(EnableCUDAPasses) MPM.add(createCUDAImagePass(floor_image_capabilities));
+    if(EnableMetalPasses) MPM.add(createMetalImagePass(floor_image_capabilities));
+    if(EnableSPIRPasses) MPM.add(createSPIRImagePass(floor_image_capabilities, EnableSPIRIntelWorkarounds));
+
+    // and cleanup afterwards, including loop and unrolling related things
+    MPM.add(createTailCallEliminationPass());
+    MPM.add(createLoopRotatePass());
+    MPM.add(createLICMPass());
+    MPM.add(createSimpleLoopUnrollPass());
+
+    MPM.add(createGVNPass());
+    MPM.add(createAggressiveDCEPass());
+    MPM.add(createCFGSimplificationPass());
+    MPM.add(createInstructionCombiningPass());
+    addExtensionsToPM(EP_Peephole, MPM);
+  }
+
   if (!DisableUnitAtATime && OptLevel > 1 && !PrepareForLTO &&
       !PrepareForThinLTO)
     // Remove avail extern fns and globals definitions if we aren't
@@ -626,6 +693,45 @@ void PassManagerBuilder::populateModulePassManager(
     MPM.add(createMergeFunctionsPass());
 
   addExtensionsToPM(EP_OptimizerLast, MPM);
+
+  // run backend final passes at the very end, no IR should change after this point!
+  if(EnableCUDAPasses) MPM.add(createCUDAFinalPass());
+  if(EnableSPIRPasses) MPM.add(createSPIRFinalPass());
+  if(EnableVulkanPasses) { // must run after spir!
+	// initial cfg cleanup/simplification
+	MPM.add(createLowerSwitchPass());
+	MPM.add(createCFGSimplificationPass());
+    MPM.add(createSinkingPass());
+
+    // structured control flow creation
+    MPM.add(createCFGStructurizationPass());
+
+    // vulkanization
+    MPM.add(createVulkanFinalPass());
+    MPM.add(createVulkanFinalModuleCleanupPass());
+  }
+  if(EnableMetalPasses) {
+    MPM.add(createMetalFinalPass(EnableMetalIntelWorkarounds, EnableMetalNvidiaWorkarounds));
+    MPM.add(createMetalFinalModuleCleanupPass());
+  }
+
+  // cleanup
+  if(EnableMetalPasses || EnableCUDAPasses || (EnableSPIRPasses && !EnableVulkanPasses)) {
+    MPM.add(createTailCallEliminationPass());
+    MPM.add(createCFGSimplificationPass());
+    MPM.add(createInstructionCombiningPass());
+    MPM.add(createGVNPass());
+    MPM.add(createAggressiveDCEPass());
+  }
+  if(EnableVulkanPasses) {
+	// certain cleanup / post-final passes are disabled for vulkan, because we don't
+	// want to change the CFG or introduce "invalid" instructions
+    MPM.add(createTailCallEliminationPass());
+    MPM.add(createInstructionCombiningPass(false));
+    MPM.add(createAggressiveDCEPass());
+  }
+
+  if(EnableVerifySPIR) MPM.add(createSpirValidationPass());
 }
 
 void PassManagerBuilder::addLTOOptimizationPasses(legacy::PassManagerBase &PM) {
diff --git a/lib/Transforms/InstCombine/InstCombineLoadStoreAlloca.cpp b/lib/Transforms/InstCombine/InstCombineLoadStoreAlloca.cpp
index 1603278..1279da1 100644
--- a/lib/Transforms/InstCombine/InstCombineLoadStoreAlloca.cpp
+++ b/lib/Transforms/InstCombine/InstCombineLoadStoreAlloca.cpp
@@ -465,13 +465,16 @@ static Instruction *combineLoadToOperationType(InstCombiner &IC, LoadInst &LI) {
   if (LI.use_empty())
     return nullptr;
 
-  Type *Ty = LI.getType();
   const DataLayout &DL = IC.getDataLayout();
 
+  // disable this as it introduces unnecessary/unwanted additional instructions and actual bitcasts
+  // (e.g. load from int* (instead of float*), then int to float cast + this is generally a bad idea on GPUs)
+#if 0
   // Try to canonicalize loads which are only ever stored to operate over
   // integers instead of any other type. We only do this when the loaded type
   // is sized and has a size exactly the same as its store size and the store
   // size is a legal integer type.
+  Type *Ty = LI.getType();
   if (!Ty->isIntegerTy() && Ty->isSized() &&
       DL.isLegalInteger(DL.getTypeStoreSizeInBits(Ty)) &&
       DL.getTypeStoreSizeInBits(Ty) == DL.getTypeSizeInBits(Ty) &&
@@ -495,6 +498,7 @@ static Instruction *combineLoadToOperationType(InstCombiner &IC, LoadInst &LI) {
       return &LI;
     }
   }
+#endif
 
   // Fold away bit casts of the loaded value by loading the desired type.
   // We can do this for BitCastInsts as well as casts from and to pointer types,
diff --git a/lib/Transforms/Scalar/AddressSpaceFix.cpp b/lib/Transforms/Scalar/AddressSpaceFix.cpp
new file mode 100644
index 0000000..23be65f
--- /dev/null
+++ b/lib/Transforms/Scalar/AddressSpaceFix.cpp
@@ -0,0 +1,555 @@
+//===- AddressSpaceFix.cpp - OpenCL/SPIR and related addrspace fixes ------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+// This file implements an address space fixer for OpenCL/Metal/Vulkan.
+//
+// This is implemented as a module pass that iterates over all functions, then
+// over all call instructions in there, fixing all calls that require a
+// different address space then what is provided by the called function.
+// Since this requires the address space information "from the top",
+// this can't be implemented as a bottom-up SCC pass.
+// Note that this will duplicate any functions that don't have matching address
+// space parameters and thus heavily depends on proper inlining later on.
+//
+//===----------------------------------------------------------------------===//
+
+#include "llvm/ADT/Statistic.h"
+#include "llvm/ADT/STLExtras.h"
+#include "llvm/ADT/SetVector.h"
+#include "llvm/ADT/SmallPtrSet.h"
+#include "llvm/ADT/SmallVector.h"
+#include "llvm/ADT/StringExtras.h"
+#include "llvm/Analysis/AliasAnalysis.h"
+#include "llvm/Analysis/BasicAliasAnalysis.h"
+#include "llvm/Analysis/GlobalsModRef.h"
+#include "llvm/IR/CFG.h"
+#include "llvm/IR/CallSite.h"
+#include "llvm/IR/CallingConv.h"
+#include "llvm/IR/ConstantRange.h"
+#include "llvm/IR/Constants.h"
+#include "llvm/IR/DataLayout.h"
+#include "llvm/IR/DebugInfo.h"
+#include "llvm/IR/DerivedTypes.h"
+#include "llvm/IR/Dominators.h"
+#include "llvm/IR/Function.h"
+#include "llvm/IR/InlineAsm.h"
+#include "llvm/IR/InstIterator.h"
+#include "llvm/IR/InstVisitor.h"
+#include "llvm/IR/IntrinsicInst.h"
+#include "llvm/IR/IRBuilder.h"
+#include "llvm/IR/LLVMContext.h"
+#include "llvm/IR/Metadata.h"
+#include "llvm/IR/Module.h"
+#include "llvm/IR/LegacyPassManager.h"
+#include "llvm/Pass.h"
+#include "llvm/Support/CommandLine.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/ErrorHandling.h"
+#include "llvm/Support/raw_ostream.h"
+#include "llvm/Transforms/IPO/PassManagerBuilder.h"
+#include "llvm/Transforms/IPO.h"
+#include "llvm/Transforms/Scalar.h"
+#include "llvm/Transforms/Utils/Cloning.h"
+#include <algorithm>
+#include <unordered_set>
+#include <cstdarg>
+#include <memory>
+#include <cxxabi.h>
+using namespace llvm;
+
+#define DEBUG_TYPE "AddressSpaceFix"
+
+#if 1
+#define DBG(x)
+#else
+#define DBG(x) x
+#endif
+
+namespace {
+	// AddressSpaceFix
+	struct AddressSpaceFix : public ModulePass, InstVisitor<AddressSpaceFix> {
+		friend class InstVisitor<AddressSpaceFix>;
+		
+		static char ID; // Pass identification, replacement for typeid
+		
+		std::shared_ptr<llvm::IRBuilder<>> builder;
+		
+		Module* M { nullptr };
+		LLVMContext* ctx { nullptr };
+		bool was_modified { false };
+		
+		AddressSpaceFix() : ModulePass(ID) {
+			initializeAddressSpaceFixPass(*PassRegistry::getPassRegistry());
+		}
+		
+		void getAnalysisUsage(AnalysisUsage &AU) const override {
+			AU.addRequired<AAResultsWrapperPass>();
+			AU.addRequired<GlobalsAAWrapperPass>();
+			AU.addRequired<AssumptionCacheTracker>();
+			AU.addRequired<TargetLibraryInfoWrapperPass>();
+		}
+		
+		bool runOnModule(Module& Mod) override {
+			M = &Mod;
+			ctx = &M->getContext();
+			builder = std::make_shared<llvm::IRBuilder<>>(*ctx);
+			
+			DBG(errs() << Mod << "\n");
+			
+			bool module_modified = false;
+			for(auto& func : Mod) {
+				// ignore non-c++ functions (e.g. ones that were created in here)
+				if(func.getName().count('.') > 0) continue;
+				module_modified |= runOnFunction(func);
+			}
+			return module_modified;
+		}
+		
+		bool runOnFunction(Function& F) {
+			// visit everything in this function
+			was_modified = false; // reset every time
+			DBG(errs() << "in func: "; errs().write_escaped(F.getName()) << '\n';)
+			visit(F);
+			if(was_modified) {
+				DBG(errs() << "!! modified function: ";)
+				DBG(errs().write_escaped(F.getName()) << '\n';)
+			}
+			return was_modified;
+		}
+		
+		// InstVisitor overrides...
+		using InstVisitor<AddressSpaceFix>::visit;
+		void visit(Instruction& I) {
+			InstVisitor<AddressSpaceFix>::visit(I);
+		}
+		
+		void fix_users(Instruction* instr, Value* parent, const uint32_t address_space, std::vector<ReturnInst*>& returns) {
+			// fix instruction
+			switch(instr->getOpcode()) {
+				case Instruction::GetElementPtr: {
+					auto GEP = cast<GetElementPtrInst>(instr);
+					if(GEP->getType()->isPointerTy()) {
+						auto new_ptr_type = PointerType::get(GEP->getType()->getPointerElementType(), address_space);
+						DBG(errs() << ">> GEP: " << *GEP->getType();)
+						GEP->mutateType(new_ptr_type);
+						DBG(errs() << " -> " << *GEP->getType() << "\n";)
+					}
+					// else: can't happen?
+					break;
+				}
+				case Instruction::BitCast: {
+					auto BC = cast<BitCastInst>(instr);
+					if(BC->getDestTy()->isPointerTy()) {
+						auto new_ptr_type = PointerType::get(BC->getDestTy()->getPointerElementType(), address_space);
+						DBG(errs() << ">> BC: " << *BC->getType() << " -> ";)
+						BC->mutateType(new_ptr_type);
+						DBG(errs() << " -> " << *BC->getType() << "\n";)
+					}
+					// else: can't do anything (TODO: warn/error?)
+					break;
+				}
+				case Instruction::Call: {
+					// TODO: should accumulate all users to *this* call instruction (there can be multiple), might want to delay this until done with the function?
+					auto CI = cast<CallInst>(instr);
+					DBG(errs() << ">> call: " << *CI << "\n";)
+					// -> recurse (note that the argument will already have the correct address space)
+					fix_call_instr(*CI, false);
+					break;
+				}
+				case Instruction::Ret: {
+					// the function return type will be changed once all returns (and return types) have been accumulated
+					returns.push_back(cast<ReturnInst>(instr));
+					return;
+				}
+
+				case Instruction::AddrSpaceCast:
+				case Instruction::Invoke:
+					// bad, should never happen
+					ctx->emitError(instr, "encountered unsupported instruction");
+					return;
+
+				// uninteresting instructions:
+				default:
+					// nothing has changed, bail out
+					return;
+			}
+			
+			// recursively fix all users
+			for(auto user : instr->users()) {
+				DBG(errs() << ">> replacing rec use: " << *user << "\n";)
+				if(auto user_instr = dyn_cast<Instruction>(user)) {
+					switch(user_instr->getOpcode()) {
+						case Instruction::GetElementPtr:
+						case Instruction::BitCast:
+						case Instruction::Call:
+						case Instruction::Ret:
+							fix_users(user_instr, instr, address_space, returns);
+							break;
+						case Instruction::AddrSpaceCast:
+						case Instruction::Invoke:
+							// bad, should never happen
+							ctx->emitError(user_instr, "encountered unsupported instruction");
+							break;
+						default: break;
+					}
+				}
+			}
+		}
+		
+		struct as_fix_arg_info {
+			uint32_t index;
+			uint32_t address_space;
+			bool read_only_fix;
+		};
+		
+		// returns true if the return type changed
+		void fix_function(llvm::Function* func, const std::vector<as_fix_arg_info>& args, const bool is_top_call) {
+			std::vector<ReturnInst*> returns; // returns to fix
+			for(const auto& arg : args) {
+				if(arg.read_only_fix) continue;
+				
+				Argument& func_arg = *(next(func->arg_begin(), arg.index));
+				for(auto user : func_arg.users()) {
+					DBG(errs() << ">> replacing use: " << *user << "\n";)
+					if(auto instr = dyn_cast<Instruction>(user)) {
+						fix_users(instr, &func_arg, arg.address_space, returns);
+					}
+					else {
+						DBG(errs() << "   not an instruction\n";)
+					}
+				}
+				DBG(errs() << "<< fixed arg: " << arg.index << "\n";)
+			}
+			
+			if(!returns.empty()) {
+				DBG(errs() << ">> fixing returns: " << returns.size() << "\n";)
+				std::unordered_set<Type*> ret_types;
+				for(const auto& ret : returns) {
+					// shouldn't occur (there'd be no initial user for this)
+					if(!ret->getReturnValue()) continue;
+					ret_types.emplace(ret->getReturnValue()->getType());
+				}
+				
+				// again, shouldn't occur, but still better to check
+				if(!ret_types.empty()) {
+					// if there is more than one expected return type we have a problem
+					if(ret_types.size() > 1) {
+						// TODO: should try and fix this properly (create alloca in caller + store result in there?)
+						// TODO: for targets with a generic address space, might want to use that instead
+						ctx->emitError("more than one return type in function " + func->getName().str());
+					}
+					else if((*ret_types.begin())->getPointerAddressSpace() !=
+							func->getReturnType()->getPointerAddressSpace()) {
+						// fix func return type
+						std::vector<Type*> param_types;
+						for(const auto& arg : func->args()) {
+							param_types.push_back(arg.getType());
+						}
+						auto new_ret_type = *ret_types.begin();
+						auto new_func_type = FunctionType::get(new_ret_type, param_types, false);
+						DBG({
+							auto old_func_type = func->getFunctionType();
+							errs() << ">> fixing return type: " << func->getName() << ": " << *old_func_type << " -> " << *new_func_type << "\n";
+						})
+						func->mutateType(PointerType::get(new_func_type, 0));
+						func->mutateFunctionType(new_func_type);
+					}
+				}
+			}
+			
+			DBG(errs() << "<< fixed func\n";)
+		}
+		
+		void fix_call(CallInst& CI, const std::vector<as_fix_arg_info>& args, const bool is_top_call) {
+			bool need_clone = false, need_read_only_fix = false;
+			for(const auto& arg : args) {
+				if(!arg.read_only_fix) need_clone = true;
+				else need_read_only_fix = true;
+			}
+			
+			CallSite CS { &CI };
+			
+			// find first non-alloca instruction in the entry block of the function
+			// -> this will be the insert position for new alloca instructions
+			Instruction* alloca_insert { nullptr };
+			if(need_read_only_fix) {
+				for(auto& instr : *CI.getParent()->getParent()->begin()) {
+					if(!isa<AllocaInst>(instr)) {
+						alloca_insert = &instr;
+						break;
+					}
+				}
+			}
+			
+			// first: fix all read-only args
+			if(need_read_only_fix) {
+				for(const auto& arg : args) {
+					if(!arg.read_only_fix) continue;
+					
+					//  * create a temporary object (of the element/pointee type of the address space pointer)
+					//  * load data from the address space pointer to the temp object
+					//  * replace the respective call operand/argument with a pointer to the temp object
+					DBG(errs() << "\tread-only fix: arg #" << arg.index << "\n";)
+					
+					// TODO: handle alignment?
+					
+					auto call_arg = CS.getArgument(arg.index);
+					
+					builder->SetInsertPoint(alloca_insert); // insert alloca at function entry
+					auto tmp = builder->CreateAlloca(call_arg->getType()->getPointerElementType(),
+													 // what about arrays?
+													 nullptr,
+													 // give it a nice name
+													 "asfixtmp");
+					
+					builder->SetInsertPoint(&CI); // insert load before call
+					builder->CreateStore(builder->CreateLoad(call_arg), tmp);
+					
+					CS.setArgument(arg.index, tmp);
+				}
+			}
+			
+			// second: create cloned function if this is necessary
+			if(need_clone) {
+				// fix it:
+				//  * clone the called function and modify the appropriate argument so that it uses the correct address space
+				//  * recursively go through the cloned called function and appropriately change all uses of our modified argument
+				//    NOTE: this can very well recursively clone and fix called functions in there (and so on ...)
+				//  * modify this call so that it calls the fixed/cloned function
+				
+				auto called_func = CI.getCalledFunction();
+				DBG(errs() << "\tclone fix: " << called_func->getName() << "\n";)
+				
+				std::vector<Type*> param_types;
+				std::string func_name = called_func->getName().str();
+				uint32_t arg_num = 0;
+				for(const auto& func_arg : called_func->args()) {
+					auto call_arg = CS.getArgument(arg_num);
+					
+					bool arg_clone_fix = false;
+					for(const auto& arg : args) {
+						if(arg.index != arg_num ||
+						   arg.read_only_fix) {
+							continue;
+						}
+						
+						arg_clone_fix = true;
+						func_name += "." + std::to_string(arg.index) + "_" + std::to_string(arg.address_space);
+						break;
+					}
+					
+					if(!arg_clone_fix) {
+						// use original type
+						param_types.push_back(func_arg.getType());
+					}
+					else {
+						// use "called with" type
+						param_types.push_back(call_arg->getType());
+					}
+					
+					++arg_num;
+				}
+				
+				// check if cloned function already exists
+				auto cloned_func = M->getFunction(func_name);
+				if(cloned_func == nullptr) {
+					// only do this once
+					auto cloned_func_type = FunctionType::get(called_func->getReturnType(), param_types, false);
+					cloned_func = dyn_cast<Function>(M->getOrInsertFunction(func_name, cloned_func_type));
+					
+					ValueToValueMapTy VMap;
+					Function::arg_iterator DestI = cloned_func->arg_begin();
+					for (const auto& I : called_func->args()) {
+						DestI->setName(I.getName());
+						VMap[&I] = &*DestI++;
+					}
+					
+					SmallVector<llvm::ReturnInst*, 8> returns;
+					llvm::CloneFunctionInto(cloned_func, called_func, VMap, false, returns);
+					
+#if 0 // for debugging purposes
+					cloned_func->addFnAttr(Attribute::NoInline);
+					cloned_func->removeFnAttr(Attribute::AlwaysInline);
+#endif
+					
+					DBG(errs() << "\n>> before <<\n" << *cloned_func);
+					
+					//
+					fix_function(cloned_func, args, is_top_call);
+					CS.setCalledFunction(cloned_func);
+					CI.mutateType(cloned_func->getReturnType());
+					
+					DBG(errs() << "\n>> after <<\n" << *cloned_func);
+				}
+				else {
+					DBG(errs() << "\t" << func_name << " already cloned\n";)
+					CS.setCalledFunction(cloned_func);
+					CI.mutateType(cloned_func->getReturnType());
+				}
+			}
+		}
+		
+		void visitCallInst(CallInst& CI) {
+			fix_call_instr(CI, true);
+		}
+		
+		void fix_call_instr(CallInst& CI, const bool is_top_call) {
+			CallSite CS { &CI };
+			PointerType* FPTy = cast<PointerType>(CS.getCalledValue()->getType());
+			FunctionType* FTy = cast<FunctionType>(FPTy->getElementType());
+			
+			std::vector<as_fix_arg_info> fix_args;
+			for (unsigned i = 0, e = FTy->getNumParams(); i != e; ++i) {
+				// check if there is a type mismatch
+				if(CS.getArgument(i)->getType() != FTy->getParamType(i)) {
+					// both types must be pointers
+					auto arg = CS.getArgument(i);
+					auto called_arg_type = arg->getType();
+					auto expected_arg_type = FTy->getParamType(i);
+					if(!called_arg_type->isPointerTy() ||
+					   !expected_arg_type->isPointerTy()) {
+						// emit original verifier assertion (TODO: fix it there!)
+						assert(false && "#1: Call parameter type does not match function signature!");
+						continue;
+					}
+					
+					// check if the mismatch is _only_ due to the addrspace
+					auto as_ptr = cast<PointerType>(called_arg_type);
+					if(PointerType::get(as_ptr->getElementType(),
+										expected_arg_type->getPointerAddressSpace()) !=
+					   expected_arg_type) {
+						// emit original verifier assertion (TODO: fix it there!)
+						assert(false && "#2: Call parameter type does not match function signature!");
+						continue;
+					}
+					// else: yup, only addrspace mismatch
+					DBG(errs() << "#####################################################\n";)
+					DBG(errs() << "\t>> call to: "; CS.getCalledFunction()->llvm::Value::getType()->dump();)
+					DBG(errs() << "\n\t>> call: " << CI << "\n";)
+					DBG(errs() << "\t>> full: " << CS.getCalledFunction()->getName() << "\n";)
+					DBG(errs() << "\treplacing arg #" << i << "!\n";)
+					DBG(errs() << "\t" << called_arg_type->getPointerAddressSpace() << ", ";)
+					DBG(errs() << expected_arg_type->getPointerAddressSpace() << "\n";)
+					DBG(errs() << "\t"; called_arg_type->dump(); errs() << ", ";)
+					DBG(expected_arg_type->dump(); errs() << "\n";)
+					DBG({
+						int err = 0;
+						const char* demangled_name = abi::__cxa_demangle(CS.getCalledFunction()->getName().data(), 0, 0, &err);
+						errs() << "\tfunc: " << (demangled_name != nullptr ? demangled_name : CS.getCalledFunction()->getName().data()) << "\n";
+						if(demangled_name != nullptr) {
+							free((void*)demangled_name);
+						}
+					})
+					
+					// abort if arg is an addrspacecast and pretend everything is fine ("someone else" is already making it fit)
+					if(isa<AddrSpaceCastInst>(arg)) {
+						DBG(errs() << "\tabort due to existing addrspacecast: " << *arg << "\n";)
+						continue;
+					}
+					
+					// the same goes for bitcasts, unless src and dst have the same address space
+					if(const auto BCI = dyn_cast_or_null<BitCastInst>(arg)) {
+						if(BCI->getSrcTy()->getPointerAddressSpace() != BCI->getDestTy()->getPointerAddressSpace()) {
+							DBG(errs() << "\tabort due to existing bitcast: " << *arg << "\n";)
+							continue;
+						}
+						// else: perform address space fix, b/c this is a simple pointer/type cast
+						DBG(errs() << "\tkeeping bitcast: " << *arg << "\n";)
+					}
+					
+					// abort if expected param address space is not 0, this is not supported (or would end in a good way ...)
+					// TODO: figure out if it would be a good idea to allow things like loading from e.g. local AS and calling a global AS function
+					if(expected_arg_type->getPointerAddressSpace() != 0) {
+						DBG(errs() << "\tabort due to expected AS not being 0\n";)
+						continue;
+					}
+					
+					// abort if current argument is in address space 0 (can't be moved to an address space)
+					if(called_arg_type->getPointerAddressSpace() == 0) {
+						DBG(errs() << "\tabort due to arg already being in AS 0\n";)
+						continue;
+					}
+					
+					// query information that decides if a store would be necessary later on,
+					// i.e. the arg is not read-only and access to it must happen using the actual arg
+					const bool is_constant_as = (as_ptr->getPointerAddressSpace() == 2);
+					const bool is_readonly = CS.onlyReadsMemory(i);
+					const bool is_load = isa<LoadInst>(arg);
+					
+					fix_args.push_back(as_fix_arg_info {
+						i,
+						as_ptr->getPointerAddressSpace(),
+						is_constant_as || is_readonly || is_load,
+					});
+				}
+			}
+			
+			if(!fix_args.empty()) {
+				// retrieving AA directly in a module pass (as a dep) in llvm 3.8 is apparantly no longer possible,
+				// so we have to this localized AA instead (specific to the current function)
+				auto func = CI.getParent()->getParent();
+				BasicAAResult BAR(createLegacyPMBasicAAResult(*this, *func));
+				AAResults AA(createLegacyPMAAResults(*this, *func, BAR));
+				
+				// check if we have both clone and read-only fixes
+				bool has_ro_fix = false, has_clone_fix = false;
+				for(const auto& arg : fix_args) {
+					if(arg.read_only_fix) has_ro_fix = true;
+					else has_clone_fix = true;
+				}
+				if(has_ro_fix && has_clone_fix) {
+					// if so, check AA for all read-only fix args and check if these alias with any clone fix arg
+					for(auto& ro_arg : fix_args) {
+						if(!ro_arg.read_only_fix) continue;
+						for(const auto& clone_arg : fix_args) {
+							if(clone_arg.read_only_fix) continue;
+							const auto aa_res = AA.alias(CS.getArgument(ro_arg.index), CS.getArgument(clone_arg.index));
+							if(aa_res != NoAlias) {
+								// -> might or must alias
+								// disable the read-only fix for this arg and use clone instead
+								ro_arg.read_only_fix = false;
+								DBG(errs() << "\tdisabling read-only fix for arg #" << ro_arg.index << " due to aliasing with clone arg #" << clone_arg.index << "\n";)
+								break;
+							}
+						}
+					}
+				}
+				
+				// fix the call (+detect return type change)
+				auto orig_ret_type = CI.getCalledFunction()->getReturnType();
+				fix_call(CI, fix_args, is_top_call);
+				auto fixed_ret_type = CI.getCalledFunction()->getReturnType();
+				
+				if(is_top_call &&
+				   orig_ret_type != fixed_ret_type) {
+					// if this is a top call and the return type changed
+					DBG(errs() << "\ttop call return type changed: " << *orig_ret_type << " -> " << *fixed_ret_type << " (in: " << CI.getParent()->getParent()->getName() << ")\n");
+				}
+				
+				// done, signal that the function was modified
+				was_modified = true;
+			}
+		}
+	};
+}
+
+char AddressSpaceFix::ID = 0;
+INITIALIZE_PASS_BEGIN(AddressSpaceFix, "AddressSpaceFix", "AddressSpaceFix Pass", false, false)
+// add all the things (not fully depending on this in getAnalysisUsage)
+INITIALIZE_PASS_DEPENDENCY(AAResultsWrapperPass)
+INITIALIZE_PASS_DEPENDENCY(GlobalsAAWrapperPass)
+INITIALIZE_PASS_DEPENDENCY(AssumptionCacheTracker)
+INITIALIZE_PASS_DEPENDENCY(CallGraphWrapperPass)
+INITIALIZE_PASS_DEPENDENCY(TargetLibraryInfoWrapperPass)
+INITIALIZE_PASS_DEPENDENCY(PostOrderFunctionAttrsLegacyPass) // TODO: what's the new method of doing this?
+INITIALIZE_PASS_END(AddressSpaceFix, "AddressSpaceFix", "AddressSpaceFix Pass", false, false)
+
+ModulePass *llvm::createAddressSpaceFixPass() {
+	return new AddressSpaceFix();
+}
diff --git a/lib/Transforms/Scalar/CFGStructurization.cpp b/lib/Transforms/Scalar/CFGStructurization.cpp
new file mode 100644
index 0000000..b3befb0
--- /dev/null
+++ b/lib/Transforms/Scalar/CFGStructurization.cpp
@@ -0,0 +1,543 @@
+//===-- CFGStructurization.cpp - CFG Structurizer -------------------------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//==-----------------------------------------------------------------------===//
+//
+// Transforms the CFG into a structurized CFG.
+//
+//===----------------------------------------------------------------------===//
+
+#include "llvm/ADT/Statistic.h"
+#include "llvm/ADT/STLExtras.h"
+#include "llvm/ADT/SetVector.h"
+#include "llvm/ADT/SmallPtrSet.h"
+#include "llvm/ADT/SmallVector.h"
+#include "llvm/ADT/StringExtras.h"
+#include "llvm/Analysis/AliasAnalysis.h"
+#include "llvm/Analysis/BasicAliasAnalysis.h"
+#include "llvm/Analysis/GlobalsModRef.h"
+#include "llvm/Analysis/PostDominators.h"
+#include "llvm/Analysis/LoopInfo.h"
+#include "llvm/IR/CFG.h"
+#include "llvm/IR/CallSite.h"
+#include "llvm/IR/CallingConv.h"
+#include "llvm/IR/ConstantRange.h"
+#include "llvm/IR/Constants.h"
+#include "llvm/IR/DataLayout.h"
+#include "llvm/IR/DebugInfo.h"
+#include "llvm/IR/DerivedTypes.h"
+#include "llvm/IR/Dominators.h"
+#include "llvm/IR/Function.h"
+#include "llvm/IR/InlineAsm.h"
+#include "llvm/IR/InstIterator.h"
+#include "llvm/IR/InstVisitor.h"
+#include "llvm/IR/IntrinsicInst.h"
+#include "llvm/IR/IRBuilder.h"
+#include "llvm/IR/LLVMContext.h"
+#include "llvm/IR/Metadata.h"
+#include "llvm/IR/Module.h"
+#include "llvm/IR/LegacyPassManager.h"
+#include "llvm/Pass.h"
+#include "llvm/Support/CommandLine.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/ErrorHandling.h"
+#include "llvm/Support/raw_ostream.h"
+#include "llvm/Transforms/IPO/PassManagerBuilder.h"
+#include "llvm/Transforms/IPO.h"
+#include "llvm/Transforms/Scalar.h"
+#include "llvm/Transforms/Utils/BasicBlockUtils.h"
+#include "llvm/Transforms/Utils/LoopUtils.h"
+#include "llvm/Transforms/Utils/Cloning.h"
+#include <algorithm>
+#include <cstdarg>
+#include <memory>
+#include <unordered_map>
+#include <unordered_set>
+#include <deque>
+#include <array>
+
+#include "StructuralAnalysis.h"
+#include "StructuralTransform.h"
+
+using namespace llvm;
+
+#define DEBUG_TYPE "cfg-structurization"
+
+#if 1
+#define DBG(x)
+#else
+#define DBG(x) x
+#endif
+
+namespace {
+	class CFGStructurization : public FunctionPass {
+	public:
+		static char ID; // Pass identification, replacement for typeid
+		
+		typedef StructuralAnalysis SA;
+		
+		Module* M { nullptr };
+		LLVMContext* ctx { nullptr };
+		Function* func { nullptr };
+		
+		DominatorTree* DT;
+		
+		bool was_modified { false };
+
+		CFGStructurization() : FunctionPass(ID) {
+			initializeCFGStructurizationPass(*PassRegistry::getPassRegistry());
+		}
+		
+		const char *getPassName() const override {
+			return "CFG structurization";
+		}
+
+		void getAnalysisUsage(AnalysisUsage &AU) const override {
+			AU.addRequired<DominatorTreeWrapperPass>();
+		}
+		
+		void sort_bbs() {
+			// dominator fixes: reorder blocks
+			// NOTE: obviously only necessary when there are more than 2 blocks
+			if(func->getBasicBlockList().size() <= 2) return;
+			
+			if(was_modified) {
+				DT->recalculate(*func);
+			}
+			
+			DBG(errs() << "\n> bbs before:\n";
+				for(BasicBlock& bb : func->getBasicBlockList()) {
+					errs() << "\t" << bb.getName() << "\n";
+				})
+			
+			// use the dominator tree order to sort the bbs, i.e. with the DT we already know the sorted order,
+			// we just need to physically move the blocks according to it
+			std::vector<BasicBlock*> sorted_blocks;
+			const std::function<void(const DomTreeNodeBase<BasicBlock>&)> sort_recurse = [&sort_recurse, &sorted_blocks](const DomTreeNodeBase<BasicBlock>& node) {
+				sorted_blocks.emplace_back(node.getBlock());
+				for(const auto& child : node) {
+					sort_recurse(*child);
+				}
+			};
+			sort_recurse(*DT->getRootNode());
+			
+			DBG(DT->print(errs());)
+			
+			// move blocks in reverse order (not moving entry of course)
+			for(size_t i = 0, count = sorted_blocks.size(); i < count - 2; ++i) {
+				sorted_blocks[count - i - 2]->moveBefore(sorted_blocks[count - i - 1]);
+			}
+			
+			DBG(errs() << "> bbs after:\n";
+				for(BasicBlock& bb : func->getBasicBlockList()) {
+					errs() << "\t" << bb.getName() << "\n";
+				})
+		}
+		
+		// returns true if the BB only contains a terminator and doesn't have a successor
+		static bool is_simple_bb(const BasicBlock* bb) {
+			if(!succ_empty(bb)) return false;
+			
+			const TerminatorInst* term = bb->getTerminator();
+			if(&bb->front() == term) {
+				return true;
+			}
+			// also need to handle special terminations (discard is a func call + unreachable/term inst)
+			if(const CallInst* CI = dyn_cast<CallInst>(&bb->front())) {
+				if(const Function* CF = CI->getCalledFunction()) {
+					if(CF->hasName() && CF->getName() == "floor.discard_fragment") {
+						// next must be term
+						if(&*next(bb->begin()) == term) {
+							return true;
+						}
+						assert("invalid discard_fragment call (not followed by term instr)");
+					}
+				}
+			}
+			return false;
+		}
+		
+		void create_loop_merge(Instruction* insert_before, BasicBlock* bb_merge, BasicBlock* bb_continue) {
+			Function* loop_merge_func = M->getFunction("floor.loop_merge");
+			if(loop_merge_func == nullptr) {
+				llvm::Type* loop_merge_arg_types[] { llvm::Type::getLabelTy(*ctx), llvm::Type::getLabelTy(*ctx) };
+				FunctionType* loop_merge_type = FunctionType::get(llvm::Type::getVoidTy(*ctx), loop_merge_arg_types, false);
+				loop_merge_func = (Function*)M->getOrInsertFunction("floor.loop_merge", loop_merge_type);
+				loop_merge_func->setCallingConv(CallingConv::FLOOR_FUNC);
+				loop_merge_func->setCannotDuplicate();
+				loop_merge_func->setDoesNotThrow();
+				loop_merge_func->setNotConvergent();
+				loop_merge_func->setDoesNotRecurse();
+			}
+			llvm::Value* merge_vars[] { bb_merge, bb_continue };
+			CallInst* loop_merge_call = CallInst::Create(loop_merge_func, merge_vars, "", insert_before);
+			loop_merge_call->setCallingConv(CallingConv::FLOOR_FUNC);
+		}
+		
+		void create_selection_merge(Instruction* insert_before, BasicBlock* merge_block) {
+			Function* sel_merge_func = M->getFunction("floor.selection_merge");
+			if(sel_merge_func == nullptr) {
+				llvm::Type* sel_merge_arg_types[] { llvm::Type::getLabelTy(*ctx) };
+				FunctionType* sel_merge_type = FunctionType::get(llvm::Type::getVoidTy(*ctx), sel_merge_arg_types, false);
+				sel_merge_func = (Function*)M->getOrInsertFunction("floor.selection_merge", sel_merge_type);
+				sel_merge_func->setCallingConv(CallingConv::FLOOR_FUNC);
+				sel_merge_func->setCannotDuplicate();
+				sel_merge_func->setDoesNotThrow();
+				sel_merge_func->setNotConvergent();
+				sel_merge_func->setDoesNotRecurse();
+			}
+			llvm::Value* merge_vars[] { merge_block };
+			CallInst* sel_merge_call = CallInst::Create(sel_merge_func, merge_vars, "", insert_before);
+			sel_merge_call->setCallingConv(CallingConv::FLOOR_FUNC);
+		};
+		
+		// recursively traverses a StructuralAnalysis node tree, applying the specified handler function on each combined node
+		template <typename F>
+		void node_recurse(const SA::NodeTy* node, SA& cfg_analysis, F&& handler) {
+			if(!node->isCombined) return;
+			
+			BasicBlock* this_block = cfg_analysis.mapNode2BB(node);
+			handler(node, this_block);
+			
+			for(const auto* child : node->childNode) {
+				node_recurse(child, cfg_analysis, std::forward<F&&>(handler));
+			}
+		}
+		
+		// this applies simple fixes on the CFG:
+		//  * split SelfLoops (single loops) into a header and body block
+		//  * clone / split off trivial exit blocks (to somewhat mitigate the "single merge block" problem)
+		void restructure_simple() {
+			DBG(errs() << "> simple CFG restructuring\n";)
+			StructuralAnalysis cfg_analysis;
+			cfg_analysis.analyze(*func);
+			DBG(cfg_analysis.write(errs());)
+			
+			node_recurse(*cfg_analysis.Net.begin(), cfg_analysis,
+						 [this](const SA::NodeTy* node, BasicBlock* this_block) {
+				switch(node->nodeType) {
+					case SA::SelfLoop: {
+						DBG(errs() << ">> splitting self loop: " << this_block->getName() << "\n";)
+						SplitBlock(this_block, this_block->getFirstNonPHI());
+						was_modified = true;
+						break;
+					}
+					case SA::IfThen:
+					case SA::IfThenElse: {
+						BranchInst* branch = dyn_cast<BranchInst>(this_block->getTerminator());
+						assert(branch != nullptr && "if-then/if-then-else block must have a branch instruction");
+						if(node->exitBB != nullptr &&
+						   is_simple_bb(node->exitBB) &&
+						   branch->isConditional()) {
+							// only do this for immediate branches to a trivial exit block, otherwise continue
+							BasicBlock* branches[] { branch->getSuccessor(0), branch->getSuccessor(1) };
+							const bool simple_bb[] {
+								is_simple_bb(branches[0]),
+								is_simple_bb(branches[1]),
+							};
+							if(simple_bb[0] || simple_bb[1]) {
+								const uint32_t simple_idx = (simple_bb[0] ? 0 : 1);
+								
+								DBG(errs() << ">> added new trivial exit: in: " << this_block->getName() << ", exit: " << branches[simple_idx]->getName() << "\n";)
+								
+								ValueToValueMapTy dummy_vmap;
+								auto new_exit = CloneBasicBlock(branches[simple_idx], dummy_vmap, ".exit", func);
+								branch->setSuccessor(simple_idx, new_exit);
+								was_modified = true;
+							}
+						}
+						break;
+					}
+					default: break;
+				}
+			});
+		}
+		
+		void restructure_and_annotate() {
+			DBG(errs() << "> final CFG restructuring and annotating\n";)
+			StructuralAnalysis cfg_analysis;
+			cfg_analysis.analyze(*func);
+			DBG(cfg_analysis.write(errs());)
+			
+			// compute LoopInfo from the DT (ideally we could use the StructuralAnalysis info for this,
+			// but it doesn't provide (correct) back-edge info)
+			if(was_modified) {
+				DT->recalculate(*func);
+			}
+			LoopInfo LI(*DT);
+			
+			// first: gather all merge block information
+			struct merge_info {
+				BasicBlock* header_block;
+				BasicBlock* continue_block; // nullptr if not a loop (TODO: still needed with node?)
+				const SA::NodeTy* node;
+			};
+			std::unordered_map<BasicBlock*, std::vector<merge_info>> merge_blocks;
+			std::unordered_set<BasicBlock*> loop_header_blocks, selection_header_blocks;
+			node_recurse(*cfg_analysis.Net.begin(), cfg_analysis, [this, &cfg_analysis,
+																   &loop_header_blocks,
+																   &selection_header_blocks,
+																   &LI, &merge_blocks](const SA::NodeTy* node,
+																					   BasicBlock* this_block) {
+				switch(node->nodeType) {
+					case SA::NaturalLoop: {
+						assert(node->exitBB != nullptr && "must have an exit block");
+						DBG(errs() << ">> @loop: " << this_block->getName() << "\n";)
+						Loop* loop = LI.getLoopFor(this_block);
+						assert(loop != nullptr && "must have LoopInfo for this loop BB!");
+						BasicBlock* back_edge = loop->getLoopLatch();
+						if(back_edge == nullptr) {
+							report_fatal_error("did not find the loop back-edge");
+							llvm_unreachable("did not find the loop back-edge");
+						}
+						DBG(errs() << "loop back-edge: " << back_edge->getName() << "\n";)
+						DBG(errs() << "loop merge: " << node->exitBB->getName() << "\n";)
+						loop_header_blocks.emplace(this_block);
+						merge_blocks[node->exitBB].emplace_back(merge_info { this_block, back_edge, node });
+						break;
+					}
+					case SA::IfThen:
+					case SA::IfThenElse: {
+						BranchInst* branch = dyn_cast<BranchInst>(this_block->getTerminator());
+						assert(branch != nullptr && "if-then/if-then-else block must have a branch instruction");
+						if(branch->isConditional()) {
+							// if this selection header block is also a loop header block, split it before the branch,
+							// because blocks can't be both (according to the current spec)
+							// NOTE: will always encounter NaturalLoop before IfThen/IfThenElse of the same block
+							if(loop_header_blocks.count(this_block) > 0) {
+								this_block = SplitBlock(this_block, this_block->getTerminator(), DT, &LI);
+								was_modified = true;
+							}
+							
+							// check if either successor is a simple return block (only this block is it's predecessor)
+							// if so, make the other block the merge block (outcome doesn't matter if both return)
+							const bool is_simple_return_bb[] {
+								branch->getSuccessor(0)->succ_empty() &&
+								branch->getSuccessor(0)->getSinglePredecessor() == this_block,
+								branch->getSuccessor(1)->succ_empty() &&
+								branch->getSuccessor(1)->getSinglePredecessor() == this_block,
+							};
+							if(is_simple_return_bb[0] || is_simple_return_bb[1]) {
+								merge_blocks[is_simple_return_bb[0] ?
+											 branch->getSuccessor(1) :
+											 branch->getSuccessor(0)].emplace_back(merge_info { this_block, nullptr, node });
+							}
+							// if not, make the exit block the merge block
+							else {
+								assert(node->exitBB != nullptr && "must have an exit block");
+								merge_blocks[node->exitBB].emplace_back(merge_info { this_block, nullptr, node });
+							}
+							selection_header_blocks.emplace(this_block);
+						}
+						// else: don't need to handle unconditionals
+						break;
+					}
+					case SA::SelfLoop: {
+						report_fatal_error("CFG should no longer contain self-loops!");
+						llvm_unreachable("CFG should no longer contain self-loops!");
+					}
+					// TODO: how to handle other invalid types?
+					default: break;
+				}
+			});
+			
+			// then: add (loop|selection) merge annotations + possibly restructure the CFG if a merge block has multiple users
+			for(auto& merge_block : merge_blocks) {
+				// simple case: single-user merge block
+				if(merge_block.second.size() == 1) {
+					// loop
+					const auto& info = merge_block.second[0];
+					if(info.continue_block != nullptr) {
+						create_loop_merge(info.header_block->getTerminator(),
+										  merge_block.first, info.continue_block);
+					}
+					// selection
+					else {
+						create_selection_merge(info.header_block->getTerminator(), merge_block.first);
+					}
+					continue;
+				}
+				
+				// will always modify something after this
+				was_modified = true;
+				DBG(errs() << ">> multi-user merge block: " << merge_block.first->getName() << "\n";
+				for(const auto& info : merge_block.second) {
+					errs() << "\tuser: " << info.header_block->getName() << "\n";
+				}
+				errs() << "\n";)
+				
+				// figure out the merge tree we need to create
+				// (due to the merge-block dominator requirements we can't just simply create a chain or binary tree)
+				// NOTE: there will always be a single parent node and it will always be the first entry in
+				//       merge_block.second (unstructured -> structured cfg transformation makes sure of this)
+				struct merge_node {
+					const merge_info& info;
+					std::vector<merge_node> children;
+				};
+				const std::function<merge_node(const merge_info&)> merge_tree_recurse =
+					[&merge_tree_recurse, &merge_block, &cfg_analysis /* TODO: if needed */](const merge_info& info) {
+						merge_node node { info, {} };
+						for(auto* direct_child : info.node->childNode) {
+							if(!direct_child->isCombined) continue;
+							
+							std::deque<SA::NodeTy*> child_stack;
+							child_stack.emplace_back(direct_child);
+							while(!child_stack.empty()) {
+								auto* child = child_stack[0];
+								child_stack.pop_front();
+								if(!child->isCombined) continue;
+								
+								const auto iter = std::find_if(merge_block.second.cbegin(), merge_block.second.cend(),
+															   [child](const merge_info& entry) {
+																   return (entry.node == child);
+															   });
+								if(iter != merge_block.second.cend()) {
+									node.children.emplace_back(merge_tree_recurse(*iter));
+									break;
+								}
+								else {
+									for(auto* indirect_child : child->childNode) {
+										child_stack.emplace_back(indirect_child);
+									}
+								}
+							}
+						}
+						return node;
+					};
+				merge_node merge_tree = merge_tree_recurse(merge_block.second[0]);
+				
+				const std::function<void(const merge_node&, const uint32_t)> dump_merge_tree =
+					[&dump_merge_tree, &loop_header_blocks](const merge_node& node, const uint32_t level) {
+						for(uint32_t i = 0; i < level; ++i) errs() << "  ";
+						errs() << node.info.header_block->getName() << "(loop: " << (node.info.continue_block != nullptr ? 1 : 0) << ", " << loop_header_blocks.count(node.info.header_block) << ")\n";
+						for(const auto& child : node.children) {
+							dump_merge_tree(child, level + 1);
+						}
+					};
+				DBG(errs() << "## merge-tree:\n";
+				dump_merge_tree(merge_tree, 1);
+				errs() << "####\n";)
+				
+				// create the actual merge tree + insert resp. merge instructions
+				BasicBlock* merge_bb = merge_block.first;
+				const std::function<void(const merge_node&,
+										 BasicBlock*,
+										 const uint32_t,
+										 const uint32_t)> create_cfg_merge_tree =
+					[this, &create_cfg_merge_tree](const merge_node& node,
+												   BasicBlock* this_merge_block,
+												   const uint32_t level,
+												   const uint32_t child_idx) {
+						BasicBlock* header = node.info.header_block;
+						
+						std::vector<BasicBlock*> child_merge_bbs;
+						for(const auto& child : node.children) {
+							std::unordered_set<BasicBlock*> preds, visited;
+							// TODO: this is inefficient
+							const std::function<void(BasicBlock* bb)> get_preds =
+								[&get_preds, &preds, &visited, &this_merge_block](BasicBlock* bb) {
+									if(visited.count(bb) > 0) return;
+									visited.emplace(bb);
+									for(auto* succ : bb->successors()) {
+										if(succ == this_merge_block) {
+											preds.emplace(bb);
+										}
+										else {
+											get_preds(succ);
+										}
+									}
+								};
+							get_preds(child.info.header_block);
+							if(preds.empty()) continue;
+							
+							std::vector<BasicBlock*> preds_vec(preds.cbegin(), preds.cend());
+							DBG(errs() << "@" << header->getName() << ", split off:\n";
+							for(const auto* pred : preds_vec) {
+								errs() << "\tpred: " << pred->getName() << "\n";
+							})
+							
+							child_merge_bbs.emplace_back(SplitBlockPredecessors(this_merge_block, preds_vec,
+																				"merge", DT, nullptr, false));
+						}
+						
+						uint32_t cidx = 0;
+						for(const auto& child : node.children) {
+							create_cfg_merge_tree(child, child_merge_bbs[cidx], level + 1, cidx);
+							cidx++;
+						}
+						
+						// add merge annotation
+						if(node.info.continue_block != nullptr) {
+							create_loop_merge(header->getTerminator(), this_merge_block, node.info.continue_block);
+						}
+						else {
+							create_selection_merge(header->getTerminator(), this_merge_block);
+						}
+						
+						return;
+					};
+				create_cfg_merge_tree(merge_tree, merge_bb, 0, 0);
+			}
+			
+			// final cleanup: sort BBs according to the DT
+			sort_bbs();
+		}
+		
+		bool runOnFunction(Function &F) override {
+			M = F.getParent();
+			ctx = &M->getContext();
+			func = &F;
+			was_modified = false;
+			
+			DT = &getAnalysis<DominatorTreeWrapperPass>().getDomTree();
+			
+#if 0
+			DBG(
+				errs() << "#################### func before: " << F.getName() << " ####\n" << F << "\n";
+				for(Loop* loop : *LI) {
+					loop->dump();
+				}
+			)
+#endif
+			
+			// initial unstructured -> structured control flow fixes
+			DBG(errs() << "> fixing unstructured control flow\n";)
+			StructuralTransform cfg_transform;
+			was_modified |= cfg_transform.transform(F);
+			
+			// apply simple cfg fixes
+			restructure_simple();
+			
+			// vulkan/spir-v specific annotations / cfg restructuring
+			restructure_and_annotate();
+			DBG({
+				StructuralAnalysis cfg_analysis;
+				cfg_analysis.analyze(F);
+				cfg_analysis.write(errs());
+			})
+			
+#if 0
+			DBG(
+				errs() << "#################### func after: " << F.getName() << " ####\n" << F << "\n";
+			)
+#endif
+			
+			DBG(errs() << "## " << F.getName() << " modified? " << was_modified << "\n";)
+			return was_modified;
+		}
+	};
+
+}
+
+char CFGStructurization::ID = 0;
+FunctionPass *llvm::createCFGStructurizationPass() {
+	return new CFGStructurization();
+}
+INITIALIZE_PASS_BEGIN(CFGStructurization, "CFGStructurization", "CFGStructurization Pass", false, false)
+INITIALIZE_PASS_DEPENDENCY(DominatorTreeWrapperPass)
+INITIALIZE_PASS_END(CFGStructurization, "CFGStructurization", "CFGStructurization Pass", false, false)
+
diff --git a/lib/Transforms/Scalar/CMakeLists.txt b/lib/Transforms/Scalar/CMakeLists.txt
index 9f04344..2500b89 100644
--- a/lib/Transforms/Scalar/CMakeLists.txt
+++ b/lib/Transforms/Scalar/CMakeLists.txt
@@ -1,4 +1,17 @@
 add_llvm_library(LLVMScalarOpts
+  AddressSpaceFix.cpp
+  CUDAImage.cpp
+  CUDAFinal.cpp
+  MetalFinal.cpp
+  SPIRFinal.cpp
+  CFGStructurization.cpp
+  StructuralAnalysis.cpp
+  StructuralTransform.cpp
+  VulkanFinal.cpp
+  FloorImage.cpp
+  MetalImage.cpp
+  SPIRImage.cpp
+  PropagateRangeInfo.cpp
   ADCE.cpp
   AlignmentFromAssumptions.cpp
   BDCE.cpp
diff --git a/lib/Transforms/Scalar/CUDAFinal.cpp b/lib/Transforms/Scalar/CUDAFinal.cpp
new file mode 100644
index 0000000..9f08fe5
--- /dev/null
+++ b/lib/Transforms/Scalar/CUDAFinal.cpp
@@ -0,0 +1,116 @@
+//===- CUDAFinal.cpp - CUDA final pass ------------------------------------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+// TODO
+//
+//===----------------------------------------------------------------------===//
+
+#include "llvm/ADT/Statistic.h"
+#include "llvm/ADT/STLExtras.h"
+#include "llvm/ADT/SetVector.h"
+#include "llvm/ADT/SmallPtrSet.h"
+#include "llvm/ADT/SmallVector.h"
+#include "llvm/ADT/StringExtras.h"
+#include "llvm/Analysis/AliasAnalysis.h"
+#include "llvm/IR/CFG.h"
+#include "llvm/IR/CallSite.h"
+#include "llvm/IR/CallingConv.h"
+#include "llvm/IR/ConstantRange.h"
+#include "llvm/IR/Constants.h"
+#include "llvm/IR/DataLayout.h"
+#include "llvm/IR/DebugInfo.h"
+#include "llvm/IR/DerivedTypes.h"
+#include "llvm/IR/Dominators.h"
+#include "llvm/IR/Function.h"
+#include "llvm/IR/InlineAsm.h"
+#include "llvm/IR/InstIterator.h"
+#include "llvm/IR/InstVisitor.h"
+#include "llvm/IR/IntrinsicInst.h"
+#include "llvm/IR/IRBuilder.h"
+#include "llvm/IR/LLVMContext.h"
+#include "llvm/IR/Metadata.h"
+#include "llvm/IR/Module.h"
+#include "llvm/IR/LegacyPassManager.h"
+#include "llvm/Pass.h"
+#include "llvm/Support/CommandLine.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/ErrorHandling.h"
+#include "llvm/Support/raw_ostream.h"
+#include "llvm/Transforms/IPO/PassManagerBuilder.h"
+#include "llvm/Transforms/IPO.h"
+#include "llvm/Transforms/Scalar.h"
+#include <algorithm>
+#include <cstdarg>
+#include <memory>
+#include <cxxabi.h>
+using namespace llvm;
+
+#define DEBUG_TYPE "CUDAFinal"
+
+#if 1
+#define DBG(x)
+#else
+#define DBG(x) x
+#endif
+
+namespace {
+	// CUDAFinal
+	struct CUDAFinal : public FunctionPass, InstVisitor<CUDAFinal> {
+		friend class InstVisitor<CUDAFinal>;
+		
+		static char ID; // Pass identification, replacement for typeid
+		
+		std::shared_ptr<llvm::IRBuilder<>> builder;
+		
+		Module* M { nullptr };
+		LLVMContext* ctx { nullptr };
+		Function* func { nullptr };
+		Instruction* alloca_insert { nullptr };
+		bool was_modified { false };
+		
+		CUDAFinal() : FunctionPass(ID) {
+			initializeCUDAFinalPass(*PassRegistry::getPassRegistry());
+		}
+		
+		bool runOnFunction(Function &F) override {
+			// exit if empty function
+			if(F.empty()) return false;
+			
+			// if not a kernel function, return (for now)
+			if(F.getCallingConv() != CallingConv::FLOOR_KERNEL) return false;
+			
+			// reset
+			M = F.getParent();
+			ctx = &M->getContext();
+			func = &F;
+			builder = std::make_shared<llvm::IRBuilder<>>(*ctx);
+			was_modified = false;
+			
+			// visit everything in this function
+			DBG(errs() << "in func: "; errs().write_escaped(F.getName()) << '\n';)
+			visit(F);
+			return was_modified;
+		}
+		
+		// InstVisitor overrides...
+		using InstVisitor<CUDAFinal>::visit;
+		void visit(Instruction& I) {
+			InstVisitor<CUDAFinal>::visit(I);
+		}
+		
+	};
+}
+
+char CUDAFinal::ID = 0;
+INITIALIZE_PASS_BEGIN(CUDAFinal, "CUDAFinal", "CUDAFinal Pass", false, false)
+INITIALIZE_PASS_END(CUDAFinal, "CUDAFinal", "CUDAFinal Pass", false, false)
+
+FunctionPass *llvm::createCUDAFinalPass() {
+	return new CUDAFinal();
+}
diff --git a/lib/Transforms/Scalar/CUDAImage.cpp b/lib/Transforms/Scalar/CUDAImage.cpp
new file mode 100644
index 0000000..2171e45
--- /dev/null
+++ b/lib/Transforms/Scalar/CUDAImage.cpp
@@ -0,0 +1,643 @@
+//===- CUDAImage.cpp - CUDA-specific floor image transformations ----------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+// This pass implements the CUDA-specific floor image transformations, i.e.
+// floor.cuda.<read/write function>.*
+//   -> PTX texture/surface instructions (inline asm)
+//
+//===----------------------------------------------------------------------===//
+
+#include "llvm/ADT/Statistic.h"
+#include "llvm/ADT/STLExtras.h"
+#include "llvm/ADT/SetVector.h"
+#include "llvm/ADT/SmallPtrSet.h"
+#include "llvm/ADT/SmallVector.h"
+#include "llvm/ADT/StringExtras.h"
+#include "llvm/Analysis/AliasAnalysis.h"
+#include "llvm/IR/CFG.h"
+#include "llvm/IR/CallSite.h"
+#include "llvm/IR/CallingConv.h"
+#include "llvm/IR/ConstantRange.h"
+#include "llvm/IR/Constants.h"
+#include "llvm/IR/DataLayout.h"
+#include "llvm/IR/DebugInfo.h"
+#include "llvm/IR/DerivedTypes.h"
+#include "llvm/IR/Dominators.h"
+#include "llvm/IR/Function.h"
+#include "llvm/IR/InlineAsm.h"
+#include "llvm/IR/InstIterator.h"
+#include "llvm/IR/InstVisitor.h"
+#include "llvm/IR/IntrinsicInst.h"
+#include "llvm/IR/IRBuilder.h"
+#include "llvm/IR/LLVMContext.h"
+#include "llvm/IR/Metadata.h"
+#include "llvm/IR/Module.h"
+#include "llvm/IR/LegacyPassManager.h"
+#include "llvm/Pass.h"
+#include "llvm/Support/CommandLine.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/ErrorHandling.h"
+#include "llvm/Support/raw_ostream.h"
+#include "llvm/Transforms/IPO/PassManagerBuilder.h"
+#include "llvm/Transforms/IPO.h"
+#include "llvm/Transforms/Scalar.h"
+#include "llvm/Transforms/Scalar/FloorImage.h"
+#include <algorithm>
+#include <cstdarg>
+#include <memory>
+#include <array>
+#include <cxxabi.h>
+using namespace llvm;
+
+#define DEBUG_TYPE "CUDAImage"
+
+#if 1
+#define DBG(x)
+#else
+#define DBG(x) x
+#endif
+
+namespace {
+	// CUDAImage
+	struct CUDAImage : public FloorImageBasePass {
+		static char ID; // Pass identification, replacement for typeid
+		
+		CUDAImage(const uint32_t image_capabilities_ = 0) :
+		FloorImageBasePass(ID, IMAGE_TYPE_ID::CUDA, image_capabilities_) {
+			initializeCUDAImagePass(*PassRegistry::getPassRegistry());
+		}
+		
+		void handle_read_image(Instruction& I,
+							   const StringRef& func_name,
+							   llvm::Value* img_handle_arg,
+							   const COMPUTE_IMAGE_TYPE& image_type,
+							   llvm::ConstantInt* const_sampler_arg,
+							   llvm::Value* dyn_sampler_arg,
+							   llvm::Value* coord_arg,
+							   llvm::Value* layer_arg,
+							   llvm::Value* sample_arg,
+							   llvm::Value* offset_arg,
+							   const SmallVector<llvm::Value*, 3>& offset_elems,
+							   const bool is_offset,
+							   llvm::Value* lod_or_bias_arg,
+							   const bool is_lod_or_bias, // true: lod, false: bias
+							   llvm::Value* dpdx_arg,
+							   llvm::Value* dpdy_arg,
+							   const bool is_gradient,
+							   const COMPARE_FUNCTION& compare_function,
+							   llvm::Value* compare_value_arg,
+							   const bool is_compare) override {
+			SmallVector<llvm::Type*, 16> asm_arg_types;
+			SmallVector<llvm::Value*, 16> asm_args;
+			std::string constraints_str = "";
+			
+			// -> return data
+			std::string dtype;
+			llvm::Type* ret_type, *ret_vec_type;
+			if(func_name == "floor.cuda.read_image.float") {
+				dtype = "f32";
+				constraints_str = "=f,=f,=f,=f";
+				ret_type = llvm::StructType::get(*ctx, std::vector<llvm::Type*> {{
+					llvm::Type::getFloatTy(*ctx),
+					llvm::Type::getFloatTy(*ctx),
+					llvm::Type::getFloatTy(*ctx),
+					llvm::Type::getFloatTy(*ctx)
+				}});
+				ret_vec_type = llvm::VectorType::get(llvm::Type::getFloatTy(*ctx), 4);
+			}
+			else if(func_name == "floor.cuda.read_image.int") {
+				dtype = "s32";
+				constraints_str = "=r,=r,=r,=r";
+				ret_type = llvm::StructType::get(*ctx, std::vector<llvm::Type*> {{
+					llvm::Type::getInt32Ty(*ctx),
+					llvm::Type::getInt32Ty(*ctx),
+					llvm::Type::getInt32Ty(*ctx),
+					llvm::Type::getInt32Ty(*ctx)
+				}});
+				ret_vec_type = llvm::VectorType::get(llvm::Type::getInt32Ty(*ctx), 4);
+			}
+			else if(func_name == "floor.cuda.read_image.uint") {
+				dtype = "u32";
+				constraints_str = "=r,=r,=r,=r";
+				ret_type = llvm::StructType::get(*ctx, std::vector<llvm::Type*> {{
+					llvm::Type::getInt32Ty(*ctx),
+					llvm::Type::getInt32Ty(*ctx),
+					llvm::Type::getInt32Ty(*ctx),
+					llvm::Type::getInt32Ty(*ctx)
+				}});
+				ret_vec_type = llvm::VectorType::get(llvm::Type::getInt32Ty(*ctx), 4);
+			}
+			// unknown -> ignore
+			else return;
+			
+			constraints_str += ",l"; // u64 tex handle
+			asm_arg_types.push_back(llvm::Type::getInt64Ty(*ctx));
+			asm_args.push_back(img_handle_arg);
+			
+			// -> geom
+			std::string geom; // .1d, .2d, .3d, .a1d, .a2d, .cube, .acube, .2dms, .a2dms
+			bool is_array = false, is_msaa = false, is_cube = false;
+			switch(image_type) {
+				case COMPUTE_IMAGE_TYPE::IMAGE_1D:					geom = "1d"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_1D_ARRAY:			geom = "a1d"; is_array = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_1D_BUFFER:			geom = "1d"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH:
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_STENCIL:
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D:					geom = "2d"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_ARRAY:
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D_ARRAY:			geom = "a2d"; is_array = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_MSAA:
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D_MSAA:				geom = "2dms"; is_msaa = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_MSAA_ARRAY:
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D_MSAA_ARRAY:		geom = "a2dms"; is_array = true; is_msaa = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_3D:					geom = "3d"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_CUBE:
+				case COMPUTE_IMAGE_TYPE::IMAGE_CUBE:				geom = "cube"; is_cube = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_CUBE_ARRAY:
+				case COMPUTE_IMAGE_TYPE::IMAGE_CUBE_ARRAY:			geom = "acube"; is_cube = true; is_array = true; break;
+				default:
+					ctx->emitError(&I, "unknown or incorrect image type");
+					return;
+			}
+			
+			// -> coords
+			auto coord_vec_type = dyn_cast_or_null<VectorType>(coord_arg->getType());
+			if(!coord_vec_type) {
+				ctx->emitError(&I, "invalid image coordinate argument (cast to vector failed)");
+				return;
+			}
+			const auto coord_dim = coord_vec_type->getVectorNumElements();
+			
+			const auto coord_type = coord_vec_type->getElementType();
+			if(is_msaa && !coord_type->isIntegerTy()) {
+				ctx->emitError(&I, "coordinate type must be integer for msaa images");
+				return;
+			}
+			
+			// TODO: add s/w support for reading cube maps with integer coords (u, v, face, *layer)
+			if(is_cube && !coord_type->isFloatTy()) {
+				ctx->emitError(&I, "coordinate type must be float for cube images");
+				return;
+			}
+			
+			std::string ctype = (coord_type->isFloatTy() ? "f32" : "s32");
+			std::string coords_placeholders;
+			const std::string coord_type_str = (coord_type->isFloatTy() ? "f" : "r");
+			uint32_t asm_arg_idx = 5;
+			if(is_msaa) {
+				asm_arg_types.push_back(sample_arg->getType());
+				asm_args.push_back(sample_arg);
+				constraints_str += ",r";
+				coords_placeholders += " $";
+				coords_placeholders += std::to_string(asm_arg_idx++);
+			}
+			if(is_array) {
+				asm_arg_types.push_back(layer_arg->getType());
+				asm_args.push_back(layer_arg);
+				constraints_str += ",r";
+				coords_placeholders += (!is_msaa ? " $" : ", $");
+				coords_placeholders += std::to_string(asm_arg_idx++);
+			}
+			for(uint32_t i = 0; i < coord_dim; ++i) {
+				asm_arg_types.push_back(coord_type);
+				asm_args.push_back(builder->CreateExtractElement(coord_arg, builder->getInt32(i)));
+				constraints_str += "," + coord_type_str;
+				coords_placeholders += (i == 0 && asm_arg_idx == 5 ? " $" : ", $");
+				coords_placeholders += std::to_string(asm_arg_idx++);
+			}
+			
+			// append (ignored) 0 coordinate if #coordinates == 3
+			if((coord_dim + (is_msaa ? 1 : 0) + (is_array ? 1 : 0)) == 3) {
+				coords_placeholders += (coord_type->isFloatTy() ? ", 0.0" : ", 0");
+			}
+			
+			// -> lod
+			std::string mipmap_prefix = "";
+			std::string lod_str = "";
+			if(is_lod_or_bias) {
+				mipmap_prefix = "level.";
+				lod_str = ", ";
+				// NOTE: lod type must match coord elem type, cast if necessary
+				if(const auto const_lod = dyn_cast_or_null<ConstantInt>(lod_or_bias_arg)) {
+					if(coord_type->isIntegerTy()) {
+						lod_str += std::to_string(const_lod->getSExtValue());
+					}
+					else {
+						// convert to float
+						lod_str += std::to_string((float)const_lod->getSExtValue());
+					}
+				}
+				else if(const auto const_lod = dyn_cast_or_null<ConstantFP>(lod_or_bias_arg)) {
+					if(coord_type->isFloatTy()) {
+						lod_str += std::to_string(const_lod->getValueAPF().convertToFloat());
+					}
+					else {
+						// convert to int
+						lod_str += std::to_string((int32_t)round(const_lod->getValueAPF().convertToFloat()));
+					}
+				}
+				else {
+					asm_arg_types.push_back(coord_type);
+					if(coord_type == lod_or_bias_arg->getType()) {
+						asm_args.push_back(lod_or_bias_arg);
+					}
+					else {
+						// convert to appropriate type
+						asm_args.push_back(coord_type->isIntegerTy() ?
+										   builder->CreateFPToSI(lod_or_bias_arg, coord_type) :
+										   builder->CreateSIToFP(lod_or_bias_arg, coord_type));
+					}
+					lod_str += "$" + std::to_string(asm_arg_idx++);
+					constraints_str += (coord_type->isIntegerTy() ? ",r" : ",f");
+				}
+			}
+			
+			// -> gradient
+			std::string gradient_str = "";
+			if(is_gradient) {
+				mipmap_prefix = "grad.";
+				
+				// dpdx
+				gradient_str += ", { ";
+				for(uint32_t i = 0; i < coord_dim; ++i) {
+					asm_arg_types.push_back(builder->getFloatTy());
+					asm_args.push_back(builder->CreateExtractElement(dpdx_arg, builder->getInt32(i)));
+					gradient_str += (i == 0 ? "$" : ", $") + std::to_string(asm_arg_idx++);
+					constraints_str += ",f";
+				}
+				if(coord_dim == 3) gradient_str += ", 0.0";
+				
+				// dpdy
+				gradient_str += " }, { ";
+				for(uint32_t i = 0; i < coord_dim; ++i) {
+					asm_arg_types.push_back(builder->getFloatTy());
+					asm_args.push_back(builder->CreateExtractElement(dpdy_arg, builder->getInt32(i)));
+					gradient_str += (i == 0 ? "$" : ", $") + std::to_string(asm_arg_idx++);
+					constraints_str += ",f";
+				}
+				if(coord_dim == 3) gradient_str += ", 0.0";
+				gradient_str += " }";
+			}
+			
+			// -> offset
+			std::string offset_str = "";
+			if(is_offset) {
+				for(uint32_t i = 0; i < coord_dim; ++i) {
+					if(i != 0) offset_str += ", ";
+					if(const auto const_offset_elem = dyn_cast_or_null<ConstantInt>(offset_elems[i])) {
+						offset_str += std::to_string(const_offset_elem->getSExtValue());
+					}
+					else {
+						asm_arg_types.push_back(llvm::Type::getInt32Ty(*ctx));
+						asm_args.push_back(offset_elems[i]);
+						offset_str += "$" + std::to_string(asm_arg_idx++);
+						constraints_str += ",r";
+					}
+				}
+				
+				// append ignored 0 offset
+				if(coord_dim == 3) {
+					offset_str += ", 0";
+				}
+			}
+			
+			// -> compare
+			std::string compare_str = "";
+			llvm::Value* compare_override = nullptr;
+			const bool has_hw_depth_compare = has_flag<IMAGE_CAPABILITY::DEPTH_COMPARE>(image_capabilities);
+			if(is_compare && has_hw_depth_compare) {
+				// must have float coords with depth compare
+				if(!coord_type->isFloatTy()) {
+					ctx->emitError(&I, "coordinate type must be float when using depth compare");
+					return;
+				}
+				
+				// check for unsupported image types
+				switch(image_type) {
+					case COMPUTE_IMAGE_TYPE::IMAGE_1D:
+					case COMPUTE_IMAGE_TYPE::IMAGE_1D_ARRAY:
+					case COMPUTE_IMAGE_TYPE::IMAGE_1D_BUFFER:
+					case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH:
+					case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_STENCIL:
+					case COMPUTE_IMAGE_TYPE::IMAGE_2D:
+					case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_ARRAY:
+					case COMPUTE_IMAGE_TYPE::IMAGE_2D_ARRAY:
+					case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_CUBE:
+					case COMPUTE_IMAGE_TYPE::IMAGE_CUBE:
+					case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_CUBE_ARRAY:
+					case COMPUTE_IMAGE_TYPE::IMAGE_CUBE_ARRAY:
+						// all supported
+						break;
+						
+					case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_MSAA:
+					case COMPUTE_IMAGE_TYPE::IMAGE_2D_MSAA:
+					case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_MSAA_ARRAY:
+					case COMPUTE_IMAGE_TYPE::IMAGE_2D_MSAA_ARRAY:
+					case COMPUTE_IMAGE_TYPE::IMAGE_3D:
+					default:
+						ctx->emitError(&I, "image type does not support depth compare");
+						return;
+				}
+				
+				asm_arg_types.push_back(builder->getFloatTy());
+				asm_args.push_back(compare_value_arg);
+				constraints_str += ",f";
+				compare_str = "$" + std::to_string(asm_arg_idx++);
+				
+				// directly skip/eval NONE/NEVER and ALWAYS compare functions
+				// while this would be DCE'ed anyways, this is somewhat cleaner
+				// NOTE: we still want all of the usual error messages and checking, which is why we're not doing this earlier
+				if(compare_function == COMPARE_FUNCTION::NONE ||
+				   compare_function == COMPARE_FUNCTION::NEVER) {
+					compare_override = ConstantFP::get(builder->getFloatTy(), 0.0f);
+				}
+				else if(compare_function == COMPARE_FUNCTION::ALWAYS) {
+					compare_override = ConstantFP::get(builder->getFloatTy(), 1.0f);
+				}
+			}
+			
+			// -> build asm string
+			std::string asm_str = "tex." + mipmap_prefix + geom + ".v4." + dtype + "." + ctype;
+			asm_str += " { $0, $1, $2, $3 },";
+			asm_str += " [$4, {" + coords_placeholders + " }]";
+			if(is_lod_or_bias) {
+				asm_str += lod_str;
+			}
+			if(is_gradient) {
+				asm_str += gradient_str;
+			}
+			if(is_offset) {
+				asm_str += ", { " + offset_str + " }";
+			}
+			if(is_compare && has_hw_depth_compare) {
+				asm_str += ", " + compare_str;
+			}
+			asm_str += ";";
+			
+			const auto asm_func_type = FunctionType::get(ret_type, asm_arg_types, false);
+			auto asm_func = InlineAsm::get(asm_func_type, asm_str, constraints_str, false /* non-volatile */);
+			auto asm_call = builder->CreateCall(asm_func, asm_args);
+			asm_call->setDoesNotAccessMemory(); // all reads are readnone (can be optimized away if unused)
+			asm_call->setDebugLoc(I.getDebugLoc()); // keep debug loc
+			asm_call->setNotConvergent();
+			
+			//
+			llvm::Value* dst_vec = UndefValue::get(ret_vec_type);
+			if(compare_override == nullptr) {
+				// -> normal color read or h/w depth compare
+				if(!is_compare || has_hw_depth_compare) {
+					for(uint32_t i = 0; i < 4; ++i) {
+						auto scalar = builder->CreateExtractValue(asm_call, i);
+						dst_vec = builder->CreateInsertElement(dst_vec, scalar, builder->getInt32(i));
+					}
+				}
+				// -> s/w depth compare
+				else {
+					emulate_depth_compare(dst_vec, builder->CreateExtractValue(asm_call, 0), compare_function, compare_value_arg);
+				}
+			}
+			// -> compare override (NONE/NEVER/ALWAYS), don't emit tex instruction
+			else {
+				dst_vec = builder->CreateInsertElement(dst_vec, compare_override, builder->getInt32(0));
+			}
+			
+			//
+			I.replaceAllUsesWith(dst_vec);
+			I.eraseFromParent();
+		}
+		
+		void handle_write_image(Instruction& I,
+								const StringRef& func_name,
+								llvm::Value* img_handle_arg,
+								const COMPUTE_IMAGE_TYPE& image_type,
+								const COMPUTE_IMAGE_TYPE& format_type,
+								const COMPUTE_IMAGE_TYPE& data_type,
+								const bool& is_normalized,
+								const uint32_t& image_channel_count,
+								llvm::Value* coord_arg,
+								llvm::Value* layer_arg,
+								// NOTE: lod is handled on the library side
+								llvm::Value* /* lod_arg */,
+								const bool /* is_lod */,
+								llvm::Value* data_arg) override {
+			SmallVector<llvm::Type*, 16> asm_arg_types;
+			SmallVector<llvm::Value*, 16> asm_args;
+			
+			//// more arg checking
+			
+			// check if format is supported (only for cuda image write)
+			switch(format_type) {
+				case COMPUTE_IMAGE_TYPE::FORMAT_8:
+				case COMPUTE_IMAGE_TYPE::FORMAT_16:
+				case COMPUTE_IMAGE_TYPE::FORMAT_24: // as 32-bit
+				case COMPUTE_IMAGE_TYPE::FORMAT_32:
+				case COMPUTE_IMAGE_TYPE::FORMAT_32_8: // for depth+stencil
+					break;
+				default:
+					// all else: nope
+					ctx->emitError(&I, "unsupported image format (must be 8-bit, 16-bit, 24-bit or 32-bit per channel)");
+					return;
+			}
+			
+			auto coord_vec_type = dyn_cast_or_null<VectorType>(coord_arg->getType());
+			if(!coord_vec_type) {
+				ctx->emitError(&I, "invalid image coordinate argument (cast to vector failed)");
+				return;
+			}
+			
+			const auto coord_type = coord_vec_type->getElementType();
+			if(!coord_type->isIntegerTy()) {
+				ctx->emitError(&I, "coordinate type must be integer");
+				return;
+			}
+			
+			if(func_name != "floor.cuda.write_image.float" &&
+			   func_name != "floor.cuda.write_image.int" &&
+			   func_name != "floor.cuda.write_image.uint") {
+				return; // unknown -> ignore
+			}
+			
+			//// func replacement
+			std::string constraints_str = "l"; // u64 surf handle
+			asm_arg_types.push_back(llvm::Type::getInt64Ty(*ctx));
+			asm_args.push_back(img_handle_arg);
+			
+			// -> geom
+			std::string geom; // .1d, .2d, .3d, .a1d, .a2d
+			bool is_array = false;
+			switch(image_type) {
+				case COMPUTE_IMAGE_TYPE::IMAGE_1D:					geom = "1d"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_1D_ARRAY:			geom = "a1d"; is_array = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_1D_BUFFER:			geom = "1d"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH:
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_STENCIL:
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D:					geom = "2d"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_ARRAY:
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D_ARRAY:			geom = "a2d"; is_array = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_3D:					geom = "3d"; break;
+				// cube and msaa formats are not writable by cuda/ptx
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_MSAA:
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D_MSAA:
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_MSAA_ARRAY:
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D_MSAA_ARRAY:
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_CUBE:
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_CUBE_ARRAY:
+				case COMPUTE_IMAGE_TYPE::IMAGE_CUBE:
+				case COMPUTE_IMAGE_TYPE::IMAGE_CUBE_ARRAY:
+					ctx->emitError(&I, "invalid image type - type is not writable");
+					return;
+				default:
+					ctx->emitError(&I, "unknown or incorrect image type");
+					return;
+			}
+			
+			// -> coords
+			const auto coord_dim = coord_vec_type->getVectorNumElements();
+			std::string coords_placeholders;
+			static const uint32_t coord_start_idx = 1;
+			uint32_t coord_idx = 0;
+			size_t x_coord_idx = 0;
+			if(is_array) {
+				asm_arg_types.push_back(layer_arg->getType());
+				asm_args.push_back(layer_arg);
+				constraints_str += ",r";
+				coords_placeholders += " $";
+				coords_placeholders += std::to_string(coord_start_idx + coord_idx++);
+			}
+			for(uint32_t i = 0; i < coord_dim; ++i) {
+				asm_arg_types.push_back(coord_type);
+				auto coord_elem = builder->CreateExtractElement(coord_arg, builder->getInt32(i));
+				if(i == 0) {
+					x_coord_idx = asm_args.size();
+				}
+				asm_args.push_back(coord_elem);
+				constraints_str += ",r";
+				coords_placeholders += (coord_idx == 0 ? " $" : ", $");
+				coords_placeholders += std::to_string(coord_start_idx + coord_idx++);
+			}
+			
+			// append (ignored) 0 coordinate if #coordinates == 3
+			if((coord_dim + (is_array ? 1 : 0)) == 3) {
+				coords_placeholders += ", 0";
+			}
+			
+			// -> data
+			const auto write_channel_count = (image_channel_count == 3 ? 4 : image_channel_count);
+			std::array<llvm::Value*, 4> data_args {{
+				builder->CreateExtractElement(data_arg, builder->getInt32(0)),
+				builder->CreateExtractElement(data_arg, builder->getInt32(1)),
+				builder->CreateExtractElement(data_arg, builder->getInt32(2)),
+				builder->CreateExtractElement(data_arg, builder->getInt32(3))
+			}};
+			
+			std::string dtype, rtype;
+			const bool is_signed_int = ((data_type & COMPUTE_IMAGE_TYPE::__DATA_TYPE_MASK) == COMPUTE_IMAGE_TYPE::INT);
+			const bool is_float = ((data_type & COMPUTE_IMAGE_TYPE::__DATA_TYPE_MASK) == COMPUTE_IMAGE_TYPE::FLOAT);
+			if(is_normalized) {
+				// need to normalize 32-bit float -> 8-bit or 16-bit unsigned/signed int
+				if(format_type != COMPUTE_IMAGE_TYPE::FORMAT_8 && format_type != COMPUTE_IMAGE_TYPE::FORMAT_16) {
+					ctx->emitError(&I, "invalid normalized write format (expected 8-bit or 16-bit dst format");
+					return;
+				}
+				
+				bool is_8_bit = true;
+				if(format_type == COMPUTE_IMAGE_TYPE::FORMAT_8) {
+					dtype = "b8";
+				}
+				else {
+					dtype = "b16";
+					is_8_bit = false;
+				}
+				rtype = "h"; // can't go lower than 16-bit
+				
+				for(uint32_t i = 0; i < write_channel_count; ++i) {
+					data_args[i] = builder->CreateFMul(data_args[i],
+													   ConstantFP::get(builder->getFloatTy(),
+																	   is_signed_int ?
+																	   (is_8_bit ? 127.0 : 32767.0) :
+																	   (is_8_bit ? 255.0 : 65535.0)));
+					data_args[i] = builder->CreateFPToUI(data_args[i],
+														 is_8_bit ? builder->getInt8Ty() : builder->getInt16Ty());
+				}
+			}
+			else {
+				switch(format_type) {
+					case COMPUTE_IMAGE_TYPE::FORMAT_8:
+						dtype = "b8";
+						rtype = "h"; // can't go lower than 16-bit
+						break;
+					case COMPUTE_IMAGE_TYPE::FORMAT_16:
+						dtype = "b16";
+						rtype = (is_float ? "f" : "h");
+						break;
+					case COMPUTE_IMAGE_TYPE::FORMAT_24:
+					case COMPUTE_IMAGE_TYPE::FORMAT_32_8:
+					case COMPUTE_IMAGE_TYPE::FORMAT_32:
+						dtype = "b32";
+						rtype = (is_float ? "f" : "r");
+						break;
+					default:
+						ctx->emitError(&I, "invalid write format");
+						return;
+				}
+				
+				// need to trunc 32-bit data to 16-bit (for 8-bit/16-bit int/uint writes)
+				if(rtype == "h") {
+					for(uint32_t i = 0; i < write_channel_count; ++i) {
+						builder->CreateTrunc(data_args[i], builder->getInt16Ty());
+					}
+				}
+			}
+			
+			// we know the written binary data size now -> update x coordinate offset
+			asm_args[x_coord_idx] = builder->CreateMul(asm_args[x_coord_idx],
+													   builder->getInt32(write_channel_count *
+																		 (dtype == "b16" ? 2 :
+																		  (dtype == "b32" ? 4 : 1 /* b8 */))));
+			
+			std::string data_placeholders;
+			uint32_t data_idx = coord_start_idx + coord_idx;
+			for(uint32_t i = 0; i < write_channel_count; ++i) {
+				asm_arg_types.push_back(data_args[i]->getType());
+				asm_args.push_back(data_args[i]);
+				constraints_str += "," + rtype;
+				data_placeholders += (i == 0 ? " $" : ", $");
+				data_placeholders += std::to_string(data_idx++);
+			}
+			
+			// -> build asm string
+			std::string asm_str = "sust.b." + geom + ".";
+			asm_str += (image_channel_count == 1 ? "" : (image_channel_count == 2 ? "v2." : "v4."));
+			asm_str += dtype + ".";
+			asm_str += "zero"; // ignore out-of-bounds writes (TODO: might want to trap in debug mode?)
+			
+			asm_str += " [$0, {" + coords_placeholders + " }],";
+			asm_str += " {" + data_placeholders + " };";
+			
+			const auto asm_func_type = FunctionType::get(builder->getVoidTy(), asm_arg_types, false);
+			auto asm_func = InlineAsm::get(asm_func_type, asm_str, constraints_str, true /* volatile */);
+			auto asm_call = builder->CreateCall(asm_func, asm_args);
+			asm_call->setDebugLoc(I.getDebugLoc()); // keep debug loc
+			asm_call->setNotConvergent();
+			
+			//
+			I.replaceAllUsesWith(asm_call);
+			I.eraseFromParent();
+		}
+		
+	};
+}
+
+char CUDAImage::ID = 0;
+INITIALIZE_PASS_BEGIN(CUDAImage, "CUDAImage", "CUDAImage Pass", false, false)
+INITIALIZE_PASS_END(CUDAImage, "CUDAImage", "CUDAImage Pass", false, false)
+
+FunctionPass *llvm::createCUDAImagePass(const uint32_t image_capabilities) {
+	return new CUDAImage(image_capabilities);
+}
diff --git a/lib/Transforms/Scalar/FloorImage.cpp b/lib/Transforms/Scalar/FloorImage.cpp
new file mode 100644
index 0000000..2b58a8c
--- /dev/null
+++ b/lib/Transforms/Scalar/FloorImage.cpp
@@ -0,0 +1,450 @@
+//===- FloorImage.cpp - base class for image transformations --------------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+// This class defines and implements the base class for all
+// image transformations (CUDA and opaque, as used for Metal, OpenCL and Vulkan).
+//
+//===----------------------------------------------------------------------===//
+
+#include "llvm/Transforms/Scalar/FloorImage.h"
+#include "llvm/ADT/Statistic.h"
+#include "llvm/ADT/STLExtras.h"
+#include "llvm/ADT/SetVector.h"
+#include "llvm/ADT/SmallPtrSet.h"
+#include "llvm/ADT/SmallVector.h"
+#include "llvm/ADT/StringExtras.h"
+#include "llvm/Analysis/AliasAnalysis.h"
+#include "llvm/IR/CFG.h"
+#include "llvm/IR/CallSite.h"
+#include "llvm/IR/CallingConv.h"
+#include "llvm/IR/ConstantRange.h"
+#include "llvm/IR/Constants.h"
+#include "llvm/IR/DataLayout.h"
+#include "llvm/IR/DebugInfo.h"
+#include "llvm/IR/DerivedTypes.h"
+#include "llvm/IR/Dominators.h"
+#include "llvm/IR/Function.h"
+#include "llvm/IR/InlineAsm.h"
+#include "llvm/IR/Metadata.h"
+#include "llvm/IR/Module.h"
+#include "llvm/IR/LegacyPassManager.h"
+#include "llvm/Support/CommandLine.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/ErrorHandling.h"
+#include "llvm/Support/raw_ostream.h"
+#include "llvm/Transforms/IPO/PassManagerBuilder.h"
+#include "llvm/Transforms/IPO.h"
+#include "llvm/Transforms/Scalar.h"
+#include <cxxabi.h>
+using namespace llvm;
+
+#if 1
+#define DBG(x)
+#else
+#define DBG(x) x
+#endif
+
+FloorImageBasePass::FloorImageBasePass(char &ID,
+									   const IMAGE_TYPE_ID& image_type_id_,
+									   const uint32_t& image_capabilities_)
+: FunctionPass(ID), image_type_id(image_type_id_),
+image_read_prefix(image_type_id == IMAGE_TYPE_ID::CUDA ? "floor.cuda.read_image." : "floor.opaque.read_image."),
+image_write_prefix(image_type_id == IMAGE_TYPE_ID::CUDA ? "floor.cuda.write_image." : "floor.opaque.write_image."),
+image_capabilities((IMAGE_CAPABILITY)image_capabilities_) {
+}
+
+bool FloorImageBasePass::runOnFunction(Function &F) {
+	// exit if empty function
+	if(F.empty()) return false;
+	
+	// reset
+	M = F.getParent();
+	ctx = &M->getContext();
+	func = &F;
+	builder = std::make_shared<llvm::IRBuilder<>>(*ctx);
+	was_modified = false;
+	
+	{
+		AttrBuilder attr_builder;
+		attr_builder.addAttribute(llvm::Attribute::NoUnwind);
+		attr_builder.addAttribute(llvm::Attribute::ReadNone);
+		nounwind_readnone_attr = AttributeSet::get(*ctx, ~0, attr_builder);
+	}
+	{
+		AttrBuilder attr_builder;
+		attr_builder.addAttribute(llvm::Attribute::NoUnwind);
+		nounwind_attr = AttributeSet::get(*ctx, ~0, attr_builder);
+	}
+	
+	// visit everything in this function
+	DBG(errs() << "in func: "; errs().write_escaped(F.getName()) << '\n';)
+	visit(F);
+	
+	return was_modified;
+}
+
+void FloorImageBasePass::visit(Instruction& I) {
+	InstVisitor<FloorImageBasePass>::visit(I);
+}
+
+void FloorImageBasePass::visitCallSite(CallSite CS) {
+	const auto func = CS.getCalledFunction();
+	if(!func) return;
+	
+	const auto full_func_name = func->getName();
+	if(full_func_name.startswith(image_read_prefix) ||
+	   full_func_name.startswith(image_write_prefix)) {
+		// strip off .(i|f)(1|2|3) from the end of the func name
+		const auto func_name = full_func_name.rsplit('.').first;
+		handle_image(CS, func_name);
+		was_modified = true;
+	}
+}
+
+void FloorImageBasePass::handle_image(CallSite& CS, const StringRef& func_name) {
+	Instruction* I = CS.getInstruction();
+	builder->SetInsertPoint(I);
+	const bool is_image_read = func_name.startswith(image_read_prefix);
+	
+	/* args for cuda and opaque read/write functions:
+	 
+	 cuda read:
+	 uint64_t tex, COMPUTE_IMAGE_TYPE type,
+	 coord_vec_type coord, uint32_t layer, uint32_t sample, offset_vec_type offset,
+	 int32_t lod_i, float lod_or_bias_f, bool is_lod, bool is_lod_float, bool is_bias,
+	 gradient_vec_type dpdx, gradient_vec_type dpdy, bool is_gradient,
+	 COMPARE_FUNCTION compare_function, float compare_value, bool is_compare
+	 
+	 cuda write:
+	 uint64_t surf, COMPUTE_IMAGE_TYPE type, coord_vec_type coord, uint32_t layer, uint32_t lod, bool is_lod, data_vec_type data
+	 
+	 opaque read:
+	 image_t img, sampler_type smplr, COMPUTE_IMAGE_TYPE type,
+	 coord_vec_type coord, uint32_t layer, uint32_t sample, offset_vec_type offset,
+	 int32_t lod_i, float lod_or_bias_f, bool is_lod, bool is_lod_float, bool is_bias,
+	 gradient_vec_type dpdx, gradient_vec_type dpdy, bool is_gradient,
+	 COMPARE_FUNCTION compare_function, float compare_value, bool is_compare
+	 
+	 opaque write:
+	 image_t img, COMPUTE_IMAGE_TYPE type, coord_vec_type coord, uint32_t layer, uint32_t lod, bool is_lod, data_vec_type data
+	 
+	 */
+	
+	const uint32_t read_arg_count = (image_type_id == IMAGE_TYPE_ID::CUDA ? 17 : 18);
+	const uint32_t write_arg_count = (image_type_id == IMAGE_TYPE_ID::CUDA ? 7 : 7);
+	
+	// as args are largely the same for cuda and opaque, just offset the arg num by 1 for opaque,
+	// instead of doing this individually for each arg.
+	// also: only offset for image reads, as image writes are identical.
+	const uint32_t read_args_offset = (image_type_id == IMAGE_TYPE_ID::CUDA ? 0 : 1);
+	const uint32_t write_args_offset = 0;
+	const uint32_t args_offset = (is_image_read ? read_args_offset : write_args_offset);
+	
+	// check + get arguments
+	if(is_image_read && CS.arg_size() != read_arg_count) {
+		ctx->emitError(I, func_name + ": invalid argument count (expected " + std::to_string(read_arg_count) + ")");
+		return;
+	}
+	if(!is_image_read && CS.arg_size() != write_arg_count) {
+		ctx->emitError(I, func_name + ": invalid argument count (expected " + std::to_string(write_arg_count) + ")");
+		return;
+	}
+	
+	// -> tex/surf/img handle
+	const auto img_handle_arg = CS.getArgument(0);
+	if(image_type_id == IMAGE_TYPE_ID::CUDA &&
+	   !img_handle_arg->getType()->isIntegerTy()) {
+		ctx->emitError(I, "invalid image handle type (must be integer)");
+		return;
+	}
+	else if(image_type_id == IMAGE_TYPE_ID::OPAQUE) {
+		if(!img_handle_arg->getType()->isPointerTy()) {
+			ctx->emitError(I, "invalid image handle type (must be an image pointer)");
+			return;
+		}
+		// TODO: check opaque? check opencl image type?
+	}
+	
+	// -> type enum
+	const auto image_type_arg = dyn_cast_or_null<ConstantInt>(CS.getArgument(1 + args_offset));
+	if(!image_type_arg) {
+		ctx->emitError(I, "image type argument must be a constant value");
+		return;
+	}
+	if(!image_type_arg->getType()->isIntegerTy()) {
+		ctx->emitError(I, "invalid image-type type (must be enum/integer)");
+		return;
+	}
+	const uint32_t image_channel_count = ((uint32_t(image_type_arg->getZExtValue()) &
+										   uint32_t(COMPUTE_IMAGE_TYPE::__CHANNELS_MASK)) >>
+										  uint32_t(COMPUTE_IMAGE_TYPE::__CHANNELS_SHIFT)) + 1u;
+	const auto full_image_type = COMPUTE_IMAGE_TYPE(image_type_arg->getZExtValue());
+	const COMPUTE_IMAGE_TYPE image_type = full_image_type & COMPUTE_IMAGE_TYPE::BASE_TYPE_MASK;
+	const COMPUTE_IMAGE_TYPE format_type = full_image_type & COMPUTE_IMAGE_TYPE::__FORMAT_MASK;
+	const COMPUTE_IMAGE_TYPE image_data_type = full_image_type & COMPUTE_IMAGE_TYPE::__DATA_TYPE_MASK;
+	const bool is_normalized = has_flag<COMPUTE_IMAGE_TYPE::FLAG_NORMALIZED>(full_image_type);
+	
+	// -> coord
+	const auto coord_arg = CS.getArgument(2 + args_offset);
+	const auto coord_arg_type = coord_arg->getType();
+	if(!(coord_arg_type->isVectorTy() && (coord_arg_type->getVectorElementType()->isFloatTy() ||
+										  coord_arg_type->getVectorElementType()->isIntegerTy()))) {
+		ctx->emitError(I, "invalid image coordinate type");
+		return;
+	}
+	const auto coord_dim = coord_arg_type->getVectorNumElements();
+	
+	// -> layer
+	const auto layer_arg = CS.getArgument(3 + args_offset);
+	if(!layer_arg->getType()->isIntegerTy()) {
+		ctx->emitError(I, "invalid image layer index type (must be integer)");
+		return;
+	}
+	
+	if(is_image_read) {
+		// -> sampler
+		// prefer const sampler / either const or dyn will be nullptr
+		llvm::ConstantInt* const_sampler_arg = nullptr;
+		llvm::Value* dyn_sampler_arg = nullptr;
+		if(image_type_id != IMAGE_TYPE_ID::CUDA) {
+			const_sampler_arg = dyn_cast_or_null<ConstantInt>(CS.getArgument(1));
+			if(const_sampler_arg == nullptr) {
+				dyn_sampler_arg = CS.getArgument(1);
+			}
+		}
+		
+		// -> sample
+		const auto sample_arg = CS.getArgument(4 + args_offset);
+		if(!sample_arg->getType()->isIntegerTy()) {
+			ctx->emitError(I, "invalid image sample index type (must be integer)");
+			return;
+		}
+		
+		// -> offset
+		const auto offset_arg = CS.getArgument(5 + args_offset);
+		if(!offset_arg->getType()->isVectorTy() ||
+		   !offset_arg->getType()->getVectorElementType()->isIntegerTy()) {
+			ctx->emitError(I, "invalid offset type (must be an int vector)");
+			return;
+		}
+		if(coord_dim != offset_arg->getType()->getVectorNumElements()) {
+			ctx->emitError(I, "invalid offset vector dimension: should be " + std::to_string(coord_dim));
+			return;
+		}
+		
+		SmallVector<llvm::Value*, 3> offset_elems;
+		bool is_offset = true;
+		if(const auto const_offset_arg = dyn_cast_or_null<Constant>(offset_arg)) {
+			// const 0 or undef -> no offset
+			if(const_offset_arg->isZeroValue() ||
+			   dyn_cast_or_null<UndefValue>(const_offset_arg)) {
+				is_offset = false;
+			}
+		}
+		
+		if(is_offset) {
+			// nobody supports this
+			if(has_flag<COMPUTE_IMAGE_TYPE::FLAG_CUBE>(image_type)) {
+				ctx->emitError(I, "image offset is not supported with cube maps");
+				return;
+			}
+			
+			// extract offset elems and check constant offset values
+			for(uint32_t i = 0; i < coord_dim; ++i) {
+				auto offset_elem = builder->CreateExtractElement(offset_arg, builder->getInt32(i));
+				offset_elems.push_back(offset_elem);
+				
+				if(const auto const_offset_elem = dyn_cast_or_null<ConstantInt>(offset_elem)) {
+					// can check if within required [-8, 7]
+					const auto val = const_offset_elem->getSExtValue();
+					if(val < -8 || val > 7) {
+						ctx->emitError(I, "offset out of range (must be in [-8, 7]): " + std::to_string(val));
+					}
+				}
+			}
+		}
+		
+		// -> misc flags
+		const auto is_lod_arg = dyn_cast_or_null<ConstantInt>(CS.getArgument(8 + args_offset));
+		const auto is_lod_float_arg = dyn_cast_or_null<ConstantInt>(CS.getArgument(9 + args_offset));
+		const auto is_bias_arg = dyn_cast_or_null<ConstantInt>(CS.getArgument(10 + args_offset));
+		const auto is_gradient_arg = dyn_cast_or_null<ConstantInt>(CS.getArgument(13 + args_offset));
+		const auto is_compare_arg = dyn_cast_or_null<ConstantInt>(CS.getArgument(16 + args_offset));
+		if(!is_lod_arg) {
+			ctx->emitError(I, "is_lod is not constant");
+			return;
+		}
+		if(!is_lod_float_arg) {
+			ctx->emitError(I, "is_lod_float is not constant");
+			return;
+		}
+		if(!is_bias_arg) {
+			ctx->emitError(I, "is_bias is not constant");
+			return;
+		}
+		if(!is_gradient_arg) {
+			ctx->emitError(I, "is_gradient is not constant");
+			return;
+		}
+		if(!is_compare_arg) {
+			ctx->emitError(I, "is_compare_arg is not constant");
+			return;
+		}
+		
+		const bool is_lod = is_lod_arg->isOne();
+		const bool is_lod_float = is_lod_float_arg->isOne();
+		const bool is_bias = is_bias_arg->isOne();
+		const bool is_gradient = is_gradient_arg->isOne();
+		const bool is_compare = is_compare_arg->isOne();
+		
+		if(is_lod && is_gradient) {
+			ctx->emitError(I, "lod and gradient are mutually exclusive");
+			return;
+		}
+		
+		// -> lod and bias
+		const auto lod_or_bias_arg = CS.getArgument(args_offset + (!is_bias && !is_lod_float ? 6 : 7));
+		
+		if(!lod_or_bias_arg->getType()->isIntegerTy() &&
+		   !lod_or_bias_arg->getType()->isFloatTy()) {
+			ctx->emitError(I, "lod must either be an integer or a float");
+			return;
+		}
+		
+		// -> gradient
+		const auto dpdx_arg = CS.getArgument(11 + args_offset);
+		const auto dpdy_arg = CS.getArgument(12 + args_offset);
+		
+		if(!dpdx_arg->getType()->isVectorTy() ||
+		   !dpdy_arg->getType()->isVectorTy()) {
+			ctx->emitError(I, "dpdx and dpdy must be vector types");
+			return;
+		}
+		if(!dpdx_arg->getType()->getVectorElementType()->isFloatTy() ||
+		   !dpdy_arg->getType()->getVectorElementType()->isFloatTy()) {
+			ctx->emitError(I, "dpdx and dpdy element type must be float");
+			return;
+		}
+		
+		const auto dpdx_dim = dpdx_arg->getType()->getVectorNumElements();
+		const auto dpdy_dim = dpdy_arg->getType()->getVectorNumElements();
+		
+		if(dpdx_dim != coord_dim || dpdy_dim != coord_dim) {
+			ctx->emitError(I, "dpdx and dpdy vector dim must correspond to the coordinate dim");
+			return;
+		}
+		
+		// -> compare
+		const auto compare_function_arg = dyn_cast_or_null<ConstantInt>(CS.getArgument(14 + args_offset));
+		if(!compare_function_arg) {
+			ctx->emitError(I, "compare function arg is not constant");
+			return;
+		}
+		const COMPARE_FUNCTION compare_function = (COMPARE_FUNCTION)compare_function_arg->getZExtValue();
+		if(compare_function >= COMPARE_FUNCTION::__MAX_COMPARE_FUNCTION) {
+			ctx->emitError(I, "invalid compare function");
+			return;
+		}
+		
+		const auto compare_value_arg = CS.getArgument(15 + args_offset);
+		
+		handle_read_image(*I, func_name,
+						  img_handle_arg, image_type,
+						  const_sampler_arg, dyn_sampler_arg,
+						  coord_arg, layer_arg, sample_arg,
+						  offset_arg, offset_elems, is_offset,
+						  lod_or_bias_arg, is_lod /* if false, then it's always bias */,
+						  dpdx_arg, dpdy_arg, is_gradient,
+						  compare_function, compare_value_arg, is_compare);
+	}
+	else {
+		// -> data
+		const auto data_arg = CS.getArgument(6 + args_offset);
+		const auto data_type = data_arg->getType();
+		if(!data_type->isVectorTy() ||
+		   data_type->getVectorNumElements() != 4) {
+			ctx->emitError(I, "invalid image data type (must be 4-component vector)");
+			return;
+		}
+		if(!data_type->getVectorElementType()->isFloatTy() &&
+		   !data_type->getVectorElementType()->isIntegerTy()) {
+			ctx->emitError(I, "invalid image data type (must be a float or integer vector)");
+			return;
+		}
+		
+		// only writes with integer coordinates are allowed
+		if(!coord_arg->getType()->getVectorElementType()->isIntegerTy()) {
+			ctx->emitError(I, "invalid coordinate type (must be integer)");
+			return;
+		}
+		
+		// -> lod
+		const auto is_lod_arg = dyn_cast_or_null<ConstantInt>(CS.getArgument(5 + args_offset));
+		const bool is_lod = is_lod_arg->isOne();
+		const auto lod_arg = CS.getArgument(4 + args_offset);
+		
+		if(!lod_arg->getType()->isIntegerTy()) {
+			ctx->emitError(I, "invalid lod type (must be integer)");
+			return;
+		}
+		
+		handle_write_image(*I, func_name,
+						   img_handle_arg,
+						   image_type, format_type, image_data_type,
+						   is_normalized, image_channel_count,
+						   coord_arg, layer_arg,
+						   lod_arg, is_lod,
+						   data_arg);
+	}
+}
+
+void FloorImageBasePass::emulate_depth_compare(llvm::Value*& dst_vec,
+											   llvm::Value* tex_value,
+											   const COMPARE_FUNCTION& compare_function,
+											   llvm::Value* compare_value_arg) {
+	llvm::Value* insert_value = nullptr;
+	llvm::Value* condition = nullptr;
+	llvm::Constant* false_val = ConstantFP::get(builder->getFloatTy(), 0.0f);
+	llvm::Constant* true_val = ConstantFP::get(builder->getFloatTy(), 1.0f);
+	
+	switch(compare_function) {
+		case COMPARE_FUNCTION::NONE:
+		case COMPARE_FUNCTION::NEVER:
+			insert_value = false_val;
+			break;
+		case COMPARE_FUNCTION::ALWAYS:
+			insert_value = true_val;
+			break;
+		case COMPARE_FUNCTION::LESS_OR_EQUAL:
+			condition = builder->CreateFCmpOLE(compare_value_arg, tex_value);
+			break;
+		case COMPARE_FUNCTION::GREATER_OR_EQUAL:
+			condition = builder->CreateFCmpOGE(compare_value_arg, tex_value);
+			break;
+		case COMPARE_FUNCTION::LESS:
+			condition = builder->CreateFCmpOLT(compare_value_arg, tex_value);
+			break;
+		case COMPARE_FUNCTION::GREATER:
+			condition = builder->CreateFCmpOGT(compare_value_arg, tex_value);
+			break;
+		case COMPARE_FUNCTION::EQUAL:
+			condition = builder->CreateFCmpOEQ(compare_value_arg, tex_value);
+			break;
+		case COMPARE_FUNCTION::NOT_EQUAL:
+			condition = builder->CreateFCmpONE(compare_value_arg, tex_value);
+			break;
+		default: llvm_unreachable("invalid compare function");
+	}
+	
+	if(condition != nullptr) {
+		insert_value = builder->CreateSelect(condition, true_val, false_val);
+	}
+	
+	dst_vec = builder->CreateInsertElement(dst_vec, insert_value, builder->getInt32(0));
+}
diff --git a/lib/Transforms/Scalar/LoopRotation.cpp b/lib/Transforms/Scalar/LoopRotation.cpp
index 4498e1d..5600e22 100644
--- a/lib/Transforms/Scalar/LoopRotation.cpp
+++ b/lib/Transforms/Scalar/LoopRotation.cpp
@@ -220,7 +220,8 @@ bool LoopRotate::rotateLoop(Loop *L, bool SimplifiedLatch) {
 
     CodeMetrics Metrics;
     Metrics.analyzeBasicBlock(OrigHeader, *TTI, EphValues);
-    if (Metrics.notDuplicatable) {
+    // TODO/NOTE: ignoring this for now, duplicates can very well exist in the same scope
+    /*if (Metrics.notDuplicatable) {
       DEBUG(dbgs() << "LoopRotation: NOT rotating - contains non-duplicatable"
                    << " instructions: ";
             L->dump());
@@ -231,7 +232,7 @@ bool LoopRotate::rotateLoop(Loop *L, bool SimplifiedLatch) {
                       "instructions: ";
             L->dump());
       return false;
-    }
+    }*/
     if (Metrics.NumInsts > MaxHeaderSize)
       return false;
   }
diff --git a/lib/Transforms/Scalar/LoopUnrollPass.cpp b/lib/Transforms/Scalar/LoopUnrollPass.cpp
index 1018b61..c916b3a 100644
--- a/lib/Transforms/Scalar/LoopUnrollPass.cpp
+++ b/lib/Transforms/Scalar/LoopUnrollPass.cpp
@@ -537,7 +537,7 @@ static unsigned ApproximateLoopSize(const Loop *L, unsigned &NumCalls,
 
   CodeMetrics Metrics;
   for (BasicBlock *BB : L->blocks())
-    Metrics.analyzeBasicBlock(BB, TTI, EphValues);
+    Metrics.analyzeBasicBlock(BB, TTI, EphValues, true /* allow duplicates */);
   NumCalls = Metrics.NumInlineCandidates;
   NotDuplicatable = Metrics.notDuplicatable;
   Convergent = Metrics.convergent;
@@ -915,11 +915,12 @@ static bool tryToUnrollLoop(Loop *L, DominatorTree &DT, LoopInfo *LI,
   unsigned LoopSize = ApproximateLoopSize(
       L, NumInlineCandidates, NotDuplicatable, Convergent, TTI, &AC);
   DEBUG(dbgs() << "  Loop Size = " << LoopSize << "\n");
-  if (NotDuplicatable) {
+  // TODO/NOTE: ignoring this for now, duplicates can very well exist in the same scope
+  /*if (NotDuplicatable) {
     DEBUG(dbgs() << "  Not unrolling loop which contains non-duplicatable"
                  << " instructions.\n");
     return false;
-  }
+  }*/
   if (NumInlineCandidates != 0) {
     DEBUG(dbgs() << "  Not unrolling loop with inlinable calls.\n");
     return false;
diff --git a/lib/Transforms/Scalar/MetalFinal.cpp b/lib/Transforms/Scalar/MetalFinal.cpp
new file mode 100644
index 0000000..588aada
--- /dev/null
+++ b/lib/Transforms/Scalar/MetalFinal.cpp
@@ -0,0 +1,928 @@
+//===- MetalFinal.cpp - Metal final pass ----------------------------------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+// This file fixes certain post-codegen issues.
+//
+//===----------------------------------------------------------------------===//
+
+#include "llvm/ADT/Statistic.h"
+#include "llvm/ADT/STLExtras.h"
+#include "llvm/ADT/SetVector.h"
+#include "llvm/ADT/SmallPtrSet.h"
+#include "llvm/ADT/SmallVector.h"
+#include "llvm/ADT/StringExtras.h"
+#include "llvm/Analysis/AliasAnalysis.h"
+#include "llvm/Analysis/BasicAliasAnalysis.h"
+#include "llvm/Analysis/GlobalsModRef.h"
+#include "llvm/IR/CFG.h"
+#include "llvm/IR/CallSite.h"
+#include "llvm/IR/CallingConv.h"
+#include "llvm/IR/ConstantRange.h"
+#include "llvm/IR/Constants.h"
+#include "llvm/IR/DataLayout.h"
+#include "llvm/IR/DebugInfo.h"
+#include "llvm/IR/DerivedTypes.h"
+#include "llvm/IR/Dominators.h"
+#include "llvm/IR/Function.h"
+#include "llvm/IR/InlineAsm.h"
+#include "llvm/IR/InstIterator.h"
+#include "llvm/IR/InstVisitor.h"
+#include "llvm/IR/IntrinsicInst.h"
+#include "llvm/IR/IRBuilder.h"
+#include "llvm/IR/LLVMContext.h"
+#include "llvm/IR/Metadata.h"
+#include "llvm/IR/Module.h"
+#include "llvm/IR/LegacyPassManager.h"
+#include "llvm/Pass.h"
+#include "llvm/Support/CommandLine.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/ErrorHandling.h"
+#include "llvm/Support/raw_ostream.h"
+#include "llvm/Transforms/IPO/PassManagerBuilder.h"
+#include "llvm/Transforms/IPO.h"
+#include "llvm/Transforms/Scalar.h"
+#include <algorithm>
+#include <cstdarg>
+#include <memory>
+#include <unordered_map>
+#include <unordered_set>
+#include <array>
+#include <cxxabi.h>
+using namespace llvm;
+
+#define DEBUG_TYPE "MetalFinal"
+
+#if 1
+#define DBG(x)
+#else
+#define DBG(x) x
+#endif
+
+//////////////////////////////////////////
+// blatantly copied/transplanted from SROA
+namespace {
+/// \brief A custom IRBuilder inserter which prefixes all names, but only in
+/// Assert builds.
+class IRBuilderPrefixedInserter : public IRBuilderDefaultInserter {
+  std::string Prefix;
+  const Twine getNameWithPrefix(const Twine &Name) const {
+    return Name.isTriviallyEmpty() ? Name : Prefix + Name;
+  }
+
+public:
+  void SetNamePrefix(const Twine &P) { Prefix = P.str(); }
+
+protected:
+  void InsertHelper(Instruction *I, const Twine &Name, BasicBlock *BB,
+                    BasicBlock::iterator InsertPt) const {
+    IRBuilderDefaultInserter::InsertHelper(I, getNameWithPrefix(Name), BB,
+                                           InsertPt);
+  }
+};
+
+/// \brief Provide a typedef for IRBuilder that drops names in release builds.
+using IRBuilderTy = llvm::IRBuilder<ConstantFolder, IRBuilderPrefixedInserter>;
+}
+
+namespace {
+  /// \brief Generic recursive split emission class.
+  template <typename Derived>
+  class OpSplitter {
+  protected:
+    /// The builder used to form new instructions.
+    IRBuilderTy IRB;
+    /// The indices which to be used with insert- or extractvalue to select the
+    /// appropriate value within the aggregate.
+    SmallVector<unsigned, 4> Indices;
+    /// The indices to a GEP instruction which will move Ptr to the correct slot
+    /// within the aggregate.
+    SmallVector<Value *, 4> GEPIndices;
+    /// The base pointer of the original op, used as a base for GEPing the
+    /// split operations.
+    Value *Ptr;
+
+    /// Initialize the splitter with an insertion point, Ptr and start with a
+    /// single zero GEP index.
+    OpSplitter(Instruction *InsertionPoint, Value *Ptr)
+      : IRB(InsertionPoint), GEPIndices(1, IRB.getInt32(0)), Ptr(Ptr) {}
+
+  public:
+    /// \brief Generic recursive split emission routine.
+    ///
+    /// This method recursively splits an aggregate op (load or store) into
+    /// scalar or vector ops. It splits recursively until it hits a single value
+    /// and emits that single value operation via the template argument.
+    ///
+    /// The logic of this routine relies on GEPs and insertvalue and
+    /// extractvalue all operating with the same fundamental index list, merely
+    /// formatted differently (GEPs need actual values).
+    ///
+    /// \param Ty  The type being split recursively into smaller ops.
+    /// \param Agg The aggregate value being built up or stored, depending on
+    /// whether this is splitting a load or a store respectively.
+    void emitSplitOps(Type *Ty, Value *&Agg, const Twine &Name) {
+      if (Ty->isSingleValueType())
+        return static_cast<Derived *>(this)->emitFunc(Ty, Agg, Name);
+
+      if (ArrayType *ATy = dyn_cast<ArrayType>(Ty)) {
+        unsigned OldSize = Indices.size();
+        (void)OldSize;
+        for (unsigned Idx = 0, Size = ATy->getNumElements(); Idx != Size;
+             ++Idx) {
+          assert(Indices.size() == OldSize && "Did not return to the old size");
+          Indices.push_back(Idx);
+          GEPIndices.push_back(IRB.getInt32(Idx));
+          emitSplitOps(ATy->getElementType(), Agg, Name + "." + Twine(Idx));
+          GEPIndices.pop_back();
+          Indices.pop_back();
+        }
+        return;
+      }
+
+      if (StructType *STy = dyn_cast<StructType>(Ty)) {
+        unsigned OldSize = Indices.size();
+        (void)OldSize;
+        for (unsigned Idx = 0, Size = STy->getNumElements(); Idx != Size;
+             ++Idx) {
+          assert(Indices.size() == OldSize && "Did not return to the old size");
+          Indices.push_back(Idx);
+          GEPIndices.push_back(IRB.getInt32(Idx));
+          emitSplitOps(STy->getElementType(Idx), Agg, Name + "." + Twine(Idx));
+          GEPIndices.pop_back();
+          Indices.pop_back();
+        }
+        return;
+      }
+
+      llvm_unreachable("Only arrays and structs are aggregate loadable types");
+    }
+  };
+
+  struct LoadOpSplitter : public OpSplitter<LoadOpSplitter> {
+    LoadOpSplitter(Instruction *InsertionPoint, Value *Ptr)
+      : OpSplitter<LoadOpSplitter>(InsertionPoint, Ptr) {}
+
+    /// Emit a leaf load of a single value. This is called at the leaves of the
+    /// recursive emission to actually load values.
+    void emitFunc(Type *Ty, Value *&Agg, const Twine &Name) {
+      assert(Ty->isSingleValueType());
+      // Load the single value and insert it using the indices.
+      Value *GEP = IRB.CreateInBoundsGEP(Ptr, GEPIndices, Name + ".gep");
+      Value *Load = IRB.CreateLoad(GEP, Name + ".load");
+      Agg = IRB.CreateInsertValue(Agg, Load, Indices, Name + ".insert");
+      DEBUG(dbgs() << "          to: " << *Load << "\n");
+    }
+  };
+
+  struct StoreOpSplitter : public OpSplitter<StoreOpSplitter> {
+    StoreOpSplitter(Instruction *InsertionPoint, Value *Ptr)
+      : OpSplitter<StoreOpSplitter>(InsertionPoint, Ptr) {}
+
+    /// Emit a leaf store of a single value. This is called at the leaves of the
+    /// recursive emission to actually produce stores.
+    void emitFunc(Type *Ty, Value *&Agg, const Twine &Name) {
+      assert(Ty->isSingleValueType());
+      // Extract the single value and store it using the indices.
+      //
+      // The gep and extractvalue values are factored out of the CreateStore
+      // call to make the output independent of the argument evaluation order.
+      Value *ExtractValue =
+          IRB.CreateExtractValue(Agg, Indices, Name + ".extract");
+      Value *InBoundsGEP =
+          IRB.CreateInBoundsGEP(nullptr, Ptr, GEPIndices, Name + ".gep");
+      Value *Store = IRB.CreateStore(ExtractValue, InBoundsGEP);
+      (void)Store;
+      DEBUG(dbgs() << "          to: " << *Store << "\n");
+    }
+  };
+
+}
+//////////////////////////////////////////
+
+namespace {
+	static bool metal_load_splitter(LoadInst& LI,
+									const bool is_vs, const bool is_kernel,
+									const bool nvidia_workarounds) {
+		if(!is_vs && !is_kernel) return false;
+		if(is_kernel && !(nvidia_workarounds && LI.getType()->isArrayTy())) return false;
+		if(is_vs && !LI.getType()->isAggregateType()) return false;
+		
+		LoadOpSplitter Splitter(&LI, LI.getPointerOperand());
+		Value *V = UndefValue::get(LI.getType());
+		Splitter.emitSplitOps(LI.getType(), V, LI.getName() + ".mtlld");
+		LI.replaceAllUsesWith(V);
+		LI.eraseFromParent();
+		return true;
+	}
+	
+	static bool metal_store_splitter(StoreInst& SI,
+									 const bool is_vs, const bool is_kernel,
+									 const bool nvidia_workarounds) {
+		if(!is_vs && !is_kernel) return false;
+		if(is_kernel && !(nvidia_workarounds && SI.getType()->isArrayTy())) return false;
+		if(is_vs && !SI.getType()->isAggregateType()) return false;
+		
+		Value *V = SI.getValueOperand();
+		StoreOpSplitter Splitter(&SI, SI.getPointerOperand());
+		Splitter.emitSplitOps(V->getType(), V, V->getName() + ".mtlst");
+		SI.eraseFromParent();
+		return true;
+	}
+	
+	// MetalFirst
+	struct MetalFirst : public FunctionPass, InstVisitor<MetalFirst> {
+		friend class InstVisitor<MetalFirst>;
+		
+		static char ID; // Pass identification, replacement for typeid
+		const bool enable_intel_workarounds, enable_nvidia_workarounds;
+		
+		Module* M { nullptr };
+		LLVMContext* ctx { nullptr };
+		
+		bool was_modified { false };
+		bool is_vertex_func { false };
+		bool is_fragment_func { false };
+		bool is_kernel_func { false };
+		
+		MetalFirst(const bool enable_intel_workarounds_ = false,
+				   const bool enable_nvidia_workarounds_ = false) :
+		FunctionPass(ID),
+		enable_intel_workarounds(enable_intel_workarounds_),
+		enable_nvidia_workarounds(enable_nvidia_workarounds_) {
+			initializeMetalFirstPass(*PassRegistry::getPassRegistry());
+		}
+		
+		bool runOnFunction(Function &F) override {
+			// exit if empty function
+			if(F.empty()) return false;
+			
+			//
+			M = F.getParent();
+			ctx = &M->getContext();
+			
+			is_vertex_func = F.getCallingConv() == CallingConv::FLOOR_VERTEX;
+			is_fragment_func = F.getCallingConv() == CallingConv::FLOOR_FRAGMENT;
+			is_kernel_func = F.getCallingConv() == CallingConv::FLOOR_KERNEL;
+			
+			//
+			was_modified = false;
+			//visit(F); // NOTE/TODO: disabled for now
+			
+			return was_modified;
+		}
+		
+		// InstVisitor overrides...
+		using InstVisitor<MetalFirst>::visit;
+		void visit(Instruction& I) {
+			InstVisitor<MetalFirst>::visit(I);
+		}
+		
+		void visitLoadInst(LoadInst &LI) {
+			was_modified = metal_load_splitter(LI, is_vertex_func, is_kernel_func, enable_nvidia_workarounds);
+		}
+		
+		void visitStoreInst(StoreInst &SI) {
+			was_modified = metal_store_splitter(SI, is_vertex_func, is_kernel_func, enable_nvidia_workarounds);
+		}
+	};
+	
+	// MetalFinal
+	struct MetalFinal : public FunctionPass, InstVisitor<MetalFinal> {
+		friend class InstVisitor<MetalFinal>;
+		
+		static char ID; // Pass identification, replacement for typeid
+		const bool enable_intel_workarounds, enable_nvidia_workarounds;
+		
+		std::shared_ptr<llvm::IRBuilder<>> builder;
+		
+		Module* M { nullptr };
+		LLVMContext* ctx { nullptr };
+		Function* func { nullptr };
+		Instruction* alloca_insert { nullptr };
+		bool was_modified { false };
+		bool is_kernel_func { false };
+		bool is_vertex_func { false };
+		bool is_fragment_func { false };
+		
+		// added kernel function args
+		Argument* global_id { nullptr };
+		Argument* global_size { nullptr };
+		Argument* local_id { nullptr };
+		Argument* local_size { nullptr };
+		Argument* group_id { nullptr };
+		Argument* group_size { nullptr };
+		
+		// added vertex function args
+		Argument* vertex_id { nullptr };
+		
+		// added fragment function args
+		Argument* point_coord { nullptr };
+		
+		MetalFinal(const bool enable_intel_workarounds_ = false,
+				   const bool enable_nvidia_workarounds_ = false) :
+		FunctionPass(ID),
+		enable_intel_workarounds(enable_intel_workarounds_),
+		enable_nvidia_workarounds(enable_nvidia_workarounds_) {
+			initializeMetalFinalPass(*PassRegistry::getPassRegistry());
+		}
+		
+		void getAnalysisUsage(AnalysisUsage &AU) const override {
+			AU.addRequired<AAResultsWrapperPass>();
+			AU.addRequired<GlobalsAAWrapperPass>();
+			AU.addRequired<AssumptionCacheTracker>();
+			AU.addRequired<TargetLibraryInfoWrapperPass>();
+		}
+		
+		template <Instruction::CastOps cast_op, typename std::enable_if<(cast_op == llvm::Instruction::FPToSI ||
+																		 cast_op == llvm::Instruction::FPToUI ||
+																		 cast_op == llvm::Instruction::SIToFP ||
+																		 cast_op == llvm::Instruction::UIToFP), int>::type = 0>
+		llvm::Value* call_conversion_func(llvm::Value* from, llvm::Type* to_type) {
+			// metal only supports conversion of a specific set of integer and float types
+			// -> find and check them
+			const auto from_type = from->getType();
+			static const std::unordered_map<llvm::Type*, const char*> type_map {
+				{ llvm::Type::getInt1Ty(*ctx), ".i1" }, // not sure about signed/unsigned conversion here
+				{ llvm::Type::getInt8Ty(*ctx), ".i8" },
+				{ llvm::Type::getInt16Ty(*ctx), ".i16" },
+				{ llvm::Type::getInt32Ty(*ctx), ".i32" },
+				{ llvm::Type::getInt64Ty(*ctx), ".i64" },
+				{ llvm::Type::getHalfTy(*ctx), "f.f16" },
+				{ llvm::Type::getFloatTy(*ctx), "f.f32" },
+				{ llvm::Type::getDoubleTy(*ctx), "f.f64" },
+			};
+			const auto from_iter = type_map.find(from_type);
+			if(from_iter == end(type_map)) {
+				DBG(errs() << "failed to find conversion function for: " << *from_type << " -> " << *to_type << "\n";)
+				return from;
+			}
+			const auto to_iter = type_map.find(to_type);
+			if(to_iter == end(type_map)) {
+				DBG(errs() << "failed to find conversion function for: " << *from_type << " -> " << *to_type << "\n";)
+				return from;
+			}
+			
+			// figure out if from/to type is signed/unsigned
+			bool from_signed = false, to_signed = false;
+			switch(cast_op) {
+				case llvm::Instruction::FPToSI: from_signed = true; to_signed = true; break;
+				case llvm::Instruction::FPToUI: from_signed = true; to_signed = false; break;
+				case llvm::Instruction::SIToFP: from_signed = true; to_signed = true; break;
+				case llvm::Instruction::UIToFP: from_signed = false; to_signed = true; break;
+				default: __builtin_unreachable();
+			}
+			
+			DBG(errs() << "converting: " << *from_type << " (" << (from_signed ? "signed" : "unsigned") << ") -> " << *to_type << "(" << (to_signed ? "signed" : "unsigned") << ")\n";)
+			
+			// for intel gpus any conversion from/to float from/to i8 or i16 needs to go through a i32 first
+			if(enable_intel_workarounds && from_iter->second[0] == 'f') {
+				if(to_iter->first == llvm::Type::getInt8Ty(*ctx) ||
+				   to_iter->first == llvm::Type::getInt16Ty(*ctx)) {
+					// convert to i32 first, then trunc from i32 to i8/i16
+					const auto to_i32_cast = call_conversion_func<cast_op>(from, llvm::Type::getInt32Ty(*ctx));
+					return builder->CreateTrunc(to_i32_cast, to_iter->first);
+				}
+			}
+			
+			// air.convert.<to_type>.<from_type>
+			std::string func_name = "air.convert.";
+			
+			if(to_iter->second[0] == '.') {
+				func_name += (to_signed ? 's' : 'u');
+			}
+			func_name += to_iter->second;
+			
+			func_name += '.';
+			if(from_iter->second[0] == '.') {
+				func_name += (from_signed ? 's' : 'u');
+			}
+			func_name += from_iter->second;
+			
+			SmallVector<llvm::Type*, 1> params(1, from_type);
+			const auto func_type = llvm::FunctionType::get(to_type, params, false);
+			return builder->CreateCall(M->getOrInsertFunction(func_name, func_type), from);
+		}
+		
+		// dummy
+		template <Instruction::CastOps cast_op, typename std::enable_if<!(cast_op == llvm::Instruction::FPToSI ||
+																		  cast_op == llvm::Instruction::FPToUI ||
+																		  cast_op == llvm::Instruction::SIToFP ||
+																		  cast_op == llvm::Instruction::UIToFP), int>::type = 0>
+		llvm::Value* call_conversion_func(llvm::Value* from, llvm::Type*) {
+			return from;
+		}
+		
+		bool runOnFunction(Function &F) override {
+			// exit if empty function
+			if(F.empty()) return false;
+			
+			//
+			M = F.getParent();
+			ctx = &M->getContext();
+			func = &F;
+			builder = std::make_shared<llvm::IRBuilder<>>(*ctx);
+			
+			for(auto& instr : F.getEntryBlock().getInstList()) {
+				if(!isa<AllocaInst>(instr)) {
+					alloca_insert = &instr;
+					break;
+				}
+			}
+			
+			// add args if this is a kernel function
+			is_kernel_func = F.getCallingConv() == CallingConv::FLOOR_KERNEL;
+			if(is_kernel_func) {
+				const auto vec_type = llvm::VectorType::get(llvm::Type::getInt32Ty(*ctx), 3);
+				global_id = new llvm::Argument(vec_type, "__metal__global_id__", &F);
+				global_size = new llvm::Argument(vec_type, "__metal__global_size__", &F);
+				local_id = new llvm::Argument(vec_type, "__metal__local_id__", &F);
+				local_size = new llvm::Argument(vec_type, "__metal__local_size__", &F);
+				group_id = new llvm::Argument(vec_type, "__metal__group_id__", &F);
+				group_size = new llvm::Argument(vec_type, "__metal__group_size__", &F);
+			}
+			
+			// add args if this is a vertex function
+			is_vertex_func = F.getCallingConv() == CallingConv::FLOOR_VERTEX;
+			if(is_vertex_func) {
+				const auto uint_type = llvm::Type::getInt32Ty(*ctx);
+				vertex_id = new llvm::Argument(uint_type, "__metal__vertex_id__", &F);
+				// TODO: this should be optional / only happen on request
+				// TODO: handle instance id
+			}
+			
+			// add args if this is a fragment function
+			is_fragment_func = F.getCallingConv() == CallingConv::FLOOR_FRAGMENT;
+			if(is_fragment_func) {
+				const auto vec_type = llvm::VectorType::get(llvm::Type::getFloatTy(*ctx), 2);
+				point_coord = new llvm::Argument(vec_type, "__metal__point_coord__", &F);
+			}
+			
+			// update function signature / param list
+			if(is_kernel_func || is_vertex_func || is_fragment_func) {
+				std::vector<Type*> param_types;
+				for(auto& arg : F.args()) {
+					// also kill "dereferenceable" arg attributes while we're at it (this is not supported by metal)
+					// NOTE: this only needs to be done here, b/c everything else will be inlined
+					if(F.getAttributes().hasAttribute(arg.getArgNo() + 1, Attribute::Dereferenceable)) {
+						// this is a bit complicated, we can't just remove any deref attribute, but it needs to be
+						// specific to the amount of bytes that are specified + attributes are actually stored in the
+						// function, so we need to set the correct arg number
+						AttrBuilder B;
+						B.addDereferenceableAttr(F.getAttributes().getDereferenceableBytes(arg.getArgNo() + 1));
+						arg.removeAttr(AttributeSet::get(*ctx, arg.getArgNo() + 1, B));
+					}
+					
+					param_types.push_back(arg.getType());
+				}
+				auto new_func_type = PointerType::get(FunctionType::get(F.getReturnType(), param_types, false), 0);
+				F.mutateType(new_func_type);
+			}
+			
+			// visit everything in this function
+			was_modified = false; // reset every time
+			DBG(errs() << "in func: "; errs().write_escaped(F.getName()) << '\n';)
+			visit(F);
+			
+			// always modified
+			return was_modified || is_kernel_func || is_vertex_func || is_fragment_func;
+		}
+		
+		// InstVisitor overrides...
+		using InstVisitor<MetalFinal>::visit;
+		void visit(Instruction& I) {
+			InstVisitor<MetalFinal>::visit(I);
+		}
+		
+		//
+		void visitCallInst(CallInst &I) {
+			// if this isn't a kernel function we don't need to do anything here (yet)
+			if(!is_kernel_func && !is_vertex_func && !is_fragment_func) return;
+			
+			const auto func_name = I.getCalledFunction()->getName();
+			if(!func_name.startswith("floor.")) return;
+			
+			CallSite CS { &I };
+			builder->SetInsertPoint(&I);
+			
+			// figure out which one we need
+			Argument* id;
+			if(func_name == "floor.get_global_id.i32") {
+				id = global_id;
+			}
+			else if(func_name == "floor.get_global_size.i32") {
+				id = global_size;
+			}
+			else if(func_name == "floor.get_local_id.i32") {
+				id = local_id;
+			}
+			else if(func_name == "floor.get_local_size.i32") {
+				id = local_size;
+			}
+			else if(func_name == "floor.get_group_id.i32") {
+				id = group_id;
+			}
+			else if(func_name == "floor.get_group_size.i32") {
+				id = group_size;
+			}
+			else if(func_name == "floor.get_work_dim.i32") {
+				if(group_size == nullptr) {
+					DBG(printf("failed to get group_size arg, probably not in a kernel function?\n"); fflush(stdout);)
+					return;
+				}
+				
+				// special case
+				// => group_size.z == 1 ? (group_size.y == 1 ? 1 : 2) : 3
+				const auto size_z = builder->CreateExtractElement(group_size, builder->getInt32(2));
+				const auto size_y = builder->CreateExtractElement(group_size, builder->getInt32(1));
+				const auto cmp_z = builder->CreateICmp(ICmpInst::ICMP_EQ, size_z, builder->getInt32(1));
+				const auto cmp_y = builder->CreateICmp(ICmpInst::ICMP_EQ, size_y, builder->getInt32(1));
+				const auto sel_x_or_y = builder->CreateSelect(cmp_y, builder->getInt32(1), builder->getInt32(2));
+				const auto sel_xy_or_z = builder->CreateSelect(cmp_z, sel_x_or_y, builder->getInt32(3));
+				I.replaceAllUsesWith(sel_xy_or_z);
+				I.eraseFromParent();
+				return;
+			}
+			else if(func_name == "floor.get_vertex_id.i32") {
+				if(vertex_id == nullptr) {
+					DBG(printf("failed to get vertex_id arg, probably not in a vertex function?\n"); fflush(stdout);)
+					return;
+				}
+				
+				I.replaceAllUsesWith(vertex_id);
+				I.eraseFromParent();
+				return;
+			}
+			else if(func_name == "floor.get_point_coord.float2") {
+				if(point_coord == nullptr) {
+					DBG(printf("failed to get point_coord arg, probably not in a fragment function?\n"); fflush(stdout);)
+					return;
+				}
+			
+				I.replaceAllUsesWith(point_coord);
+				I.eraseFromParent();
+				return;
+			}
+			// unknown -> ignore for now
+			else return;
+			
+			if(id == nullptr) {
+				DBG(printf("failed to get id arg, probably not in a kernel function?\n"); fflush(stdout);)
+				return;
+			}
+			
+			// replace call with vector load / elem extraction from the appropriate vector
+			I.replaceAllUsesWith(builder->CreateExtractElement(id, CS.getArgument(0)));
+			I.eraseFromParent();
+		}
+		
+		// like SPIR, Metal only supports scalar conversion ops ->
+		// * scalarize source vector
+		// * call conversion op for each scalar
+		// * reassemble a vector from the converted scalars
+		// * replace all uses of the original vector
+		template <Instruction::CastOps cast_op>
+		__attribute__((always_inline))
+		bool vec_to_scalar_ops(CastInst& I) {
+			if(!I.getType()->isVectorTy()) return false;
+			
+			// start insertion before instruction
+			builder->SetInsertPoint(&I);
+			
+			// setup
+			auto src_vec = I.getOperand(0);
+			const auto src_vec_type = src_vec->getType();
+			const auto dim = src_vec_type->getVectorNumElements();
+			
+			const auto si_type = I.getDestTy();
+			const auto dst_scalar_type = si_type->getScalarType();
+			llvm::Value* dst_vec = UndefValue::get(si_type);
+			
+			// iterate over all vector components, emit a scalar instruction and insert into a new vector
+			for(uint32_t i = 0; i < dim; ++i) {
+				auto scalar = builder->CreateExtractElement(src_vec, builder->getInt32(i));
+				llvm::Value* cast;
+				switch(cast_op) {
+					case llvm::Instruction::FPToSI:
+					case llvm::Instruction::FPToUI:
+					case llvm::Instruction::SIToFP:
+					case llvm::Instruction::UIToFP:
+						cast = call_conversion_func<cast_op>(scalar, dst_scalar_type);
+						break;
+					default:
+						cast = builder->CreateCast(cast_op, scalar, dst_scalar_type);
+						break;
+				}
+				dst_vec = builder->CreateInsertElement(dst_vec, cast, builder->getInt32(i));
+			}
+			
+			// finally, replace all uses with the new vector and remove the old vec instruction
+			I.replaceAllUsesWith(dst_vec);
+			I.eraseFromParent();
+			was_modified = true;
+			return true;
+		}
+		
+		// si/ui/fp -> si/ui/fp conversions require a call to an intrinsic air function (air.convert.*)
+		template <Instruction::CastOps cast_op>
+		__attribute__((always_inline))
+		void scalar_conversion(CastInst& I) {
+			builder->SetInsertPoint(&I);
+			
+			// replace original conversion
+			I.replaceAllUsesWith(call_conversion_func<cast_op>(I.getOperand(0), I.getDestTy()));
+			I.eraseFromParent();
+			was_modified = true;
+		}
+		
+		void visitTruncInst(TruncInst &I) {
+			vec_to_scalar_ops<Instruction::Trunc>(I);
+		}
+		void visitZExtInst(ZExtInst &I) {
+			vec_to_scalar_ops<Instruction::ZExt>(I);
+		}
+		void visitSExtInst(SExtInst &I) {
+			vec_to_scalar_ops<Instruction::SExt>(I);
+		}
+		void visitFPTruncInst(FPTruncInst &I) {
+			vec_to_scalar_ops<Instruction::FPTrunc>(I);
+		}
+		void visitFPExtInst(FPExtInst &I) {
+			vec_to_scalar_ops<Instruction::FPExt>(I);
+		}
+		void visitFPToUIInst(FPToUIInst &I) {
+			if(!vec_to_scalar_ops<Instruction::FPToUI>(I)) {
+				scalar_conversion<Instruction::FPToUI>(I);
+			}
+		}
+		void visitFPToSIInst(FPToSIInst &I) {
+			if(!vec_to_scalar_ops<Instruction::FPToSI>(I)) {
+				scalar_conversion<Instruction::FPToSI>(I);
+			}
+		}
+		void visitUIToFPInst(UIToFPInst &I) {
+			if(!vec_to_scalar_ops<Instruction::UIToFP>(I)) {
+				scalar_conversion<Instruction::UIToFP>(I);
+			}
+		}
+		void visitSIToFPInst(SIToFPInst &I) {
+			if(!vec_to_scalar_ops<Instruction::SIToFP>(I)) {
+				scalar_conversion<Instruction::SIToFP>(I);
+			}
+		}
+		
+		// metal can only handle i32 indices
+		void visitExtractElement(ExtractElementInst& EEI) {
+			const auto idx_op = EEI.getIndexOperand();
+			const auto idx_type = idx_op->getType();
+			if(!idx_type->isIntegerTy(32)) {
+				if(const auto const_idx_op = dyn_cast_or_null<ConstantInt>(idx_op)) {
+					EEI.setOperand(1 /* idx op */, builder->getInt32((int32_t)const_idx_op->getValue().getZExtValue()));
+				}
+				else {
+					builder->SetInsertPoint(&EEI);
+					const auto i32_index = builder->CreateIntCast(idx_op, builder->getInt32Ty(), false);
+					EEI.setOperand(1 /* idx op */, i32_index);
+				}
+				was_modified = true;
+			}
+		}
+		
+		// metal can only handle i32 indices
+		void visitInsertElement(InsertElementInst& IEI) {
+			const auto idx_op = IEI.llvm::User::getOperand(2);
+			const auto idx_type = idx_op->getType();
+			if(!idx_type->isIntegerTy(32)) {
+				if(const auto const_idx_op = dyn_cast_or_null<ConstantInt>(idx_op)) {
+					IEI.setOperand(2 /* idx op */, builder->getInt32((int32_t)const_idx_op->getValue().getZExtValue()));
+				}
+				else {
+					builder->SetInsertPoint(&IEI);
+					const auto i32_index = builder->CreateIntCast(idx_op, builder->getInt32Ty(), false);
+					IEI.setOperand(2 /* idx op */, i32_index);
+				}
+				was_modified = true;
+			}
+		}
+		
+		void visitLoadInst(LoadInst &LI) {
+			was_modified = metal_load_splitter(LI, is_vertex_func, is_kernel_func, enable_nvidia_workarounds);
+		}
+		
+		void visitStoreInst(StoreInst &SI) {
+			was_modified = metal_store_splitter(SI, is_vertex_func, is_kernel_func, enable_nvidia_workarounds);
+		}
+		
+		void visitAllocaInst(AllocaInst &AI) {
+			if(!enable_intel_workarounds) return;
+			DBG(errs() << "alloca: " << AI << ", " << *AI.getType() << "\n";)
+			
+			BasicAAResult BAR(createLegacyPMBasicAAResult(*this, *func));
+			AAResults AA(createLegacyPMAAResults(*this, *func, BAR));
+			
+			// recursively find all users of this alloca + store all select and phi instructions that select/choose based on the alloca pointer
+			std::vector<Instruction*> users;
+			std::unordered_set<Instruction*> visited;
+			const std::function<void(Instruction&)> collect_users = [&users, &collect_users, &visited, &AI, &AA](Instruction& I) {
+				for(auto user : I.users()) {
+					auto instr = cast<Instruction>(user);
+					const auto has_visited = visited.insert(instr);
+					if(!has_visited.second) continue;
+					
+					// TODO: ideally, we want to track all GEPs and bitcasts to/of the alloca and only add select/phi instructions that
+					//       either use these or directly use the alloca (and not all pointers) - for now, AA will do
+					if(SelectInst* SI = dyn_cast<SelectInst>(user)) {
+						DBG(errs() << ">> select: " << *SI << "\n";)
+						DBG(errs() << "cond: " << *SI->getCondition() << "\n";)
+						DBG(errs() << "ops: " << *SI->getTrueValue() << ", " << *SI->getFalseValue() << "\n";)
+						
+						// skip immediately if not a pointer type
+						if(SI->getTrueValue()->getType()->isPointerTy() /* false val has the same type */) {
+							// check if either true or false alias with our alloca
+							const auto aa_res_true = AA.alias(SI->getTrueValue(), &AI);
+							const auto aa_res_false = AA.alias(SI->getFalseValue(), &AI);
+							DBG(errs() << "aa: " << aa_res_true << ", " << aa_res_false << "\n";)
+							if(aa_res_true != NoAlias ||
+							   aa_res_false != NoAlias) {
+								// if so, add this select
+								users.push_back(SI);
+							}
+						}
+					}
+					else if(PHINode* PHI = dyn_cast<PHINode>(user)) {
+						DBG(errs() << ">> phi: " << *PHI << "\n";)
+						DBG(errs() << "type: " << *PHI->getType() << "\n";)
+						
+						// skip immediately if not a pointer type
+						if(PHI->getType()->isPointerTy()) {
+							// check if it aliases with our alloca
+							const auto aa_res = AA.alias(PHI, &AI);
+							DBG(errs() << "aa: " << aa_res << "\n";)
+							if(aa_res != NoAlias) {
+								// if so, add this phi node
+								users.push_back(PHI);
+							}
+						}
+					}
+					collect_users(*instr);
+				}
+			};
+			collect_users(AI);
+			
+			DBG({
+				errs() << "####### users ##\n";
+				for(const auto& user : users) {
+					errs() << "user: " << *user << "\n";
+				}
+				errs() << "\n";
+			})
+			
+			// select replacement strategy:
+			// * create a tmp alloca that will later hold the selected data
+			// * replace the select with two branches (true/false)
+			// * depending on the select condition, branch to either true/false branch
+			// * inside these branches, store the corresponding true/false value into our tmp alloca, then branch back to after the select
+			// * remove the select
+			const auto select_replace = [&](SelectInst* SI) {
+				builder->SetInsertPoint(alloca_insert);
+				auto tmp_alloca = builder->CreateAlloca(AI.getType()->getPointerElementType(), nullptr, "sel_tmp");
+				tmp_alloca->setAlignment(AI.getAlignment());
+				
+				// create our branch condition and true/false blocks that will replace the select
+				auto bb_true = BasicBlock::Create(*ctx, "sel.true", func);
+				auto bb_false = BasicBlock::Create(*ctx, "sel.false", func);
+				builder->SetInsertPoint(SI);
+				builder->CreateCondBr(SI->getCondition(), bb_true, bb_false);
+				
+				// split block before the select instruction so that we can branch back to it later
+				auto bb_start = SI->getParent();
+				auto bb_end = SI->getParent()->splitBasicBlock(SI);
+				// remove automatically inserted branch instruction from parent, since we already have a branch instruction
+				bb_start->getTerminator()->eraseFromParent();
+				
+				// create true/false branches that will copy the true/false data to our tmp alloca accordingly
+				// -> true branch
+				builder->SetInsertPoint(bb_true);
+				builder->CreateStore(builder->CreateLoad(SI->getTrueValue()), tmp_alloca);
+				builder->CreateBr(bb_end);
+				
+				// -> false branch
+				builder->SetInsertPoint(bb_false);
+				builder->CreateStore(builder->CreateLoad(SI->getFalseValue()), tmp_alloca);
+				builder->CreateBr(bb_end);
+				
+				// cleanup, replace select instruction with our new alloca
+				SI->replaceAllUsesWith(tmp_alloca);
+				SI->eraseFromParent();
+			};
+			
+			// phi replacement strategy:
+			// * create a tmp alloca (pointer), this will be used to store all phi pointers
+			// * iterate over all incoming values/pointers, then create a store of their pointer to the tmp pointer in their originating block
+			// * create a load from the tmp alloca and replace all uses of the phi node with it
+			// NOTE: loads and stores are volatile, so that no optimization can do any re-phi-ification(tm) later on
+			const auto phi_replace = [&](PHINode* PHI) {
+				auto phi_tmp_alloca = new AllocaInst(PHI->getType(), nullptr, PHI->getName() + ".tmp", alloca_insert);
+				
+				for(uint32_t i = 0; i < PHI->getNumIncomingValues(); ++i) {
+					auto origin = PHI->getIncomingBlock(i);
+					new StoreInst(PHI->getIncomingValue(i), phi_tmp_alloca, true, origin->getTerminator());
+				}
+				
+				auto load_repl = new LoadInst(phi_tmp_alloca, PHI->getName() + ".repl", true, PHI->getParent()->getFirstNonPHI());
+				PHI->replaceAllUsesWith(load_repl);
+				PHI->eraseFromParent();
+			};
+			
+			for(const auto& user : users) {
+				if(SelectInst* SI = dyn_cast<SelectInst>(user)) {
+					select_replace(SI);
+				}
+				else if(PHINode* PHI = dyn_cast<PHINode>(user)) {
+					phi_replace(PHI);
+				}
+			}
+			was_modified = !users.empty();
+		}
+		
+	};
+	
+	// MetalFinalModuleCleanup:
+	// * calling convention cleanup
+	// * strip unused functions/prototypes/externs
+	struct MetalFinalModuleCleanup : public ModulePass {
+		static char ID; // Pass identification, replacement for typeid
+		
+		Module* M { nullptr };
+		LLVMContext* ctx { nullptr };
+		bool was_modified { false };
+		
+		MetalFinalModuleCleanup() : ModulePass(ID) {
+			initializeMetalFinalModuleCleanupPass(*PassRegistry::getPassRegistry());
+		}
+		
+		bool runOnModule(Module& Mod) override {
+			M = &Mod;
+			ctx = &M->getContext();
+			
+			// * strip floor_* calling convention from all functions and their users (replace it with C CC)
+			// * kill all functions named floor.*
+			bool module_modified = false;
+			for(auto func_iter = Mod.begin(); func_iter != Mod.end();) {
+				auto& func = *func_iter;
+				if(func.getName().startswith("floor.")) {
+					if(func.getNumUses() != 0) {
+						errs() << func.getName() << " should not have an uses at this point!\n";
+					}
+					++func_iter; // inc before erase
+					func.eraseFromParent();
+					module_modified = true;
+					continue;
+				}
+				
+				if(func.getCallingConv() != CallingConv::C) {
+					func.setCallingConv(CallingConv::C);
+					for(auto user : func.users()) {
+						if(auto instr = dyn_cast<Instruction>(user)) {
+							CallSite call_site(instr);
+							call_site.setCallingConv(CallingConv::C);
+						}
+					}
+					module_modified = true;
+				}
+				++func_iter;
+			}
+			return module_modified;
+		}
+		
+	};
+	
+}
+
+char MetalFirst::ID = 0;
+FunctionPass *llvm::createMetalFirstPass(const bool enable_intel_workarounds,
+										 const bool enable_nvidia_workarounds) {
+	return new MetalFirst(enable_intel_workarounds, enable_nvidia_workarounds);
+}
+INITIALIZE_PASS_BEGIN(MetalFirst, "MetalFirst", "MetalFirst Pass", false, false)
+INITIALIZE_PASS_END(MetalFirst, "MetalFirst", "MetalFirst Pass", false, false)
+
+char MetalFinal::ID = 0;
+FunctionPass *llvm::createMetalFinalPass(const bool enable_intel_workarounds,
+										 const bool enable_nvidia_workarounds) {
+	return new MetalFinal(enable_intel_workarounds, enable_nvidia_workarounds);
+}
+INITIALIZE_PASS_BEGIN(MetalFinal, "MetalFinal", "MetalFinal Pass", false, false)
+INITIALIZE_PASS_END(MetalFinal, "MetalFinal", "MetalFinal Pass", false, false)
+
+char MetalFinalModuleCleanup::ID = 0;
+ModulePass *llvm::createMetalFinalModuleCleanupPass() {
+	return new MetalFinalModuleCleanup();
+}
+INITIALIZE_PASS_BEGIN(MetalFinalModuleCleanup, "MetalFinal module cleanup", "MetalFinal module cleanup Pass", false, false)
+INITIALIZE_PASS_END(MetalFinalModuleCleanup, "MetalFinal module cleanup", "MetalFinal module cleanup Pass", false, false)
diff --git a/lib/Transforms/Scalar/MetalImage.cpp b/lib/Transforms/Scalar/MetalImage.cpp
new file mode 100644
index 0000000..0a3eeb1
--- /dev/null
+++ b/lib/Transforms/Scalar/MetalImage.cpp
@@ -0,0 +1,507 @@
+//===- MetalImage.cpp - Metal-specific floor image transformations --------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+// This pass implements the Metal-specific floor image transformations, i.e.
+// floor.opaque.<read/write function>.* -> air.<read/write function>.*
+//
+//===----------------------------------------------------------------------===//
+
+#include "llvm/ADT/Statistic.h"
+#include "llvm/ADT/STLExtras.h"
+#include "llvm/ADT/SetVector.h"
+#include "llvm/ADT/SmallPtrSet.h"
+#include "llvm/ADT/SmallVector.h"
+#include "llvm/ADT/StringExtras.h"
+#include "llvm/Analysis/AliasAnalysis.h"
+#include "llvm/IR/CFG.h"
+#include "llvm/IR/CallSite.h"
+#include "llvm/IR/CallingConv.h"
+#include "llvm/IR/ConstantRange.h"
+#include "llvm/IR/Constants.h"
+#include "llvm/IR/DataLayout.h"
+#include "llvm/IR/DebugInfo.h"
+#include "llvm/IR/DerivedTypes.h"
+#include "llvm/IR/Dominators.h"
+#include "llvm/IR/Function.h"
+#include "llvm/IR/InlineAsm.h"
+#include "llvm/IR/InstIterator.h"
+#include "llvm/IR/InstVisitor.h"
+#include "llvm/IR/IntrinsicInst.h"
+#include "llvm/IR/IRBuilder.h"
+#include "llvm/IR/LLVMContext.h"
+#include "llvm/IR/Metadata.h"
+#include "llvm/IR/Module.h"
+#include "llvm/IR/LegacyPassManager.h"
+#include "llvm/Pass.h"
+#include "llvm/Support/CommandLine.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/ErrorHandling.h"
+#include "llvm/Support/raw_ostream.h"
+#include "llvm/Transforms/IPO/PassManagerBuilder.h"
+#include "llvm/Transforms/IPO.h"
+#include "llvm/Transforms/Scalar.h"
+#include "llvm/Transforms/Scalar/FloorImage.h"
+using namespace llvm;
+
+#define DEBUG_TYPE "MetalImage"
+
+#if 1
+#define DBG(x)
+#else
+#define DBG(x) x
+#endif
+
+namespace {
+	struct MetalImage : public FloorImageBasePass {
+		static char ID; // Pass identification, replacement for typeid
+		
+		MetalImage(const uint32_t image_capabilities_ = 0) :
+		FloorImageBasePass(ID, IMAGE_TYPE_ID::OPAQUE, image_capabilities_) {
+			initializeMetalImagePass(*PassRegistry::getPassRegistry());
+		}
+		
+		void handle_read_image(Instruction& I,
+							   const StringRef& func_name,
+							   llvm::Value* img_handle_arg,
+							   const COMPUTE_IMAGE_TYPE& image_type,
+							   llvm::ConstantInt* const_sampler_arg,
+							   llvm::Value* dyn_sampler_arg,
+							   llvm::Value* coord_arg,
+							   llvm::Value* layer_arg,
+							   llvm::Value* sample_arg,
+							   llvm::Value* offset_arg,
+							   const SmallVector<llvm::Value*, 3>& offset_elems,
+							   const bool is_offset,
+							   llvm::Value* lod_or_bias_arg,
+							   const bool is_lod_or_bias, // true: lod, false: bias
+							   llvm::Value* dpdx_arg,
+							   llvm::Value* dpdy_arg,
+							   const bool is_gradient,
+							   const COMPARE_FUNCTION& compare_function,
+							   llvm::Value* compare_value_arg,
+							   const bool is_compare) override {
+			SmallVector<llvm::Type*, 16> func_arg_types;
+			SmallVector<llvm::Value*, 16> func_args;
+			
+			// -> return data
+			std::string dtype;
+			llvm::Type* ret_type;
+			if(func_name.endswith("float")) {
+				dtype = "v4f32";
+				ret_type = llvm::VectorType::get(llvm::Type::getFloatTy(*ctx), 4);
+			}
+			else if(func_name.endswith("int")) {
+				dtype = "s.v4i32";
+				ret_type = llvm::VectorType::get(llvm::Type::getInt32Ty(*ctx), 4);
+			}
+			else if(func_name.endswith("uint")) {
+				dtype = "u.v4i32";
+				ret_type = llvm::VectorType::get(llvm::Type::getInt32Ty(*ctx), 4);
+			}
+			else if(func_name.endswith("half")) {
+				dtype = "v4f16";
+				ret_type = llvm::VectorType::get(llvm::Type::getHalfTy(*ctx), 4);
+			}
+			else if(func_name.endswith("short")) {
+				dtype = "s.v4i16";
+				ret_type = llvm::VectorType::get(llvm::Type::getInt16Ty(*ctx), 4);
+			}
+			else if(func_name.endswith("ushort")) {
+				dtype = "u.v4i16";
+				ret_type = llvm::VectorType::get(llvm::Type::getInt16Ty(*ctx), 4);
+			}
+			// unknown -> ignore
+			else return;
+			
+			// -> geom
+			std::string geom;
+			bool is_array = false, is_msaa = false, is_cube = false, is_depth = false;
+			switch(image_type) {
+				case COMPUTE_IMAGE_TYPE::IMAGE_1D:					geom = "texture_1d"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_1D_ARRAY:			geom = "texture_1d_array"; is_array = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_1D_BUFFER:			geom = "texture_1d_buffer"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH:
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_STENCIL:		geom = "depth_2d"; is_depth = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D:					geom = "texture_2d"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_ARRAY:			geom = "depth_2d_array"; is_array = true; is_depth = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D_ARRAY:			geom = "texture_2d_array"; is_array = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_MSAA:			geom = "depth_2d_ms"; is_msaa = true; is_depth = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D_MSAA:				geom = "texture_2d_ms"; is_msaa = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_3D:					geom = "texture_3d"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_CUBE:			geom = "depth_cube"; is_cube = true; is_depth = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_CUBE_ARRAY:	geom = "depth_cube_array"; is_cube = true; is_array = true; is_depth = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_CUBE:				geom = "texture_cube"; is_cube = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_CUBE_ARRAY:			geom = "texture_cube_array"; is_cube = true; is_array = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_MSAA_ARRAY:
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D_MSAA_ARRAY:
+					ctx->emitError(&I, "unsupported image type");
+					return;
+				default:
+					ctx->emitError(&I, "unknown or incorrect image type");
+					return;
+			}
+			
+			// -> coord type
+			auto coord_vec_type = dyn_cast_or_null<VectorType>(coord_arg->getType());
+			if(!coord_vec_type) {
+				ctx->emitError(&I, "invalid image coordinate argument (cast to vector failed)");
+				return;
+			}
+			
+			const auto coord_type = coord_vec_type->getElementType();
+			if(is_msaa && !coord_type->isIntegerTy()) {
+				ctx->emitError(&I, "coordinate type must be integer for msaa images");
+				return;
+			}
+			if(is_cube && !coord_type->isFloatTy()) {
+				ctx->emitError(&I, "coordinate type must be float for cube images");
+				return;
+			}
+			
+			// air.read_* or air.sample_*?
+			// for msaa: always read
+			// for all else: read if int coords, sample if float coords
+			const bool is_sample_call = (!is_msaa && !coord_type->isIntegerTy());
+			
+			// img handle and sampler
+			func_arg_types.push_back(img_handle_arg->getType());
+			func_args.push_back(img_handle_arg);
+			
+			if(is_sample_call) {
+				// only add the sampler arg if this is a sample call
+				const auto sampler_arg = (const_sampler_arg == nullptr ? dyn_sampler_arg : const_sampler_arg);
+				func_arg_types.push_back(sampler_arg->getType());
+				func_args.push_back(sampler_arg);
+			}
+			
+			if(is_depth) {
+				// must always add the depth type 1 (== float)
+				func_arg_types.push_back(llvm::Type::getInt32Ty(*ctx));
+				func_args.push_back(builder->getInt32(1));
+				
+				// depth return type is always a float
+				ret_type = llvm::Type::getFloatTy(*ctx);
+				dtype = "f32";
+				
+				if(is_compare) {
+					if(!is_sample_call) {
+						ctx->emitError(&I, "compare must be a sample call");
+						return;
+					}
+				}
+			}
+			else {
+				if(is_compare) {
+					ctx->emitError(&I, "compare is only allowed with depth types");
+					return;
+				}
+			}
+			
+			// handle offset
+			llvm::Value* offset_coord_arg = coord_arg;
+			if(!is_sample_call && is_offset) {
+				offset_coord_arg = builder->CreateAdd(coord_arg, offset_arg);
+			}
+			
+			// -> coords: coords, sample, face, layer
+			if(coord_vec_type->getNumElements() == 1) {
+				// 1D coord, make it scalar
+				func_arg_types.push_back(coord_type);
+				func_args.push_back(builder->CreateExtractElement(offset_coord_arg, builder->getInt32(0)));
+			}
+			else {
+				// normal coord arg
+				if(!is_cube || coord_type->isFloatTy()) {
+					func_arg_types.push_back(offset_coord_arg->getType());
+					func_args.push_back(offset_coord_arg);
+				}
+				// cube with int coords
+				else {
+					// extract the face integer from the coords
+					const auto face_arg = builder->CreateExtractElement(coord_arg, builder->getInt32(2));
+					
+					// create new int2 arg
+					llvm::Value* coord_i2_arg = UndefValue::get(llvm::VectorType::get(llvm::Type::getInt32Ty(*ctx), 2));
+					coord_i2_arg = builder->CreateInsertElement(coord_i2_arg, builder->CreateExtractElement(offset_coord_arg, builder->getInt32(0)), builder->getInt32(0));
+					coord_i2_arg = builder->CreateInsertElement(coord_i2_arg, builder->CreateExtractElement(offset_coord_arg, builder->getInt32(1)), builder->getInt32(1));
+					
+					func_arg_types.push_back(coord_i2_arg->getType());
+					func_args.push_back(coord_i2_arg);
+					
+					func_arg_types.push_back(face_arg->getType());
+					func_args.push_back(face_arg);
+				}
+			}
+			
+			if(is_msaa) {
+				func_arg_types.push_back(sample_arg->getType());
+				func_args.push_back(sample_arg);
+			}
+			
+			if(is_array) {
+				func_arg_types.push_back(layer_arg->getType());
+				func_args.push_back(layer_arg);
+			}
+			
+			if(is_compare) {
+				func_arg_types.push_back(compare_value_arg->getType());
+				func_args.push_back(compare_value_arg);
+			}
+			
+			// -> additional args: lod, bias, gradient, offset
+			if(!is_sample_call) {
+				// -> read
+				if(!is_msaa) { // msaa is always lod 0, hence needs no arg
+					// -> lod
+					if(is_lod_or_bias) {
+						// for read, only int lods are allowed
+						if(!lod_or_bias_arg->getType()->isIntegerTy()) {
+							// convert to int
+							const auto int_lod = builder->CreateFPToSI(lod_or_bias_arg, llvm::Type::getInt32Ty(*ctx));
+							func_arg_types.push_back(int_lod->getType());
+							func_args.push_back(int_lod);
+						}
+						else {
+							func_arg_types.push_back(lod_or_bias_arg->getType());
+							func_args.push_back(lod_or_bias_arg);
+						}
+					}
+					else {
+						// if no lod is specified (bias is not allowed here), add a 0 lod
+						func_arg_types.push_back(llvm::Type::getInt32Ty(*ctx));
+						func_args.push_back(builder->getInt32(0));
+					}
+				}
+			}
+			else {
+				// -> sample
+				
+				// -> gradient
+				if(is_gradient) {
+					func_arg_types.push_back(dpdx_arg->getType());
+					func_args.push_back(dpdx_arg);
+					func_arg_types.push_back(dpdy_arg->getType());
+					func_args.push_back(dpdy_arg);
+				}
+				
+				// -> offset
+				if(!is_cube) { // cube allows no offset
+					func_arg_types.push_back(llvm::Type::getInt1Ty(*ctx));
+					func_args.push_back(builder->getInt1(is_offset));
+					
+					func_arg_types.push_back(offset_arg->getType());
+					func_args.push_back(offset_arg);
+				}
+				
+				// -> lod / bias
+				if(!is_gradient) {
+					// lod or bias?
+					func_arg_types.push_back(llvm::Type::getInt1Ty(*ctx));
+					func_args.push_back(builder->getInt1(is_lod_or_bias));
+					
+					// for sample, only float lods are allowed
+					if(!lod_or_bias_arg->getType()->isFloatTy()) {
+						// convert to float
+						const auto float_lod = builder->CreateSIToFP(lod_or_bias_arg, llvm::Type::getFloatTy(*ctx));
+						func_arg_types.push_back(float_lod->getType());
+						func_args.push_back(float_lod);
+					}
+					else {
+						func_arg_types.push_back(lod_or_bias_arg->getType());
+						func_args.push_back(lod_or_bias_arg);
+					}
+				}
+				
+			}
+			
+			// -> build read func name
+			std::string read_func_name = "air.";
+			
+			read_func_name += (is_sample_call ? "sample_" : "read_");
+			if(is_compare) read_func_name += "compare_";
+			read_func_name += geom;
+			if(is_gradient) read_func_name += "_grad";
+			
+			read_func_name += '.' + dtype;
+			
+			// create the air call
+			const auto func_type = llvm::FunctionType::get(ret_type, func_arg_types, false);
+			llvm::CallInst* read_call = builder->CreateCall(M->getOrInsertFunction(read_func_name, func_type, nounwind_readnone_attr), func_args);
+			read_call->setDoesNotAccessMemory(); // all reads are readnone (can be optimized away if unused)
+			read_call->setDebugLoc(I.getDebugLoc()); // keep debug loc
+			
+			// if this is a depth read/sample, the return type is a float -> create a float4
+			llvm::Value* read_call_result = read_call;
+			if(is_depth) {
+				read_call_result = UndefValue::get(llvm::VectorType::get(llvm::Type::getFloatTy(*ctx), 4));
+				read_call_result = builder->CreateInsertElement(read_call_result, read_call, builder->getInt32(0));
+				// rest is undef/zero (and will be stripped away again anyways)
+			}
+			
+			//
+			I.replaceAllUsesWith(read_call_result);
+			I.eraseFromParent();
+		}
+		
+		void handle_write_image(Instruction& I,
+								const StringRef& func_name,
+								llvm::Value* img_handle_arg,
+								const COMPUTE_IMAGE_TYPE& image_type,
+								const COMPUTE_IMAGE_TYPE& format_type,
+								const COMPUTE_IMAGE_TYPE& data_type,
+								const bool& is_normalized,
+								const uint32_t& image_channel_count,
+								llvm::Value* coord_arg,
+								llvm::Value* layer_arg,
+								llvm::Value* lod_arg,
+								const bool is_lod,
+								llvm::Value* data_arg) override {
+			SmallVector<llvm::Type*, 16> func_arg_types;
+			SmallVector<llvm::Value*, 16> func_args;
+			
+			//// more arg checking
+			auto coord_vec_type = dyn_cast_or_null<VectorType>(coord_arg->getType());
+			if(!coord_vec_type) {
+				ctx->emitError(&I, "invalid image coordinate argument (cast to vector failed)");
+				return;
+			}
+			
+			const auto coord_type = coord_vec_type->getElementType();
+			if(!coord_type->isIntegerTy()) {
+				ctx->emitError(&I, "coordinate type must be integer");
+				return;
+			}
+			
+			std::string dtype;
+			if(func_name.endswith("float")) {
+				dtype = "v4f32";
+			}
+			else if(func_name.endswith("int")) {
+				dtype = "s.v4i32";
+			}
+			else if(func_name.endswith("uint")) {
+				dtype = "u.v4i32";
+			}
+			else if(func_name.endswith("half")) {
+				dtype = "v4f16";
+			}
+			else if(func_name.endswith("short")) {
+				dtype = "s.v4i16";
+			}
+			else if(func_name.endswith("ushort")) {
+				dtype = "u.v4i16";
+			}
+			// unknown -> ignore
+			else return;
+			
+			//// func replacement
+			func_arg_types.push_back(img_handle_arg->getType());
+			func_args.push_back(img_handle_arg);
+			
+			// -> geom
+			std::string geom;
+			bool is_array = false, is_cube = false;
+			switch(image_type) {
+				case COMPUTE_IMAGE_TYPE::IMAGE_1D:					geom = "texture_1d"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_1D_ARRAY:			geom = "texture_1d_array"; is_array = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_1D_BUFFER:			geom = "texture_1d_buffer"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D:					geom = "texture_2d"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D_ARRAY:			geom = "texture_2d_array"; is_array = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_3D:					geom = "texture_3d"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_CUBE:				geom = "texture_cube"; is_cube = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_CUBE_ARRAY:			geom = "texture_cube_array"; is_cube = true; is_array = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D_MSAA:
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH:
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_STENCIL:
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_ARRAY:
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_MSAA:
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_CUBE:
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_CUBE_ARRAY:
+					ctx->emitError(&I, "invalid image type - type is not writable");
+					return;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_MSAA_ARRAY:
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D_MSAA_ARRAY:
+					ctx->emitError(&I, "unsupported image type");
+					return;
+				default:
+					ctx->emitError(&I, "unknown or incorrect image type");
+					return;
+			}
+			
+			// -> coords: coords, face, layer
+			if(coord_vec_type->getNumElements() == 1) {
+				// 1D coord, make it scalar
+				func_arg_types.push_back(coord_type);
+				func_args.push_back(builder->CreateExtractElement(coord_arg, builder->getInt32(0)));
+			}
+			else {
+				// normal coord arg
+				if(!is_cube) {
+					func_arg_types.push_back(coord_vec_type);
+					func_args.push_back(coord_arg);
+				}
+				// cube with int coords
+				else {
+					// extract the face integer from the coords
+					const auto face_arg = builder->CreateExtractElement(coord_arg, builder->getInt32(2));
+					
+					// create new int2 arg
+					llvm::Value* coord_i2_arg = UndefValue::get(llvm::VectorType::get(llvm::Type::getInt32Ty(*ctx), 2));
+					coord_i2_arg = builder->CreateInsertElement(coord_i2_arg, builder->CreateExtractElement(coord_arg, builder->getInt32(0)), builder->getInt32(0));
+					coord_i2_arg = builder->CreateInsertElement(coord_i2_arg, builder->CreateExtractElement(coord_arg, builder->getInt32(1)), builder->getInt32(1));
+					
+					func_arg_types.push_back(coord_i2_arg->getType());
+					func_args.push_back(coord_i2_arg);
+					
+					func_arg_types.push_back(face_arg->getType());
+					func_args.push_back(face_arg);
+				}
+			}
+			
+			if(is_array) {
+				func_arg_types.push_back(layer_arg->getType());
+				func_args.push_back(layer_arg);
+			}
+			
+			// -> data (also a 4-component vector)
+			func_arg_types.push_back(data_arg->getType());
+			func_args.push_back(data_arg);
+			
+			// -> lod
+			func_arg_types.push_back(llvm::Type::getInt32Ty(*ctx));
+			if(!is_lod) {
+				func_args.push_back(builder->getInt32(0));
+			}
+			else {
+				func_args.push_back(lod_arg);
+			}
+			
+			// -> build write func name
+			const std::string write_func_name = "air.write_" + geom + '.' + dtype;
+			
+			// create the air call
+			const auto func_type = llvm::FunctionType::get(builder->getVoidTy(), func_arg_types, false);
+			llvm::CallInst* write_call = builder->CreateCall(M->getOrInsertFunction(write_func_name, func_type, nounwind_attr), func_args);
+			write_call->setDebugLoc(I.getDebugLoc()); // keep debug loc
+			
+			//
+			I.replaceAllUsesWith(write_call);
+			I.eraseFromParent();
+		}
+		
+	};
+}
+
+char MetalImage::ID = 0;
+INITIALIZE_PASS_BEGIN(MetalImage, "MetalImage", "MetalImage Pass", false, false)
+INITIALIZE_PASS_END(MetalImage, "MetalImage", "MetalImage Pass", false, false)
+
+FunctionPass *llvm::createMetalImagePass(const uint32_t image_capabilities) {
+	return new MetalImage(image_capabilities);
+}
diff --git a/lib/Transforms/Scalar/PropagateRangeInfo.cpp b/lib/Transforms/Scalar/PropagateRangeInfo.cpp
new file mode 100644
index 0000000..9366898
--- /dev/null
+++ b/lib/Transforms/Scalar/PropagateRangeInfo.cpp
@@ -0,0 +1,207 @@
+//===- PropagateRangeInfo.cpp - Vulkan final pass -------------------------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+// TODO
+//
+//===----------------------------------------------------------------------===//
+
+#include "llvm/ADT/Statistic.h"
+#include "llvm/ADT/STLExtras.h"
+#include "llvm/ADT/SetVector.h"
+#include "llvm/ADT/SmallPtrSet.h"
+#include "llvm/ADT/SmallVector.h"
+#include "llvm/ADT/StringExtras.h"
+#include "llvm/Analysis/AliasAnalysis.h"
+#include "llvm/Analysis/BasicAliasAnalysis.h"
+#include "llvm/Analysis/GlobalsModRef.h"
+#include "llvm/Analysis/PostDominators.h"
+#include "llvm/Analysis/LoopInfo.h"
+#include "llvm/IR/CFG.h"
+#include "llvm/IR/CallSite.h"
+#include "llvm/IR/CallingConv.h"
+#include "llvm/IR/ConstantRange.h"
+#include "llvm/IR/Constants.h"
+#include "llvm/IR/DataLayout.h"
+#include "llvm/IR/DebugInfo.h"
+#include "llvm/IR/DerivedTypes.h"
+#include "llvm/IR/Dominators.h"
+#include "llvm/IR/Function.h"
+#include "llvm/IR/InlineAsm.h"
+#include "llvm/IR/InstIterator.h"
+#include "llvm/IR/InstVisitor.h"
+#include "llvm/IR/IntrinsicInst.h"
+#include "llvm/IR/IRBuilder.h"
+#include "llvm/IR/LLVMContext.h"
+#include "llvm/IR/Metadata.h"
+#include "llvm/IR/Module.h"
+#include "llvm/IR/LegacyPassManager.h"
+#include "llvm/Pass.h"
+#include "llvm/Support/CommandLine.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/ErrorHandling.h"
+#include "llvm/Support/raw_ostream.h"
+#include "llvm/Transforms/IPO/PassManagerBuilder.h"
+#include "llvm/Transforms/IPO.h"
+#include "llvm/Transforms/Scalar.h"
+#include "llvm/Transforms/Utils/BasicBlockUtils.h"
+#include "llvm/Transforms/Utils/LoopUtils.h"
+#include "llvm/Transforms/Utils/Cloning.h"
+#include <algorithm>
+#include <cstdarg>
+#include <memory>
+#include <unordered_map>
+#include <unordered_set>
+#include <deque>
+#include <array>
+using namespace llvm;
+
+#define DEBUG_TYPE "PropagateRangeInfo"
+
+#if 1
+#define DBG(x)
+#else
+#define DBG(x) x
+#endif
+
+namespace {
+	// PropagateRangeInfo
+	struct PropagateRangeInfo : public FunctionPass, InstVisitor<PropagateRangeInfo> {
+		friend class InstVisitor<PropagateRangeInfo>;
+		
+		static char ID; // Pass identification, replacement for typeid
+		
+		Module* M { nullptr };
+		LLVMContext* ctx { nullptr };
+		Function* func { nullptr };
+		
+		bool was_modified { false };
+		
+		PropagateRangeInfo() :
+		FunctionPass(ID) {
+			initializePropagateRangeInfoPass(*PassRegistry::getPassRegistry());
+		}
+		
+		const char *getPassName() const override {
+			return "Propagate Range Info";
+		}
+		
+		void getAnalysisUsage(AnalysisUsage &AU) const override {
+			AU.setPreservesCFG();
+			FunctionPass::getAnalysisUsage(AU);
+		}
+		
+		bool runOnFunction(Function &F) override {
+			// exit if empty function
+			if(F.empty()) return false;
+			
+			//
+			M = F.getParent();
+			ctx = &M->getContext();
+			func = &F;
+			was_modified = false;
+			
+			visit(F);
+			return was_modified;
+		}
+		
+		// InstVisitor overrides...
+		using InstVisitor<PropagateRangeInfo>::visit;
+		void visit(Instruction& I) {
+			InstVisitor<PropagateRangeInfo>::visit(I);
+		}
+		
+		// we always start at call instructions, because this is where range info originates from
+		void visitCallInst(CallInst &CI) {
+			MDNode* range = CI.getMetadata(LLVMContext::MD_range);
+			if(range == nullptr) return;
+			
+			for(User* user : CI.users()) {
+				if(Instruction* I = dyn_cast<Instruction>(user)) {
+					DBG(errs() << "adding range info to user: " << *I << "\n";)
+					addRangeInfo(*I, range);
+				}
+			}
+		}
+		
+		void addRangeInfo(Instruction& I, MDNode* range) {
+			// can't handle non-integer types or int bit-width > 64 yet
+			IntegerType* int_type = dyn_cast<IntegerType>(I.getType());
+			if(int_type == nullptr ||
+			   int_type->getBitWidth() > 64) {
+				return;
+			}
+			
+			// can only propagate to certain instruction
+			switch(I.getOpcode()) {
+				// trunc/extend are obvious
+				case llvm::Instruction::Trunc:
+				case llvm::Instruction::SExt:
+				case llvm::Instruction::ZExt:
+					break;
+				
+				// TODO: integer/other ops when the operand is a ConstantInt
+				// add/sub/mul/div/rem/shl/shr -> obvious
+				// and -> [0, currrent max]?
+				// or/xor -> remove range info, b/c [0, int max]?
+				// select -> merge
+				// phi -> merge if all have range info
+				
+				// else: can't propagate
+				default: return;
+			}
+			
+			// will modify now
+			was_modified = true;
+			
+			// check if we need to convert the integer type
+			// TODO: how to handle signed values? can't retrieve that info from APInt or ConstantInt
+			const auto range_type = mdconst::extract<ConstantInt>(range->getOperand(0))->getType();
+			MDNode* apply_range = range;
+			if(range_type != int_type) {
+				const uint64_t max_value = int_type->getBitMask();
+				
+				SmallVector<Metadata*, 2> conv_range_ints;
+				conv_range_ints.reserve(range->getNumOperands());
+				for(const auto& op : range->operands()) {
+					const auto val = mdconst::extract<ConstantInt>(op)->getValue();
+					const auto clamped_val = std::min(val.getZExtValue(), max_value);
+					conv_range_ints.push_back(llvm::ConstantAsMetadata::get(ConstantInt::get(int_type, clamped_val, false)));
+				}
+				apply_range = MDNode::get(*ctx, conv_range_ints);
+			}
+			
+			// if the instruction already contains range info, merge it
+			MDNode* instr_range = I.getMetadata(LLVMContext::MD_range);
+			if(instr_range == nullptr) {
+				I.setMetadata(LLVMContext::MD_range, apply_range);
+			}
+			else {
+				I.setMetadata(LLVMContext::MD_range, MDNode::getMostGenericRange(apply_range, instr_range));
+			}
+			
+			// continue the recursion
+			for(User* user : I.users()) {
+				if(Instruction* UI = dyn_cast<Instruction>(user)) {
+					DBG(errs() << "> adding range info to user: " << *UI << "\n";)
+					addRangeInfo(*UI, apply_range);
+				}
+			}
+		}
+		
+	};
+	
+}
+
+char PropagateRangeInfo::ID = 0;
+FunctionPass *llvm::createPropagateRangeInfoPass() {
+	return new PropagateRangeInfo();
+}
+INITIALIZE_PASS_BEGIN(PropagateRangeInfo, "PropagateRangeInfo", "PropagateRangeInfo Pass", false, false)
+INITIALIZE_PASS_END(PropagateRangeInfo, "PropagateRangeInfo", "PropagateRangeInfo Pass", false, false)
+
diff --git a/lib/Transforms/Scalar/SPIRFinal.cpp b/lib/Transforms/Scalar/SPIRFinal.cpp
new file mode 100644
index 0000000..4bebcc8
--- /dev/null
+++ b/lib/Transforms/Scalar/SPIRFinal.cpp
@@ -0,0 +1,313 @@
+//===- SPIRFinal.cpp - OpenCL/SPIR fixes ----------------------------------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+// This file tries to fix the LLVM IR so that it is SPIR-conformant.
+//
+//===----------------------------------------------------------------------===//
+
+#include "llvm/ADT/Statistic.h"
+#include "llvm/ADT/STLExtras.h"
+#include "llvm/ADT/SetVector.h"
+#include "llvm/ADT/SmallPtrSet.h"
+#include "llvm/ADT/SmallVector.h"
+#include "llvm/ADT/StringExtras.h"
+#include "llvm/Analysis/AliasAnalysis.h"
+#include "llvm/IR/CFG.h"
+#include "llvm/IR/CallSite.h"
+#include "llvm/IR/CallingConv.h"
+#include "llvm/IR/ConstantRange.h"
+#include "llvm/IR/Constants.h"
+#include "llvm/IR/DataLayout.h"
+#include "llvm/IR/DebugInfo.h"
+#include "llvm/IR/DerivedTypes.h"
+#include "llvm/IR/Dominators.h"
+#include "llvm/IR/Function.h"
+#include "llvm/IR/InlineAsm.h"
+#include "llvm/IR/InstIterator.h"
+#include "llvm/IR/InstVisitor.h"
+#include "llvm/IR/IntrinsicInst.h"
+#include "llvm/IR/IRBuilder.h"
+#include "llvm/IR/LLVMContext.h"
+#include "llvm/IR/Metadata.h"
+#include "llvm/IR/Module.h"
+#include "llvm/IR/LegacyPassManager.h"
+#include "llvm/Pass.h"
+#include "llvm/Support/CommandLine.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/ErrorHandling.h"
+#include "llvm/Support/raw_ostream.h"
+#include "llvm/Transforms/IPO/PassManagerBuilder.h"
+#include "llvm/Transforms/IPO.h"
+#include "llvm/Transforms/Scalar.h"
+#include <algorithm>
+#include <cstdarg>
+#include <memory>
+#include <cxxabi.h>
+using namespace llvm;
+
+#define DEBUG_TYPE "SPIRFinal"
+
+#if 1
+#define DBG(x)
+#else
+#define DBG(x) x
+#endif
+
+namespace {
+	// SPIRFinal
+	struct SPIRFinal : public FunctionPass, InstVisitor<SPIRFinal> {
+		friend class InstVisitor<SPIRFinal>;
+		
+		static char ID; // Pass identification, replacement for typeid
+		
+		std::shared_ptr<llvm::IRBuilder<>> builder;
+		
+		Module* M { nullptr };
+		LLVMContext* ctx { nullptr };
+		Function* func { nullptr };
+		Instruction* alloca_insert { nullptr };
+		bool was_modified { false };
+		
+		SPIRFinal() : FunctionPass(ID) {
+			initializeSPIRFinalPass(*PassRegistry::getPassRegistry());
+		}
+		
+		bool runOnFunction(Function &F) override {
+			// exit if empty function
+			if (F.empty()) return false;
+			
+			//
+			M = F.getParent();
+			ctx = &M->getContext();
+			func = &F;
+			builder = std::make_shared<llvm::IRBuilder<>>(*ctx);
+			
+			// visit everything in this function
+			was_modified = false; // reset every time
+			DBG(errs() << "in func: "; errs().write_escaped(F.getName()) << '\n';)
+			
+			// update function signature / param list
+			if(F.getCallingConv() == CallingConv::FLOOR_KERNEL) {
+				std::vector<Type*> param_types;
+				for(auto& arg : F.args()) {
+					// add "byval" attribute for all kernel struct parameters
+					if(arg.getType()->isPointerTy() &&
+					   arg.getType()->getPointerElementType()->isAggregateType() &&
+					   arg.getType()->getPointerAddressSpace() == 0 &&
+					   !F.getAttributes().hasAttribute(arg.getArgNo() + 1, Attribute::ByVal)) {
+						AttrBuilder B;
+						B.addAttribute(Attribute::ByVal);
+						arg.addAttr(AttributeSet::get(*ctx, arg.getArgNo() + 1,  B));
+						was_modified = true;
+					}
+					
+					param_types.push_back(arg.getType());
+				}
+				if(was_modified) {
+					auto new_func_type = PointerType::get(FunctionType::get(F.getReturnType(), param_types, false), 0);
+					F.mutateType(new_func_type);
+				}
+			}
+			
+			//
+			visit(F);
+			if(was_modified) {
+				DBG(errs() << "!! modified function: ";)
+				DBG(errs().write_escaped(F.getName()) << '\n';)
+			}
+			return was_modified;
+		}
+		
+		// InstVisitor overrides...
+		using InstVisitor<SPIRFinal>::visit;
+		void visit(Instruction& I) {
+			InstVisitor<SPIRFinal>::visit(I);
+		}
+		
+		// SPIR only supports scalar conversion ops ->
+		// * scalarize source vector
+		// * call conversion op for each scalar
+		// * reassemble a vector from the converted scalars
+		// * replace all uses of the original vector
+		template <Instruction::CastOps cast_op>
+		__attribute__((always_inline))
+		void vec_to_scalar_ops(CastInst& I) {
+			if(!I.getType()->isVectorTy()) return;
+			
+			// start insertion before instruction
+			builder->SetInsertPoint(&I);
+			
+			// setup
+			auto* src_vec = I.getOperand(0);
+			const auto dim = src_vec->getType()->getVectorNumElements();
+			const auto si_type = I.getDestTy();
+			const auto si_scalar_type = si_type->getScalarType();
+			llvm::Value* dst_vec = UndefValue::get(si_type);
+			
+			// iterate over all vector components, emit a scalar instruction and insert into a new vector
+			for(uint32_t i = 0; i < dim; ++i) {
+				auto scalar = builder->CreateExtractElement(src_vec, builder->getInt32(i));
+				dst_vec = builder->CreateInsertElement(dst_vec,
+													   builder->CreateCast(cast_op, scalar, si_scalar_type),
+													   builder->getInt32(i));
+			}
+			
+			// finally, replace all uses with the new vector and remove the old vec instruction
+			I.replaceAllUsesWith(dst_vec);
+			I.eraseFromParent();
+			was_modified = true;
+		}
+		
+		void visitTruncInst(TruncInst &I) {
+			vec_to_scalar_ops<Instruction::Trunc>(I);
+		}
+		void visitZExtInst(ZExtInst &I) {
+			vec_to_scalar_ops<Instruction::ZExt>(I);
+		}
+		void visitSExtInst(SExtInst &I) {
+			vec_to_scalar_ops<Instruction::SExt>(I);
+		}
+		void visitFPTruncInst(FPTruncInst &I) {
+			vec_to_scalar_ops<Instruction::FPTrunc>(I);
+		}
+		void visitFPExtInst(FPExtInst &I) {
+			vec_to_scalar_ops<Instruction::FPExt>(I);
+		}
+		void visitFPToUIInst(FPToUIInst &I) {
+			vec_to_scalar_ops<Instruction::FPToUI>(I);
+		}
+		void visitFPToSIInst(FPToSIInst &I) {
+			vec_to_scalar_ops<Instruction::FPToSI>(I);
+		}
+		void visitUIToFPInst(UIToFPInst &I) {
+			vec_to_scalar_ops<Instruction::UIToFP>(I);
+		}
+		void visitSIToFPInst(SIToFPInst &I) {
+			vec_to_scalar_ops<Instruction::SIToFP>(I);
+		}
+		
+		// SPIR doesn't support LLVM lifetime and assume intrinsics
+		// -> simply remove them
+		// TODO: should probably kill the global decl as well
+		void visitIntrinsicInst(IntrinsicInst &I) {
+			if (I.getIntrinsicID() == Intrinsic::lifetime_start ||
+				I.getIntrinsicID() == Intrinsic::lifetime_end ||
+				I.getIntrinsicID() == Intrinsic::assume) {
+				I.eraseFromParent();
+				was_modified = true;
+			}
+		}
+		
+		// "ashr" instructions may not be "exact"
+		void visitAShr(BinaryOperator& O) {
+			auto* ashr = dyn_cast_or_null<PossiblyExactOperator>(&O);
+			if(ashr && ashr->isExact()) {
+				// -> replace with a non-exact version
+				builder->SetInsertPoint(&O);
+				auto* new_ashr = builder->CreateAShr(O.getOperand(0), O.getOperand(1));
+				O.replaceAllUsesWith(new_ashr);
+				O.eraseFromParent();
+				was_modified = true;
+			}
+		}
+		
+		// unsupported LLVM IR instructions - fail on these
+		void visitIndirectBrInst(IndirectBrInst &I) {
+			ctx->emitError(&I, "indirect-br instruction is not supported by SPIR");
+		}
+		void visitInvokeInst(InvokeInst &I) {
+			ctx->emitError(&I, "invoke instruction is not supported by SPIR");
+		}
+		// NOTE: unwind no longer exists
+		void visitResumeInst(ResumeInst &I) {
+			ctx->emitError(&I, "resume instruction is not supported by SPIR");
+		}
+		void visitFenceInst(FenceInst &I) {
+			ctx->emitError(&I, "fence instruction is not supported by SPIR");
+		}
+		void visitAtomicCmpXchgInst(AtomicCmpXchgInst &I) {
+			ctx->emitError(&I, "atomic-cmp-xchg instruction is not supported by SPIR - use atomic_* function calls instead!");
+		}
+		void visitAtomicRMWInst(AtomicRMWInst &I) {
+			ctx->emitError(&I, "atomic-rmv instruction is not supported by SPIR - use atomic_* function calls instead!");
+		}
+		void visitVAArgInst(VAArgInst &I) {
+			ctx->emitError(&I, "va-arg instruction is not supported by SPIR");
+		}
+		void visitLandingPadInst(LandingPadInst &I) {
+			ctx->emitError(&I, "landing-pad instruction is not supported by SPIR");
+		}
+		
+		// calls to function pointers are not allowed
+		void visitCallInst(CallInst &I) {
+			if(I.getCalledFunction() == nullptr) {
+				ctx->emitError(&I, "indirect function call / call to function pointer is not supported by SPIR");
+			}
+		}
+		
+		// atomic load/store instructions are not allowed
+		void visitLoadInst(LoadInst &I) {
+			if(I.isAtomic()) {
+				ctx->emitError(&I, "atomic-load instruction is not supported by SPIR - use atomic_* function calls instead!");
+			}
+		}
+		void visitStoreInst(StoreInst &I) {
+			if(I.isAtomic()) {
+				ctx->emitError(&I, "atomic-store instruction is not supported by SPIR - use atomic_* function calls instead!");
+			}
+		}
+		
+		// convert illegal integer types in select and switch instructions to legal ones
+		// TODO/NOTE: ideally, this should be done for all instructions in the module, but right now this
+		//            is the only place where illegal int types get emitted
+		void visitSelectInst(SelectInst& SI) {
+			if(!SI.getType()->isIntegerTy()) return;
+			
+			const auto bit_width = SI.getType()->getIntegerBitWidth();
+			if(M->getDataLayout().isLegalInteger(bit_width)) {
+				return;
+			}
+			
+			const bool mutate_true_val = (SI.getTrueValue()->getType()->getIntegerBitWidth() == bit_width);
+			const bool mutate_false_val = (SI.getFalseValue()->getType()->getIntegerBitWidth() == bit_width);
+			if((mutate_true_val && !isa<ConstantInt>(SI.getTrueValue())) ||
+			   (mutate_false_val && !isa<ConstantInt>(SI.getFalseValue()))) {
+				ctx->emitError(&SI, "select uses an illegal integer bit width (" + std::to_string(bit_width) + ") " +
+							   "and true/false values can not be in-place converted to a legal integer width, " +
+							   "because they are not constant values!");
+				SI.dump();
+				return;
+			}
+			
+			const auto smallest_legal_type = M->getDataLayout().getSmallestLegalIntType(*ctx, bit_width);
+			if(mutate_true_val) SI.getTrueValue()->mutateType(smallest_legal_type);
+			if(mutate_false_val) SI.getFalseValue()->mutateType(smallest_legal_type);
+			SI.mutateType(smallest_legal_type);
+		}
+		void visitSwitchInst(SwitchInst& SI) {
+			if(!SI.getCondition()->getType()->isIntegerTy()) return;
+			
+			const auto bit_width = SI.getCondition()->getType()->getIntegerBitWidth();
+			if(M->getDataLayout().isLegalInteger(bit_width)) {
+				return;
+			}
+			
+			const auto smallest_legal_type = M->getDataLayout().getSmallestLegalIntType(*ctx, bit_width);
+			SI.getCondition()->mutateType(smallest_legal_type);
+		}
+	};
+}
+
+char SPIRFinal::ID = 0;
+INITIALIZE_PASS_BEGIN(SPIRFinal, "SPIRFinal", "SPIRFinal Pass", false, false)
+INITIALIZE_PASS_END(SPIRFinal, "SPIRFinal", "SPIRFinal Pass", false, false)
+
+FunctionPass *llvm::createSPIRFinalPass() {
+	return new SPIRFinal();
+}
diff --git a/lib/Transforms/Scalar/SPIRImage.cpp b/lib/Transforms/Scalar/SPIRImage.cpp
new file mode 100644
index 0000000..b094838
--- /dev/null
+++ b/lib/Transforms/Scalar/SPIRImage.cpp
@@ -0,0 +1,657 @@
+//===- SPIRImage.cpp - SPIR-specific floor image transformations ----------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+// This pass implements the SPIR-specific floor image transformations, i.e.
+// floor.opaque.<read/write function>.* -> spir image function call
+//
+//===----------------------------------------------------------------------===//
+
+#include "llvm/ADT/Statistic.h"
+#include "llvm/ADT/STLExtras.h"
+#include "llvm/ADT/SetVector.h"
+#include "llvm/ADT/SmallPtrSet.h"
+#include "llvm/ADT/SmallVector.h"
+#include "llvm/ADT/StringExtras.h"
+#include "llvm/Analysis/AliasAnalysis.h"
+#include "llvm/IR/CFG.h"
+#include "llvm/IR/CallSite.h"
+#include "llvm/IR/CallingConv.h"
+#include "llvm/IR/ConstantRange.h"
+#include "llvm/IR/Constants.h"
+#include "llvm/IR/DataLayout.h"
+#include "llvm/IR/DebugInfo.h"
+#include "llvm/IR/DerivedTypes.h"
+#include "llvm/IR/Dominators.h"
+#include "llvm/IR/Function.h"
+#include "llvm/IR/InlineAsm.h"
+#include "llvm/IR/InstIterator.h"
+#include "llvm/IR/InstVisitor.h"
+#include "llvm/IR/IntrinsicInst.h"
+#include "llvm/IR/IRBuilder.h"
+#include "llvm/IR/LLVMContext.h"
+#include "llvm/IR/Metadata.h"
+#include "llvm/IR/Module.h"
+#include "llvm/IR/LegacyPassManager.h"
+#include "llvm/Pass.h"
+#include "llvm/Support/CommandLine.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/ErrorHandling.h"
+#include "llvm/Support/raw_ostream.h"
+#include "llvm/Transforms/IPO/PassManagerBuilder.h"
+#include "llvm/Transforms/IPO.h"
+#include "llvm/Transforms/Scalar.h"
+#include "llvm/Transforms/Scalar/FloorImage.h"
+#include <unordered_map>
+using namespace llvm;
+
+#define DEBUG_TYPE "SPIRImage"
+
+#if 1
+#define DBG(x)
+#else
+#define DBG(x) x
+#endif
+
+namespace {
+	struct SPIRImage : public FloorImageBasePass {
+		static char ID; // Pass identification, replacement for typeid
+		bool enable_intel_workarounds { false };
+		
+		SPIRImage(const uint32_t image_capabilities_ = 0,
+				  const bool enable_intel_workarounds_ = false) :
+		FloorImageBasePass(ID, IMAGE_TYPE_ID::OPAQUE, image_capabilities_),
+		enable_intel_workarounds(enable_intel_workarounds_) {
+			initializeSPIRImagePass(*PassRegistry::getPassRegistry());
+		}
+		
+		llvm::Value* get_or_create_spir_function(std::string func_name,
+												 llvm::Type* ret_type,
+												 const SmallVector<llvm::Type*, 8>& func_arg_types,
+												 const bool is_readnone = false) {
+			if(enable_intel_workarounds) {
+				// intel name mangling is a bit off sometimes, so use their name mangling instead
+				// correct -> intel
+				static const std::unordered_map<std::string, std::string> intel_func_repl {
+					{ "_Z11read_imagef11ocl_image2d11ocl_samplerDv2_fDv2_fDv2_f", "_Z11read_imagef11ocl_image2d11ocl_samplerDv2_fS_S_" },
+					{ "_Z11read_imagei11ocl_image2d11ocl_samplerDv2_fDv2_fDv2_f", "_Z11read_imagei11ocl_image2d11ocl_samplerDv2_fS_S_" },
+					{ "_Z12read_imageui11ocl_image2d11ocl_samplerDv2_fDv2_fDv2_f", "_Z12read_imageui11ocl_image2d11ocl_samplerDv2_fS_S_" },
+					{ "_Z11read_imagef16ocl_image2ddepth11ocl_samplerDv2_fDv2_fDv2_f", "_Z11read_imagef16ocl_image2ddepth11ocl_samplerDv2_fS_S_" },
+					{ "_Z11read_imagef11ocl_image3d11ocl_samplerDv4_fDv4_fDv4_f", "_Z11read_imagef11ocl_image3d11ocl_samplerDv4_fS_S_" },
+					{ "_Z11read_imagei11ocl_image3d11ocl_samplerDv4_fDv4_fDv4_f", "_Z11read_imagei11ocl_image3d11ocl_samplerDv4_fS_S_" },
+					{ "_Z12read_imageui11ocl_image3d11ocl_samplerDv4_fDv4_fDv4_f", "_Z12read_imageui11ocl_image3d11ocl_samplerDv4_fS_S_" },
+					{ "_Z12write_imagei11ocl_image3dDv4_iDv4_i", "_Z12write_imagei11ocl_image3dDv4_iS_" },
+					{ "_Z12write_imagei11ocl_image3dDv4_iiDv4_i", "_Z12write_imagei11ocl_image3dDv4_iiS_" },
+					{ "_Z12write_imagei16ocl_image2darrayDv4_iDv4_i", "_Z12write_imagei16ocl_image2darrayDv4_iS_" },
+					{ "_Z12write_imagei16ocl_image2darrayDv4_iiDv4_i", "_Z12write_imagei16ocl_image2darrayDv4_iiS_" },
+				};
+				const auto iter = intel_func_repl.find(func_name);
+				if(iter != intel_func_repl.end()) {
+					func_name = iter->second;
+				}
+			}
+			
+			const auto func_type = llvm::FunctionType::get(ret_type, func_arg_types, false);
+			auto func = M->getFunction(func_name);
+			if(func == nullptr) { // only do this once
+				func = dyn_cast<Function>(M->getOrInsertFunction(func_name, func_type,
+																 is_readnone ?
+																 nounwind_readnone_attr :
+																 nounwind_attr));
+				func->setCallingConv(CallingConv::FLOOR_FUNC);
+			}
+			return func;
+		}
+		
+		SmallVector<llvm::Value*, 3> get_image_dim(llvm::Value* img_handle_arg,
+												   llvm::Type* coord_type,
+												   const std::string& geom) {
+			SmallVector<llvm::Value*, 3> ret;
+			
+			static const char* img_dim_funcs[] {
+				"_Z15get_image_width",
+				"_Z16get_image_height",
+				"_Z15get_image_depth"
+			};
+			
+			const auto dim = coord_type->getVectorNumElements();
+			SmallVector<llvm::Type*, 8> get_dim_arg_types;
+			SmallVector<llvm::Value*, 8> get_dim_func_args;
+			get_dim_arg_types.push_back(img_handle_arg->getType());
+			get_dim_func_args.push_back(img_handle_arg);
+			for(uint32_t i = 0; i < dim; ++i) {
+				auto get_dim_func = get_or_create_spir_function(img_dim_funcs[i] + geom,
+																builder->getInt32Ty(),
+																get_dim_arg_types);
+				llvm::CallInst* get_dim_call = builder->CreateCall(get_dim_func, get_dim_func_args);
+				get_dim_call->setDoesNotAccessMemory();
+				get_dim_call->setCallingConv(CallingConv::FLOOR_FUNC);
+				ret.push_back(get_dim_call);
+			}
+			
+			return ret;
+		}
+		
+		void handle_cl_coord(Instruction& I,
+							 llvm::Value* coord_arg,
+							 llvm::Value* layer_arg,
+							 const bool is_array,
+							 const bool is_msaa,
+							 const bool must_have_int_args,
+							 std::string& cl_func_name,
+							 SmallVector<llvm::Type*, 8>& func_arg_types,
+							 SmallVector<llvm::Value*, 8>& func_args) {
+			auto coord_vec_type = dyn_cast_or_null<VectorType>(coord_arg->getType());
+			const auto coord_dim = coord_vec_type->getNumElements();
+			if(!coord_vec_type) {
+				ctx->emitError(&I, "invalid image coordinate argument (cast to vector failed)");
+				return;
+			}
+			
+			const auto coord_type = coord_vec_type->getElementType();
+			const auto is_int_coord = coord_type->isIntegerTy();
+			if(is_msaa && !is_int_coord) {
+				ctx->emitError(&I, "coordinate type must be integer for msaa images");
+				return;
+			}
+			
+			if(must_have_int_args && !is_int_coord) {
+				ctx->emitError(&I, "coordinate type must be integer");
+				return;
+			}
+			
+			// opencl only knows scalar, vector2 and vector4 coordinates -> need to create them if necessary
+			auto cl_coord_dim = coord_dim + (is_array ? 1 : 0);
+			if(cl_coord_dim == 3) cl_coord_dim = 4;
+			const auto cl_coord_scalar_type = (is_int_coord ? llvm::Type::getInt32Ty(*ctx) : llvm::Type::getFloatTy(*ctx));
+			const auto cl_coord_type = (cl_coord_dim == 1 ?
+										cl_coord_scalar_type :
+										llvm::VectorType::get(cl_coord_scalar_type, cl_coord_dim));
+			
+			// start with the specified coord arg, there are some cases where we can just use it without rebuilding
+			auto cl_coord_arg = coord_arg;
+			if(cl_coord_type != coord_vec_type) {
+				if(cl_coord_dim == 1) {
+					// just a scalar
+					cl_coord_arg = builder->CreateExtractElement(coord_arg, builder->getInt32(0));
+				}
+				else {
+					// create a new tmp coord, then copy coord elements (keep unused undef)
+					cl_coord_arg = UndefValue::get(cl_coord_type);
+					uint32_t coord_idx = 0;
+					for(; coord_idx < coord_dim; ++coord_idx) {
+						cl_coord_arg = builder->CreateInsertElement(cl_coord_arg,
+																	builder->CreateExtractElement(coord_arg,
+																								  builder->getInt32(coord_idx)),
+																	builder->getInt32(coord_idx));
+					}
+					
+					// need to pull the layer index into the coordinate, including possible int -> float conversion
+					if(is_array) {
+						auto layer = layer_arg;
+						if(!is_int_coord) {
+							// need to convert
+							layer = builder->CreateUIToFP(layer_arg, cl_coord_scalar_type);
+						}
+						cl_coord_arg = builder->CreateInsertElement(cl_coord_arg, layer, builder->getInt32(coord_idx++));
+					}
+				}
+			}
+			func_arg_types.push_back(cl_coord_arg->getType());
+			func_args.push_back(cl_coord_arg);
+			
+			if(cl_coord_dim > 1) {
+				cl_func_name += "Dv" + std::to_string(cl_coord_dim) + "_";
+			}
+			cl_func_name += (is_int_coord ? "i" : "f");
+		}
+		
+		void handle_read_image(Instruction& I,
+							   const StringRef& func_name,
+							   llvm::Value* img_handle_arg,
+							   const COMPUTE_IMAGE_TYPE& image_type,
+							   llvm::ConstantInt* const_sampler_arg,
+							   llvm::Value* dyn_sampler_arg,
+							   llvm::Value* coord_arg,
+							   llvm::Value* layer_arg,
+							   llvm::Value* sample_arg,
+							   llvm::Value* offset_arg,
+							   const SmallVector<llvm::Value*, 3>& offset_elems,
+							   const bool is_offset,
+							   llvm::Value* lod_or_bias_arg,
+							   const bool is_lod_or_bias, // true: lod, false: bias
+							   llvm::Value* dpdx_arg,
+							   llvm::Value* dpdy_arg,
+							   const bool is_gradient_,
+							   const COMPARE_FUNCTION& compare_function,
+							   llvm::Value* compare_value_arg,
+							   const bool is_compare) override {
+			SmallVector<llvm::Type*, 8> func_arg_types;
+			SmallVector<llvm::Value*, 8> func_args;
+			
+			// must be constant/constexpr for now
+			if(const_sampler_arg == nullptr) {
+				ctx->emitError(&I, "sampler must be a constant");
+				return;
+			}
+			auto sampler_arg = const_sampler_arg;
+			
+			// NOTE: opencl is rather limited when it comes to image functionality, hence not all types of image reads
+			//       are supported, though some can simply be ignored or emulated in s/w
+			
+			// TODO: add an option to disable advanced image functions and silently fallback to simple ones (at the loss of functionality)
+			
+			// get geom string / mangled name + flags
+			std::string geom;
+			bool is_array = false, is_msaa = false, is_depth = false, is_cube = false;
+			switch(image_type) {
+				case COMPUTE_IMAGE_TYPE::IMAGE_1D:					geom = "11ocl_image1d"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_1D_ARRAY:			geom = "16ocl_image1darray"; is_array = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_1D_BUFFER:			geom = "17ocl_image1dbuffer"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH:
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_STENCIL:		geom = "16ocl_image2ddepth"; is_depth = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D:					geom = "11ocl_image2d"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_ARRAY:			geom = "21ocl_image2darraydepth"; is_array = true; is_depth = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D_ARRAY:			geom = "16ocl_image2darray"; is_array = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_MSAA:			geom = "20ocl_image2dmsaadepth"; is_msaa = true; is_depth = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D_MSAA:				geom = "15ocl_image2dmsaa"; is_msaa = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_3D:					geom = "11ocl_image3d"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_MSAA_ARRAY:	geom = "25ocl_image2darraymsaadepth"; is_msaa = true; is_depth = true; is_array = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D_MSAA_ARRAY:		geom = "20ocl_image2darraymsaa"; is_msaa = true; is_array = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_CUBE:			geom = "18ocl_imagecubedepth"; is_depth = true; is_cube = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_CUBE_ARRAY:	geom = "23ocl_imagecubearraydepth"; is_depth = true; is_cube = true; is_array = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_CUBE:				geom = "13ocl_imagecube"; is_cube = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_CUBE_ARRAY:			geom = "18ocl_imagecubearray"; is_cube = true; is_array = true; break;
+				default:
+					ctx->emitError(&I, "unknown or incorrect image type");
+					return;
+			}
+			// TODO: properly handle cube images in vulkan mode (+error in opencl mode)
+			
+			// -> caps check
+			if(is_lod_or_bias) {
+				if(!has_flag<IMAGE_CAPABILITY::MIPMAP_READ>(image_capabilities)) {
+					ctx->emitError(&I, "lod read not supported by device");
+					return;
+				}
+				
+				// *sigh* will be supported with opencl 2.1 though
+				// -> convert int coords to float coords and swap out sampler
+				if(coord_arg->getType()->getVectorElementType()->isIntegerTy()) {
+					const auto coord_type = coord_arg->getType();
+					const auto coord_dim = coord_arg->getType()->getVectorNumElements();
+					const auto fp_coord_type = llvm::VectorType::get(llvm::Type::getFloatTy(*ctx), coord_dim);
+					
+					auto img_dims = get_image_dim(img_handle_arg, coord_type, geom);
+					
+					llvm::Value* fp_coord = UndefValue::get(fp_coord_type);
+					for(uint32_t i = 0; i < coord_dim; ++i) {
+						// fp_coord_i = (float(int_coord_i) + 0.5) / float(img_dim_i)
+						auto elem = builder->CreateExtractElement(coord_arg, builder->getInt32(i));
+						auto fp_elem = builder->CreateSIToFP(elem, builder->getFloatTy());
+						auto fp_elem_half = builder->CreateFAdd(fp_elem, ConstantFP::get(builder->getFloatTy(), 0.5));
+						auto fp_dim_i = builder->CreateSIToFP(img_dims[i], builder->getFloatTy());
+						auto div = builder->CreateFDiv(fp_elem_half, fp_dim_i);
+						fp_coord = builder->CreateInsertElement(fp_coord, div, builder->getInt32(i));
+					}
+					coord_arg = fp_coord;
+					
+					// sampler: set NORMALIZED/CLK_NORMALIZED_COORDS_TRUE flag
+					// NOTE: PIXEL/CLK_NORMALIZED_COORDS_FALSE is 0, so we don't need to clear anything
+					sampler_arg = ConstantInt::get(const_sampler_arg->getType(), const_sampler_arg->getZExtValue() | 0x1);
+				}
+			}
+			
+			bool is_gradient = is_gradient_;
+			if(is_gradient_) {
+				if(!has_flag<IMAGE_CAPABILITY::MIPMAP_READ>(image_capabilities)) {
+					ctx->emitError(&I, "gradient read not supported by device");
+					return;
+				}
+				
+				// again, not supported (also: doesn't make much sense?)
+				// -> not going to s/w emulate this for now
+				// -> silently ignore for now
+#if 0
+				if(coord_arg->getType()->getVectorElementType()->isIntegerTy()) {
+					ctx->emitError(&I, "gradient read not supported with integer coordinates");
+					return;
+				}
+#else
+				if(coord_arg->getType()->getVectorElementType()->isIntegerTy()) {
+					is_gradient = false;
+				}
+#endif
+			}
+			
+			// -> return data and cl function name
+			// NOTE: we don't have a c++ mangling support in here, so do it manually
+			// (this is actually easy enough, since everything is very static)
+			std::string cl_func_name;
+			llvm::Type* ret_type;
+			if(func_name.endswith("float")) {
+				cl_func_name = "_Z11read_imagef";
+				ret_type = llvm::VectorType::get(llvm::Type::getFloatTy(*ctx), 4);
+			}
+			else if(func_name.endswith("int")) {
+				cl_func_name = "_Z11read_imagei";
+				ret_type = llvm::VectorType::get(llvm::Type::getInt32Ty(*ctx), 4);
+			}
+			else if(func_name.endswith("uint")) {
+				cl_func_name = "_Z12read_imageui";
+				ret_type = llvm::VectorType::get(llvm::Type::getInt32Ty(*ctx), 4);
+			}
+			else if(func_name.endswith("half")) {
+				cl_func_name = "_Z11read_imageh";
+				ret_type = llvm::VectorType::get(llvm::Type::getHalfTy(*ctx), 4);
+			}
+			// unknown -> ignore
+			else return;
+			
+			// -> geom
+			cl_func_name += geom;
+			
+			func_arg_types.push_back(img_handle_arg->getType());
+			func_args.push_back(img_handle_arg);
+			
+			if(is_depth) {
+				// depth return type is always a float
+				ret_type = llvm::Type::getFloatTy(*ctx);
+			}
+			
+			// except for msaa, we always have a sampler
+			if(!is_msaa) {
+				cl_func_name += "11ocl_sampler";
+				func_arg_types.push_back(sampler_arg->getType());
+				func_args.push_back(sampler_arg);
+			}
+			
+			// -> offset
+			// opencl has no offset support, so always add it
+			llvm::Value* offset_coord_arg = coord_arg;
+			if(is_offset) {
+				if(coord_arg->getType()->getVectorElementType()->isIntegerTy()) {
+					offset_coord_arg = builder->CreateAdd(coord_arg, offset_arg);
+				}
+				else {
+					// need to fallback to s/w for fp coords
+					auto coord_type = coord_arg->getType();
+					auto offset_dim = coord_type->getVectorNumElements();
+					auto img_dims = get_image_dim(img_handle_arg, coord_type, geom);
+					
+					// float_offset_i = float(offset_i) / float(dim_i)
+					llvm::Value* fp_offset = UndefValue::get(coord_type);
+					for(uint32_t i = 0; i < offset_dim; ++i) {
+						auto offset_i = builder->CreateExtractElement(offset_arg, builder->getInt32(i));
+						
+						// one offset elem is often 0
+						// -> add some special handling since the si->fp conversion and fdiv are unnecessary here
+						// (this might later also get rid of unnecessary get_image_* calls)
+						if(const auto const_offset_i = dyn_cast_or_null<ConstantInt>(offset_i)) {
+							if(const_offset_i->getSExtValue() == 0) {
+								builder->CreateInsertElement(fp_offset, ConstantFP::get(builder->getFloatTy(), 0.0),
+															 builder->getInt32(i));
+								continue;
+							}
+						}
+						
+						auto offset_i_fp = builder->CreateSIToFP(offset_i, builder->getFloatTy());
+						auto dim_i = builder->CreateSIToFP(img_dims[i], builder->getFloatTy());
+						fp_offset = builder->CreateInsertElement(fp_offset,
+																 builder->CreateFDiv(offset_i_fp, dim_i),
+																 builder->getInt32(i));
+					}
+					
+					// finally: add the compute fp offset
+					offset_coord_arg = builder->CreateFAdd(coord_arg, fp_offset);
+				}
+			}
+			
+			// -> coord
+			handle_cl_coord(I,
+							offset_coord_arg,
+							layer_arg,
+							is_array,
+							is_msaa,
+							false, // can have either int or float coords
+							cl_func_name,
+							func_arg_types,
+							func_args);
+			
+			// -> sample
+			if(is_msaa) {
+				if(!sample_arg->getType()->isIntegerTy()) {
+					ctx->emitError(&I, "msaa sample index must be integer");
+					return;
+				}
+				
+				cl_func_name += "i";
+				func_arg_types.push_back(sample_arg->getType());
+				func_args.push_back(sample_arg);
+			}
+			
+			// -> gradient
+			if(is_gradient) {
+				const auto coord_dim = coord_arg->getType()->getVectorNumElements();
+				if(coord_dim == 1) {
+					// extract scalar
+					cl_func_name += "ff";
+					func_arg_types.push_back(builder->getFloatTy());
+					func_args.push_back(builder->CreateExtractElement(dpdx_arg, builder->getInt32(0)));
+					func_arg_types.push_back(builder->getFloatTy());
+					func_args.push_back(builder->CreateExtractElement(dpdy_arg, builder->getInt32(0)));
+				}
+				else if(coord_dim == 2) {
+					// just pass-through
+					cl_func_name += "Dv2_fDv2_f";
+					func_arg_types.push_back(dpdx_arg->getType());
+					func_args.push_back(dpdx_arg);
+					func_arg_types.push_back(dpdy_arg->getType());
+					func_args.push_back(dpdy_arg);
+				}
+				else if(coord_dim == 3) {
+					// need to create a vector4
+					cl_func_name += "Dv4_fDv4_f";
+					
+					const auto grad_type = llvm::VectorType::get(builder->getFloatTy(), 4);
+					func_arg_types.push_back(grad_type);
+					func_arg_types.push_back(grad_type);
+					
+					llvm::Value* dpdx4 = UndefValue::get(grad_type);
+					llvm::Value* dpdy4 = UndefValue::get(grad_type);
+					for(uint32_t i = 0; i < 3; ++i) {
+						auto idx = builder->getInt32(i);
+						dpdx4 = builder->CreateInsertElement(dpdx4, builder->CreateExtractElement(dpdx_arg, idx), idx);
+						dpdy4 = builder->CreateInsertElement(dpdy4, builder->CreateExtractElement(dpdy_arg, idx), idx);
+					}
+					func_args.push_back(dpdx4);
+					func_args.push_back(dpdy4);
+				}
+				else llvm_unreachable("invalid coord dim");
+			}
+			
+			// -> lod
+			// NOTE: bias is never supported
+			if(is_lod_or_bias) {
+				cl_func_name += "f";
+				
+				auto lod = lod_or_bias_arg;
+				if(lod_or_bias_arg->getType()->isIntegerTy()) {
+					// only float is supported, convert it
+					lod = builder->CreateSIToFP(lod_or_bias_arg, builder->getFloatTy());
+				}
+				func_arg_types.push_back(lod->getType());
+				func_args.push_back(lod);
+			}
+			
+			// create the opencl call
+			auto read_func = get_or_create_spir_function(cl_func_name, ret_type, func_arg_types, true);
+			llvm::CallInst* read_call = builder->CreateCall(read_func, func_args);
+			read_call->setDoesNotAccessMemory(); // all reads are readnone (can be optimized away if unused)
+			read_call->setDebugLoc(I.getDebugLoc()); // keep debug loc
+			read_call->setCallingConv(CallingConv::FLOOR_FUNC);
+			
+			// if this is a depth read/sample, the return type is a float -> create a float4
+			llvm::Value* read_call_result = read_call;
+			if(is_depth) {
+				read_call_result = UndefValue::get(llvm::VectorType::get(llvm::Type::getFloatTy(*ctx), 4));
+				if(!is_compare) {
+					read_call_result = builder->CreateInsertElement(read_call_result, read_call, builder->getInt32(0));
+				}
+				// -> compare
+				else {
+					emulate_depth_compare(read_call_result, read_call, compare_function, compare_value_arg);
+				}
+				// NOTE: rest of vector is undef/zero (and will be stripped away again anyways)
+			}
+			
+			//
+			I.replaceAllUsesWith(read_call_result);
+			I.eraseFromParent();
+		}
+		
+		void handle_write_image(Instruction& I,
+								const StringRef& func_name,
+								llvm::Value* img_handle_arg,
+								const COMPUTE_IMAGE_TYPE& image_type,
+								const COMPUTE_IMAGE_TYPE& format_type,
+								const COMPUTE_IMAGE_TYPE& data_type,
+								const bool& is_normalized,
+								const uint32_t& image_channel_count,
+								llvm::Value* coord_arg,
+								llvm::Value* layer_arg,
+								llvm::Value* lod_arg,
+								const bool is_lod,
+								llvm::Value* data_arg) override {
+			SmallVector<llvm::Type*, 8> func_arg_types;
+			SmallVector<llvm::Value*, 8> func_args;
+			
+			//// more arg checking
+			auto coord_vec_type = dyn_cast_or_null<VectorType>(coord_arg->getType());
+			if(!coord_vec_type) {
+				ctx->emitError(&I, "invalid image coordinate argument (cast to vector failed)");
+				return;
+			}
+			
+			const auto coord_type = coord_vec_type->getElementType();
+			if(!coord_type->isIntegerTy()) {
+				ctx->emitError(&I, "coordinate type must be integer");
+				return;
+			}
+			
+			std::string cl_func_name, dtype;
+			if(func_name.endswith("float")) {
+				cl_func_name = "_Z12write_imagef";
+				dtype = "f";
+			}
+			else if(func_name.endswith("int")) {
+				cl_func_name = "_Z12write_imagei";
+				dtype = "i";
+			}
+			else if(func_name.endswith("uint")) {
+				cl_func_name = "_Z13write_imageui";
+				dtype = "j";
+			}
+			else if(func_name.endswith("half")) {
+				cl_func_name = "_Z12write_imageh";
+				dtype = "h";
+			}
+			// unknown -> ignore
+			else return;
+			
+			//// func replacement
+			// -> geom
+			std::string geom;
+			bool is_array = false, is_depth = false;
+			// TODO: vulkan/spir-v can write cube, depth, msaa images
+			switch(image_type) {
+				case COMPUTE_IMAGE_TYPE::IMAGE_1D:					geom = "11ocl_image1d"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_1D_ARRAY:			geom = "16ocl_image1darray"; is_array = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_1D_BUFFER:			geom = "17ocl_image1dbuffer"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH:
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_STENCIL:		geom = "16ocl_image2ddepth"; is_depth = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D:					geom = "11ocl_image2d"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_ARRAY:			geom = "21ocl_image2darraydepth"; is_array = true; is_depth = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D_ARRAY:			geom = "16ocl_image2darray"; is_array = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_3D:					geom = "11ocl_image3d"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_MSAA:
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D_MSAA:
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_MSAA_ARRAY:
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D_MSAA_ARRAY:
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_CUBE:
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_CUBE_ARRAY:
+				case COMPUTE_IMAGE_TYPE::IMAGE_CUBE:
+				case COMPUTE_IMAGE_TYPE::IMAGE_CUBE_ARRAY:
+					ctx->emitError(&I, "unsupported image type");
+					return;
+				default:
+					ctx->emitError(&I, "unknown or incorrect image type");
+					return;
+			}
+			cl_func_name += geom;
+			
+			func_arg_types.push_back(img_handle_arg->getType());
+			func_args.push_back(img_handle_arg);
+			
+			// -> coord
+			handle_cl_coord(I,
+							coord_arg,
+							layer_arg,
+							is_array,
+							false, // no msaa
+							true, // must always have int coords for writes
+							cl_func_name,
+							func_arg_types,
+							func_args);
+			
+			// -> lod
+			if(is_lod) {
+				// always int
+				cl_func_name += "i";
+				func_arg_types.push_back(lod_arg->getType());
+				func_args.push_back(lod_arg);
+			}
+			
+			// -> data
+			// data is always a vector4, unless we're writing depth
+			if(!is_depth) {
+				cl_func_name += "Dv4_";
+				func_arg_types.push_back(data_arg->getType());
+				func_args.push_back(data_arg);
+			}
+			else {
+				// extract and use depth elem
+				auto depth_arg = builder->CreateExtractElement(data_arg, builder->getInt32(0));
+				func_arg_types.push_back(depth_arg->getType());
+				func_args.push_back(depth_arg);
+			}
+			cl_func_name += dtype;
+			
+			// create the opencl call
+			auto write_func = get_or_create_spir_function(cl_func_name, builder->getVoidTy(), func_arg_types, false);
+			llvm::CallInst* write_call = builder->CreateCall(write_func, func_args);
+			write_call->setDebugLoc(I.getDebugLoc()); // keep debug loc
+			write_call->setCallingConv(CallingConv::FLOOR_FUNC);
+			
+			//
+			I.replaceAllUsesWith(write_call);
+			I.eraseFromParent();
+			
+		}
+		
+	};
+}
+
+char SPIRImage::ID = 0;
+INITIALIZE_PASS_BEGIN(SPIRImage, "SPIRImage", "SPIRImage Pass", false, false)
+INITIALIZE_PASS_END(SPIRImage, "SPIRImage", "SPIRImage Pass", false, false)
+
+FunctionPass *llvm::createSPIRImagePass(const uint32_t image_capabilities,
+										const bool intel_workarounds) {
+	return new SPIRImage(image_capabilities, intel_workarounds);
+}
diff --git a/lib/Transforms/Scalar/Scalar.cpp b/lib/Transforms/Scalar/Scalar.cpp
index b1d2420..c5dc40f 100644
--- a/lib/Transforms/Scalar/Scalar.cpp
+++ b/lib/Transforms/Scalar/Scalar.cpp
@@ -96,6 +96,58 @@ void LLVMInitializeScalarOpts(LLVMPassRegistryRef R) {
   initializeScalarOpts(*unwrap(R));
 }
 
+void LLVMAddAddressSpaceFixPass(LLVMPassManagerRef PM) {
+  unwrap(PM)->add(createAddressSpaceFixPass());
+}
+
+void LLVMAddCUDAImagePass(LLVMPassManagerRef PM) {
+  unwrap(PM)->add(createCUDAImagePass());
+}
+
+void LLVMAddCUDAFinalPass(LLVMPassManagerRef PM) {
+  unwrap(PM)->add(createCUDAFinalPass());
+}
+
+void LLVMAddMetalFirstPass(LLVMPassManagerRef PM) {
+  unwrap(PM)->add(createMetalFirstPass());
+}
+
+void LLVMAddMetalFinalPass(LLVMPassManagerRef PM) {
+  unwrap(PM)->add(createMetalFinalPass());
+}
+
+void LLVMAddMetalFinalModuleCleanupPass(LLVMPassManagerRef PM) {
+  unwrap(PM)->add(createMetalFinalModuleCleanupPass());
+}
+
+void LLVMAddMetalImagePass(LLVMPassManagerRef PM) {
+  unwrap(PM)->add(createMetalImagePass());
+}
+
+void LLVMAddSPIRFinalPass(LLVMPassManagerRef PM) {
+  unwrap(PM)->add(createSPIRFinalPass());
+}
+
+void LLVMAddSPIRImagePass(LLVMPassManagerRef PM) {
+  unwrap(PM)->add(createSPIRImagePass());
+}
+
+void LLVMAddCFGStructurizationPass(LLVMPassManagerRef PM) {
+  unwrap(PM)->add(createCFGStructurizationPass());
+}
+
+void LLVMAddVulkanFinalPass(LLVMPassManagerRef PM) {
+  unwrap(PM)->add(createVulkanFinalPass());
+}
+
+void LLVMAddVulkanFinalModuleCleanupPass(LLVMPassManagerRef PM) {
+  unwrap(PM)->add(createVulkanFinalModuleCleanupPass());
+}
+
+void LLVMAddPropagateRangeInfoPass(LLVMPassManagerRef PM) {
+  unwrap(PM)->add(createPropagateRangeInfoPass());
+}
+
 void LLVMAddAggressiveDCEPass(LLVMPassManagerRef PM) {
   unwrap(PM)->add(createAggressiveDCEPass());
 }
diff --git a/lib/Transforms/Scalar/StructuralAnalysis.cpp b/lib/Transforms/Scalar/StructuralAnalysis.cpp
new file mode 100644
index 0000000..ff8406e
--- /dev/null
+++ b/lib/Transforms/Scalar/StructuralAnalysis.cpp
@@ -0,0 +1,1813 @@
+//===- StructuralAnalysis.cpp - -------------------------------------------===//
+//
+// Copyright (c) 2015, Computer Architecture and Systems Laboratory at Georgia
+// Tech
+// Copyright (c) 2016, Florian Ziesche (LLVM port + general fixes/cleanup)
+// All rights reserved.
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+// * Redistributions of source code must retain the above copyright notice, this
+//   list of conditions and the following disclaimer.
+//
+// * Redistributions in binary form must reproduce the above copyright notice,
+//   this list of conditions and the following disclaimer in the documentation
+//   and/or other materials provided with the distribution.
+//
+// * Neither the name of gpuocelot nor the names of its
+//   contributors may be used to endorse or promote products derived from
+//   this software without specific prior written permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+// ARE
+// DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+// FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+// DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+// SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+// CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+// OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+//===----------------------------------------------------------------------===//
+// \author  Haicheng Wu <hwu36@gatech.edu>
+// \date    Monday April 4, 2011
+// \brief   The source file for the StructuralAnalysis pass.
+//===----------------------------------------------------------------------===//
+//
+// This file defines the class of Structural Analysis which will return the
+// control tree and unstructured branches of a function
+//
+//===----------------------------------------------------------------------===//
+
+#include "StructuralAnalysis.h"
+#include <algorithm>
+
+namespace llvm {
+
+StructuralAnalysis::Node::~Node() {
+  for (auto n = childNode.begin(); n != childNode.end(); ++n) {
+    delete *n;
+  }
+}
+
+// buildSimpleCFG - Build a Simple CFG out of the LLVM CFG
+void StructuralAnalysis::buildSimpleCFG(NodeSetTy &N) {
+  // Create a simple CFG node for every Basic Block
+  for (BasicBlock &i : *_function) {
+    NodeTy *n = new NodeTy();
+    n->BB = &i;
+    n->containedBB.insert(&i);
+    N.insert(n);
+    BB2NodeMap[&i] = n;
+  }
+
+  // Setup the edges of the simple CFG
+  for (BasicBlock &block : *_function) {
+    NodeTy *n = BB2NodeMap[&block];
+
+    // Setup the predecessor of every node
+    for (BasicBlock *pred : block.predecessors()) {
+      n->predNode.emplace_back(BB2NodeMap[pred]);
+    }
+
+    // Setup the successor of every node
+    for (BasicBlock *succ : block.successors()) {
+      n->succNode.emplace_back(BB2NodeMap[succ]);
+    }
+  }
+
+  // Remove unreachable node
+  NodeTy *entry = BB2NodeMap[&_function->getEntryBlock()];
+
+  deleteUnreachableNodes(N, entry);
+}
+
+// structuralAnalysis - Follow Fig 7.39 of Muchnick book
+void StructuralAnalysis::structuralAnalysis(NodeSetTy &N, NodeTy *entry) {
+  NodeTy *n = nullptr, *p = nullptr, *entryNode = nullptr, *exitNode = nullptr;
+  RegionTy rType;
+  NodeSetTy nodeSet, reachUnder;
+
+  unstructuredBRVec.clear();
+
+  // Handle the case if the Function has only one Basic Block
+  if (N.size() == 1) {
+    NodeTy *node = new NodeTy();
+    NodeTy *singleNode = *(N.begin());
+    node->isCombined = true;
+    node->childNode.insert(singleNode);
+    node->entryNode = singleNode;
+    node->exitBB = singleNode->BB;
+    node->containedBB.insert(singleNode->BB);
+    node->nodeType = Block;
+
+    singleNode->parentNode = node;
+
+    N.erase(singleNode);
+    N.insert(node);
+
+    return;
+  }
+
+  do {
+    bool change = false;
+
+    post.clear();
+    preTree.clear();
+    postTree.clear();
+
+    visit.clear();
+    visitPath.clear();
+    postMax = 0;
+    postCtr = 1;
+    preMax = 0;
+
+    for (NodeTy *node : N) {
+      preTree[node] = 0;
+      postTree[node] = 0;
+    }
+
+    DFSPostorder(N, entry);
+
+    while (N.size() > 1 && postCtr <= postMax) {
+      n = post[postCtr];
+
+      if (N.count(n) == 0)
+        continue;
+
+      // Locate an acyclic region, if present
+      if (n->isLoopHeader && n->loopExitNode) {
+        visitPath.clear();
+
+        if (path(n, n->loopExitNode, N, nullptr)) {
+          NodeTy *tmpNode = n->loopExitNode;
+
+          while (tmpNode->parentNode)
+            tmpNode = tmpNode->parentNode;
+
+          n->remove_successor(tmpNode);
+          tmpNode->remove_predecessor(n);
+          n->loopExitNode = tmpNode;
+        } else
+          n->loopExitNode = nullptr;
+      }
+
+      rType = acyclicRegionType(N, n, nodeSet, &entryNode, &exitNode, entry);
+
+      if (n->isLoopHeader && n->loopExitNode) {
+        n->add_successor(n->loopExitNode);
+        n->loopExitNode->add_predecessor(n);
+      }
+
+      if (rType == Improper) {
+        change = true;
+
+        break;
+      } else if (rType != Nil) {
+        p = reduce(N, rType, nodeSet, entryNode, exitNode);
+        change = true;
+
+        if (nodeSet.count(entry))
+          entry = p;
+
+        break;
+      } else {
+        if (NodeTy *backEdgeNode = pathBack(n, N, reachUnder)) {
+          rType = cyclicRegionType(N, reachUnder, n, backEdgeNode, &exitNode,
+                                   entry);
+
+          if (rType == Improper) {
+            change = true;
+
+            break;
+          } else if (rType != Nil) {
+            change = true;
+            p = reduce(N, rType, reachUnder, n, exitNode);
+
+            if (reachUnder.count(entry))
+              entry = p;
+
+            break;
+          } else
+            postCtr++;
+        } else
+          postCtr++;
+      }
+    }
+
+    if (!change) {
+      for (uint32_t i = 1; i <= postMax; i++) {
+        NodeTy *node = post[i];
+
+        if (node->predNode.size() > 1 && node->succNode.empty()) {
+          uint32_t min = postMax + 1;
+
+          for (NodeTy *predNode : node->predNode) {
+            if (postTree[predNode] < min)
+              min = postTree[predNode];
+          }
+
+          for (NodeTy *predNode : node->predNode) {
+            if (postTree[predNode] != min) {
+              if (isStillReachableFromEntry(N, entry, node, predNode)) {
+                findUnstructuredBR(N, predNode, node, true, true);
+                change = true;
+              }
+            }
+          }
+
+          if (change)
+            break;
+        }
+      }
+    }
+
+    if (!change) {
+      for (uint32_t i = 1; i <= postMax; i++) {
+        NodeTy *node = post[i];
+
+        if (node->predNode.size() > 1 && !node->isBackEdge) {
+          NodeTy *tmpNode = nullptr;
+          bool processThisNode = true;
+
+          for (NodeTy *predNode : node->predNode) {
+            if (edge2ClassMap[std::make_pair(predNode, node)] == BACK) {
+              processThisNode = false;
+
+              break;
+            }
+
+            if (tmpNode == nullptr)
+              tmpNode = predNode;
+            else {
+              visitPath.clear();
+
+              if (path(tmpNode, predNode, N, node))
+                continue;
+              else {
+                visitPath.clear();
+
+                if (path(predNode, tmpNode, N, node))
+                  tmpNode = predNode;
+                else {
+                  processThisNode = false;
+
+                  break;
+                }
+              }
+            }
+          }
+
+          if (processThisNode) {
+            for (NodeTy *predNode : node->predNode) {
+              if (predNode == tmpNode) {
+                if (isStillReachableFromEntry(N, entry, node, predNode)) {
+                  findUnstructuredBR(N, predNode, node, true, true);
+                  change = true;
+                }
+              }
+            }
+
+            if (change)
+              break;
+          }
+        }
+      }
+    }
+
+    if (!change) {
+      for (uint32_t i = 1; i <= postMax; i++) {
+        NodeTy *node = post[i];
+
+        if (node->predNode.size() > 1 && !node->isBackEdge) {
+          bool processThisNode = true;
+          uint32_t min = postMax + 1;
+
+          for (NodeTy *predNode : node->predNode) {
+            if (edge2ClassMap[std::make_pair(predNode, node)] == BACK) {
+              processThisNode = false;
+
+              break;
+            }
+
+            if (postTree[predNode] < min)
+              min = postTree[predNode];
+          }
+
+          if (processThisNode) {
+
+            for (NodeTy *predNode : node->predNode) {
+              if (postTree[predNode] != min) {
+                if (isStillReachableFromEntry(N, entry, node, predNode)) {
+                  findUnstructuredBR(N, predNode, node, true, true);
+                  change = true;
+                }
+              }
+            }
+
+            if (change)
+              break;
+          }
+        }
+      }
+    }
+
+    // TODO: properly report this instead of asserting
+    assert(change != false && "Cannot reduce any more in structural analysis");
+    if (!change)
+      break;
+  } while (N.size() != 1);
+}
+
+// DFSPostorder - Follow Fig 7.40 of Muchnick book
+void StructuralAnalysis::DFSPostorder(NodeSetTy &N, NodeTy *x) {
+  visit.emplace(x);
+  preTree[x] = ++preMax;
+
+  for (NodeTy *y : x->succNode) {
+    if (visit.count(y) == 0) {
+      DFSPostorder(N, y);
+      edge2ClassMap[std::make_pair(x, y)] = TREE;
+    } else if (preTree[x] < preTree[y])
+      edge2ClassMap[std::make_pair(x, y)] = FORWARD;
+    else if (postTree[y] == 0 || preTree[x] == preTree[y])
+      edge2ClassMap[std::make_pair(x, y)] = BACK;
+    else
+      edge2ClassMap[std::make_pair(x, y)] = CROSS;
+  }
+
+  postMax++;
+  post[postMax] = x;
+  postTree[x] = postMax;
+}
+
+// acyclicRegionType - Follow Fig 7.41 of Muchnick book
+StructuralAnalysis::RegionTy
+StructuralAnalysis::acyclicRegionType(NodeSetTy &N, NodeTy *node,
+                                      NodeSetTy &nset, NodeTy **entryNode,
+                                      NodeTy **exitNode, NodeTy *entry) {
+  NodeTy *m, *n;
+  bool p, s;
+
+  nset.clear();
+
+  // Check for a block containing node
+  NodeTy *firstNode, *lastNode;
+  firstNode = lastNode = n = node;
+  p = true;
+  s = (n->succNode.size() == 1);
+
+  while (p && s) {
+    lastNode = n;
+
+    if (nset.count(n) == 0)
+      nset.insert(n);
+    else
+      return Nil;
+
+    n = *(n->succNode.begin());
+    p = (n->predNode.size() == 1);
+    s = (n->succNode.size() == 1);
+  }
+
+  if (p) {
+    if (nset.count(n) == 0) {
+      nset.insert(n);
+      lastNode = n;
+    } else
+      return Nil;
+  }
+
+  n = node;
+  p = (n->predNode.size() == 1);
+  s = true;
+
+  while (p && s) {
+    firstNode = n;
+
+    if (nset.count(n) == 0 || n == node)
+      nset.insert(n);
+    else
+      return Nil;
+    n = *(n->predNode.begin());
+    p = (n->predNode.size() == 1);
+    s = (n->succNode.size() == 1);
+  }
+
+  if (s) {
+    if (nset.count(n) == 0 || n == node) {
+      firstNode = n;
+      nset.insert(n);
+    } else
+      return Nil;
+  }
+
+  if (firstNode->has_predecessor(lastNode)) {
+    if (nset.size() == 2)
+      return Nil;
+    else
+      nset.erase(firstNode);
+  }
+
+  *entryNode = n;
+
+  if (nset.size() >= 2) {
+    if (nset.count(*entryNode) == 0)
+      for (NodeTy *succ : (*entryNode)->succNode)
+        if (nset.count(succ) > 0)
+          *entryNode = succ;
+
+    *exitNode = lastNode;
+
+    return Block;
+  }
+
+  *entryNode = node;
+
+  if ((*entryNode)->succNode.size() == 2) {
+    auto i = (*entryNode)->succNode.begin();
+    m = *i;
+    ++i;
+    n = *i;
+
+    if (m == *entryNode || n == *entryNode)
+      return Nil;
+
+    if (edge2ClassMap[std::make_pair(*entryNode, m)] == BACK)
+      return Nil;
+    if (edge2ClassMap[std::make_pair(*entryNode, n)] == BACK)
+      return Nil;
+
+    // Check for a normal IfThenElse
+    if (m->succNode.size() == 1 && n->succNode.size() == 1 &&
+        m->predNode.size() == 1 && n->predNode.size() == 1 &&
+        *(m->succNode.begin()) == *(n->succNode.begin()) &&
+        *(m->succNode.begin()) != *entryNode) {
+
+      if (edge2ClassMap[std::make_pair(m, *entryNode)] == BACK)
+        return Nil;
+      if (edge2ClassMap[std::make_pair(n, *entryNode)] == BACK)
+        return Nil;
+
+      nset.insert(*entryNode);
+      nset.insert(m);
+      nset.insert(n);
+      *exitNode = *(m->succNode.begin());
+
+      return IfThenElse;
+    }
+    // Check for an IfThenElse with no exit block
+    if (m->succNode.empty() && n->succNode.empty() && m->predNode.size() == 1 &&
+        n->predNode.size() == 1) {
+      nset.insert(*entryNode);
+      nset.insert(m);
+      nset.insert(n);
+      *exitNode = nullptr;
+
+      return IfThenElse;
+    }
+    // Check for an IfThen
+    // n is the Then part
+    else if (n->succNode.size() == 1 && n->predNode.size() == 1 &&
+             m == *(n->succNode.begin())) {
+      if (edge2ClassMap[std::make_pair(n, m)] != BACK) {
+        if (edge2ClassMap[std::make_pair(n, *entryNode)] == BACK)
+          return Nil;
+
+        nset.insert(*entryNode);
+        nset.insert(n);
+        *exitNode = m;
+
+        return IfThen;
+      }
+    }
+    // m is the Then part
+    else if (m->succNode.size() == 1 && m->predNode.size() == 1 &&
+             n == *(m->succNode.begin())) {
+      if (edge2ClassMap[std::make_pair(m, n)] != BACK) {
+        if (edge2ClassMap[std::make_pair(m, *entryNode)] == BACK)
+          return Nil;
+
+        nset.insert(*entryNode);
+        nset.insert(m);
+        *exitNode = n;
+
+        return IfThen;
+      }
+    }
+    // n is the Then part w/o exiting edge
+    else if (n->succNode.empty() && n->predNode.size() == 1) {
+      visitPath.clear();
+
+      if (!path(m, *entryNode, N, nullptr)) {
+        nset.insert(*entryNode);
+        nset.insert(n);
+        *exitNode = nullptr;
+
+        return IfThen;
+      }
+    }
+    // m is the Then part w/o exiting edge
+    else if (m->succNode.empty() && m->predNode.size() == 1) {
+      visitPath.clear();
+
+      if (!path(n, *entryNode, N, nullptr)) {
+        nset.insert(*entryNode);
+        nset.insert(m);
+        *exitNode = nullptr;
+
+        return IfThen;
+      }
+    }
+    // Check for an IfThenElse with incoming edges
+    else if (m->succNode.size() == 1 && n->succNode.size() == 1 &&
+             *(m->succNode.begin()) == *(n->succNode.begin()) &&
+             *(m->succNode.begin()) != *entryNode) {
+
+      if (edge2ClassMap[std::make_pair(m, *entryNode)] == BACK)
+        return Nil;
+      if (edge2ClassMap[std::make_pair(n, *entryNode)] == BACK)
+        return Nil;
+
+      if (!n->has_predecessor(*(n->succNode.begin())) &&
+          !m->has_predecessor(*(m->succNode.begin()))) {
+
+        if (m->has_predecessor(*(m->succNode.begin())) ||
+            n->has_predecessor(*(n->succNode.begin())))
+          return Nil;
+
+        bool improperFlag = false;
+
+        if (m->predNode.size() > 1) {
+          for (auto pi = m->predNode.begin(), pe = m->predNode.end(); pi != pe;
+               ++pi)
+            if (*pi != *entryNode &&
+                isStillReachableFromEntry(N, entry, m, *pi) &&
+                edge2ClassMap[std::make_pair(*pi, m)] != BACK) {
+              findUnstructuredBR(N, *pi, m, true, true);
+              improperFlag = true;
+            }
+        }
+
+        if (n->predNode.size() > 1) {
+          for (auto pi = n->predNode.begin(), pe = n->predNode.end(); pi != pe;
+               ++pi)
+            if (*pi != *entryNode &&
+                isStillReachableFromEntry(N, entry, n, *pi) &&
+                edge2ClassMap[std::make_pair(*pi, n)] != BACK) {
+              findUnstructuredBR(N, *pi, n, true, true);
+              improperFlag = true;
+            }
+        }
+
+        if (improperFlag)
+          return Improper;
+      }
+    }
+    // Check for an IfThen with incoming edges
+    // n is the Then part
+    else if (n->succNode.size() == 1 && n->predNode.size() > 1 &&
+             m == *(n->succNode.begin())) {
+      if (edge2ClassMap[std::make_pair(n, *entryNode)] == BACK)
+        return Nil;
+
+      if (edge2ClassMap[std::make_pair(n, m)] != BACK) {
+        if (n->has_predecessor(m))
+          return Nil;
+
+        bool improperFlag = false;
+
+        for (auto pi = n->predNode.begin(), pe = n->predNode.end(); pi != pe;
+             ++pi)
+          if (*pi != *entryNode &&
+              isStillReachableFromEntry(N, entry, n, *pi) &&
+              edge2ClassMap[std::make_pair(*pi, n)] != BACK) {
+            findUnstructuredBR(N, *pi, n, true, true);
+            improperFlag = true;
+          }
+
+        if (improperFlag)
+          return Improper;
+      }
+    }
+    // m is the Then part
+    else if (m->succNode.size() == 1 && m->predNode.size() > 1 &&
+             n == *(m->succNode.begin())) {
+      if (edge2ClassMap[std::make_pair(m, *entryNode)] == BACK)
+        return Nil;
+
+      if (edge2ClassMap[std::make_pair(m, n)] != BACK) {
+        if (m->has_predecessor(n))
+          return Nil;
+
+        bool improperFlag = false;
+
+        for (auto pi = m->predNode.begin(), pe = m->predNode.end(); pi != pe;
+             ++pi)
+          if (*pi != *entryNode &&
+              isStillReachableFromEntry(N, entry, m, *pi) &&
+              edge2ClassMap[std::make_pair(*pi, m)] != BACK) {
+            findUnstructuredBR(N, *pi, m, true, true);
+            improperFlag = true;
+          }
+
+        if (improperFlag)
+          return Improper;
+      }
+    }
+    // Check for an IfThenElse (w/o exit block) with incoming edges
+    else if (m->succNode.empty() && n->succNode.empty()) {
+      bool improperFlag = false;
+
+      if (m->predNode.size() > 1) {
+        for (auto pi = m->predNode.begin(), pe = m->predNode.end(); pi != pe;
+             ++pi)
+          if (*pi != *entryNode &&
+              isStillReachableFromEntry(N, entry, m, *pi)) {
+            findUnstructuredBR(N, *pi, m, true, true);
+            improperFlag = true;
+          }
+      }
+
+      if (n->predNode.size() > 1) {
+        for (auto pi = n->predNode.begin(), pe = n->predNode.end(); pi != pe;
+             ++pi)
+          if (*pi != *entryNode &&
+              isStillReachableFromEntry(N, entry, n, *pi)) {
+            findUnstructuredBR(N, *pi, n, true, true);
+            improperFlag = true;
+          }
+      }
+
+      if (improperFlag)
+        return Improper;
+    }
+    // n is the Then part (w/o exiting edge) with incoming edges
+    else if (n->succNode.empty() && n->predNode.size() > 1) {
+      visitPath.clear();
+
+      if (!path(m, *entryNode, N, nullptr)) {
+        if (n->has_predecessor(m))
+          return Nil;
+
+        bool improperFlag = false;
+
+        for (auto pi = n->predNode.begin(), pe = n->predNode.end(); pi != pe;
+             ++pi)
+          if (*pi != *entryNode &&
+              isStillReachableFromEntry(N, entry, n, *pi)) {
+            findUnstructuredBR(N, *pi, n, true, true);
+            improperFlag = true;
+          }
+
+        if (improperFlag)
+          return Improper;
+      }
+    }
+    // m is the Then part w/o exiting edge with incoming edges
+    else if (m->succNode.empty() && m->predNode.size() > 1) {
+      visitPath.clear();
+
+      if (!path(n, *entryNode, N, nullptr)) {
+        if (m->has_predecessor(n))
+          return Nil;
+
+        bool improperFlag = false;
+
+        for (auto pi = m->predNode.begin(), pe = m->predNode.end(); pi != pe;
+             ++pi)
+          if (*pi != *entryNode &&
+              isStillReachableFromEntry(N, entry, n, *pi)) {
+            findUnstructuredBR(N, *pi, m, true, true);
+            improperFlag = true;
+          }
+
+        if (improperFlag)
+          return Improper;
+      }
+    }
+  }
+  // Check for Case
+  else if ((*entryNode)->succNode.size() > 2) {
+    if (isCaseWithDefault(N, *entryNode, exitNode, entry)) {
+      nset.insert(*entryNode);
+
+      for (auto i = (*entryNode)->succNode.begin(),
+                e = (*entryNode)->succNode.end();
+           i != e; ++i)
+        nset.insert(*i);
+
+      return Case;
+    } else if (isCaseWithoutDefault(N, *entryNode, exitNode, entry)) {
+      nset.insert(*entryNode);
+
+      for (auto i = (*entryNode)->succNode.begin(),
+                e = (*entryNode)->succNode.end();
+           i != e; ++i)
+        if (*i != *exitNode)
+          nset.insert(*i);
+
+      return Case;
+    } else if (isImproperCaseWithDefault(N, *entryNode, entry))
+      return Improper;
+    else if (isImproperCaseWithoutDefault(N, *entryNode, exitNode, entry))
+      return Improper;
+  }
+
+  return Nil;
+}
+
+// isCaseWithDefault - Check if node leads a case block
+bool StructuralAnalysis::isCaseWithDefault(NodeSetTy &N, NodeTy *entryNode,
+                                           NodeTy **exitNode, NodeTy *entry) {
+  *exitNode = nullptr;
+
+  for (auto i = entryNode->succNode.begin(), e = entryNode->succNode.end();
+       i != e; ++i) {
+    // Check if every successor node has only one successor
+    if ((*i)->succNode.size() > 1)
+      return false;
+
+    if (edge2ClassMap[std::make_pair(entryNode, *i)] == BACK)
+      return false;
+
+    // If successor has only one predessor, it has to be the entry node
+    if ((*i)->predNode.size() == 1) {
+      if (entryNode != *((*i)->predNode.begin()))
+        return false;
+    }
+    // If successor has two predessors, one has to be the entry node
+    // and the other has to be another successor node
+    else if ((*i)->predNode.size() == 2) {
+      auto pi = (*i)->predNode.begin();
+      NodeTy *predNode1 = *pi;
+      ++pi;
+      NodeTy *predNode2 = *pi;
+
+      if (predNode1 != entryNode || !entryNode->has_successor(predNode2))
+        if (!entryNode->has_successor(predNode1) || predNode2 != entryNode)
+          return false;
+    }
+    // The predecessor node number has to be less than 3
+    else
+      return false;
+
+    NodeTy *succNode = *((*i)->succNode.begin());
+
+    if (succNode == nullptr)
+      continue;
+
+    if (succNode == entryNode)
+      return false;
+
+    // Check if the successor of the successor node is not another successor
+    if (!entryNode->has_successor(succNode)) {
+      // Check if the successor of the successor is the only exit node
+      if (!*exitNode)
+        *exitNode = succNode;
+      else if (*exitNode != succNode)
+        return false;
+    }
+    // There is no loop between successors
+    else if (succNode->has_successor(*i))
+      return false;
+  }
+
+  for (auto i = entryNode->succNode.begin(), e = entryNode->succNode.end();
+       i != e; ++i) {
+    if ((*i)->succNode.empty()) {
+      visitPath.clear();
+
+      if (path(*exitNode, entryNode, N, nullptr))
+        return false;
+    }
+  }
+
+  return true;
+}
+
+// isImproperCaseWithDefault - Check if node leads a case block
+bool StructuralAnalysis::isImproperCaseWithDefault(NodeSetTy &N,
+                                                   NodeTy *entryNode,
+                                                   NodeTy *entry) {
+  NodeTy *exitNode = nullptr;
+  EdgeSetTy improperEdgeSet;
+
+  for (auto i = entryNode->succNode.begin(), e = entryNode->succNode.end();
+       i != e; ++i) {
+    // Check if every successor node has only one successor
+    if ((*i)->succNode.size() > 1)
+      return false;
+
+    if (edge2ClassMap[std::make_pair(entryNode, *i)] == BACK)
+      return false;
+
+    NodeTy *succNode = *((*i)->succNode.begin());
+
+    if (succNode) {
+      if (succNode == entryNode)
+        return false;
+
+      // Check if the successor of the successor node
+      // is not another successor node
+      if (!entryNode->has_successor(succNode)) {
+        // Is the successor of the successor node is the only exit node?
+        if (!exitNode)
+          exitNode = succNode;
+        else if (exitNode != succNode)
+          return false;
+      }
+      // There is no loop between successors
+      else if (succNode->has_successor(*i))
+        return false;
+    }
+
+    // If successor has only one predessor, it has to be the entry node
+    if ((*i)->predNode.size() == 1) {
+      if (entryNode != *((*i)->predNode.begin()))
+        return false;
+    }
+    // If successor has two predessors, one has to be the entry node
+    // and the other has to be another successor node
+    else if ((*i)->predNode.size() == 2) {
+      auto pi = (*i)->predNode.begin();
+      NodeTy *predNode1 = *pi;
+      ++pi;
+      NodeTy *predNode2 = *pi;
+
+      if (predNode1 != entryNode || !entryNode->has_successor(predNode2))
+        if (!entryNode->has_successor(predNode1) || predNode2 != entryNode)
+          return false;
+    }
+    // The predecessor node number has to be less than 3
+    else {
+      int insideIncomingNum = 0;
+
+      for (auto pi = (*i)->predNode.begin(), pe = (*i)->predNode.end();
+           pi != pe; ++pi) {
+
+        if (edge2ClassMap[std::make_pair(*pi, *i)] != BACK && *pi != exitNode &&
+            *pi != entryNode) {
+          if (!entryNode->has_successor(*pi))
+            improperEdgeSet.insert(std::make_pair(*pi, *i));
+          else {
+            insideIncomingNum++;
+
+            if (insideIncomingNum > 1)
+              improperEdgeSet.insert(std::make_pair(*pi, *i));
+          }
+        } else
+          return false;
+      }
+    }
+  }
+
+  for (auto i = entryNode->succNode.begin(), e = entryNode->succNode.end();
+       i != e; ++i) {
+    if ((*i)->succNode.empty()) {
+      visitPath.clear();
+
+      if (path(exitNode, entryNode, N, nullptr))
+        return false;
+    }
+  }
+
+  bool improperFlag = false;
+
+  for (EdgeSetTy::iterator i = improperEdgeSet.begin(),
+                           e = improperEdgeSet.end();
+       i != e; ++i)
+    if (isStillReachableFromEntry(N, entry, i->second, i->first)) {
+      findUnstructuredBR(N, i->first, i->second, true, true);
+      improperFlag = true;
+    }
+
+  return improperFlag;
+}
+
+// isCaseWithoutDefault - Check if node leads a case block
+bool StructuralAnalysis::isCaseWithoutDefault(NodeSetTy &N, NodeTy *entryNode,
+                                              NodeTy **exitNode,
+                                              NodeTy *entry) {
+  // Find the exit node first
+  *exitNode = nullptr;
+
+  for (auto i = entryNode->succNode.begin(), e = entryNode->succNode.end();
+       i != e; ++i) {
+    NodeTy *node1 = *i;
+    bool foundExit = true;
+
+    // all of successors of exit node are not within the switch block
+    for (auto si = node1->succNode.begin(), se = node1->succNode.end();
+         si != se; ++si) {
+      NodeTy *succNode = *si;
+
+      if (succNode) {
+        if (entryNode->has_successor(succNode)) {
+          foundExit = false;
+
+          break;
+        } else if (succNode == entryNode)
+          return false;
+      }
+    }
+
+    if (!foundExit)
+      continue;
+
+    foundExit = false;
+
+    // at least one of predcessors of exit node comes from switch block
+    for (auto pi = node1->predNode.begin(), pe = node1->predNode.end();
+         pi != pe; ++pi) {
+      NodeTy *predNode = *pi;
+
+      if (predNode != entryNode && entryNode->has_successor(predNode)) {
+        foundExit = true;
+      }
+    }
+
+    if (foundExit) {
+      *exitNode = node1;
+
+      break;
+    }
+  }
+
+  if (!(*exitNode))
+    return false;
+
+  for (auto i = entryNode->succNode.begin(), e = entryNode->succNode.end();
+       i != e; ++i) {
+    if (*i == *exitNode)
+      continue;
+
+    // Check if every successor node has only one successor
+    if ((*i)->succNode.size() > 1)
+      return false;
+
+    NodeTy *succNode = *((*i)->succNode.begin());
+
+    if (succNode) {
+      if (succNode == nullptr)
+        continue;
+
+      if (edge2ClassMap[std::make_pair(entryNode, *i)] == BACK)
+        return false;
+
+      // The successor of the successor node should be the the another
+      // successor node of node
+      if (!entryNode->has_successor(succNode))
+        return false;
+      // There is no loop between successors
+      else if (succNode != *exitNode && succNode->has_successor(*i))
+        return false;
+    }
+
+    // If successor has only one predessor, it has to be the entry node
+    if ((*i)->predNode.size() == 1) {
+      if (entryNode != *((*i)->predNode.begin()))
+        return false;
+    }
+    // If successor has two predessors, one has to be the entry node
+    // and the other has to be another successor node
+    else if ((*i)->predNode.size() == 2) {
+      auto pi = (*i)->predNode.begin();
+      NodeTy *predNode1 = *pi;
+      ++pi;
+      NodeTy *predNode2 = *pi;
+
+      if (predNode1 != entryNode || !entryNode->has_successor(predNode2))
+        if (!entryNode->has_successor(predNode1) || predNode2 != entryNode)
+          return false;
+    }
+    // The predecessor node number has to be less than 3
+    else
+      return false;
+  }
+
+  for (auto i = entryNode->succNode.begin(), e = entryNode->succNode.end();
+       i != e; ++i) {
+    if ((*i)->succNode.empty()) {
+      visitPath.clear();
+
+      if (path(*exitNode, entryNode, N, nullptr))
+        return false;
+    }
+  }
+
+  return true;
+}
+
+// isImproperCaseoutWithDefault - Check if node leads a case block with incoming
+// edges
+bool StructuralAnalysis::isImproperCaseWithoutDefault(NodeSetTy &N,
+                                                      NodeTy *entryNode,
+                                                      NodeTy **exitNode,
+                                                      NodeTy *entry) {
+  EdgeSetTy improperEdgeSet;
+
+  // Find the exit node first
+  *exitNode = nullptr;
+
+  for (auto i = entryNode->succNode.begin(), e = entryNode->succNode.end();
+       i != e; ++i) {
+    NodeTy *node1 = *i;
+    bool foundExit = true;
+
+    // all of successors of exit node are not within the switch block
+    for (auto si = node1->succNode.begin(), se = node1->succNode.end();
+         si != se; ++si) {
+      NodeTy *succNode = *si;
+
+      if (succNode) {
+        if (entryNode->has_successor(succNode)) {
+          foundExit = false;
+
+          break;
+        } else if (succNode == entryNode)
+          return false;
+      }
+    }
+
+    if (!foundExit)
+      continue;
+
+    foundExit = false;
+
+    // at least one of predcessors of exit node comes from switch block
+    for (auto pi = node1->predNode.begin(), pe = node1->predNode.end();
+         pi != pe; ++pi) {
+      NodeTy *predNode = *pi;
+
+      if (predNode != entryNode && entryNode->has_successor(predNode)) {
+        foundExit = true;
+      }
+    }
+
+    if (foundExit) {
+      *exitNode = node1;
+
+      break;
+    }
+  }
+
+  if (!(*exitNode))
+    return false;
+
+  for (auto i = entryNode->succNode.begin(), e = entryNode->succNode.end();
+       i != e; ++i) {
+    if (*i == *exitNode)
+      continue;
+
+    // Check if every successor node has only one successor
+    if ((*i)->succNode.size() > 1)
+      return false;
+
+    if (edge2ClassMap[std::make_pair(entryNode, *i)] == BACK)
+      return false;
+
+    NodeTy *succNode = *((*i)->succNode.begin());
+
+    if (succNode) {
+      if (succNode == nullptr)
+        continue;
+
+      // The successor of the successor node should be the the another
+      // successor node of node
+      if (!entryNode->has_successor(succNode))
+        return false;
+      // There is no loop between successors
+      else if (succNode != *exitNode && succNode->has_successor(*i))
+        return false;
+    }
+
+    // If successor has only one predessor, it has to be the entry node
+    if ((*i)->predNode.size() == 1) {
+      if (entryNode != *((*i)->predNode.begin()))
+        return false;
+    }
+    // If successor has two predessors, one has to be the entry node
+    // and the other has to be another successor node
+    else if ((*i)->predNode.size() == 2) {
+      auto pi = (*i)->predNode.begin();
+      NodeTy *predNode1 = *pi;
+      ++pi;
+      NodeTy *predNode2 = *pi;
+
+      if (predNode1 != entryNode || !entryNode->has_successor(predNode2))
+        if (!entryNode->has_successor(predNode1) || predNode2 != entryNode)
+          return false;
+
+      if (predNode1 == *exitNode)
+        return false;
+
+      if (predNode2 == *exitNode)
+        return false;
+    }
+    // The predecessor node number has to be less than 3
+    else {
+      int insideIncomingNum = 0;
+
+      for (auto pi = (*i)->predNode.begin(), pe = (*i)->predNode.end();
+           pi != pe; ++pi) {
+
+        if (edge2ClassMap[std::make_pair(*pi, *i)] != BACK &&
+            (*i) != *exitNode && (*pi) != entryNode && (*pi) != *exitNode) {
+          if (!entryNode->has_successor(*pi))
+            improperEdgeSet.insert(std::make_pair(*pi, *i));
+          else {
+            insideIncomingNum++;
+
+            if (insideIncomingNum > 1)
+              improperEdgeSet.insert(std::make_pair(*pi, *i));
+          }
+        } else
+          return false;
+      }
+    }
+  }
+
+  for (auto i = entryNode->succNode.begin(), e = entryNode->succNode.end();
+       i != e; ++i) {
+    if ((*i)->succNode.empty()) {
+      visitPath.clear();
+
+      if (path(*exitNode, entryNode, N, nullptr))
+        return false;
+    }
+  }
+
+  bool improperFlag = false;
+
+  for (EdgeSetTy::iterator i = improperEdgeSet.begin(),
+                           e = improperEdgeSet.end();
+       i != e; ++i)
+    if (isStillReachableFromEntry(N, entry, i->second, i->first)) {
+      findUnstructuredBR(N, i->first, i->second, true, true);
+      improperFlag = true;
+    }
+
+  return improperFlag;
+}
+
+// cyclicRegionType - Follow Fig 7.42 of Muchnick book
+StructuralAnalysis::RegionTy StructuralAnalysis::cyclicRegionType(
+    NodeSetTy &N, NodeSetTy &nset, NodeTy *loopHeaderNode, NodeTy *backEdgeNode,
+    NodeTy **exitNode, NodeTy *entry) {
+  // Check for a SelfLoop
+  if (nset.size() == 1) {
+    if (loopHeaderNode == backEdgeNode) {
+      *exitNode = *(backEdgeNode->succNode.begin());
+
+      return SelfLoop;
+    } else
+      return Nil;
+  }
+
+  if (isImproper(N, nset, loopHeaderNode, backEdgeNode, exitNode, entry))
+    // It is an Improper region
+    return Improper;
+
+  if (nset.size() == 2) {
+    if (backEdgeNode->succNode.size() == 1) {
+      for (NodeTy *pred : loopHeaderNode->predNode) {
+        if (pred != backEdgeNode) {
+          if (edge2ClassMap[std::make_pair(pred, loopHeaderNode)] == BACK)
+            return Nil;
+        }
+      }
+
+      for (NodeTy *succ : loopHeaderNode->succNode) {
+        if (succ != backEdgeNode) {
+          if (edge2ClassMap[std::make_pair(loopHeaderNode, succ)] == BACK)
+            return Nil;
+        }
+      }
+
+      if (backEdgeNode->predNode.size() != 1 ||
+          backEdgeNode->succNode.size() != 1)
+        return Nil;
+
+      return NaturalLoop;
+    } else if (backEdgeNode->succNode.size() > 1) {
+      for (NodeTy *pred : loopHeaderNode->predNode) {
+        if (pred != backEdgeNode) {
+          if (edge2ClassMap[std::make_pair(pred, loopHeaderNode)] == BACK)
+            return Nil;
+        }
+      }
+
+      for (NodeTy *succ : loopHeaderNode->succNode) {
+        if (succ != backEdgeNode) {
+          if (edge2ClassMap[std::make_pair(loopHeaderNode, succ)] == BACK)
+            return Nil;
+        }
+      }
+
+      if (backEdgeNode->predNode.size() != 1)
+        return Nil;
+
+      return NaturalLoop;
+    }
+  }
+
+  return Nil;
+}
+
+// reduce - Follow Fig 7.43 of Muchnick book
+StructuralAnalysis::NodeTy *
+StructuralAnalysis::reduce(NodeSetTy &N, RegionTy rType, NodeSetTy &nodeSet,
+                           NodeTy *entryNode, NodeTy *exitNode) {
+  NodeTy *node = new NodeTy();
+
+  node->isCombined = true;
+
+  if (entryNode) {
+    node->entryNode = entryNode;
+    node->entryBB = findEntryBB(entryNode);
+  }
+
+  replace(N, node, nodeSet /*, addSelfEdge*/);
+
+  node->isLoopHeader = false;
+  node->loopExitNode = nullptr;
+  node->isBackEdge = false;
+  node->parentNode = nullptr;
+
+  if (exitNode)
+    node->exitBB = findEntryBB(exitNode);
+  else
+    node->exitBB = nullptr;
+
+  for (auto &i : nodeSet)
+    findBB(i, node->containedBB);
+
+  node->nodeType = rType;
+
+  return node;
+}
+
+// replace - Follow Fig 7.44 of Muchnick book
+void StructuralAnalysis::replace(NodeSetTy &N, NodeTy *node,
+                                 NodeSetTy &nodeSet /*, bool addSelfEdge*/) {
+  // Link region node into abstract flowgraph, adjust the postorder traversal
+  // and predecessor and successor functions, and augment the control tree
+  compact(N, node, nodeSet /*, addSelfEdge*/);
+
+  for (auto i = nodeSet.begin(), e = nodeSet.end(); i != e; ++i) {
+    node->childNode.insert(*i);
+    (*i)->parentNode = node;
+  }
+}
+
+// isImproper - Follow Fig 7.45 of Muchnick book
+bool StructuralAnalysis::isImproper(NodeSetTy &N, NodeSetTy &nset,
+                                    NodeTy *loopHeaderNode,
+                                    NodeTy *backEdgeNode, NodeTy **exitNode,
+                                    NodeTy *entry) {
+  bool improperFlag = false;
+
+  // Check loopHeaderNode first
+  for (auto i = loopHeaderNode->predNode.begin(),
+            e = loopHeaderNode->predNode.end();
+       i != e; ++i) {
+    NodeTy *predNode = *i;
+
+    if (edge2ClassMap[std::make_pair(predNode, loopHeaderNode)] == BACK) {
+      if (nset.count(predNode) == 0 &&
+          isStillReachableFromEntry(N, entry, loopHeaderNode, predNode)) {
+        findUnstructuredBR(N, predNode, loopHeaderNode, true, true);
+        improperFlag = true;
+      } else if (nset.count(predNode) > 0 && predNode != backEdgeNode) {
+        findUnstructuredBR(N, predNode, loopHeaderNode, false, false);
+        improperFlag = true;
+      }
+    }
+  }
+
+  // Check the incoming edges
+  for (auto i = nset.begin(), e = nset.end(); i != e; ++i) {
+    NodeTy *node = *i;
+
+    if (node != loopHeaderNode)
+      for (auto ii = node->predNode.begin(), ee = node->predNode.end();
+           ii != ee; ++ii) {
+        if (nset.count(*ii) == 0
+            /*&& isStillReachableFromEntry(N, entry, node, *ii)*/) {
+          improperFlag = true;
+
+          findUnstructuredBR(N, *ii, node, false, true);
+          deleteUnreachableNodes(N, entry);
+        }
+      }
+  }
+
+  EdgeSetTy exitEdgeSet;
+  NodeTy *exitNodeOfHeader = nullptr;
+  NodeTy *exitNodeOfBackEdge = nullptr;
+  NodeTy *mainExitNode = nullptr;
+
+  for (auto i = nset.begin(), e = nset.end(); i != e; ++i) {
+    NodeTy *node = *i;
+
+    for (auto ii = node->succNode.begin(), ee = node->succNode.end(); ii != ee;
+         ++ii) {
+      if (nset.count(*ii) == 0) {
+        exitEdgeSet.insert(std::make_pair(node, *ii));
+
+        if (node == loopHeaderNode) {
+          if (exitNodeOfHeader == nullptr)
+            exitNodeOfHeader = *ii;
+        } else if (node == backEdgeNode) {
+          if (exitNodeOfBackEdge == nullptr)
+            exitNodeOfBackEdge = *ii;
+        }
+      }
+    }
+  }
+
+  if (exitNodeOfHeader)
+    mainExitNode = exitNodeOfHeader;
+  else if (exitNodeOfBackEdge)
+    mainExitNode = exitNodeOfBackEdge;
+
+  for (EdgeSetTy::iterator i = exitEdgeSet.begin(), e = exitEdgeSet.end();
+       i != e; ++i) {
+    EdgeTy exitEdge = *i;
+
+    if (exitEdge.second != mainExitNode) {
+      findUnstructuredBR(N, exitEdge.first, exitEdge.second, false, true);
+      deleteUnreachableNodes(N, entry);
+      improperFlag = true;
+    }
+  }
+
+  if (exitNodeOfHeader) {
+    for (EdgeSetTy::iterator i = exitEdgeSet.begin(), e = exitEdgeSet.end();
+         i != e; ++i) {
+      if (i->first != loopHeaderNode && (*i).second == mainExitNode) {
+        findUnstructuredBR(N, i->first, i->second, false, false);
+        improperFlag = true;
+      }
+    }
+  } else if (exitNodeOfBackEdge) {
+    for (EdgeSetTy::iterator i = exitEdgeSet.begin(), e = exitEdgeSet.end();
+         i != e; ++i) {
+      if (i->first != backEdgeNode && i->second == mainExitNode) {
+        findUnstructuredBR(N, i->first, i->second, false, false);
+        improperFlag = true;
+      }
+    }
+  }
+
+  *exitNode = mainExitNode;
+  loopHeaderNode->isLoopHeader = true;
+  backEdgeNode->isBackEdge = true;
+  loopHeaderNode->loopExitNode = mainExitNode;
+
+  return improperFlag;
+}
+
+// pathBack - Check if there is a node k such that there is a path from
+// m to k that does not pass through n and an edge k->n that is a back edge
+StructuralAnalysis::NodeTy *
+StructuralAnalysis::pathBack(NodeTy *n, NodeSetTy &N, NodeSetTy &reachUnder) {
+  NodeTy *backEdgeNode = nullptr;
+
+  reachUnder.clear();
+
+  // Find backedge first
+  for (NodeTy *predNode : n->predNode) {
+    if (edge2ClassMap[std::make_pair(predNode, n)] == BACK) {
+      if (reachUnder.count(predNode) == 0) {
+        backEdgeNode = predNode;
+
+        // Locate a cyclic region, if present
+        reachUnder.clear();
+        reachUnder.insert(n);
+        reachUnder.insert(backEdgeNode);
+
+        for (NodeTy *m : N) {
+          // Check if there is a path from m to loop exit node
+          visitPath.clear();
+          if (path(m, backEdgeNode, N, n)) {
+            visitPath.clear();
+
+            if (path(n, m, N, backEdgeNode))
+              reachUnder.insert(m);
+          }
+        }
+      }
+    }
+  }
+
+  return backEdgeNode;
+}
+
+// path(n, m, I) - Return true if there is a path from from n to m
+// such that all the nodes in it are in I and false otherwise
+bool StructuralAnalysis::path(NodeTy *n, NodeTy *m, NodeSetTy &I, NodeTy *esc) {
+  visitPath.emplace(n);
+
+  if (n == esc || m == esc)
+    return false;
+
+  if (n == m)
+    return true;
+
+  for (auto i = n->succNode.begin(), e = n->succNode.end(); i != e; ++i)
+    if (I.count(*i) > 0 && *i != esc && visitPath.count(*i) == 0) {
+      if (*i == m)
+        return true;
+      else if (path(*i, m, I, esc))
+        return true;
+    }
+
+  return false;
+}
+
+// path(n, m, I, src, dst ) - Return true if there is a path from from n to m
+// such that all the nodes in it are in I without going through edge src->dst
+// and false otherwise
+bool StructuralAnalysis::path(NodeTy *n, NodeTy *m, NodeSetTy &I, NodeTy *src,
+                              NodeTy *dst) {
+  visitPath.emplace(n);
+
+  if (n == m)
+    return true;
+
+  for (auto i = n->succNode.begin(), e = n->succNode.end(); i != e; ++i)
+    if (I.count(*i) > 0 && visitPath.count(*i) == 0) {
+      if (*i == dst && n == src)
+        continue;
+
+      if (*i == m)
+        return true;
+      else if (path(*i, m, I, src, dst))
+        return true;
+    }
+
+  return false;
+}
+
+// compact - Compact nodes in nset into n;
+void StructuralAnalysis::compact(NodeSetTy &N, NodeTy *n,
+                                 NodeSetTy &nset /*, bool addSelfEdge*/) {
+  // Adds node n to N
+  N.insert(n);
+
+  // Remove the nodes in nset from both N and post()
+  for (auto nset_node : nset) {
+    for (auto succ : nset_node->succNode) {
+      if (nset.count(succ) == 0) {
+        n->add_successor(succ);
+        succ->add_predecessor(n);
+        succ->remove_predecessor(nset_node);
+      }
+    }
+
+    for (auto pred : nset_node->predNode) {
+      if (nset.count(pred) == 0) {
+        n->add_predecessor(pred);
+        pred->add_successor(n);
+        pred->remove_successor(nset_node);
+      }
+    }
+
+    N.erase(nset_node);
+  }
+}
+
+// mapNode2BB - Return the corresponding BasicBlock* of the node
+BasicBlock *StructuralAnalysis::mapNode2BB(const NodeTy *node) const {
+  const NodeTy *tmpNode = node;
+  while (tmpNode->isCombined) {
+    tmpNode = tmpNode->entryNode;
+  }
+  return tmpNode->BB;
+}
+
+// mapBB2Node - Return the corresponding sturcture node of the basic block
+StructuralAnalysis::NodeTy *StructuralAnalysis::mapBB2Node(BasicBlock *bb) {
+  NodeTy *node, *tmpNode;
+
+  node = BB2NodeMap[bb];
+
+  while ((tmpNode = node->parentNode) != nullptr)
+    node = tmpNode;
+
+  return node;
+}
+
+// dumpCTNode - dump one CT node
+void StructuralAnalysis::dumpCTNode(llvm::raw_ostream &stream,
+                                    NodeTy *node) const {
+  if (!node->isCombined)
+    return;
+
+  stream << "\t";
+
+  switch (node->nodeType) {
+  case Block:
+    stream << "Block      ";
+    break;
+  case IfThen:
+    stream << "IfThen     ";
+    break;
+  case IfThenElse:
+    stream << "IfThenElse ";
+    break;
+  case Case:
+    stream << "Case       ";
+    break;
+  case SelfLoop:
+    stream << "SelfLoop   ";
+    break;
+  case NaturalLoop:
+    stream << "NaturalLoop";
+    break;
+  default:
+    break;
+  }
+
+  stream << "\t";
+
+  dumpNode(stream, node);
+  stream << " -> exit: "
+         << (node->exitBB != nullptr ? node->exitBB->getName().str() : "null");
+
+  stream << '\n';
+
+  for (auto i = node->childNode.begin(), e = node->childNode.end(); i != e;
+       ++i) {
+    dumpCTNode(stream, *i);
+  }
+}
+
+// dumpNode - dump one node
+void StructuralAnalysis::dumpNode(llvm::raw_ostream &stream,
+                                  NodeTy *node) const {
+  BBVecTy BBVec;
+
+  BasicBlock *this_block = mapNode2BB(node);
+  stream << "[" << this_block->getName().str() << "]\t";
+
+  findBB(node, BBVec);
+  for (BasicBlock *BB : BBVec) {
+    if (BB == this_block)
+      continue;
+    stream << BB->getName().str() << "\t";
+  }
+}
+
+// findUnstructuredBR - Record the branch and remove it from CFG
+void StructuralAnalysis::findUnstructuredBR(NodeSetTy &N, NodeTy *srcNode,
+                                            NodeTy *dstNode,
+                                            bool needForwardCopy, bool isGoto) {
+  BBVecTy srcNodeVec, dstNodeVec;
+  findBB(srcNode, srcNodeVec);
+  findBB(dstNode, dstNodeVec);
+
+  for (BasicBlock *srcBB : srcNodeVec) {
+    for (BasicBlock *succ : srcBB->successors()) {
+      for (BasicBlock *dstBB : dstNodeVec) {
+        if (dstBB == succ) {
+          if (isGoto) {
+            if (checkUnique(unstructuredBRVec, srcBB, dstBB))
+              unstructuredBRVec.push_back(std::make_pair(srcBB, dstBB));
+          }
+
+          if (needForwardCopy) {
+            if (checkUnique(dstNode->incomingForwardBR, srcBB, dstBB))
+              dstNode->incomingForwardBR.push_back(
+                  std::make_pair(srcBB, dstBB));
+          }
+        }
+      }
+    }
+  }
+
+  srcNode->remove_successor(dstNode);
+  dstNode->remove_predecessor(srcNode);
+
+  if (edge2ClassMap[std::make_pair(srcNode, dstNode)] == BACK) {
+    dstNode->isLoopHeader = false;
+    dstNode->loopExitNode = nullptr;
+  }
+}
+
+// findBB - put all Basic Blocks in node into nodeVec
+void StructuralAnalysis::findBB(NodeTy *node, BBVecTy &nodeVec) const {
+  if (!node->isCombined) {
+    if (find(nodeVec.cbegin(), nodeVec.cend(), node->BB) != nodeVec.cend())
+      return;
+    nodeVec.emplace_back(node->BB);
+  } else {
+    for (NodeTy *child : node->childNode)
+      findBB(child, nodeVec);
+  }
+}
+
+// findBB - put all Basic Blocks in node into nodeSet
+void StructuralAnalysis::findBB(NodeTy *node, BBSetTy &nodeSet) const {
+  if (!node->isCombined)
+    nodeSet.insert(node->BB);
+  else {
+    for (NodeTy *child : node->childNode)
+      findBB(child, nodeSet);
+  }
+}
+
+// dumpUnstructuredBR - Dump all found unstructured branches
+void StructuralAnalysis::dumpUnstructuredBR(llvm::raw_ostream &stream) const {
+  stream << "\nUnstructured Branches:\n";
+
+  for (EdgeVecTy::const_iterator i = unstructuredBRVec.begin(),
+                                 e = unstructuredBRVec.end();
+       i != e; ++i) {
+    stream << "\t" << i->first->getName().str() << "\t"
+           << i->second->getName().str() << "\n";
+  }
+
+  stream << "\n";
+}
+
+// True if after erasing edge src->dst, dst is still reachable from entry
+bool StructuralAnalysis::isStillReachableFromEntry(NodeSetTy &N, NodeTy *entry,
+                                                   NodeTy *dstNode,
+                                                   NodeTy *srcNode) {
+  visitPath.clear();
+
+  return path(entry, dstNode, N, srcNode, dstNode);
+}
+
+// findEntryBB - find the entry Basic Block of the node
+BasicBlock *StructuralAnalysis::findEntryBB(NodeTy *node) {
+  if (!node->isCombined)
+    return node->BB;
+  else
+    return findEntryBB(node->entryNode);
+}
+
+void StructuralAnalysis::cleanupUnreachable() {
+  for (auto i = unreachableNodeSet.begin(), e = unreachableNodeSet.end();
+       i != e; ++i) {
+    cleanup(*i);
+  }
+}
+
+// clean - fill in the element of incoming branches and outgoing branches
+void StructuralAnalysis::cleanup(NodeTy *node) {
+  if (!node->isCombined)
+    return;
+  else {
+    if ((node->nodeType == NaturalLoop || node->nodeType == SelfLoop) &&
+        node->containedBB.size() > 1) {
+      for (BBSetTy::iterator i = node->containedBB.begin(),
+                             e = node->containedBB.end();
+           i != e; ++i) {
+        BasicBlock *BB = *i;
+
+        if (BB != node->entryBB) {
+          for (BasicBlock *Pred : BB->predecessors()) {
+            if (node->containedBB.count(Pred) == 0)
+              node->incomingBR.push_back(std::make_pair(Pred, BB));
+          }
+
+          for (BasicBlock *Succ : BB->successors()) {
+            if (node->containedBB.count(Succ) == 0 && Succ != node->exitBB)
+              node->outgoingBR.push_back(std::make_pair(BB, Succ));
+          }
+        }
+      }
+    }
+
+    NodeSetTy nodeSet = node->childNode;
+
+    for (auto i = nodeSet.begin(), e = nodeSet.end(); i != e; ++i)
+      cleanup(*i);
+  }
+}
+
+// deleteUnreachableNode - delete nodes no longer reachable from the entry
+void StructuralAnalysis::deleteUnreachableNodes(NodeSetTy &N, NodeTy *entry) {
+  for (auto i = N.begin(), e = N.end(); i != e; ++i) {
+    visitPath.clear();
+    NodeTy *node = *i;
+
+    if (!path(entry, node, N, nullptr)) {
+      for (auto pi = node->predNode.begin(), pe = node->predNode.end();
+           pi != pe; ++pi)
+        (*pi)->remove_successor(node);
+
+      for (auto si = node->succNode.begin(), se = node->succNode.end();
+           si != se; ++si) {
+        (*si)->remove_predecessor(node);
+      }
+
+      unreachableNodeSet.insert(node);
+
+      N.erase(node);
+    }
+  }
+}
+
+void StructuralAnalysis::reconstructUnreachable() {
+BEGIN:
+  bool merge = false;
+
+  for (auto i = unreachableNodeSet.begin(), e = unreachableNodeSet.end();
+       i != e; ++i) {
+    NodeTy *node1 = *i;
+
+    for (auto ii = unreachableNodeSet.begin(), ee = unreachableNodeSet.end();
+         ii != ee; ++ii) {
+      NodeTy *node2 = *i;
+
+      if (node1 == node2)
+        continue;
+
+      for (auto pi = node1->predNode.begin(), pe = node1->predNode.end();
+           pi != pe; ++pi) {
+        NodeTy *pred = *pi;
+
+        if ((pred->isCombined && node2->containedBB.count(pred->entryBB) > 0) ||
+            (!pred->isCombined && node2->containedBB.count(pred->BB) > 0)) {
+          pred->add_successor(node1);
+          merge = true;
+        }
+      }
+
+      for (auto si = node1->succNode.begin(), se = node1->succNode.end();
+           si != se; ++si) {
+        NodeTy *succ = *si;
+
+        if ((succ->isCombined && node2->containedBB.count(succ->entryBB) > 0) ||
+            (!succ->isCombined && node2->containedBB.count(succ->BB) > 0)) {
+          succ->add_predecessor(node1);
+          merge = true;
+        }
+      }
+
+      if (merge) {
+        NodeSetTy nodeSet;
+
+        nodeSet.insert(node1);
+        nodeSet.insert(node2);
+
+        reduce(unreachableNodeSet, Unreachable, nodeSet, nullptr, nullptr);
+
+        goto BEGIN;
+      }
+    }
+  }
+}
+
+StructuralAnalysis::~StructuralAnalysis() {
+  for (auto n = Net.begin(); n != Net.end(); ++n) {
+    delete *n;
+  }
+}
+
+void StructuralAnalysis::analyze(Function &F) {
+  _function = &F;
+
+  // build a Simple CFG out of the LLVM CFG
+  buildSimpleCFG(Net);
+
+  NodeTy *entry = BB2NodeMap[&_function->getEntryBlock()];
+
+  // Follow the Fig 7.39 of Muchnick book
+  structuralAnalysis(Net, entry);
+
+  cleanup(*(Net.begin()));
+
+  reconstructUnreachable();
+
+  cleanupUnreachable();
+}
+
+void StructuralAnalysis::write(llvm::raw_ostream &stream) const {
+  stream << _function->getName().str() << ":\n";
+
+  dumpCTNode(stream, *(Net.begin()));
+
+  dumpUnstructuredBR(stream);
+}
+
+bool StructuralAnalysis::checkUnique(EdgeVecTy &edgeVec, BasicBlock *srcBB,
+                                     BasicBlock *dstBB) {
+  for (EdgeVecTy::iterator i = edgeVec.begin(), e = edgeVec.end(); i != e;
+       ++i) {
+
+    if (i->first == srcBB && i->second == dstBB)
+      return false;
+  }
+
+  return true;
+}
+}
diff --git a/lib/Transforms/Scalar/StructuralAnalysis.h b/lib/Transforms/Scalar/StructuralAnalysis.h
new file mode 100644
index 0000000..d2bbbee
--- /dev/null
+++ b/lib/Transforms/Scalar/StructuralAnalysis.h
@@ -0,0 +1,306 @@
+//===- StructuralAnalysis.h - ---------------------------------------------===//
+//
+// Copyright (c) 2015, Computer Architecture and Systems Laboratory at Georgia
+// Tech
+// Copyright (c) 2016, Florian Ziesche (LLVM port + general fixes/cleanup)
+// All rights reserved.
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+// * Redistributions of source code must retain the above copyright notice, this
+//   list of conditions and the following disclaimer.
+//
+// * Redistributions in binary form must reproduce the above copyright notice,
+//   this list of conditions and the following disclaimer in the documentation
+//   and/or other materials provided with the distribution.
+//
+// * Neither the name of gpuocelot nor the names of its
+//   contributors may be used to endorse or promote products derived from
+//   this software without specific prior written permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+// ARE
+// DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+// FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+// DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+// SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+// CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+// OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+//===----------------------------------------------------------------------===//
+// \author  Haicheng Wu <hwu36@gatech.edu>
+// \date    Monday April 4, 2011
+// \brief   The header file for the StructuralAnalysis pass.
+//===----------------------------------------------------------------------===//
+//
+// This file defines the class of Structural Analysis which will return the
+// control tree and unstructured branches of a function
+//
+// ref: "Using Hammock Graphs to Structure Programs",
+// Fubo Zhang and Erik H. DHollander
+// -> https://biblio.ugent.be/publication/291746/file/451220
+//
+// ref: "Characterization and Transformation of Unstructured Control Flow in GPU
+// Applications", Haicheng Wu, Gregory Diamos, Si Li, and Sudhakar Yalamanchili
+// -> http://www.gdiamos.net/papers/caches-paper.pdf
+//
+//===----------------------------------------------------------------------===//
+
+#ifndef CFGANALYSIS_STRUCTURALANALYSIS_H
+#define CFGANALYSIS_STRUCTURALANALYSIS_H
+
+#include "llvm/Analysis/AliasAnalysis.h"
+#include "llvm/Analysis/BasicAliasAnalysis.h"
+#include "llvm/Analysis/GlobalsModRef.h"
+#include "llvm/Analysis/LoopInfo.h"
+#include "llvm/Analysis/PostDominators.h"
+#include "llvm/IR/CFG.h"
+#include "llvm/IR/Function.h"
+#include "llvm/Support/raw_ostream.h"
+
+#include <map>
+#include <set>
+#include <unordered_map>
+#include <unordered_set>
+#include <vector>
+
+// TODO: modernize/c++ify this
+
+namespace llvm {
+
+// StructuralAnalysis - This class holds all the methods and data structures
+class StructuralAnalysis {
+public:
+  typedef enum { TREE, FORWARD, BACK, CROSS } EdgeClass;
+  typedef std::pair<BasicBlock *, BasicBlock *> EdgeLLVMTy;
+  typedef std::vector<EdgeLLVMTy> EdgeVecTy;
+  typedef std::unordered_set<BasicBlock *> BBSetTy;
+  typedef std::vector<BasicBlock *> BBVecTy;
+
+  // Types defined in Fig 7.38 of Muchnick book
+  typedef enum {
+    Nil,
+    Block,
+    IfThen,
+    IfThenElse,
+    Case,
+    SelfLoop,
+    NaturalLoop,
+    Improper,
+    Unreachable
+  } RegionTy;
+
+  // NodeTy - This type is used for the CFG node
+  typedef struct Node {
+    bool isCombined{
+        false}; // Whether it is an original or combined from original
+    // Map to the corresponding BasicBlock* if it is original
+    BasicBlock *BB{nullptr};
+    std::vector<struct Node *> predNode; // Predecessor of the node
+    std::vector<struct Node *> succNode; // Successor of the node
+    // If isCombined is true, it points to the entry of the nodeset
+    struct Node *entryNode{nullptr};
+    struct Node *parentNode{nullptr};  // Parent Node in Control Tree
+    std::set<struct Node *> childNode; // Child Nodes in Control Tree
+    EdgeVecTy outgoingBR;              // Outgoing Branches of a loop
+    EdgeVecTy incomingBR;              // Incoming Branches of a loop
+    BasicBlock *entryBB{nullptr};      // The entry Basic Block
+    BasicBlock *exitBB{nullptr};       // The exit Basic Block
+    BBSetTy containedBB;               // BasicBlock*s contained in this node
+    EdgeVecTy incomingForwardBR;       // The shared code of unstructured branch
+    RegionTy nodeType{Nil};            // The type of the node
+    bool isLoopHeader{false};
+    bool isBackEdge{false};
+    struct Node *loopExitNode{nullptr};
+
+    void remove_predecessor(struct Node *pred) {
+      predNode.erase(std::remove(predNode.begin(), predNode.end(), pred),
+                     predNode.end());
+    }
+    bool has_predecessor(struct Node *pred) const {
+      const auto iter = std::find(predNode.cbegin(), predNode.cend(), pred);
+      return (iter != predNode.cend());
+    }
+    bool add_predecessor(struct Node *pred) {
+      if (has_predecessor(pred))
+        return false;
+      predNode.emplace_back(pred);
+      return true;
+    }
+    void remove_successor(struct Node *succ) {
+      succNode.erase(std::remove(succNode.begin(), succNode.end(), succ),
+                     succNode.end());
+    }
+    bool has_successor(struct Node *succ) const {
+      const auto iter = std::find(succNode.cbegin(), succNode.cend(), succ);
+      return (iter != succNode.cend());
+    }
+    bool add_successor(struct Node *succ) {
+      if (has_successor(succ))
+        return false;
+      succNode.emplace_back(succ);
+      return true;
+    }
+
+    ~Node();
+  } NodeTy;
+
+  // NodeSetTy - used to holds nodes in a set
+  typedef std::set<NodeTy *> NodeSetTy;
+  typedef std::unordered_map<BasicBlock *, NodeTy *> BB2NodeMapTy;
+  typedef std::map<NodeTy *, NodeTy *> Node2NodeMapTy;
+  typedef std::map<NodeTy *, RegionTy> Node2RegionTyMapTy;
+  typedef std::map<NodeTy *, NodeSetTy *> Node2NodeSetMapTy;
+  typedef std::pair<NodeTy *, NodeTy *> EdgeTy;
+  typedef std::map<EdgeTy, EdgeClass> Edge2ClassMapTy;
+  typedef std::set<EdgeTy> EdgeSetTy;
+  typedef std::set<NodeTy *> VisitSetTy;
+
+public:
+  ~StructuralAnalysis();
+  void analyze(Function &F);
+
+  // Get a text representation of the analysis
+  void write(llvm::raw_ostream &stream) const;
+
+public:
+  NodeSetTy Net;
+
+  // unstructuredBRVec - store the detected unstructured branches
+  EdgeVecTy unstructuredBRVec;
+
+  // BB2NodeMap - This var is used to find the Node from BasicBlock*
+  BB2NodeMapTy BB2NodeMap;
+
+  NodeSetTy unreachableNodeSet;
+
+private:
+  Function *_function;
+
+  // postorder traversal of the flowgraph
+  uint32_t postCtr, postMax, preMax;
+  std::map<uint32_t, NodeTy *> post;
+  VisitSetTy visit, visitPath;
+  std::map<NodeTy *, uint32_t> preTree, postTree;
+
+  // edge2ClassMap - map the edge to its class
+  Edge2ClassMapTy edge2ClassMap;
+
+public:
+  // buildSimpleCFG - Build a Simple CFG out of the LLVM CFG
+  void buildSimpleCFG(NodeSetTy &N);
+
+  // structuralAnalysis - Follow Fig 7.39 of Muchnick book
+  void structuralAnalysis(NodeSetTy &N, NodeTy *entry);
+
+  // DFSPostorder - Follow Fig 7.40 of Muchnick book
+  void DFSPostorder(NodeSetTy &N, NodeTy *x);
+
+  // acyclicRegionType - Follow Fig 7.41 of Muchnick book
+  RegionTy acyclicRegionType(NodeSetTy &N, NodeTy *node, NodeSetTy &nset,
+                             NodeTy **entryNode, NodeTy **exitNode,
+                             NodeTy *entry);
+
+  // cyclicRegionType - Follow Fig 7.42 of Muchnick book
+  RegionTy cyclicRegionType(NodeSetTy &N, NodeSetTy &nset,
+                            NodeTy *loopHeaderNode, NodeTy *backEdgeNode,
+                            NodeTy **exitNode, NodeTy *entry);
+
+  // reduce - Follow Fig 7.43 of Muchnick book
+  NodeTy *reduce(NodeSetTy &N, RegionTy rType, NodeSetTy &nodeSet,
+                 NodeTy *entryNode, NodeTy *exitNode);
+
+  // replace - Follow Fig 7.44 of Muchnick book
+  void replace(NodeSetTy &N, NodeTy *node, NodeSetTy &nodeSet);
+
+  // isImproper - Follow Fig 7.45 of Muchnick book
+  bool isImproper(NodeSetTy &N, NodeSetTy &nset, NodeTy *loopHeaderNode,
+                  NodeTy *backEdgeNode, NodeTy **exitNode, NodeTy *entry);
+
+  // pathBack - Check if there is a node k such that there is a path from
+  // m to k that does not pass through n and an edge k->n that is a back edge
+  NodeTy *pathBack(NodeTy *n, NodeSetTy &N, NodeSetTy &reachUnder);
+
+  // isCaseWithDefault - Check if node leads a case block
+  bool isCaseWithDefault(NodeSetTy &N, NodeTy *entryNode, NodeTy **exitNode,
+                         NodeTy *entry);
+
+  // isCaseWithoutDefault - Check if node leads a case block
+  bool isCaseWithoutDefault(NodeSetTy &N, NodeTy *entryNode, NodeTy **exitNode,
+                            NodeTy *entry);
+
+  // isImproperCaseWithDefault - Check if node leads
+  // a case block with incoming edges
+  bool isImproperCaseWithDefault(NodeSetTy &N, NodeTy *entryNode,
+                                 NodeTy *entry);
+
+  // isImproperCaseoutWithDefault - Check if node leads
+  //	a case block with incoming edges
+  bool isImproperCaseWithoutDefault(NodeSetTy &N, NodeTy *entryNode,
+                                    NodeTy **exitNode, NodeTy *entry);
+
+  // path(n, m, I) - Return true if there is a path from from n to m
+  // such that all the nodes in it are in I and false otherwise
+  bool path(NodeTy *n, NodeTy *m, NodeSetTy &I, NodeTy *esc);
+
+  // path(n, m, I, src, dst ) - Return true if there is a path from from
+  // n to m such that all the nodes in it are in I without going through edge
+  // src->dst and false otherwise
+  bool path(NodeTy *n, NodeTy *m, NodeSetTy &I, NodeTy *src, NodeTy *dst);
+
+  // compact - Compact nodes in nset into n;
+  void compact(NodeSetTy &N, NodeTy *n, NodeSetTy &nset);
+
+  // mapNode2BB - Return the corresponding BasicBlock* of the node
+  BasicBlock *mapNode2BB(const NodeTy *node) const;
+
+  // mapBB2Node - Return the corresponding sturcture node of the basic block
+  NodeTy *mapBB2Node(BasicBlock *bb);
+
+  // dumpCTNode - Dump one Control Node
+  void dumpCTNode(llvm::raw_ostream &stream, NodeTy *n) const;
+
+  // dumpNode - Dump one node
+  void dumpNode(llvm::raw_ostream &stream, NodeTy *node) const;
+
+  // findUnstructuredBR - Record the branch and remove it from CFG
+  void findUnstructuredBR(NodeSetTy &N, NodeTy *srcNode, NodeTy *dstNode,
+                          bool needForwardCopy, bool isGoto);
+
+  // findBB - put all Basic Blocks in node into nodeVec
+  void findBB(NodeTy *node, BBVecTy &nodeVec) const;
+
+  // findBB - put all Basic Blocks in node into nodeSet
+  void findBB(NodeTy *node, BBSetTy &nodeSet) const;
+
+  // findEntryBB - find the entry Basic Block of the node
+  BasicBlock *findEntryBB(NodeTy *node);
+
+  // dumpUnstructuredBR - Dump all found unstructured branches
+  void dumpUnstructuredBR(llvm::raw_ostream &stream) const;
+
+  // isStillReachableFrom entry -Return true if after erasing
+  // edge src->dst, dst is still reachable from entry
+  bool isStillReachableFromEntry(NodeSetTy &N, NodeTy *entry, NodeTy *dstNode,
+                                 NodeTy *srcNode);
+
+  // clean - fill in the element of incoming branches and outgoing branches
+  void cleanup(NodeTy *node);
+
+  void cleanupUnreachable();
+
+  void reconstructUnreachable();
+
+  // deleteUnreachableNode - delete nodes that is no longer
+  // reachable from the entry
+  void deleteUnreachableNodes(NodeSetTy &N, NodeTy *entry);
+
+  bool checkUnique(EdgeVecTy &edgeVec, BasicBlock *srcBB, BasicBlock *dstBB);
+};
+}
+
+#endif
diff --git a/lib/Transforms/Scalar/StructuralTransform.cpp b/lib/Transforms/Scalar/StructuralTransform.cpp
new file mode 100644
index 0000000..8fdf806
--- /dev/null
+++ b/lib/Transforms/Scalar/StructuralTransform.cpp
@@ -0,0 +1,535 @@
+//===- StructuralTransform.cpp - ------------------------------------------===//
+//
+// Copyright (c) 2015, Computer Architecture and Systems Laboratory at Georgia
+// Tech
+// Copyright (c) 2016, Florian Ziesche (LLVM port + general fixes/cleanup)
+// All rights reserved.
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+// * Redistributions of source code must retain the above copyright notice, this
+//   list of conditions and the following disclaimer.
+//
+// * Redistributions in binary form must reproduce the above copyright notice,
+//   this list of conditions and the following disclaimer in the documentation
+//   and/or other materials provided with the distribution.
+//
+// * Neither the name of gpuocelot nor the names of its
+//   contributors may be used to endorse or promote products derived from
+//   this software without specific prior written permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+// ARE
+// DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+// FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+// DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+// SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+// CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+// OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+//===----------------------------------------------------------------------===//
+// \author  Haicheng Wu <hwu36@gatech.edu>
+// \date    Monday April 4, 2011
+// \brief   The source file for the StructuralTransform pass.
+//===----------------------------------------------------------------------===//
+//
+// This file implements an Structural Transform based on Zhang's paper
+//
+//===----------------------------------------------------------------------===//
+
+#include "StructuralTransform.h"
+#include "llvm/Transforms/Utils/BasicBlockUtils.h"
+#include "llvm/Transforms/Utils/Cloning.h"
+#include "llvm/Transforms/Utils/LoopUtils.h"
+
+#if 1
+#define DBG(x)
+#else
+#define DBG(x) x
+#endif
+
+#define report(x) DBG(errs() << x << "\n"; errs().flush();)
+
+namespace llvm {
+
+typedef StructuralAnalysis SA;
+
+// Algorithm 2 of Zhang's paper -- elimination of outgoing branches
+bool StructuralTransform::Cut(NodeTy *N) {
+  report("Applying cut transform");
+  bool change = false;
+
+  for (auto *child : N->childNode) {
+    change |= Cut(child);
+  }
+
+  if (!stopCut) {
+    if (N->isCombined &&
+        (N->nodeType == SA::NaturalLoop || N->nodeType == SA::SelfLoop) &&
+        N->containedBB.size() > 1 && !N->outgoingBR.empty()) {
+      change = true;
+
+      BasicBlock *TopExitBB = N->exitBB;
+
+      for (auto &edge : N->outgoingBR) {
+        // 1. Before loop, insert fp = false
+        auto fp = new AllocaInst(condition_type, nullptr, "fp", alloca_insert);
+
+        // TODO: "before loop" doesn't equal "in the entry block", or does it?
+        // what if it is contained by another loop?
+        new StoreInst(ConstantInt::get(condition_type, 0), fp,
+                      condition_init_insert);
+
+        // 2. replace branch to targe t by if (B) then {fp = true; exit}
+        new StoreInst(ConstantInt::get(condition_type, 1), fp,
+                      edge.first->getFirstNonPHI());
+
+        for (BasicBlock *succ : edge.first->successors()) {
+          if (N->containedBB.count(succ) == 0)
+            continue;
+
+          new StoreInst(ConstantInt::get(condition_type, 0), fp,
+                        succ->getFirstNonPHI());
+        }
+
+        // 3. After loop, insert if (fp) goto t
+        BasicBlock *NewCmpBB = BasicBlock::Create(
+            _function->getContext(), "NewCmpBB", _function, nullptr);
+
+        // ValueMap
+        STValueToValueMapTy ValueMap;
+        ValueMap[edge.second] = NewCmpBB;
+
+        if (TopExitBB != nullptr) {
+          ValueMap[TopExitBB] = NewCmpBB;
+        }
+
+        // For each BasicBlock
+        // Remap Values here for Instructions
+        for (BasicBlock *BB : N->containedBB) {
+          // TODO: handle switches
+          assert(!isa<ReturnInst>(BB->getTerminator()) &&
+                 "terminator can not be a return instruction");
+          BranchInst *branch = dyn_cast<BranchInst>(BB->getTerminator());
+          assert(branch != nullptr &&
+                 "terminator must be a branch instruction");
+
+          if (branch->isUnconditional()) {
+            STValueToValueMapTy::iterator it =
+                ValueMap.find(branch->getSuccessor(0));
+
+            // found in ValueMap
+            if (it != ValueMap.end()) {
+              DBG(errs() << "changing successor of " << BB->getName()
+                         << " from " << branch->getSuccessor(0)->getName()
+                         << " to " << it->second->getName() << "\n";)
+              branch->setSuccessor(0, it->second);
+            }
+          } else if (branch->isConditional()) {
+            STValueToValueMapTy::iterator it1 =
+                ValueMap.find(branch->getSuccessor(0));
+            STValueToValueMapTy::iterator it2 =
+                ValueMap.find(branch->getSuccessor(1));
+
+            const bool found1 = (it1 != ValueMap.end());
+            const bool found2 = (it2 != ValueMap.end());
+
+            // both found in ValueMap
+            if (found1 && found2) {
+              branch->eraseFromParent();
+              BranchInst::Create(it1->second, BB);
+            }
+            // edge 1 is found in ValueMap & edge 2 is not
+            else if (found1 && !found2) {
+              branch->setSuccessor(0, it1->second);
+            }
+            // edge 2 is found in ValueMap & edge 1 is not
+            else if (!found1 && found2) {
+              branch->setSuccessor(1, it2->second);
+            }
+          }
+        }
+
+        if (TopExitBB != nullptr) {
+          // TODO: insert before branch?
+          ICmpInst *cmp =
+              new ICmpInst(NewCmpBB->getFirstNonPHI(), CmpInst::ICMP_EQ, fp,
+                           ConstantInt::get(condition_type, 1), "fp_cmp");
+
+          BranchInst::Create(edge.second, TopExitBB, cmp, NewCmpBB);
+        } else {
+          BranchInst::Create(edge.second, NewCmpBB);
+        }
+
+        TopExitBB = NewCmpBB;
+      }
+
+      if (N->exitBB == nullptr) {
+        // TODO: can this be an unconditional? also: handle switch?
+        BranchInst *branch = dyn_cast<BranchInst>(N->entryBB->getTerminator());
+        assert(branch != nullptr && branch->isUnconditional() &&
+               "invalid branch in entryBB");
+        branch->setSuccessor(0, TopExitBB);
+      }
+
+      stopCut = true;
+      return change;
+    }
+  }
+
+  return change;
+}
+
+// Algorithm 3 of Zhang's paper -- elimination of backward branches
+bool StructuralTransform::BackwardCopy(NodeTy *N) {
+  // report("Applying backward copy");
+  assert(false && "BackwardCopy not implemented yet");
+  // TODO: !
+  return false;
+}
+
+// Algorithm 4 of Zhang's paper -- elimination of Forward branches
+bool StructuralTransform::ForwardCopy(NodeTy *N) {
+  report("Applying forward copy");
+  bool change = false;
+
+  for (auto *child : N->childNode) {
+    change |= ForwardCopy(child);
+  }
+
+  if (!N->incomingForwardBR.empty()) {
+    change = true;
+
+    for (auto &edge : N->incomingForwardBR) {
+      // ValueMap
+      STValueToValueMapTy ValueMap;
+      std::unordered_map<BasicBlock *, std::unique_ptr<ValueToValueMapTy>>
+          clone_vmap;
+
+      // Clone BasicBlocks to the new function
+      // TODO: properly handle loop cloning
+      for (BasicBlock *BB : N->containedBB) {
+        auto vmap = std::make_unique<ValueToValueMapTy>();
+        BasicBlock *ClonedBB = CloneBasicBlock(BB, *vmap.get(), ".scfg.cloned",
+                                               _function, nullptr);
+
+        // replace instruction uses of instructions that were cloned in the
+        // cloned block
+        // (CloneBasicBlock will only clone the "lhs", not the uses/operands
+        // inside instructions)
+        for (Instruction &instr : *ClonedBB) {
+          for (uint32_t i = 0, count = instr.getNumOperands(); i < count; ++i) {
+            const auto iter = vmap->find(instr.getOperand(i));
+            if (iter != vmap->end()) {
+              instr.setOperand(i, iter->second);
+            }
+          }
+        }
+
+        clone_vmap[ClonedBB] = std::move(vmap);
+        ValueMap[BB] = ClonedBB;
+      }
+
+      // For each BasicBlock
+      // Remap Values here for Instructions
+      for (auto &ValuePair : ValueMap) {
+        // nothing to do here
+        if (isa<ReturnInst>(ValuePair.first->getTerminator())) {
+          continue;
+        }
+
+        BranchInst *branch =
+            dyn_cast<BranchInst>(ValuePair.first->getTerminator());
+        assert(branch != nullptr && "terminator must be a branch instruction");
+        BranchInst *sec_branch =
+            dyn_cast<BranchInst>(ValuePair.second->getTerminator());
+        assert(sec_branch != nullptr && "invalid branch");
+
+        if (branch->isUnconditional()) {
+          STValueToValueMapTy::iterator it =
+              ValueMap.find(branch->getSuccessor(0));
+
+          BasicBlock *new_sec_branch_target = nullptr;
+          // found in ValueMap
+          if (it != ValueMap.end()) {
+            new_sec_branch_target = it->second;
+          }
+          // not found in ValueMap
+          else {
+            new_sec_branch_target = branch->getSuccessor(0);
+          }
+
+          // transform conditional branch to an unconditional one
+          if (sec_branch->isConditional()) {
+            BranchInst::Create(new_sec_branch_target, sec_branch);
+            sec_branch->eraseFromParent();
+          }
+        } else if (branch->isConditional()) {
+          STValueToValueMapTy::iterator it1 =
+              ValueMap.find(branch->getSuccessor(0));
+          STValueToValueMapTy::iterator it2 =
+              ValueMap.find(branch->getSuccessor(1));
+
+          // both found in ValueMap
+          if (it1 != ValueMap.end() && it2 != ValueMap.end()) {
+            sec_branch->setSuccessor(0, it1->second);
+            sec_branch->setSuccessor(1, it2->second);
+          }
+          // edge 1 is found in ValueMap & edge 2 is not
+          else if (it1 != ValueMap.end() && it2 == ValueMap.end()) {
+            sec_branch->setSuccessor(0, it1->second);
+            sec_branch->setSuccessor(1, branch->getSuccessor(1));
+          }
+          // edge 2 is found in ValueMap & edge 1 is not
+          else if (it1 == ValueMap.end() && it2 != ValueMap.end()) {
+            // TODO: correct order? or reverse here?
+            sec_branch->setSuccessor(0, it2->second);
+            sec_branch->setSuccessor(1, branch->getSuccessor(0));
+          }
+          // neither is in ValueMap
+          else if (it1 == ValueMap.end() && it2 == ValueMap.end()) {
+            sec_branch->setSuccessor(0, branch->getSuccessor(0));
+            sec_branch->setSuccessor(1, branch->getSuccessor(1));
+          }
+        }
+      }
+
+      BranchInst *branch = dyn_cast<BranchInst>(edge.first->getTerminator());
+      BasicBlock *newDst = ValueMap[edge.second];
+      assert(branch != nullptr && "terminator must be a branch instruction");
+      if (branch->getSuccessor(0) == edge.second) {
+        branch->setSuccessor(0, newDst);
+      } else if (branch->isConditional() &&
+                 branch->getSuccessor(1) == edge.second) {
+        branch->setSuccessor(1, newDst);
+      } else {
+        assert(false && "initial edge doesn't point to edge target");
+      }
+
+      // update phi nodes of cloned blocks + successors preds / phi nodes
+      for (auto &entry : ValueMap) {
+        BasicBlock *orig = entry.first;
+        BasicBlock *clone = entry.second;
+        const auto update_phis = [&clone_vmap](BasicBlock *bb,
+                                               BasicBlock *orig_bb) {
+          // update incoming
+          std::unordered_set<BasicBlock *> preds;
+          for (BasicBlock *pred : bb->predecessors()) {
+            preds.emplace(pred);
+          }
+          for (Instruction *instr = &bb->front(),
+                           *non_phi = bb->getFirstNonPHI();
+               instr != non_phi; instr = instr->getNextNode()) {
+            if (PHINode *phi = dyn_cast<PHINode>(instr)) {
+              // remove incoming BB values from BBs that no longer point to this
+              std::unordered_set<BasicBlock *> rem_bbs;
+              DBG(std::unordered_set<BasicBlock *> keep_bbs;)
+              for (BasicBlock *bb_in : phi->blocks()) {
+                if (preds.count(bb_in) == 0) {
+                  rem_bbs.emplace(bb_in);
+                }
+                DBG(else keep_bbs.emplace(bb_in);)
+              }
+              for (BasicBlock *rem_bb : rem_bbs) {
+                phi->removeIncomingValue(rem_bb);
+              }
+              // TODO: do we need to add non-existing preds? can this happen?
+              DBG(for (BasicBlock *pred
+                       : preds) {
+                if (keep_bbs.count(pred) == 0) {
+                  errs() << "predecessor " << pred->getName()
+                         << " not in phi node of " << bb->getName() << ": "
+                         << *phi << "\n";
+                  assert(false && "predecessor not in phi node");
+                }
+              })
+            }
+          }
+
+          // update outgoing (only necessary for clones)
+          if (orig_bb == nullptr)
+            return;
+          for (BasicBlock *succ : bb->successors()) {
+            for (Instruction *instr = &succ->front(),
+                             *non_phi = succ->getFirstNonPHI();
+                 instr != non_phi; instr = instr->getNextNode()) {
+              if (PHINode *phi = dyn_cast<PHINode>(instr)) {
+                Value *orig_val = phi->getIncomingValueForBlock(orig_bb);
+                assert(orig_val != nullptr &&
+                       "original block was not using this phi/block?");
+                phi->addIncoming((*clone_vmap[bb])[orig_val], bb);
+              }
+            }
+          }
+        };
+        update_phis(orig, nullptr);
+        update_phis(clone, orig);
+      }
+    }
+
+    return change;
+  }
+
+  return change;
+}
+
+bool StructuralTransform::transform(Function &F) {
+  _function = &F;
+
+  alloca_insert = &F.getEntryBlock().front();
+  condition_init_insert = F.getEntryBlock().getTerminator();
+
+  // TODO: can we merge multiple conditions to a larger integer and then use a
+  // switch instead?
+  if (condition_type == nullptr) {
+    condition_type = llvm::Type::getInt1Ty(F.getContext());
+  }
+
+  SA.unstructuredBRVec.clear();
+  SA.unreachableNodeSet.clear();
+  SA.Net.clear();
+  SA.analyze(F);
+
+  DBG(SA.write(errs());)
+
+  bool was_modified = false;
+  while (!SA.unstructuredBRVec.empty()) {
+    NodeTy *entry = *(SA.Net.begin());
+
+    stopCut = false;
+
+    for (NodeTy *node : SA.unreachableNodeSet) {
+      if (Cut(node)) {
+        was_modified = true;
+        goto ANALYSIS;
+      }
+    }
+
+    if (ForwardCopy(entry)) {
+      was_modified = true;
+      goto ANALYSIS;
+    }
+
+    if (Cut(entry)) {
+      was_modified = true;
+      goto ANALYSIS;
+    }
+
+    if (BackwardCopy(entry)) {
+      was_modified = true;
+      goto ANALYSIS;
+    }
+
+  ANALYSIS:
+    SA.unstructuredBRVec.clear();
+    SA.unreachableNodeSet.clear();
+    SA.Net.clear();
+    SA.analyze(*_function);
+  }
+
+  SA.Net.clear();
+  // SA.analyze(*_function); // TODO: needed?
+
+  return was_modified;
+}
+
+const BasicBlock *StructuralTransform::bb(NodeTy *node) const {
+  return (node->isCombined ? nullptr : node->BB);
+}
+
+const StructuralTransform::NodeListTy &
+StructuralTransform::children(const NodeTy *node) const {
+  NodeListTy *nList = new NodeListTy;
+  NodeTy *tmp = nullptr;
+
+  switch (node->nodeType) {
+  case SA::Block:
+    tmp = node->entryNode;
+    nList->push_back(tmp);
+
+    while (tmp->succNode.size() == 1) {
+      tmp = *(tmp->succNode.begin());
+      nList->push_back(tmp);
+    }
+
+    break;
+  case SA::IfThen:
+    nList->push_back(cond(node));
+    nList->push_back(*(node->childNode.begin()));
+
+    break;
+  case SA::IfThenElse:
+    nList->push_back(cond(node));
+    nList->push_back(ifTrue(node));
+    nList->push_back(ifFalse(node));
+
+    break;
+  case SA::SelfLoop:
+    nList->push_back(*(node->childNode.begin()));
+    break;
+  case SA::NaturalLoop:
+    tmp = node->entryNode;
+    nList->push_back(tmp);
+
+    tmp = *(tmp->succNode.begin());
+    nList->push_back(tmp);
+
+    break;
+  default:
+    break;
+  }
+
+  return *nList;
+}
+
+const SA::NodeTy *StructuralTransform::cond(const NodeTy *node) const {
+  return node->entryNode;
+}
+
+const SA::NodeTy *StructuralTransform::ifTrue(const NodeTy *node) const {
+  if (node->nodeType == SA::IfThen)
+    return *(node->childNode.begin());
+
+  const NodeTy *lastChild = node;
+
+  while (!lastChild->isCombined)
+    lastChild = children(lastChild).back();
+
+  BranchInst *branch = dyn_cast<BranchInst>(lastChild->BB->getTerminator());
+  assert(branch != nullptr && "terminator must be a branch instruction");
+
+  SA::NodeSetTy::iterator tmpNode = node->childNode.begin();
+  NodeTy *childNode1 = *tmpNode;
+  ++tmpNode;
+  NodeTy *childNode2 = *tmpNode;
+
+  if (branch->getSuccessor(0) == childNode1->entryBB)
+    return childNode2;
+  else
+    return childNode1;
+}
+
+const SA::NodeTy *StructuralTransform::ifFalse(const NodeTy *node) const {
+  const NodeTy *lastChild = node;
+
+  while (!lastChild->isCombined)
+    lastChild = children(lastChild).back();
+
+  BranchInst *branch = dyn_cast<BranchInst>(lastChild->BB->getTerminator());
+  assert(branch != nullptr && "terminator must be a branch instruction");
+
+  SA::NodeSetTy::iterator tmpNode = node->childNode.begin();
+  NodeTy *childNode1 = *tmpNode;
+  ++tmpNode;
+  NodeTy *childNode2 = *tmpNode;
+
+  if (branch->getSuccessor(0) == childNode1->entryBB)
+    return childNode1;
+  else
+    return childNode2;
+}
+}
diff --git a/lib/Transforms/Scalar/StructuralTransform.h b/lib/Transforms/Scalar/StructuralTransform.h
new file mode 100644
index 0000000..cadb3f0
--- /dev/null
+++ b/lib/Transforms/Scalar/StructuralTransform.h
@@ -0,0 +1,124 @@
+//===- StructuralTransform.h - --------------------------------------------===//
+//
+// Copyright (c) 2015, Computer Architecture and Systems Laboratory at Georgia
+// Tech
+// Copyright (c) 2016, Florian Ziesche (LLVM port + general fixes/cleanup)
+// All rights reserved.
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+// * Redistributions of source code must retain the above copyright notice, this
+//   list of conditions and the following disclaimer.
+//
+// * Redistributions in binary form must reproduce the above copyright notice,
+//   this list of conditions and the following disclaimer in the documentation
+//   and/or other materials provided with the distribution.
+//
+// * Neither the name of gpuocelot nor the names of its
+//   contributors may be used to endorse or promote products derived from
+//   this software without specific prior written permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+// ARE
+// DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+// FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+// DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+// SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+// CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+// OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+//===----------------------------------------------------------------------===//
+// \author  Haicheng Wu <hwu36@gatech.edu>
+// \date    Monday April 4, 2011
+// \brief   The header file for the StructuralTransform pass.
+//===----------------------------------------------------------------------===//
+//
+// This file implements an Structural Transform based on Zhang's paper
+//
+// ref: "Using Hammock Graphs to Structure Programs",
+// Fubo Zhang and Erik H. DHollander
+// -> https://biblio.ugent.be/publication/291746/file/451220
+//
+// ref: "Characterization and Transformation of Unstructured Control Flow in GPU
+// Applications", Haicheng Wu, Gregory Diamos, Si Li, and Sudhakar Yalamanchili
+// -> http://www.gdiamos.net/papers/caches-paper.pdf
+//
+//===----------------------------------------------------------------------===//
+
+#ifndef CFGANALYSIS_STRUCTURALTRANSFORM_H
+#define CFGANALYSIS_STRUCTURALTRANSFORM_H
+
+#include "llvm/Analysis/AliasAnalysis.h"
+#include "llvm/Analysis/BasicAliasAnalysis.h"
+#include "llvm/Analysis/GlobalsModRef.h"
+#include "llvm/Analysis/LoopInfo.h"
+#include "llvm/Analysis/PostDominators.h"
+#include "llvm/IR/CFG.h"
+#include "llvm/IR/Function.h"
+
+#include "StructuralAnalysis.h"
+
+#include <list>
+#include <unordered_map>
+
+namespace llvm {
+
+/// StructuralTransform - This class holds all the methods and data structures
+class StructuralTransform {
+public:
+  typedef StructuralAnalysis::BBVecTy BBVecTy;
+  typedef StructuralAnalysis::NodeTy NodeTy;
+
+public:
+  bool transform(Function &F);
+
+private:
+  typedef std::unordered_map<BasicBlock *, BasicBlock *> STValueToValueMapTy;
+
+  // alloca insertion point
+  Instruction *alloca_insert{nullptr};
+
+  // insertion point for condition initialization
+  Instruction *condition_init_insert{nullptr};
+
+  // type used when creating new conditions (i1)
+  llvm::Type *condition_type{nullptr};
+
+  Function *_function;
+
+  // Algorithm 2 of Zhang's paper -- elimination of outgoing branches
+  bool Cut(NodeTy *N);
+
+  // Algorithm 3 of Zhang's paper -- elimination of backward branches
+  bool BackwardCopy(NodeTy *N);
+
+  // Algorithm 4 of Zhang's paper -- elimination of Forward branches
+  bool ForwardCopy(NodeTy *N);
+
+  bool stopCut;
+
+  StructuralAnalysis SA;
+
+  /// Get iterator to the basic block in the cfg
+  const BasicBlock *bb(NodeTy *node) const;
+
+  typedef std::list<const NodeTy *> NodeListTy;
+
+  /// Get the children (returns an ordered container)
+  const NodeListTy &children(const NodeTy *node) const;
+
+  /// Get condition node from IfThen and IfThenElse.
+  /// The last instruction of the condition node should be a branch.
+  const NodeTy *cond(const NodeTy *node) const;
+  /// Get if-true node from IfThen and IfThenElse
+  const NodeTy *ifTrue(const NodeTy *node) const;
+  /// Get if-false node from IfThenElse
+  const NodeTy *ifFalse(const NodeTy *node) const;
+};
+}
+
+#endif
diff --git a/lib/Transforms/Scalar/VulkanFinal.cpp b/lib/Transforms/Scalar/VulkanFinal.cpp
new file mode 100644
index 0000000..40887e4
--- /dev/null
+++ b/lib/Transforms/Scalar/VulkanFinal.cpp
@@ -0,0 +1,548 @@
+//===- VulkanFinal.cpp - Vulkan final pass --------------------------------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+// This file fixes certain post-codegen issues and transforms specific builtin
+// functions with uses of new function arguments, as well as transforming
+// input/output variables/arguments for later use in the SPIR-V backend.
+//
+//===----------------------------------------------------------------------===//
+
+#include "llvm/ADT/Statistic.h"
+#include "llvm/ADT/STLExtras.h"
+#include "llvm/ADT/SetVector.h"
+#include "llvm/ADT/SmallPtrSet.h"
+#include "llvm/ADT/SmallVector.h"
+#include "llvm/ADT/StringExtras.h"
+#include "llvm/Analysis/AliasAnalysis.h"
+#include "llvm/Analysis/BasicAliasAnalysis.h"
+#include "llvm/Analysis/GlobalsModRef.h"
+#include "llvm/Analysis/PostDominators.h"
+#include "llvm/Analysis/LoopInfo.h"
+#include "llvm/IR/CFG.h"
+#include "llvm/IR/CallSite.h"
+#include "llvm/IR/CallingConv.h"
+#include "llvm/IR/ConstantRange.h"
+#include "llvm/IR/Constants.h"
+#include "llvm/IR/DataLayout.h"
+#include "llvm/IR/DebugInfo.h"
+#include "llvm/IR/DerivedTypes.h"
+#include "llvm/IR/Dominators.h"
+#include "llvm/IR/Function.h"
+#include "llvm/IR/InlineAsm.h"
+#include "llvm/IR/InstIterator.h"
+#include "llvm/IR/InstVisitor.h"
+#include "llvm/IR/IntrinsicInst.h"
+#include "llvm/IR/IRBuilder.h"
+#include "llvm/IR/LLVMContext.h"
+#include "llvm/IR/Metadata.h"
+#include "llvm/IR/Module.h"
+#include "llvm/IR/LegacyPassManager.h"
+#include "llvm/Pass.h"
+#include "llvm/Support/CommandLine.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/ErrorHandling.h"
+#include "llvm/Support/raw_ostream.h"
+#include "llvm/Transforms/IPO/PassManagerBuilder.h"
+#include "llvm/Transforms/IPO.h"
+#include "llvm/Transforms/Scalar.h"
+#include "llvm/Transforms/Utils/BasicBlockUtils.h"
+#include "llvm/Transforms/Utils/LoopUtils.h"
+#include "llvm/Transforms/Utils/Cloning.h"
+#include <algorithm>
+#include <cstdarg>
+#include <memory>
+#include <unordered_map>
+#include <unordered_set>
+#include <deque>
+#include <array>
+using namespace llvm;
+
+#define DEBUG_TYPE "VulkanFinal"
+
+#if 1
+#define DBG(x)
+#else
+#define DBG(x) x
+#endif
+
+namespace {
+	// -> SPIRVInternal.h (can't include, b/c it's not in a proper path)
+	static const uint32_t SPIRAS_Uniform = 5;
+	static const uint32_t SPIRAS_Input = 6;
+	static const uint32_t SPIRAS_Output = 7;
+	
+	// VulkanFinal
+	struct VulkanFinal : public FunctionPass, InstVisitor<VulkanFinal> {
+		friend class InstVisitor<VulkanFinal>;
+		
+		static char ID; // Pass identification, replacement for typeid
+		
+		std::shared_ptr<llvm::IRBuilder<>> builder;
+		
+		Module* M { nullptr };
+		LLVMContext* ctx { nullptr };
+		Function* func { nullptr };
+		bool is_kernel_func { false };
+		bool is_vertex_func { false };
+		bool is_fragment_func { false };
+		
+		// added kernel function args
+		Argument* global_id { nullptr };
+		Argument* local_id { nullptr };
+		Argument* group_id { nullptr };
+		Argument* group_size { nullptr };
+		GlobalVariable* workgroup_size { nullptr };
+		
+		// added vertex function args
+		Argument* vertex_id { nullptr };
+		
+		// added fragment function args
+		Argument* point_coord { nullptr };
+		
+		std::unordered_set<Instruction*> unreachable_kill_list;
+		
+		VulkanFinal() :
+		FunctionPass(ID) {
+			initializeVulkanFinalPass(*PassRegistry::getPassRegistry());
+		}
+		
+		void getAnalysisUsage(AnalysisUsage &AU) const override {
+			AU.addRequired<AAResultsWrapperPass>();
+			AU.addRequired<GlobalsAAWrapperPass>();
+			AU.addRequired<AssumptionCacheTracker>();
+			AU.addRequired<TargetLibraryInfoWrapperPass>();
+		}
+		
+		bool runOnFunction(Function &F) override {
+			// exit if empty function
+			if(F.empty()) return false;
+			DBG(errs() << "in func: "; errs().write_escaped(F.getName()) << '\n';)
+			
+			// determine this function type + exit if it isn't a kernel or shader function
+			is_kernel_func = F.getCallingConv() == CallingConv::FLOOR_KERNEL;
+			is_vertex_func = F.getCallingConv() == CallingConv::FLOOR_VERTEX;
+			is_fragment_func = F.getCallingConv() == CallingConv::FLOOR_FRAGMENT;
+			if(!is_kernel_func && !is_vertex_func && !is_fragment_func) return false;
+			
+			//
+			M = F.getParent();
+			ctx = &M->getContext();
+			func = &F;
+			builder = std::make_shared<llvm::IRBuilder<>>(*ctx);
+			
+			DBG(errs() << "> adding built-in args ...\n";)
+			// add args if this is a kernel function
+			if(is_kernel_func) {
+				const auto vec_type = llvm::VectorType::get(llvm::Type::getInt32Ty(*ctx), 3)->getPointerTo(SPIRAS_Input);
+				global_id = new llvm::Argument(vec_type, "vulkan.global_invocation_id", &F);
+				local_id = new llvm::Argument(vec_type, "vulkan.local_invocation_id", &F);
+				group_id = new llvm::Argument(vec_type, "vulkan.workgroup_id", &F);
+				group_size = new llvm::Argument(vec_type, "vulkan.num_workgroups", &F);
+			}
+			
+			// add args if this is a vertex function
+			if(is_vertex_func) {
+				const auto uint_type = llvm::Type::getInt32PtrTy(*ctx, SPIRAS_Input);
+				vertex_id = new llvm::Argument(uint_type, "vulkan.vertex_index", &F);
+				// TODO: this should be optional / only happen on request
+				// TODO: handle instance id
+			}
+			
+			// add args if this is a fragment function
+			if(is_fragment_func) {
+				const auto vec_type = llvm::VectorType::get(llvm::Type::getFloatTy(*ctx), 2)->getPointerTo(SPIRAS_Input);
+				point_coord = new llvm::Argument(vec_type, "vulkan.point_coord", &F);
+			}
+			
+			// handle return value / output
+			DBG(errs() << "> handling return values ...\n";)
+			if(is_vertex_func || is_fragment_func) {
+				const auto emit_output_var = [this](const std::string& var_name,
+													llvm::Type* global_type,
+													uint32_t address_space,
+													bool is_constant,
+													Constant* initializer) {
+					auto GV = new GlobalVariable(*M,
+												 global_type,
+												 is_constant,
+												 GlobalVariable::InternalLinkage,
+												 initializer,
+												 var_name,
+												 nullptr,
+												 GlobalValue::NotThreadLocal,
+												 address_space);
+					return GV;
+				};
+				
+				const auto ret_type = F.getReturnType();
+				const auto func_name = F.getName().str();
+				uint32_t return_idx = 0;
+				if(ret_type->isStructTy()) {
+					const auto st_type = cast<llvm::StructType>(ret_type);
+					for(const auto& elem : st_type->elements()) {
+						emit_output_var(func_name + ".vulkan_output." + std::to_string(return_idx++),
+										elem, SPIRAS_Output, false, nullptr);
+					}
+				}
+				else if(ret_type->isArrayTy()) {
+					emit_output_var(func_name + ".vulkan_output.0", ret_type, SPIRAS_Output, false, nullptr);
+				}
+				else if(!ret_type->isVoidTy()) {
+					emit_output_var(func_name + ".vulkan_output.0", ret_type, SPIRAS_Output, false, nullptr);
+				}
+				// else: nothing/passthrough
+			}
+			else if(is_kernel_func) {
+				// emit work-group size constant for this function
+				auto workgroup_size_type = llvm::VectorType::get(llvm::Type::getInt32Ty(*ctx), 3);
+				std::vector<llvm::Constant*> workgroup_size_vals {
+					llvm::ConstantInt::get(llvm::Type::getInt32Ty(*ctx), 512),
+					llvm::ConstantInt::get(llvm::Type::getInt32Ty(*ctx), 1),
+					llvm::ConstantInt::get(llvm::Type::getInt32Ty(*ctx), 1),
+				};
+				auto workgroup_size_init = llvm::ConstantVector::get(workgroup_size_vals);
+				workgroup_size = new GlobalVariable(*M,
+													workgroup_size_type,
+													true,
+													GlobalVariable::InternalLinkage,
+													workgroup_size_init,
+													F.getName().str() + ".vulkan_constant.workgroup_size",
+													nullptr,
+													GlobalValue::NotThreadLocal,
+													0);
+			}
+			
+			// visit everything in this function
+			DBG(errs() << "> handling instructions ...\n";)
+			visit(F);
+			
+			DBG(errs() << "> updating function signature / parameters ...\n";)
+			{
+				// update function signature / param list
+				// NOTE: this always changes the return type to void (vs/fs returns have already been modified)
+				// NOTE: must be called after visiting rets and other ret type/val users
+				std::vector<Type*> param_types;
+				for(auto& arg : F.args()) {
+					auto arg_type = arg.getType();
+					
+					// fix non-struct uniforms by enclosing them in a struct
+					// NOTE: only fix direct args here (uniforms, not SSBOs, those will be fixed later)
+					if(arg.onlyReadsMemory() &&
+					   (arg.hasAttribute(Attribute::Dereferenceable) ||
+						arg.hasAttribute(Attribute::DereferenceableOrNull))) {
+					   if(auto ptr_type = dyn_cast<llvm::PointerType>(arg_type)) {
+						   auto elem_type = ptr_type->getElementType();
+						   if(ptr_type->getAddressSpace() == SPIRAS_Uniform &&
+							  !elem_type->isStructTy()) {
+							   llvm::Type* st_elems[] { elem_type };
+							   auto enclosing_type = llvm::StructType::create(*ctx, st_elems, "enclose." + arg.getName().str());
+							   auto new_arg_type = enclosing_type->getPointerTo(SPIRAS_Uniform);
+							   arg_type = new_arg_type;
+							   arg.mutateType(new_arg_type);
+							   
+							   // replace, should usually only have one load
+							   llvm::Value* idx_list[] {
+								   llvm::ConstantInt::get(llvm::Type::getInt32Ty(*ctx), 0),
+								   llvm::ConstantInt::get(llvm::Type::getInt32Ty(*ctx), 0),
+							   };
+							   
+							   std::vector<User*> users;
+							   for(auto* user : arg.users()) {
+								   users.emplace_back(user);
+							   }
+							   for(auto& user : users) {
+								   if(auto instr = dyn_cast<Instruction>(user)) {
+									   if(isa<LoadInst>(instr)) {
+										   auto elem_gep = llvm::GetElementPtrInst::CreateInBounds(&arg, idx_list, "", instr);
+										   auto repl_instr = new LoadInst(elem_gep, instr->getName(), false, instr);
+										   instr->replaceAllUsesWith(repl_instr);
+										   instr->eraseFromParent();
+									   }
+									   // TODO: ?
+									   else errs() << "unhandled arg user: " << *instr << "\n";
+								   }
+								   else errs() << "arg user is not an instruction\n";
+							   }
+						   }
+					   }
+					}
+					
+					param_types.push_back(arg_type);
+				}
+				auto new_func_type = FunctionType::get(llvm::Type::getVoidTy(*ctx), param_types, false);
+				F.mutateType(PointerType::get(new_func_type, 0));
+				F.mutateFunctionType(new_func_type);
+			}
+			
+			// always modified
+			DBG(errs() << "> " << F.getName() << " done\n";)
+			return true;
+		}
+		
+		// InstVisitor overrides...
+		using InstVisitor<VulkanFinal>::visit;
+		void visit(Instruction& I) {
+			InstVisitor<VulkanFinal>::visit(I);
+		}
+		
+		//
+		void visitCallInst(CallInst &I) {
+			const auto func_name = I.getCalledFunction()->getName();
+			if(!func_name.startswith("floor.builtin.")) return;
+			
+			CallSite CS { &I };
+			builder->SetInsertPoint(&I);
+			
+			// figure out which one we need
+			Argument* id;
+			if(func_name == "floor.builtin.global_id.i32") {
+				id = global_id;
+			}
+			else if(func_name == "floor.builtin.local_id.i32") {
+				id = local_id;
+			}
+			else if(func_name == "floor.builtin.group_id.i32") {
+				id = group_id;
+			}
+			else if(func_name == "floor.builtin.group_size.i32") {
+				id = group_size;
+			}
+			else if(func_name == "floor.builtin.local_size.i32") {
+				// this doesn't have a direct built-in equivalent, but must be loaded from the WorkgroupSize constant
+				I.replaceAllUsesWith(builder->CreateExtractElement(builder->CreateLoad(workgroup_size), CS.getArgument(0)));
+				I.eraseFromParent();
+				return;
+			}
+			else if(func_name == "floor.builtin.global_size.i32") {
+				// this doesn't have a direct built-in equivalent, but must be computed from the WorkgroupSize constant
+				// TODO/NOTE: this might need some more work on the spir-v side, right now this is always constant folded
+				auto dim_idx = CS.getArgument(0);
+				auto wg_size_dim = builder->CreateExtractElement(builder->CreateLoad(workgroup_size), dim_idx);
+				auto grp_count_dim = builder->CreateExtractElement(builder->CreateLoad(group_size), dim_idx);
+				auto global_size_dim = builder->CreateMul(wg_size_dim, grp_count_dim);
+				I.replaceAllUsesWith(global_size_dim);
+				I.eraseFromParent();
+				return;
+			}
+			else if(func_name == "floor.builtin.work_dim.i32") {
+				if(group_size == nullptr) {
+					DBG(printf("failed to get group_size arg, probably not in a kernel function?\n"); fflush(stdout);)
+					return;
+				}
+				
+				// special case
+				// => group_size.z == 1 ? (group_size.y == 1 ? 1 : 2) : 3
+				const auto loaded_group_size = builder->CreateLoad(group_size);
+				const auto size_z = builder->CreateExtractElement(loaded_group_size, builder->getInt32(2));
+				const auto size_y = builder->CreateExtractElement(loaded_group_size, builder->getInt32(1));
+				const auto cmp_z = builder->CreateICmp(ICmpInst::ICMP_EQ, size_z, builder->getInt32(1));
+				const auto cmp_y = builder->CreateICmp(ICmpInst::ICMP_EQ, size_y, builder->getInt32(1));
+				const auto sel_x_or_y = builder->CreateSelect(cmp_y, builder->getInt32(1), builder->getInt32(2));
+				const auto sel_xy_or_z = builder->CreateSelect(cmp_z, sel_x_or_y, builder->getInt32(3));
+				I.replaceAllUsesWith(sel_xy_or_z);
+				I.eraseFromParent();
+				return;
+			}
+			else if(func_name == "floor.builtin.vertex_id.i32") {
+				if(vertex_id == nullptr) {
+					DBG(printf("failed to get vertex_id arg, probably not in a vertex function?\n"); fflush(stdout);)
+					return;
+				}
+				
+				I.replaceAllUsesWith(builder->CreateLoad(vertex_id, "vertex_index"));
+				I.eraseFromParent();
+				return;
+			}
+			else if(func_name == "floor.builtin.point_coord.float2") {
+				if(point_coord == nullptr) {
+					DBG(printf("failed to get point_coord arg, probably not in a fragment function?\n"); fflush(stdout);)
+					return;
+				}
+				
+				I.replaceAllUsesWith(builder->CreateLoad(point_coord, "point_coord"));
+				I.eraseFromParent();
+				return;
+			}
+			// unknown -> ignore for now
+			else return;
+			
+			if(id == nullptr) {
+				DBG(printf("failed to get id arg, probably not in a kernel function?\n"); fflush(stdout);)
+				return;
+			}
+			
+			// replace call with vector load / elem extraction from the appropriate vector
+			I.replaceAllUsesWith(builder->CreateExtractElement(builder->CreateLoad(id), CS.getArgument(0)));
+			I.eraseFromParent();
+		}
+		
+		// prefer i32 indices so that we don't need the Int64 capability
+		void visitExtractElement(ExtractElementInst& EEI) {
+			const auto idx_op = EEI.getIndexOperand();
+			const auto idx_type = idx_op->getType();
+			if(!idx_type->isIntegerTy(32)) {
+				if(const auto const_idx_op = dyn_cast_or_null<ConstantInt>(idx_op)) {
+					EEI.setOperand(1 /* idx op */, builder->getInt32((int32_t)const_idx_op->getValue().getZExtValue()));
+				}
+				// else: can't do anything, b/c other int type would still be used when casting
+			}
+		}
+		
+		// prefer i32 indices so that we don't need the Int64 capability
+		void visitInsertElement(InsertElementInst& IEI) {
+			const auto idx_op = IEI.llvm::User::getOperand(2);
+			const auto idx_type = idx_op->getType();
+			if(!idx_type->isIntegerTy(32)) {
+				if(const auto const_idx_op = dyn_cast_or_null<ConstantInt>(idx_op)) {
+					IEI.setOperand(2 /* idx op */, builder->getInt32((int32_t)const_idx_op->getValue().getZExtValue()));
+				}
+				// else: can't do anything, b/c other int type would still be used when casting
+			}
+		}
+		
+		void visitGetElementPtrInst(GetElementPtrInst &I) {
+			// prefer i32 indices so that we don't need the Int64 capability
+			for(auto& op : I.operands()) {
+				if(op->getType()->isIntegerTy() &&
+				   !op->getType()->isIntegerTy(32)) {
+					if(const auto const_idx_op = dyn_cast_or_null<ConstantInt>(op)) {
+						op.set(builder->getInt32((int32_t)const_idx_op->getValue().getZExtValue()));
+					}
+					else {
+						builder->SetInsertPoint(&I);
+						op.set(builder->CreateIntCast(op, builder->getInt32Ty(), false));
+					}
+				}
+			}
+			
+			// GEP fusion, i.e. can't have GEPs into GEPs, so merge them together
+			// TODO: loop / recurse
+			if(GetElementPtrInst* GEP = dyn_cast<GetElementPtrInst>(I.getPointerOperand())) {
+				// simple case: only need to swap out the base pointer + modify the first index
+				if(GEP->getNumIndices() == 1) {
+					I.setOperand(0, GEP->getPointerOperand());
+					
+					// is the first index 0?
+					ConstantInt* first_const_idx = dyn_cast<ConstantInt>(I.getOperand(1));
+					if(first_const_idx != nullptr && first_const_idx->getZExtValue() == 0) {
+						// if so, just swap it out with the first index from the other GEP
+						I.setOperand(1, GEP->getOperand(1));
+					}
+					else {
+						// if not, then we need to add both
+						auto added_idx = BinaryOperator::CreateAdd(GEP->getOperand(1), I.getOperand(1), "idxadd", &I);
+						I.setOperand(1, added_idx);
+					}
+				}
+				// else: need to create a new GEP and merge both indices lists
+				else {
+					// TODO: !
+				}
+			}
+		}
+		
+		void visitAllocaInst(AllocaInst &AI) {
+			// TODO: should do this, but can't (no pointers to pointers in vulkan, but also no phi/select of pointers ...)
+		}
+		
+		void visitReturnInst(ReturnInst &RI) {
+			if(!is_vertex_func && !is_fragment_func) return;
+			
+			auto ret_val = RI.getReturnValue();
+			const auto ret_type = ret_val->getType();
+			if(ret_val == nullptr) return;
+			
+			const auto get_output_var = [this](uint32_t& idx) -> GlobalValue* {
+				const auto name = func->getName().str() + ".vulkan_output." + std::to_string(idx++);
+				auto output_var = M->getNamedValue(name);
+				if(output_var == nullptr) {
+					errs() << "output variable \"" << name << "\" doesn't exist\n";
+					return nullptr;
+				}
+				return output_var;
+			};
+			
+			uint32_t ret_idx = 0;
+			if(ret_type->isStructTy()) {
+				// struct -> split up to individual field stores
+				const auto st_type = cast<llvm::StructType>(ret_type);
+				for(uint32_t i = 0; i < st_type->getNumElements(); ++i) {
+					auto output_var = get_output_var(ret_idx);
+					if(output_var == nullptr) return;
+					
+					SmallVector<uint32_t, 1> idx_list { ret_idx - 1 };
+					auto st_extract = ExtractValueInst::Create(ret_val, idx_list, "ret.extract", &RI);
+					new StoreInst(st_extract, output_var, false, &RI);
+				}
+			}
+			else {
+				// else: array, scalars, vectors -> direct store
+				auto output_var = get_output_var(ret_idx);
+				if(output_var == nullptr) return;
+				new StoreInst(ret_val, output_var, false, &RI);
+			}
+			
+			// clear return
+			ReturnInst::Create(*ctx, RI.getParent());
+			RI.eraseFromParent();
+		}
+	};
+	
+	// VulkanFinalModuleCleanup:
+	// * strip unused functions/prototypes/externs
+	struct VulkanFinalModuleCleanup : public ModulePass {
+		static char ID; // Pass identification, replacement for typeid
+		
+		Module* M { nullptr };
+		LLVMContext* ctx { nullptr };
+		
+		VulkanFinalModuleCleanup() : ModulePass(ID) {
+			initializeVulkanFinalModuleCleanupPass(*PassRegistry::getPassRegistry());
+		}
+		
+		bool runOnModule(Module& Mod) override {
+			M = &Mod;
+			ctx = &M->getContext();
+			
+			// kill all functions named floor.builtin.* (we still need other floor.* functions)
+			bool module_modified = false;
+			for(auto func_iter = Mod.begin(); func_iter != Mod.end();) {
+				auto& func = *func_iter;
+				if(func.getName().startswith("floor.builtin.")) {
+					if(func.getNumUses() != 0) {
+						errs() << func.getName() << " should not have an uses at this point!\n";
+					}
+					++func_iter; // inc before erase
+					func.eraseFromParent();
+					module_modified = true;
+					continue;
+				}
+				++func_iter;
+			}
+			return module_modified;
+		}
+		
+	};
+	
+}
+
+char VulkanFinal::ID = 0;
+FunctionPass *llvm::createVulkanFinalPass() {
+	return new VulkanFinal();
+}
+INITIALIZE_PASS_BEGIN(VulkanFinal, "VulkanFinal", "VulkanFinal Pass", false, false)
+INITIALIZE_PASS_DEPENDENCY(AAResultsWrapperPass)
+INITIALIZE_PASS_END(VulkanFinal, "VulkanFinal", "VulkanFinal Pass", false, false)
+
+char VulkanFinalModuleCleanup::ID = 0;
+ModulePass *llvm::createVulkanFinalModuleCleanupPass() {
+	return new VulkanFinalModuleCleanup();
+}
+INITIALIZE_PASS_BEGIN(VulkanFinalModuleCleanup, "VulkanFinal module cleanup", "VulkanFinal module cleanup Pass", false, false)
+INITIALIZE_PASS_END(VulkanFinalModuleCleanup, "VulkanFinal module cleanup", "VulkanFinal module cleanup Pass", false, false)
diff --git a/tools/CMakeLists.txt b/tools/CMakeLists.txt
index b654b8c..56c4ad3 100644
--- a/tools/CMakeLists.txt
+++ b/tools/CMakeLists.txt
@@ -39,6 +39,7 @@ add_llvm_tool_subdirectory(llvm-ar)
 add_llvm_tool_subdirectory(llvm-config)
 add_llvm_tool_subdirectory(llvm-lto)
 add_llvm_tool_subdirectory(llvm-profdata)
+add_llvm_tool_subdirectory(llvm-spirv)
 
 # Projects supported via LLVM_EXTERNAL_*_SOURCE_DIR need to be explicitly
 # specified.
diff --git a/tools/LLVMBuild.txt b/tools/LLVMBuild.txt
index d4b0147..32bc9a7 100644
--- a/tools/LLVMBuild.txt
+++ b/tools/LLVMBuild.txt
@@ -41,6 +41,7 @@ subdirectories =
  llvm-profdata
  llvm-rtdyld
  llvm-size
+ llvm-spirv
  llvm-split
  opt
  verify-uselistorder
diff --git a/tools/llvm-spirv/CMakeLists.txt b/tools/llvm-spirv/CMakeLists.txt
new file mode 100644
index 0000000..88e3178
--- /dev/null
+++ b/tools/llvm-spirv/CMakeLists.txt
@@ -0,0 +1,14 @@
+set(LLVM_LINK_COMPONENTS
+  Analysis
+  BitReader
+  BitWriter
+  IPO
+  SPIRVLib
+  Core
+  Support
+  TransformUtils
+  )
+
+add_llvm_tool(llvm-spirv
+  llvm-spirv.cpp
+  )
diff --git a/tools/llvm-spirv/LLVMBuild.txt b/tools/llvm-spirv/LLVMBuild.txt
new file mode 100644
index 0000000..4accaea
--- /dev/null
+++ b/tools/llvm-spirv/LLVMBuild.txt
@@ -0,0 +1,22 @@
+;===- ./tools/llvm-bil/LLVMBuild.txt ----------------------------*- Conf -*--===;
+;
+;                     The LLVM Compiler Infrastructure
+;
+; This file is distributed under the University of Illinois Open Source
+; License. See LICENSE.TXT for details.
+;
+;===------------------------------------------------------------------------===;
+;
+; This is an LLVMBuild description file for the components in this subdirectory.
+;
+; For more information on the LLVMBuild system, please see:
+;
+;   http://llvm.org/docs/LLVMBuild.html
+;
+;===------------------------------------------------------------------------===;
+
+[component_0]
+type = Tool
+name = llvm-spirv
+parent = Tools
+required_libraries = Analysis BitReader BitWriter SPIRVLib IPO
diff --git a/tools/llvm-spirv/Makefile b/tools/llvm-spirv/Makefile
new file mode 100644
index 0000000..9d4edc3
--- /dev/null
+++ b/tools/llvm-spirv/Makefile
@@ -0,0 +1,17 @@
+##===- tools/llvm-as/Makefile ------------------------------*- Makefile -*-===##
+# 
+#                     The LLVM Compiler Infrastructure
+#
+# This file is distributed under the University of Illinois Open Source
+# License. See LICENSE.TXT for details.
+# 
+##===----------------------------------------------------------------------===##
+
+LEVEL := ../..
+TOOLNAME := llvm-spirv
+LINK_COMPONENTS := analysis bitwriter bitreader spirvlib
+
+# This tool has no plugins, optimize startup time.
+TOOL_NO_EXPORTS := 1
+
+include $(LEVEL)/Makefile.common
diff --git a/tools/llvm-spirv/llvm-spirv.cpp b/tools/llvm-spirv/llvm-spirv.cpp
new file mode 100644
index 0000000..4ffe7df
--- /dev/null
+++ b/tools/llvm-spirv/llvm-spirv.cpp
@@ -0,0 +1,325 @@
+//===-- llvm-spirv.cpp - The LLVM/SPIR-V translator utility -----*- C++ -*-===//
+//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the "Software"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+/// \file
+///
+///  Common Usage:
+///  llvm-spirv          - Read LLVM bitcode from stdin, write SPIRV to stdout
+///  llvm-spirv x.bc     - Read LLVM bitcode from the x.bc file, write SPIR-V
+///                        to x.bil file
+///  llvm-spirv -r       - Read SPIRV from stdin, write LLVM bitcode to stdout
+///  llvm-spirv -r x.bil - Read SPIRV from the x.bil file, write SPIR-V to
+///                        the x.bc file
+///
+///  Options:
+///      --help   - Output command line options
+///
+//===----------------------------------------------------------------------===//
+
+#include "llvm/Bitcode/ReaderWriter.h"
+#include "llvm/IR/LLVMContext.h"
+#include "llvm/IR/Module.h"
+#include "llvm/IR/Verifier.h"
+#include "llvm/Support/CommandLine.h"
+#include "llvm/Support/DataStream.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/FileSystem.h"
+#include "llvm/Support/PrettyStackTrace.h"
+#include "llvm/Support/raw_ostream.h"
+#include "llvm/Support/Signals.h"
+#include "llvm/Support/ToolOutputFile.h"
+
+#ifndef _SPIRV_SUPPORT_TEXT_FMT
+#define _SPIRV_SUPPORT_TEXT_FMT
+#endif
+
+#include "llvm/Support/SPIRV.h"
+
+#include <memory>
+#include <fstream>
+#include <iostream>
+
+#define DEBUG_TYPE "spirv"
+
+namespace kExt {
+  const char SpirvBinary[] = ".spv";
+  const char SpirvText[] = ".spt";
+  const char LLVMBinary[] = ".bc";
+}
+
+using namespace llvm;
+
+static cl::opt<std::string>
+InputFile(cl::Positional, cl::desc("<input file>"), cl::init("-"));
+
+static cl::opt<std::string>
+OutputFile("o", cl::desc("Override output filename"),
+               cl::value_desc("filename"));
+
+static cl::opt<bool>
+IsReverse("r", cl::desc("Reverse translation (SPIR-V to LLVM)"));
+
+static cl::opt<bool>
+IsRegularization("s", cl::desc(
+    "Regularize LLVM to be representable by SPIR-V"));
+
+#ifdef _SPIRV_SUPPORT_TEXT_FMT
+namespace SPIRV {
+// Use textual format for SPIRV.
+extern bool SPIRVUseTextFormat;
+}
+
+static cl::opt<bool>
+ToText("to-text", cl::desc("Convert input SPIR-V binary to internal textual format"));
+
+static cl::opt<bool>
+ToBinary("to-binary",
+    cl::desc("Convert input SPIR-V in internal textual format to binary"));
+#endif
+
+static std::string
+removeExt(const std::string& FileName) {
+  size_t Pos = FileName.find_last_of(".");
+  if (Pos != std::string::npos)
+    return FileName.substr(0, Pos);
+  return FileName;
+}
+
+static int
+convertLLVMToSPIRV() {
+  LLVMContext Context;
+
+  std::string Err;
+  auto DS = getDataFileStreamer(InputFile, &Err);
+  if (!DS) {
+    errs() << "Fails to open input file: " << Err;
+    return -1;
+  }
+
+  ErrorOr<std::unique_ptr<Module>> MOrErr =
+      getStreamedBitcodeModule(InputFile, std::move(DS), Context);
+
+  if (std::error_code EC = MOrErr.getError()) {
+    errs() << "Fails to load bitcode: " << EC.message();
+    return -1;
+  }
+
+  std::unique_ptr<Module> M = std::move(*MOrErr);
+
+  if (std::error_code EC = M->materializeAll()){
+    errs() << "Fails to materialize: " << EC.message();
+    return -1;
+  }
+
+  if (OutputFile.empty()) {
+    if (InputFile == "-")
+      OutputFile = "-";
+    else
+      OutputFile = removeExt(InputFile) +
+                   (SPIRV::SPIRVUseTextFormat ? kExt::SpirvText : kExt::SpirvBinary);
+  }
+
+  llvm::StringRef outFile(OutputFile);
+  std::error_code EC;
+  llvm::raw_fd_ostream OFS(outFile, EC, llvm::sys::fs::F_None);
+  if (!WriteSPIRV(M.get(), OFS, Err)) {
+    errs() << "Fails to save LLVM as SPIRV: " << Err << '\n';
+    return -1;
+  }
+  return 0;
+}
+
+static int
+convertSPIRVToLLVM() {
+  LLVMContext Context;
+  std::ifstream IFS(InputFile, std::ios::binary);
+  Module *M;
+  std::string Err;
+
+  if (!ReadSPIRV(Context, IFS, M, Err)) {
+    errs() << "Fails to load SPIRV as LLVM Module: " << Err << '\n';
+    return -1;
+  }
+
+  DEBUG(dbgs() << "Converted LLVM module:\n" << *M);
+
+
+  raw_string_ostream ErrorOS(Err);
+  if (verifyModule(*M, &ErrorOS)){
+    errs() << "Fails to verify module: " << ErrorOS.str();
+    return -1;
+  }
+
+  if (OutputFile.empty()) {
+    if (InputFile == "-")
+      OutputFile = "-";
+    else
+      OutputFile = removeExt(InputFile) + kExt::LLVMBinary;
+  }
+
+  std::error_code EC;
+  tool_output_file Out(OutputFile.c_str(), EC, sys::fs::F_None);
+  if (EC) {
+    errs() << "Fails to open output file: " << EC.message();
+    return -1;
+  }
+
+  WriteBitcodeToFile(M, Out.os());
+  Out.keep();
+  delete M;
+  return 0;
+}
+
+#ifdef _SPIRV_SUPPORT_TEXT_FMT
+static int
+convertSPIRV() {
+  if (ToBinary == ToText) {
+    errs() << "Invalid arguments\n";
+    return -1;
+  }
+  std::ifstream IFS(InputFile, std::ios::binary);
+
+  if (OutputFile.empty()) {
+    if (InputFile == "-")
+      OutputFile = "-";
+    else {
+      OutputFile = removeExt(InputFile)
+                 + (ToBinary?kExt::SpirvBinary:kExt::SpirvText);
+    }
+  }
+
+  auto Action = [&](llvm::raw_ostream &OFS) {
+    std::string Err;
+      if (!SPIRV::ConvertSPIRV(IFS, OFS, Err, ToBinary, ToText)) {
+      errs() << "Fails to convert SPIR-V : " << Err << '\n';
+      return -1;
+    }
+    return 0;
+  };
+  if (OutputFile != "-") {
+    std::error_code EC;
+    llvm::raw_fd_ostream OFS(llvm::StringRef(OutputFile), EC, llvm::sys::fs::F_None);
+    return Action(OFS);
+  } else
+    return Action(outs());
+}
+#endif
+
+static int
+regularizeLLVM() {
+  LLVMContext Context;
+
+  std::string Err;
+  auto DS = getDataFileStreamer(InputFile, &Err);
+  if (!DS) {
+    errs() << "Fails to open input file: " << Err;
+    return -1;
+  }
+
+  ErrorOr<std::unique_ptr<Module>> MOrErr =
+      getStreamedBitcodeModule(InputFile, std::move(DS), Context);
+
+  if (std::error_code EC = MOrErr.getError()) {
+    errs() << "Fails to load bitcode: " << EC.message();
+    return -1;
+  }
+
+  std::unique_ptr<Module> M = std::move(*MOrErr);
+
+  if (std::error_code EC = M->materializeAll()){
+    errs() << "Fails to materialize: " << EC.message();
+    return -1;
+  }
+
+  if (OutputFile.empty()) {
+    if (InputFile == "-")
+      OutputFile = "-";
+    else
+      OutputFile = removeExt(InputFile) + ".regularized.bc";
+  }
+
+  if (!RegularizeLLVMForSPIRV(M.get(), Err)) {
+    errs() << "Fails to save LLVM as SPIRV: " << Err << '\n';
+    return -1;
+  }
+
+  std::error_code EC;
+  tool_output_file Out(OutputFile.c_str(), EC, sys::fs::F_None);
+  if (EC) {
+    errs() << "Fails to open output file: " << EC.message();
+    return -1;
+  }
+
+  WriteBitcodeToFile(M.get(), Out.os());
+  Out.keep();
+  return 0;
+}
+
+
+int
+main(int ac, char** av) {
+  EnablePrettyStackTrace();
+  sys::PrintStackTraceOnErrorSignal(av[0]);
+  PrettyStackTraceProgram X(ac, av);
+
+  cl::ParseCommandLineOptions(ac, av, "LLVM/SPIR-V translator");
+
+#ifdef _SPIRV_SUPPORT_TEXT_FMT
+  if (ToText && (ToBinary || IsReverse || IsRegularization)) {
+    errs() << "Cannot use -to-text with -to-binary, -r, -s\n";
+    return -1;
+  }
+
+  if (ToBinary && (ToText || IsReverse || IsRegularization)) {
+    errs() << "Cannot use -to-binary with -to-text, -r, -s\n";
+    return -1;
+  }
+
+  if (ToBinary || ToText)
+    return convertSPIRV();
+#endif
+
+  if (!IsReverse && !IsRegularization)
+    return convertLLVMToSPIRV();
+
+  if (IsReverse && IsRegularization) {
+    errs() << "Cannot have both -r and -s options\n";
+    return -1;
+  }
+  if (IsReverse)
+    return convertSPIRVToLLVM();
+
+  if (IsRegularization)
+    return regularizeLLVM();
+
+  return 0;
+}
diff --git a/tools/spirv-tool/gen_spirv.bash b/tools/spirv-tool/gen_spirv.bash
new file mode 100644
index 0000000..e948ba8
--- /dev/null
+++ b/tools/spirv-tool/gen_spirv.bash
@@ -0,0 +1,206 @@
+#!/usr/bin/bash
+# script to generate code for LLVM/SPIR-V translator based on khronos 
+# header file spirv.hpp.
+#
+
+
+######################
+#
+# generate NameMap
+#
+######################
+
+genNameMap() {
+prefix=$1
+echo "template<> inline void
+SPIRVMap<$prefix, std::string>::init() {"
+
+cat $spirvHeader | sed -n -e "/^ *${prefix}[^a-z]/s:^ *${prefix}\([^= ][^= ]*\)[= ][= ]*\([0x]*[0-9][0-9]*\).*:\1 \2:p"  | while read a b; do
+  printf "  add(${prefix}%s, \"%s\");\n" $a $a
+done
+
+echo "}
+SPIRV_DEF_NAMEMAP($prefix, SPIRV${prefix}NameMap)
+"
+
+}
+
+###########################
+#
+# generate isValid function
+#
+###########################
+genIsValid() {
+prefix=$1
+echo "inline bool
+isValid(spv::$prefix V) {
+  switch(V) {"
+
+  cat $spirvHeader | sed -n -e "/^ *${prefix}[^a-z]/s:^ *${prefix}\([^= ][^= ]*\)[= ][= ]*\(.*\).*:\1 \2:p"  | while read a b; do
+  if [[ $a == CapabilityNone ]]; then
+    continue
+  fi
+  printf "    case ${prefix}%s:\n" $a
+done
+
+echo "      return true;
+    default:
+      return false;
+  }
+}
+"
+}
+genMaskIsValid() {
+prefix=$1
+subprefix=`echo $prefix | sed -e "s:Mask::g"`
+echo "inline bool
+isValid$prefix(SPIRVWord Mask) {
+  SPIRVWord ValidMask = 0u;"
+
+  cat $spirvHeader | sed -n -e "/^ *${subprefix}[^a-z]/s:^ *${subprefix}\([^= ][^= ]*\)Mask[= ][= ]*\(.*\).*:\1 \2:p"  | while read a b; do
+  if [[ $a == None ]]; then
+    continue
+  fi
+  printf "  ValidMask |= ${subprefix}%sMask;\n" $a
+done
+
+echo "
+  return (Mask & ~ValidMask) == 0;
+}
+"
+}
+
+##############################
+#
+# generate entries for td file
+#
+##############################
+genTd() {
+prefix=$1
+
+if [[ $prefix == "Capability" ]]; then
+  echo "class SPIRV${prefix}_ {"
+else
+  echo "def SPIRV${prefix} : Operand<i32> {
+  let PrintMethod = \"printSPIRV${prefix}\";
+"
+fi
+
+cat $spirvHeader | sed -n -e "/^ *${prefix}[^a-z]/s:^ *${prefix}\([^= ][^= ]*\)[= ][= ]*\([0xX]*[0-9a-fA-F][0-9a-fA-F]*\).*:\1 \2:p"  | while read a b; do
+  if [[ $a == CapabilityNone ]]; then
+    continue
+  fi
+  printf "  int %s = %s;\n" $a $b
+done
+
+if [[ $prefix == "Capability" ]]; then
+  echo "}
+def SPIRV${prefix} : SPIRV${prefix}_;
+"
+else 
+  echo "}
+"
+fi
+}
+
+gen() {
+type=$1
+for prefix in SourceLanguage ExecutionModel AddressingModel MemoryModel ExecutionMode StorageClass Dim SamplerAddressingMode SamplerFilterMode ImageFormat \
+  ImageChannelOrder ImageChannelDataType FPRoundingMode LinkageType AccessQualifier FunctionParameterAttribute Decoration BuiltIn Scope GroupOperation \
+  KernelEnqueueFlags Capability Op; do
+  if [[ "$type" == NameMap ]]; then
+    genNameMap $prefix
+  elif [[ "$type" == isValid ]]; then
+    genIsValid $prefix
+  elif [[ "$type" == td ]]; then
+    genTd $prefix
+  else
+    echo "invalid type \"$type\"."
+    exit
+  fi
+done
+for prefix in ImageOperandsMask FPFastMathModeMask SelectionControlMask LoopControlMask FunctionControlMask MemorySemanticsMask MemoryAccessMask \
+  KernelProfilingInfoMask; do
+  if [[ "$type" == isValid ]]; then
+    genMaskIsValid $prefix
+  fi
+done
+}
+
+####################
+#
+# main
+#
+####################
+
+if [[ $# -ne 3 ]]; then
+  echo "usage: gen_spirv path_to_spirv.hpp [NameMap|isValid|td] output_file"
+  exit
+fi
+
+spirvHeader=$1
+type=$2
+outputFile=$3
+includeGuard="`echo ${outputFile} | tr '[:lower:]' '[:upper:]' | sed -e 's/\./_/g'`_"
+
+echo "//===- ${outputFile} - SPIR-V ${type} enums ----------------*- C++ -*-===//
+//
+//                     The LLVM/SPIRV Translator
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+// Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a
+// copy of this software and associated documentation files (the \"Software\"),
+// to deal with the Software without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Software, and to permit persons to whom the
+// Software is furnished to do so, subject to the following conditions:
+//
+// Redistributions of source code must retain the above copyright notice,
+// this list of conditions and the following disclaimers.
+// Redistributions in binary form must reproduce the above copyright notice,
+// this list of conditions and the following disclaimers in the documentation
+// and/or other materials provided with the distribution.
+// Neither the names of Advanced Micro Devices, Inc., nor the names of its
+// contributors may be used to endorse or promote products derived from this
+// Software without specific prior written permission.
+// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH
+// THE SOFTWARE.
+//
+//===----------------------------------------------------------------------===//
+/// \\file
+///
+/// This file defines SPIR-V ${type} enums.
+///
+//===----------------------------------------------------------------------===//
+// WARNING:
+//
+// This file has been generated using \`tools/spirv-tool/gen_spirv.bash\` and
+// should not be modified manually. If the file needs to be updated, edit the
+// script and any other source file instead, before re-generating this file.
+//===----------------------------------------------------------------------===//
+
+#ifndef ${includeGuard}
+#define ${includeGuard}
+
+#include \"spirv.hpp\"
+#include \"SPIRVEnum.h\"
+
+using namespace spv;
+
+namespace SPIRV {
+" > ${outputFile}
+
+gen $type >> ${outputFile}
+
+echo "} /* namespace SPIRV */
+
+#endif /* ${includeGuard} */" >> ${outputFile}
